<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.0.2","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="今日事，今日毕">
<meta property="og:type" content="website">
<meta property="og:title" content="SoundMemories">
<meta property="og:url" content="https://soundmemories.github.io/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="今日事，今日毕">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="SoundMemories">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://soundmemories.github.io/">


<script data-pjax class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>SoundMemories</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SoundMemories</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-归档">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
	   
		  
      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">118</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">
      

      
    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/23/NLP/08.%E8%92%B8%E9%A6%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/23/NLP/08.%E8%92%B8%E9%A6%8F/" class="post-title-link" itemprop="url">蒸馏</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-23 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-23T00:00:00+08:00">2021-07-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="模型压缩"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩</h1><p><strong>1、为什么需要模型压缩？</strong><br>理论上来说，深度神经网络模型越深，非线性程度也就越大，相应的对现实问题的表达能力越强，但相应的代价是，训练成本和模型大小的增加。同时，在部署时，大模型预测速度较低且需要更好的硬件支持。但随着深度学习越来越多的参与到产业中，很多情况下，需要将模型在手机端、IoT端部署，这种部署环境受到能耗和设备体积的限制，端侧硬件的计算能力和存储能力相对较弱，突出的诉求主要体现在以下三点：</p>
<ul>
<li>首先是<strong>速度</strong>，比如像人脸闸机、人脸解锁手机等应用，对响应速度比较敏感，需要做到实时响应。</li>
<li>其次是<strong>存储</strong>，比如电网周边环境监测这个应用场景中，要图像目标检测模型部署在可用内存只有200M的监控设备上，且当监控程序运行后，剩余内存会小于30M。</li>
<li>最后是<strong>耗能</strong>，离线翻译这种移动设备内置AI模型的能耗直接决定了它的续航能力。</li>
</ul>
<p>以上三点诉求都需要我们根据终端环境对现有模型进行小型化处理，在不损失精度的情况下，让模型的体积更小、速度更快，能耗更低。</p>
<p>但如何能产出小模型呢？常见的方式包括设计更高效的网络结构、将模型的参数量变少、将模型的计算量减少，同时提高模型的精度。 可能有人会提出疑问，为什么不直接设计一个小模型？ 要知道，实际业务子垂类众多，任务复杂度不同，在这种情况下，人工设计有效小模型难度非常大，需要非常强的领域知识。而模型压缩可以在经典小模型的基础上，稍作处理就可以快速拔高模型的各项性能，达到“多快好省”的目的。</p>
<p><strong>2、模型压缩的基本方法</strong></p>
<ul>
<li><strong>剪裁</strong>：类似“化学结构式的减肥”，将模型结构中对预测结果不重要的网络结构剪裁掉，使网络结构变得更加 ”瘦身“。比如，在每层网络，有些神经元节点的权重非常小，对模型加载信息的影响微乎其微。如果将这些权重较小的神经元删除，则既能保证模型精度不受大影响，又能减小模型大小。</li>
<li><strong>量化</strong>：类似“量子级别的减肥”，神经网络模型的参数一般都用float32的数据表示，但如果我们将float32的数据计算精度变成int8的计算精度，则可以牺牲一点模型精度来换取更快的计算速度。</li>
<li><strong>蒸馏</strong>：类似“老师教学生”，使用一个效果好的大模型指导一个小模型训练，因为大模型可以提供更多的软分类信息量，所以会训练出一个效果接近大模型的小模型。</li>
<li><strong>神经网络架构搜索</strong>（NAS）：类似“化学结构式的重构”，以模型大小和推理速度为约束进行模型结构搜索，从而获得更高效的网络结构。</li>
</ul>
<p>除此以外，还有权重共享、低秩分解等技术也可实现模型压缩。</p>
<h1 id="模型蒸馏原理"><a href="#模型蒸馏原理" class="headerlink" title="模型蒸馏原理"></a>模型蒸馏原理</h1><p>Hinton提出了知识蒸馏（Knowledge Distillation）的概念，旨在把一个大模型或者多个模型ensemble学到的知识迁移到另一个轻量级单模型上，方便部署。简单的说就是用小模型去学习大模型的预测结果，而不是直接学习训练集中的label。</p>
<p>在蒸馏的过程中，我们将原始大模型称为教师模型（teacher），新的小模型称为学生模型（student），训练集中的标签称为hard label，教师模型预测的概率输出为soft label，temperature(T)是用来调整soft label的超参数。</p>
<p>蒸馏这个概念之所以work，核心思想是<strong>好模型的目标不是拟合训练数据，而是学习如何泛化到新的数据</strong>。所以蒸馏的目标是让学生模型学习到教师模型的泛化能力，理论上得到的结果会比单纯拟合训练数据的学生模型要好。</p>
<h1 id="如何蒸馏"><a href="#如何蒸馏" class="headerlink" title="如何蒸馏"></a>如何蒸馏</h1><p>蒸馏发展到今天，有各种各样的花式方法，我们先从最基本的说起。</p>
<p>之前提到学生模型需要通过教师模型的输出学习泛化能力，那对于简单的二分类任务来说，直接拿教师预测的0/1结果会与训练集差不多，没什么意义，那拿概率值是不是好一些？于是Hinton采用了教师模型的输出概率 $q$ （又称 soft target），同时为了更好地控制输出概率的平滑程度，给教师模型的softmax中加了一个参数T:</p>
<script type="math/tex; mode=display">q_i=\dfrac{exp(z_i/T)}{\sum_j exp(z_i/T)}</script><p>同时，拟合真实标签 $y$ （hard label），于是我们有了新的loss（又称 hard target）：</p>
<script type="math/tex; mode=display">L=(1-\alpha)CE(y,p)+\alpha CE(q,p)\cdot T^2</script><p>新loss包括两部分：学生模型与真实标签之间的交叉熵$CE(y,p)$；教师模型与学生模型的输出之间的交叉熵$CE(q,p)$。其中 $CE$ 是交叉熵（Cross-Entropy），$y$ 是真实label，$p$ 是学生模型的预测结果，$\alpha$ 是蒸馏loss的权重。<br>这里要注意的是，因为学生模型要拟合教师模型的分布，所以在求 $p$ 时的也要使用一样的参数 $T$ （在训练结束以后使用正常温度 T=1 进行预测）。另外，因为在求梯度时新的目标函数会导致梯度是以前的 $1/T^2$，所以要再乘上 $T^2$，不然 $T$ 变了的话，但soft label会变小，hard label不变（T=1）。</p>
<h1 id="BERT蒸馏"><a href="#BERT蒸馏" class="headerlink" title="BERT蒸馏"></a>BERT蒸馏</h1><p>在BERT提出后，如何瘦身就成了一个重要分支。主流的方法主要有剪枝、蒸馏和量化。量化的提升有限，因此免不了采用<strong>剪枝+蒸馏</strong>的融合方法来获取更好的效果。<br>接下来将介绍BERT蒸馏的主要发展脉络，从各个研究看来，蒸馏的提升一方面来源于从<strong>精调阶段蒸馏-&gt;预训练阶段蒸馏</strong>，另一方面则来源于<strong>蒸馏最后一层知识-&gt;蒸馏隐层知识-&gt;蒸馏注意力矩阵</strong>。</p>
<h2 id="Distilled-BiLSTM"><a href="#Distilled-BiLSTM" class="headerlink" title="Distilled BiLSTM"></a>Distilled BiLSTM</h2><p>Distilled BiLSTM于2019年5月提出，作者将BERT-large蒸馏到了单层的BiLSTM中，参数量减少了100倍，速度提升了15倍，效果虽然比BERT差不少，但可以和ELMo打成平手。<br><img src="/images/蒸馏/1.png" width="80%"></p>
<p>Distilled BiLSTM的教师模型采用精调过的BERT-large，学生模型采用BiLSTM+ReLU，蒸馏的目标是<strong>hard labe的交叉熵+logits之间的MSE</strong>（作者经过实验发现MSE比上文的 $CE(p,q)$ 更好）。<br>Distilled BiLSTM 一文采用的目标函数为：<br><img src="/images/蒸馏/2.png" width="40%"></p>
<p>面对数据集小的问题，作者随机使用以下方式进行数据增强（使用教师模型在无监督语料上进行标记），来获得更多的无监督语料：</p>
<ul>
<li>随机的mask掩码</li>
<li>将随机词替换为相同POS属性的词</li>
<li>随机截取n-gram作为样本</li>
</ul>
<p>实验结果，蒸馏比得上ELMO了：<br><img src="/images/蒸馏/3.png" width="80%"></p>
<p>参数与运行速度对比：<br><img src="/images/蒸馏/4.png" width="40%"></p>
<h2 id="BERT-PKD-EMNLP2019"><a href="#BERT-PKD-EMNLP2019" class="headerlink" title="BERT-PKD (EMNLP2019)"></a>BERT-PKD (EMNLP2019)</h2><p>将原始大模型压缩为同等有效的轻量级浅层网络。同时，作者对以往的知识蒸馏方法进行了调研，如下图所示，vanilla KD在QNLI和MNLI的训练集上可以很快的达到和teacher model相媲美的性能，但在测试集上则很快达到饱和。对此，作者提出一种假设，在知识蒸馏的过程中过拟合会导致泛化能力不良。为缓解这个问题，论文中提出一种“耐心”师生机制，即<strong>让Patient-KD中的学生模型从教师网络的多个中间层进行知识提取</strong>，而不是只从教师网络的最后一层输出中学习，避免在蒸馏最后一层时拟合过快的现象（有过拟合的风险）。<br><img src="/images/蒸馏/5.png" width="90%"></p>
<p><strong>模型实现</strong><br>Patient-KD中提出如下两个知识蒸馏策略：</p>
<ul>
<li><strong>PKD-Skip</strong>: 从每k层学习，这种策略是假设网络的底层包含重要信息，需要被学习到（如下图(a):PKD-Skip 学生网络学习教师网络每两层的输出）。</li>
<li><strong>PKD-last</strong>: 从最后k层学习，假设教师网络越靠后的层包含越丰富的知识信息（如下图(b):PKD-Last 学生网络从教师网络的最后六层学习）。<br><img src="/images/蒸馏/6.png" width="70%"></li>
</ul>
<p>因为在BERT中仅使用最后一层的[CLS] token的输出来进行预测，且在其他BERT的变体模型中，如SDNet，是通过对每一层的[CLS] embedding的加权平均值进行处理并预测。由此可以推断，如果学生模型可以从任何教师网络中间层中的[CLS]表示中学习，那么它就有可能获得类似教师网络的泛化能力。因此，Patient-KD中提出特殊的一种损失函数的计算方式：</p>
<p>BERT-PKD 加入了对中间层 [CLS] 位置上隐状态的拟合，使用教师与学生模型 [CLS] 隐状态之间的 MSE 作为额外的损失。<br><img src="/images/蒸馏/7.png" width="40%"></p>
<p>其中，对于输入 $x_i$，所有层[CLS]的输出表示为：<br><img src="/images/蒸馏/8.png" width="40%"></p>
<p>$I_{pt}$ 表示表示要从中提取知识的一组中间层，以从 BERT_12 压缩到 BERT_6 为例：</p>
<ul>
<li>对于PKD-Skip策略，$I_{pt}=2,4,6,8,10$；</li>
<li>对于PKD-Last策略，$I_{pt}=7,8,9,10,11$。</li>
</ul>
<p>M表示学生网络的层数，N是训练样本的数量，上标 s 和 t 分别代表学生网络和教师网络。最终实验显示PKD-skip要略好一点点（&lt;0.01）</p>
<p>同时，Patient-KD中也使用了 $L_{DS}$ 和 $L_{CE}^S$ 两种损失函数用来衡量教师和学生网络的预测值的距离和学生网络在特定下游任务上的交叉熵损失。<br><img src="/images/蒸馏/9.png" width="50%"></p>
<p>最终的目标损失函数可以表示为：<br><img src="/images/蒸馏/10.png" width="40%"></p>
<p><strong>实验结果</strong><br><img src="/images/蒸馏/11.png" width="80%"><br>作者将模型预测提交到GLUE并获得了在测试集上的结果，如上图所示。与fine-tuning和vanilla KD这两种方法相比，使用PKD训练的BERT_3和BERT_6在除MRPC外的几乎所有任务上都表现良好。其中，PKD代表Patient-KD-Skip方法。对于MNLI-m和MNLI-mm，六层模型比微调（FT）基线提高了1.1%和1.3%，</p>
<p>我们将模型预测提交给官方 GLUE 评估服务器以获得测试数据的结果。 与直接微调和普通 KD 相比，我们使用 BERT3 和 BERT6 学生的 Patient-KD 模型在除 MRPC 之外的几乎所有任务上都表现最好。 此外，6层的BERT6−PKD在7个任务中有5个都达到了和BERT-Base相似的性能，其中，SST-2（与 BERT-Base 教师相比为-2.3%）、QQP（-0.1%）、MNLI-m（-2.2%）、MNLI-mm（-1.8%）和 QNLI (-1.4%))，这五个任务都有超过6万个训练样本，这表明了PKD在大数据集上的表现往往更好。</p>
<p>PKD-Last 和 PKD-Skip 在GLUE基准上的对比：<br><img src="/images/蒸馏/12.png" width="80%"><br>尽管这两种策略都比vanilla KD有所改进，但PKD-Skip的表现略好于PKD-Last。作者推测，这可能是由于每k层的信息提炼捕获了从低级到高级的语义，具备更丰富的内容和更多不同的表示，而只关注最后k层往往会捕获相对同质的语义信息。</p>
<p>参数量和推理时间对比：<br><img src="/images/蒸馏/13.png" width="80%"><br>上表展示了BERT3、BERT6、BERT12的推理时间即参数量, 实验表明Patient-KD方法实现了几乎线性的加速，BERT6和BERT3分别提速1.94倍和3.73倍。</p>
<h2 id="DistillBERT-NIPS2019）"><a href="#DistillBERT-NIPS2019）" class="headerlink" title="DistillBERT (NIPS2019）"></a>DistillBERT (NIPS2019）</h2><p>之前的工作都是对精调后的BERT进行蒸馏，学生模型学到的都是任务相关的知识。HuggingFace则提出了DistillBERT，<strong>在预训练阶段进行蒸馏</strong>。将尺寸减小了40%，速度提升60%，效果好于BERT-PKD，为教师模型的97%。即，<strong>DistillBERT的教师模型采用了预训练好的BERT-base，学生模型则是6层transformer（层数消减了一半，12层的bert蒸馏成了6层），移除了 token-type embeddings 和 pooler，采用了PKD-skip的方式进行初始化（从教师网络中每两层抽取一层来进行初始化）</strong>。</p>
<p>和之前蒸馏目标不同的是，为了调整教师和学生的隐层向量方向，作者新增了一个cosine embedding loss，蒸馏最后一层hidden的。最终损失函数由以下三部分组成：</p>
<ul>
<li>$L_{ce}$，这是teacher网络softmax层输出的概率分布和student网络softmax层输出的概率分布的交叉熵（注：MLM任务的输出）。</li>
<li>$L_{mlm}$，这是student网络softmax层输出的概率分布和真实的one-hot标签的交叉熵。也就是student模型做预训练的mlm损失。</li>
<li>$L_{cos}$，这是student网络最后一隐层输出和teacher网络最后一隐层输出的余弦相似度值。</li>
</ul>
<p>其中，$L_{ce}$训练学生模仿教师模型的输出分布：</p>
<script type="math/tex; mode=display">L_{ce}=\sum\limits_i t_i * log(s_i)</script><p>$t_i$和$s_i$分别是教师网络和学生网络的预测概率。</p>
<p>同时使用了Hinton在2015年提出的softmax-temperature：</p>
<script type="math/tex; mode=display">p_i=\dfrac{exp(z_i/T)}{\sum_j exp(z_i/T)}</script><p>其中，$T$控制输出分布的平滑度，$T=1$时代表传统的softmax，$T<1$时分布逐渐极端化，最终等价于argmax，$T>1$分布逐渐趋于均匀分布。当$T$变大时，类别之间的差距变小(平滑)，从而导致loss变小；当$T$变小时类别间的差距变大(陡峭)，从而导致loss变小。</p>
<p>$z_i$代表分类$i$的模型分数。在训练时对学生网络和教师网络使用同样的temperature $T$，在推理时，设置$T=1$恢复为标准的softmax最终的loss函数为$L_{ce}$、Mask language model loss $L_{mlm}$（参考BERT）和 cosine embedding loss $L_{cos}$（student和teacher隐藏状态向量的cos计算）的线性组合。</p>
<p>从消融实验可以看出，MLM loss对于学生模型的表现影响较小，同时初始化也是影响效果的重要因素：<br><img src="/images/蒸馏/14.png" width="80%"></p>
<p>预训练蒸馏时使用与BERT预训练相同的语料。在8个V100（16GB）上耗时90小时。</p>
<p>最终DistilBERT与BERT相比减少了40%的参数，同时保留了BERT 97%的性能，但提高了60%的速度。<br><img src="/images/蒸馏/15.png" width="80%"></p>
<h2 id="TinyBERT（EMNLP2019）"><a href="#TinyBERT（EMNLP2019）" class="headerlink" title="TinyBERT（EMNLP2019）"></a>TinyBERT（EMNLP2019）</h2><p>TinyBERT是由华中科技大学和华为诺亚方舟实验室联合提出的一种针对transformer-based模型的知识蒸馏方法，以BERT为例对大型预训练模型进行研究。它的核心思想：<strong>预训练</strong>阶段和<strong>fine-tuning</strong>阶段都分别被蒸馏过了，理论上<strong>两步联合</strong>起来的效果可能会更好。</p>
<p>TinyBERT就提出了two-stage learning框架，分别在<strong>预训练</strong>和<strong>精调</strong>阶段蒸馏教师模型：<br>第一个阶段，利用预训练 BERT 蒸馏出一个 General TinyBERT。<br>第二个阶段，利用 General TinyBERT 在任务上fine-tuning(使用了数据增强)，之后蒸馏。</p>
<p><img src="/images/蒸馏/16.png" width="60%"></p>
<p><strong>四层结构的 TinyBERT4</strong> 相比BERT-base参数量减少7.5倍，速度提升9.4倍，效果可以达到教师模型的96.8%；<strong>六层结构的 TinyBERT6</strong> 甚至接近BERT-base，超过了BERT-PKD和DistillBERT。</p>
<p>TinyBERT主要做了以下两点创新：</p>
<ul>
<li>提供一种新的针对 transformer-based 模型进行蒸馏的方法，使得BERT中具有的语言知识可以迁移到TinyBERT中去。</li>
<li>提出一个两阶段学习框架，在<strong>预训练</strong>阶段和<strong>fine-tuning</strong>阶段都进行蒸馏，确保TinyBERT可以充分的从BERT中学习到一般领域和特定任务两部分的知识。</li>
</ul>
<p><strong>知识蒸馏</strong><br>知识蒸馏的目的在于将一个大型的教师网络 $T$ 学习到的知识迁移到小型的学生网络 $S$ 中。学生网络通过训练来模仿教师网络的行为。$f^S$ 和 $f^T$ 代表教师网络和学生网络的behavior functions。这个行为函数的目的是将网络的输入转化为信息性表示，并且它可被定义为网络中任何层的输出。在基于transformer的模型的蒸馏中，MHA（multi-head attention）层或FFN（fully connected feed-forward network）层的输出或一些中间表示，比如注意力矩阵 $A$ 都可被作为行为函数使用。</p>
<script type="math/tex; mode=display">L_{KD}=\sum\limits_{x\in X}L(f^S(x),f^T(x))</script><p>其中 $L(⋅)$ 是一个用于评估教师网络和学生网络之间差异的损失函数，$x$ 是输入文本，$X$ 代表训练数据集。因此，蒸馏的关键问题在于如何定义行为函数和损失函数。</p>
<p><strong>Transformer Distillation</strong><br>假设TinyBert有 M 层transformer layer，teacher BERT有 N 层transformer layer，则需要从teacher BERT的 N 层中抽取 M 层用于transformer层的蒸馏。$n=g(m)$ 定义了一个从学生网络到教师网络的映射关系，表示学生网络中第 $m$ 层网络信息是从教师网络的第 $g(m)$ 层学习到的，也就是教师网络的第 $n$ 层。TinyBERT嵌入层和预测层也是从BERT的相应层学习知识的，其中嵌入层对应的指数为0，预测层对应的指数为 M+1，对应的层映射定义为 $0=g(0)$ 和 $N+1=g(M+1)$。在形式上，学生模型可以通过最小化以下的目标函数来获取教师模型的知识：</p>
<script type="math/tex; mode=display">L_{model}=\sum\limits_{x\in X}\sum\limits_{m=0}^{M+1}\lambda_mL_{layer}(f_m^S(x),f_{g(m)}^T(x))</script><p>其中 $L_{layer}$ 是给定的模型层的损失函数（比如transformer层或嵌入层），$f_{m}$ 代表第 m 层引起的行为函数，$\lambda_m$ 表示第 m 层蒸馏的重要程度。</p>
<p>TinyBERT的蒸馏分为以下三个部分：</p>
<ul>
<li>transformer-layer distillation (包括attention和hidden states损失)</li>
<li>embedding-layer distillation</li>
<li>prediction-layer distillation</li>
</ul>
<p><strong>1、transformer-layer distillation</strong><br>Transformer-layer的蒸馏由attention based蒸馏和hidden states based蒸馏两部分组成。<br><img src="/images/蒸馏/18.png" width="50%"></p>
<p><strong>attention based</strong>蒸馏是受到论文 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDYuMDQzNDEucGRm">Clack et al., 2019<i class="fa fa-external-link-alt"></i></span> 的启发，这篇论文中提到，BERT学习的注意力权重可以捕获丰富的语言知识，这些语言知识包括对自然语言理解非常重要的语法和共指信息。因此，TinyBERT提出attention based蒸馏，其目的是使学生网络很好地从教师网络处学习到这些语言知识。具体到模型中，就是让TinyBERT网络学习拟合BERT网络中的多头注意力矩阵，目标函数定义如下：</p>
<script type="math/tex; mode=display">L_{attn}=\frac{1}{h}\sum\limits_{i=1}^hMSE(A_i^S,A_i^T)</script><p>其中，$h$ 代表注意力头数，$A_i\in R^{l\times l}$ 代表学生或教师的第 $i$ 个注意力头对应的注意力矩阵，$l$ 代表输入文本的长度。论文中提到，使用注意力矩阵 $A$ 而不是 $softmax(A)$ 是因为实验结果显示这样可以得到更快的收敛速度和更好的性能表现。</p>
<p><strong>hidden states based</strong>蒸馏是对transformer层输出的知识进行了蒸馏处理，目标函数定义为：</p>
<script type="math/tex; mode=display">L_{hidn}=MSE(H^SW_h,H^T)</script><p>其中，$H^S\in R^{l×d^′}$,$H^T\in R^{l×d}$ 分别代表学生网络和教师网络的隐状态，是FFN的输出。$d$ 和 $d^′$ 代表教师网络和学生网络的隐藏状态大小，且 $d^′&lt;d$，因为学生网络总是小于教师网络。$W_h\in R^{d^′×d}$ 是一个可训练的线性变换矩阵，将学生网络的隐藏状态投影到教师网络隐藏状态所在的空间。</p>
<p><strong>2、Embedding-layer Distillation</strong></p>
<script type="math/tex; mode=display">L_{embd}=MSE(E^SW_e,W^T)</script><p>Embedding loss和hidden states loss同理，其中 $E^S$,$E^T$ 代表学生网络和教师网络的嵌入（embedding），和隐藏状态矩阵的形状相同，同时 $W_e$ 和 $W_h$ 的作用也相同。</p>
<p><strong>3、Prediction-layer Distillation</strong></p>
<script type="math/tex; mode=display">L_{pred}=CE(z^T/t,z^S/t)</script><p>其中，$z^S$,$z^T$ 分别是学生网络和教师网络预测的 logits 向量，$CE$ 代表交叉熵损失，$t$ 是temperature value，当 $t=1$ 时，表现良好。</p>
<p>对上述三个部分的loss函数进行整合，则可以得到教师网络和学生网络之间对应层的蒸馏损失如下：<br><img src="/images/蒸馏/19.png" width="30%"></p>
<p><strong>实验结果</strong><br>分析两个阶段的知识蒸馏 TD (Task-specific Distillation)和GD (General Distillation)，以及数据增强DA (Data Augmentation) 对TinyBERT整体效果的作用（最后的实验中，预训练阶段只对中间层进行了蒸馏；精调阶段则先对中间层蒸馏20个epochs，再对最后一层蒸馏3个epochs）：<br><img src="/images/蒸馏/20.png" width="50%"></p>
<ul>
<li>去掉TD和DA对整体结果影响较大，<strong>去掉GD对整体的结果作用较小</strong>（GD带来的提升不如TD或者DA），TD和DA对最终结果的影响差不多。</li>
<li><strong>去掉GD对CoLA的作用大于MNLI和MRPC</strong>(CoLA在没有GD的情况下降了9%)，CoLA是判断一句话是否语法正确的数据集，需要更多语言学知识，而GD的过程正是捕获这种知识的手段。</li>
</ul>
<p>分析知识蒸馏过程中，选取的不同的特征表示对整体结果的作用：<br><img src="/images/蒸馏/21.png" width="50%"></p>
<ul>
<li>没有Transformer层对模型的影响最大，Transformer层是整个模型的主要构成部分。</li>
<li>Transformer层中attention矩阵相比隐层输出的作用要大。</li>
<li>整体来说，Transformer层，embeding层，预测输出层，对于提高模型的整体效果都是有效的。</li>
</ul>
<h2 id="MobileBERT（ACL2020）"><a href="#MobileBERT（ACL2020）" class="headerlink" title="MobileBERT（ACL2020）"></a>MobileBERT（ACL2020）</h2><p>前文介绍的模型都是层次剪枝+蒸馏的操作，MobileBERT则致力于减少每层的维度，在保留24层的情况下，减少了4.3倍的参数，速度提升5.5倍，在GLUE上平均只比BERT-base低了0.6个点，效果好于TinyBERT和DistillBERT。</p>
<p>MobileBERT压缩维度的主要思想在于bottleneck机制，如下图所示：<br><img src="/images/蒸馏/22.png" width="80%"></p>
<p>其中a是标准的BERT，b是加入bottleneck的BERT-large，作为教师模型，c是加入bottleneck的学生模型。Bottleneck的原理是在transformer的输入输出各加入一个线性层，实现维度的缩放。对于教师模型，embedding的维度是512，进入transformer后扩大为1024，而学生模型则是从512缩小至128，使得参数量骤减。</p>
<p>另外，作者发现在标准BERT中，多头注意力机制MHA和非线性层FFN的参数比为1:2，这个参数比相比其他比例更好。所以为了维持比例，会在学生模型中多加几层FFN。</p>
<p>MobileBERT还有一点不同于之前的TinyBERT，就是预训练阶段蒸馏之后，作者直接在MobileBERT上用任务数据精调，而不需要再进行精调阶段的蒸馏，方便了很多。</p>
<p>MobileBERT的蒸馏中，作者先用b的结构预训练一个BERT-large，再蒸馏到24层学生模型中。蒸馏的loss有多个：</p>
<ul>
<li>Feature Map Transfer：每个模块的隐状态输出之间的MSE $L_{FMT}^l=\frac{1}{TN}\sum\limits_{t=1}^T\sum\limits_{n=1}^N(H_{t,l,n}^{tr}-H_{t,l,n}^{st})^2$，作者发现，将这项差异分解成归一化后的差异与统计差异有助于训练的稳定性。</li>
<li>Attention Transfer：注意力矩阵的KL散度 $L_{AT}^l=\frac{1}{TA}\sum\limits_{a=1}^AD_{KL}(a_{t,l,n}^{tr}||a_{t,l,n}^{st})$，即每个多头自注意力矩阵的KL散度。</li>
<li>Pre-training Distillation：预训练蒸馏 $L_{PD}=\alpha L_{MLM}+(1-\alpha)L_{KD}+L_{NSP}$，即MLM任务，NSP任务的损失加上MLM蒸馏的损失。</li>
</ul>
<p>同时作者还研究了三种不同的蒸馏策略：直接蒸馏所有层、先蒸馏中间层再蒸馏最后一层、逐层蒸馏。如下图：<br><img src="/images/蒸馏/23.png" width="90%"><br>最后的结论是逐层蒸馏效果最好，但差距最大才0.5个点，性价比有些低了。其中OPT表示：使用relu代替gelu，移除layer Norm。这不优化比优化了效果还好，但是花的时间也更多了。<br><img src="/images/蒸馏/24.png" width="90%"></p>
<p>从蒸馏损失消融实验结果可以看出FMT带来的提升最大：<br><img src="/images/蒸馏/25.png" width="50%"></p>
<p>对于训练方法，果然是逐层蒸馏效果最好：<br><img src="/images/蒸馏/26.png" width="50%"></p>
<h2 id="MiniLM"><a href="#MiniLM" class="headerlink" title="MiniLM"></a>MiniLM</h2><p>之前的各种模型基本上把BERT里面能蒸馏的都蒸了个遍，但MiniLM还是找到了新的蓝海——<strong>蒸馏Value-Value矩阵+助教机制</strong>：<br><img src="/images/蒸馏/27.png" width="80%"></p>
<p><strong>Value-Relation Transfer</strong>可以让学生模型更深入地模仿教师模型，实验表明可以带来1-2个点的提升。同时作者考虑到学生模型的层数、维度都可能和教师模型不同，在实验中只蒸馏最后一层，并且只蒸馏这两个矩阵的KL散度。另外，作者还引入了<strong>助教机制</strong>。当学生模型的层数、维度都小很多时，先用一个维度小但层数和教师模型一致的助教模型蒸馏，之后再把助教的知识传递给学生。</p>
<p>最终采用BERT-base作为教师，实验下来6层的学生模型比起TinyBERT和DistillBERT好了不少，基本是20年性价比数一数二的蒸馏了。</p>
<h2 id="DynaBERT"><a href="#DynaBERT" class="headerlink" title="DynaBERT"></a>DynaBERT</h2><p>DynaBERT（dynamic BERT）提出一种不同的思路，它可以通过选择自适应宽度和深度来灵活地调整网络大小，从而得到一个尺寸可变的网络。</p>
<p>DynaBERT的训练阶段包括两部分：</p>
<ul>
<li>首先通过知识蒸馏的方法将teacher BERT的知识迁移到有自适应宽度的子网络student DynaBERTW中。</li>
<li>然后再对 DynaBERTW 进行知识蒸馏得到同时支持深度自适应和宽度自适应的子网络 DynaBERT。</li>
</ul>
<p>训练过程流程图所示：<br><img src="/images/蒸馏/28.png" width="80%"></p>
<p><strong>宽度自适应 Adaptive Width</strong><br>一个标准的transfomer中包含一个多头注意力（MHA）模块和一个前馈网络（FFN）。在论文中，作者通过变换注意力头的个数 $N_h$ 和前馈网络中中间层的神经元个数 $d_{ff}$ 来更改transformer的宽度。同时定义一个缩放系数 $m_w$ 来进行剪枝，保留MHA中最左边的 $[m_wN_H]$ 个注意力头和 FFN中 $[m_wd_{ff}]$ 个神经元。</p>
<p>为了充分利用网络的容量，更重要的头部或神经元应该在更多的子网络中共享。因此，在训练宽度自适应网络前，作者在 fine-tuned BERT网络中根据注意力头和神经元的重要性对它们进行了排序，然后在宽度方向上以降序进行排列。这种选取机制被称为 <strong>Network Rewiring</strong>。<br><img src="/images/蒸馏/29.png" width="50%"></p>
<p>那么，要如何界定注意力头和神经元的重要性呢？作者参考 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE2MTEuMDY0NDAucGRm">P. Molchanov et al., 2017<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE4MDQuMDc0NjEucGRm">E. Voita et al., 2019<i class="fa fa-external-link-alt"></i></span> 两篇论文提出，去掉某个注意力头或神经元前后的loss变化，就是该注意力头或神经元的重要程度，变化越大则越重要。</p>
<p><strong>训练宽度自适应网络</strong><br>首先，将BERT网络作为固定的教师网络，并初始化 DynaBERTW。然后通过知识蒸馏将知识从教师网络迁移到 DynaBERTW 中不同宽度的学生子网络。其中，$m_w=[1.0,0.75,0.5,0.25]$。</p>
<p>模型蒸馏的loss定义为：<br><img src="/images/蒸馏/30.png" width="60%"></p>
<p>其中， $\lambda_1$,$\lambda_2$ 是控制不同损失函数权重的参数， $l_{pred}$,$l_{emb}$,$l_{hidn}$ 分别定义为：<br><img src="/images/蒸馏/31.png" width="60%"></p>
<p>$l_{pred}$ 代表预测层的loss，SCE 代表交叉熵损失函数。$l_{emb}$ 代表嵌入层的loss，MSE代表均方差损失函数。$l_{hidn}$ 则为隐藏层的loss。</p>
<p><strong>训练深度自适应网络</strong><br>训练好宽度自适应的DynaBERTW后，就可以将其作为教师网络训练同时具备宽度自适应和深度自适应的DynaBERT了。为了避免宽度方向上的灾难性遗忘，在每一轮训练中，仍对不同宽度进行训练。深度调节系数 $m_d$ 对网络层数进行调节，在训练中定义 $m_d=[1.0,0.75,0.5]$。深度方向上的剪枝根据 $mod(d+1,\frac{1}{md})=0$ 来去掉特定层。</p>
<p>模型蒸馏的loss定义为：<br><img src="/images/蒸馏/32.png" width="70%"></p>
<p><strong>实验结果</strong><br>根据不同的宽度和深度剪裁系数，作者最终得到12个大小不同的DyneBERT模型，其在GLUE上的效果如下：<br><img src="/images/蒸馏/33.png" width="70%"></p>
<p>论文中提出的DynaBERT和DynaRoBERTa可以达到和 BERTBASE 及 DynaRoBERTa 相当的精度，但是通常包含更少的参数，FLOPs或更低的延迟。在相同效率的约束下，从DynaBERT中提取的子网性能优于DistilBERT和TinyBERT。<br><img src="/images/蒸馏/34.png" width="70%"></p>
<h1 id="BERT蒸馏技巧"><a href="#BERT蒸馏技巧" class="headerlink" title="BERT蒸馏技巧"></a>BERT蒸馏技巧</h1><p><strong>1、选择哪种蒸馏方案？</strong></p>
<ul>
<li>预训练蒸馏的数据比较充分，可以参考MiniLM、MobileBERT或者TinyBERT那样进行剪层+维度缩减。</li>
<li>对于针对某项任务、只想蒸馏精调后BERT的情况，则推荐进行剪层，同时利用教师模型的层对学生模型进行初始化。</li>
</ul>
<p><strong>2、用什么蒸馏目标函数？</strong><br><img src="/images/蒸馏/35.png" width="70%"><br>对于hard label，使用KL和CE是一样的，因为$KL(p||q)=H(p||q)-H(p)$，训练集不变时label分布是一定的。但对于soft label则不同了，不过表中不少模型还是采用了CE，只有Distilled BiLSTM发现MSE更好。可以CE/MSE/KL都试一下，但MSE有个好处是可以避免T的调参。中间层输出的蒸馏，大多数模型都采用了MSE，只有DistillBERT加入了cosine loss来对齐方向。注意力矩阵的蒸馏loss则比较统一，如果要蒸馏softmax之前的attention logits可以采用MSE，之后的attention prob可以用KL散度。</p>
<ul>
<li>使用finetune任务自身的loss是有效的，但是效果不大，大概能够提升0.2个百分点。</li>
<li>使用attention output输出logits的mse效果甚微，基本没有太大提升。我推测可能是当前对于序列标注任务来说，attention的学习提升不大。建议使用更多不同的任务来实验。</li>
<li>使用hidden output输出logits的mse是非常有效的，能够提升1个百分点。</li>
<li>使用概率输出做蒸馏和使用logits输出做蒸馏差距不大，并不能看到显著的区别，建议用更多不同的任务来实验。</li>
</ul>
<p><strong>3、超参T和α的设置</strong><br>超参 α 用来控制各个蒸馏目标的权重。</p>
<p>超参 T 越大越能学到teacher模型的泛化信息。一部分文章发现 T=1时候效果最好，大部分文章与1-20之间调 T。</p>
<p><strong>4、蒸馏方式</strong><br>逐层蒸馏可以提高一些成绩，但是花费还是很大的。</p>
<p><strong>5、助教机制似乎有效</strong><br>miniLM发现的，论文中它的最终目标是将模型裁剪到4层，hidden_size裁剪一半。实际操作时，它并非直接使用蒸馏训练一个最小模型，而是先用原始模型蒸馏一个中介模型，其层数为4层，但是hidden_size不变，然后使用这个中介模型作为teacher模型来蒸馏得到最终的模型。我尝试了这种方式，发现有一定的效果，为了蒸馏得到4层的模型，我先将原始模型蒸馏到6层，然后再蒸馏到4层。这种方式比直接蒸馏小模型能够有3-4个百分点的提升。当然，我这里要说明一点，我比较的是训练相同epoch数下的两个模型的精度，也有可能是一步到位蒸馏小模型需要更多的训练步数才能达到收敛，并不能直接断定一步到位为训练法一定就比较差，但至少在相同的训练成本下，采用中介过渡是更有效的。</p>
<p><strong>尽量沿用teacher模型的权重，如初始化</strong>。</p>
<h1 id="TextBrewer"><a href="#TextBrewer" class="headerlink" title="TextBrewer"></a>TextBrewer</h1><p>TextBrewer 提供了通用的蒸馏框架，使用者只需要提供一些配置与数据就可以进行简单的蒸馏。详情参考<span class="exturl" data-url="aHR0cHM6Ly90ZXh0YnJld2VyLnJlYWR0aGVkb2NzLmlvL2VuL2xhdGVzdC9UdXRvcmlhbC5odG1s">TextBrewer官方文档<i class="fa fa-external-link-alt"></i></span>。</p>
<p>TextBrewer的主要功能与模块：</p>
<ul>
<li>Distillers：进行蒸馏的核心部件，不同的distiller提供不同的蒸馏模式。目前包含GeneralDistiller, MultiTeacherDistiller, MultiTaskDistiller等。</li>
<li>Configurations and presets：训练与蒸馏方法的配置，并提供预定义的蒸馏策略以及多种知识蒸馏损失函数。</li>
<li>Utilities：模型参数分析等辅助工具。</li>
</ul>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p><img src="/images/蒸馏/36.png" width="70%"></p>
<p><strong>第一步</strong>：蒸馏之前的准备工作：</p>
<ul>
<li>训练<strong>教师</strong>模型。</li>
<li>定义与初始化<strong>学生</strong>模型（随机初始化，或载入预训练权重）。</li>
<li>构造蒸馏用数据集的 dataloader，训练<strong>学生</strong>模型用的 optimizer 和 learning rate scheduler 。</li>
</ul>
<p><strong>第二步</strong>：使用TextBrewer蒸馏：</p>
<ul>
<li>构造训练配置(TrainingConfig)和蒸馏配置(DistillationConfig),初始化distiller。</li>
<li>定义 adaptor 和 callback ，分别用于适配模型输入输出和训练过程中的回调。</li>
<li>调用 distiller.train() 方法开始蒸馏。</li>
</ul>
<h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><p>以蒸馏BERT-base到3层BERT为例展示TextBrewer用法。</p>
<p>在开始蒸馏之前准备：</p>
<ul>
<li>训练好的教师模型teacher_model (BERT-base)，待训练学生模型student_model (3-layer BERT)。</li>
<li>数据集dataloader，优化器optimizer，学习率调节器类或者构造函数scheduler_class 和构造用的参数字典 scheduler_args。</li>
</ul>
<p>使用TextBrewer蒸馏:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> textbrewer</span><br><span class="line"><span class="keyword">from</span> textbrewer <span class="keyword">import</span> GeneralDistiller</span><br><span class="line"><span class="keyword">from</span> textbrewer <span class="keyword">import</span> TrainingConfig, DistillationConfig</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">teacher_model为Bert-base，student_model为bert-3-layer。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 展示模型参数量的统计</span></span><br><span class="line">print(<span class="string">&quot;\nteacher_model&#x27;s parametrers:&quot;</span>)</span><br><span class="line">result, _ = textbrewer.utils.display_parameters(teacher_model,max_level=<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (result)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;student_model&#x27;s parametrers:&quot;</span>)</span><br><span class="line">result, _ = textbrewer.utils.display_parameters(student_model,max_level=<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义adaptor用于解释模型的输出</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">simple_adaptor</span>(<span class="params">batch, model_outputs</span>):</span></span><br><span class="line">    <span class="comment"># model输出的第二、三个元素分别是logits和hidden states</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;logits&#x27;</span>: model_outputs[<span class="number">1</span>], <span class="string">&#x27;hidden&#x27;</span>: model_outputs[<span class="number">2</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 蒸馏与训练配置</span></span><br><span class="line"><span class="comment"># 匹配教师和学生层: 教师第0层和学生第0层匹配hidden层(loss计算方式为mse)；教师第8层和学生第2层...</span></span><br><span class="line">distill_config = DistillationConfig(</span><br><span class="line">    intermediate_matches=[    </span><br><span class="line">     &#123;<span class="string">&#x27;layer_T&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;layer_S&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;feature&#x27;</span>:<span class="string">&#x27;hidden&#x27;</span>, <span class="string">&#x27;loss&#x27;</span>: <span class="string">&#x27;hidden_mse&#x27;</span>,<span class="string">&#x27;weight&#x27;</span> : <span class="number">1</span>&#125;,</span><br><span class="line">     &#123;<span class="string">&#x27;layer_T&#x27;</span>:<span class="number">8</span>, <span class="string">&#x27;layer_S&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;feature&#x27;</span>:<span class="string">&#x27;hidden&#x27;</span>, <span class="string">&#x27;loss&#x27;</span>: <span class="string">&#x27;hidden_mse&#x27;</span>,<span class="string">&#x27;weight&#x27;</span> : <span class="number">1</span>&#125;])</span><br><span class="line">train_config = TrainingConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化distiller</span></span><br><span class="line">distiller = GeneralDistiller(</span><br><span class="line">    train_config=train_config, distill_config = distill_config,</span><br><span class="line">    model_T = teacher_model, model_S = student_model, </span><br><span class="line">    adaptor_T = simple_adaptor, adaptor_S = simple_adaptor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始蒸馏</span></span><br><span class="line"><span class="keyword">with</span> distiller:</span><br><span class="line">    distiller.train(optimizer, </span><br><span class="line">                    dataloader, </span><br><span class="line">                    num_epochs=<span class="number">1</span>, </span><br><span class="line">                    scheduler_class=scheduler_class, </span><br><span class="line">                    scheduler_args=scheduler_args, </span><br><span class="line">                    callback=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>蒸馏配置</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># matches地址：https://github.com/airaria/TextBrewer/blob/master/examples/matches/matches.py</span></span><br><span class="line">distill_config = DistillationConfig(temperature = <span class="number">8</span>, intermediate_matches = matches) <span class="comment"># 其他参数为默认值</span></span><br></pre></td></tr></table></figure></p>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><p><strong>1、Configurations</strong><br>TrainingConfig 和 DistillationConfig：训练和蒸馏相关的配置。</p>
<p><strong>2、Distillers</strong><br>Distiller负责执行实际的蒸馏过程。目前实现了以下的distillers:</p>
<ul>
<li><code>BasicDistiller</code>: 提供<strong>单模型单任务</strong>蒸馏方式。可用作测试或简单实验。</li>
<li><code>GeneralDistiller</code> (常用): 提供<strong>单模型单任务</strong>蒸馏方式，并且支持<strong>中间层特征匹配</strong>，一般情况下<strong>推荐使用</strong>。</li>
<li><code>MultiTeacherDistiller</code>: <strong>多教师蒸馏</strong>。将多个（同任务）教师模型蒸馏到一个学生模型上。<strong>暂不支持中间层特征匹配</strong>。</li>
<li><code>MultiTaskDistiller</code>：<strong>多任务蒸馏</strong>。将多个（不同任务）单任务教师模型蒸馏到一个多任务学生模型上。<strong>暂不支持中间层特征匹配</strong>。</li>
<li><code>BasicTrainer</code>：用于<strong>单个模型</strong>的有监督训练，而非蒸馏。可用于<strong>训练教师模型</strong>。</li>
</ul>
<p><strong>3、用户定义函数</strong><br>蒸馏实验中，有两个组件需要由用户提供，分别是 callback 和 adaptor :</p>
<ul>
<li><code>callback</code>：回调函数。在每个checkpoint，保存模型后会被distiller调用，并传入当前模型。可以借由回调函数在每个checkpoint评测模型效果。</li>
<li><code>adaptor</code>：将模型的输入和输出转换为指定的格式，向distiller解释模型的输入和输出，以便distiller根据不同的策略进行不同的计算。在每个训练步，batch和模型的输出model_outputs会作为参数传递给adaptor，adaptor负责重新组织这些数据，返回一个字典。字典的key参考<span class="exturl" data-url="aHR0cHM6Ly90ZXh0YnJld2VyLnJlYWR0aGVkb2NzLmlvL2VuL2xhdGVzdC9Db25jZXB0cy5odG1sI3VzZXItZGVmaW5lZC1mdW5jdGlvbnM=">官网说明<i class="fa fa-external-link-alt"></i></span>。</li>
</ul>
<p>adaptor和callback流程图：<br><img src="/images/蒸馏/37.png" width="40%"></p>
<p>整体工作流如上图所示，黄色框为上文讨论到的Adaptor，用于将模型前向传导的输出整理为计算蒸馏损失所需要的字典（蓝色部分），最后在checkpoint时调用callback，callback可以评测模型效果。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9wYWRkbGVwZWRpYS5yZWFkdGhlZG9jcy5pby9lbi9sYXRlc3QvdHV0b3JpYWxzL21vZGVsX2NvbXByZXNzL2luZGV4Lmh0bWw=">模型压缩+模型蒸馏<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80MTk2Nzk3MDI=">TextBrewer 通用蒸馏配置说明与工作流程介绍<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cDovL3d1amlhd2VuLnh5ei8yMDIxLzEwLzA5L2Rpc3RpbGwv">bert蒸馏小综述<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvdEtmSHE0OWhlYWt2ak0wRVZRUGdIdw==">BERT蒸馏完全指南｜原理/技巧/代码<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMjQyMTU3NjA=">模型压缩实践收尾篇——模型蒸馏以及其他一些技巧实践小结<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MDQzMjM0NjU=">深度学习高温蒸馏：Softmax With Temperature<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE1MDMuMDI1MzE=">Distilling the Knowledge in a Neural Network<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MDMuMTIxMzY=">Distilling Task-Specific Knowledge from BERT into Simple Neural Networks<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MDguMDkzNTU=">Patient Knowledge Distillation for BERT Model Compression<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MTAuMDExMDg=">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MDkuMTAzNTE=">TinyBERT: Distilling BERT for Natural Language Understanding<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDQuMDI5ODQ=">MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDIuMTA5NTc=">MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIwMDQuMDQwMzcucGRm">DynaBERT: Dynamic BERT with Adaptive Width and Depth<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FpcmFyaWEvVGV4dEJyZXdlcg==">TextBrewer-github<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vbWFjcm9oYXJkL1RleHRCcmV3ZXIvdHJlZS9tYXN0ZXI=">TextBrewer-gitee<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly90ZXh0YnJld2VyLnJlYWR0aGVkb2NzLmlvL2VuL2xhdGVzdC9pbmRleC5odG1s">TextBrewer<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/22/NLP/07.%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/22/NLP/07.%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87/" class="post-title-link" itemprop="url">检索系统和常见指标</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-22T00:00:00+08:00">2021-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="检索式"><a href="#检索式" class="headerlink" title="检索式"></a>检索式</h1><h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>核心为<strong>信息检索</strong>（Information Retrieval，IR），即从大规模<strong>非结构化数据</strong>（通常为文本）的集合（通常保存在计算机上）中找出<strong>满足用户信息需求</strong>的资料（通常是文档）的过程。是研究信息的获取（acquisition）、表示（representation）、存储（storage）、组织（organization）和访问（access）的一门学问。</p>
<p>信息检索不仅仅是搜索，信息检索系统也不仅仅是搜索引擎。比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">返回与信息检索相关的网页-&gt;搜索引擎（SearchEngine，SE）</span><br><span class="line">姚明是谁？-&gt;问答系统（Question Answering，QA）</span><br><span class="line">返回Ipad的各类型号、配置等-&gt;信息抽取（Information Extraction，IE）</span><br><span class="line">使用Google Reader订阅新闻，并获取推荐-&gt;信息过滤（Information Filtering）、信息推荐（Information Recommending）</span><br></pre></td></tr></table></figure></p>
<h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><p>一个例子：《莎士比亚全集》这本大头书，我们想知道：哪些剧本包含Brutus和Caesar但是不包含Calpurnia？一种方式是采用Unix下的grep程序，先找出所有包含Brutus和Caesar的剧本，然后再将包含Calpurnia的剧本排除。但是很多情况下，采用上述线性扫描的方式是远远不够的。可以考虑用<strong>空间换取时间</strong>。</p>
<p><strong>词项文档索引</strong><br>词项-文档关联矩阵（incidence matrix），采用非线性的扫描方式，事先给文档建立索引。比如行索引为人名，列索引为书名，如果此人在书中出现过就是1，否则为0。这种方法要很大的存储空间。遇到更大的数据集根本不可用这种方法。</p>
<p><strong>倒排索引</strong><br>对于每一个词项，存储包含整个词项的文档的一个列表，一个文档用一个序列号docID来表示。我们能用一个固定长度的数据来存储它吗？不能， 不利于增删。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Brutus-&gt;[1,2,4,11,31,45,173,174]</span><br><span class="line">Caesar-&gt;[1,2,4,5,6,16,57,132]</span><br><span class="line">Calpurnia-&gt;[2,31,54,101]</span><br></pre></td></tr></table></figure><br>如果Caesar被添加到14号文档中，固定长度数组就不行了，所以使用可变长度的记录列表：<br>1、在硬盘上，一串<strong>连续的记录</strong>是正常的，也是最好的。<br>2、在内存里，可以使用<strong>链表</strong>，或者可变长度的整数。</p>
<p>上面所说的<strong>docID链表</strong>（排序后的结果）就是<strong>倒排记录表</strong>（inverted list），人名构成的词项就是<strong>词项词典</strong>。词项-&gt;文档。</p>
<p>建立步骤：<br>1、建立<strong>词条</strong>和<strong>docID</strong>序列。<br>2、排序（<strong>先按照词条排序，再按照docID排序</strong>）。<br><img src="/images/对话系统/3.png" width="40%"></p>
<p>考虑查询Brutus和Caesar：<br>1、在字典中找到Brutus，得到它的倒排记录表。<br>2、在字典中找到Caesar，得到它的倒排记录表。<br>3、两个倒排记录表取交集（使用双指针查询，O(n)）。</p>
<h1 id="近邻搜索-召回"><a href="#近邻搜索-召回" class="headerlink" title="近邻搜索(召回)"></a>近邻搜索(召回)</h1><h2 id="字符级别"><a href="#字符级别" class="headerlink" title="字符级别"></a>字符级别</h2><h3 id="BM25"><a href="#BM25" class="headerlink" title="BM25"></a>BM25</h3><p>bm25 是一种用来评价搜索词和文档之间相关性的算法，它是一种基于<strong>概率检索模型</strong>提出的算法，再用简单的话来描述下bm25算法：我们有一个 $query$ 和一批文档 $Ds$ ，现在要计算 $query$ 和每篇文档 $D$ 之间的相关性分数，我们的做法是，先对 $query$ 进行切分，得到单词 $q_i$ ，然后单词的分数由3部分组成：</p>
<ul>
<li>每个单词的权重。</li>
<li>相关性分数 $R$：单词和 $D$ 之间的相关性，单词和 $query$ 之间的相关性。</li>
</ul>
<p>最后对于每个单词的分数我们做一个求和，就得到了query和文档之间的分数。</p>
<script type="math/tex; mode=display">Score(Q,d)=\sum\limits^nW_iR(q_i,d)</script><p>其中，$W_i$代表单词 $q_i$ 权重，$R(q_i,d)$ 代表单词 $q_i$ 和文档 $d$ 相关性。</p>
<p><strong>每个单词的权重(IDF变形)</strong><br>$N$ 表示所有文档数目，$n(q_i)$ 为单词 $q_i$ 出现的文档数目，0.5主要是做平滑处理。</p>
<script type="math/tex; mode=display">IDF(q_i)=log(\frac{N-n(q_i)+0.5}{n(q_i)+0.5})</script><p>依据IDF的作用，对于某个 $q_i$ ，包含 $q_i$ 的文档数越多，说明 $q_i$ 重要性越小，或者区分度越低，IDF越小，因此IDF可以用来刻画 $q_i$ 与文档的相似性。</p>
<p><strong>相关性分数(TF变形)</strong><br>BM25的设计依据一个重要的发现：词频和相关性之间的关系是非线性的，也就是说，每个词对于文档的相关性分数不会超过一个特定的阈值，当词出现的次数达到一个阈值后，其影响就不在线性增加了，而这个阈值会跟文档本身有关。</p>
<script type="math/tex; mode=display">R(q_i,d)=\frac{f_i\cdot (k_1+1)}{f_i+K}\cdot\frac{qf_i\cdot(k_2+1)}{qf_i+k_2}</script><script type="math/tex; mode=display">K=k_1\cdot(1-b+b\cdot\frac{dl}{avgdl})</script><p>其中，$f_i$ 为单词 $q_i$ 在文档 $d$ 中的词频。$qf_i$ 为单词 $q_i$ 在 $query$ 中出现的频率。<br>$dl$ 是文档 $d$ 的长度，$avgdl$ 是所有文档的平均长度。<br>$k_1$ 是一个正的参数（一般为2），用来标准化文章词频的范围，$k_1$ 越大，我们越看重单词在文档d中词频的影响。<br>$k_2$ 越大，越看重单词在query中的词频，$k_2$ 一般为1。$b$为0~1之间的值（一般为0.75），决定使用文档长度来表示信息量的范围。</p>
<h3 id="WAND"><a href="#WAND" class="headerlink" title="WAND"></a>WAND</h3><p>wand（weak and）算法，通过计算每个词的贡献上限来估计文档的相关性上限，并与预设的阈值比较，进而跳过一些相关性一定达不到要求的文档，从而得到提速效果（$query$比较长的时候使用）。</p>
<p>wand 算法首先要估计<strong>每个词对相关性贡献的上限（upper bound）</strong>，最简单的相关性就是TF-IDF，一般IDF是固定的，因此只需要估计一个词在各个文档中的词频TF上限（即这个词在各个文档中最大的TF），该步骤通过线下计算即可完成。线下计算出各个词的相关性上限，可以计算出一个 $query$ 和一个文档的相关性上限值，就是它们共同出现的词的相关性上限值的和，通过与预设的阈值比较，如果 $query$ 与文档的相关性大于阈值，则进行下一步的计算，否则丢弃。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">query：the quick brown fox     </span><br><span class="line">with top k&#x3D;2</span><br></pre></td></tr></table></figure><br>根据倒排索引表，计算每个词的相关性贡献上限，即 TF-IDF，取每个词的最大值即可，如下表中max值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">        max  倒排索引</span><br><span class="line">the     0.9  [2,3,7,8,9,10,11,12,13,17,18,19...]</span><br><span class="line">qucik   1.9  [5,6,9,11,14,18]</span><br><span class="line">brown   2.3  [2,4,5,15,42,84,96]</span><br><span class="line">fox     7.1  [5,7,8,13]</span><br></pre></td></tr></table></figure><br>根据max可得到 $query$ 和文档的相关性上限。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">the和brown都出现在2文档，假设2文档中the的tfidf为0.1，brown为1。</span><br><span class="line">the只出现在3文档，假设3文档中the的tfidf为0.5。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 2.0 | 2 |</span><br><span class="line">2 | 0.5 | 3 |</span><br><span class="line">一般用heap维持k个。</span><br></pre></td></tr></table></figure><br>维持top-2这个heap堆，不停的这样寻找。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">当走到4的时候，只有brown出在4中，且max为2.3，那么文档4的score可能战胜0.5，计算文档4的tfidf，假设为1.4，替换掉0.5。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 2.0 | 2 |</span><br><span class="line">2 | 1.4 | 4 |</span><br><span class="line"></span><br><span class="line">同理，走到文档5的时候，brown、quick、fox都出现在文档5中，假设score计算为6.3，替换掉1.4。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 6.3 | 5 |</span><br><span class="line">2 | 2.0 | 2 |</span><br><span class="line"></span><br><span class="line">走到文档6的时候，只有quick出现在文档6中，且max为1.9，不可能超过heap中最小的score，所以跳过不用计算。</span><br></pre></td></tr></table></figure><br>预设的阈值，就是heap中最小score值，每次都是和它比较。</p>
<h2 id="向量级别"><a href="#向量级别" class="headerlink" title="向量级别"></a>向量级别</h2><h3 id="SIF"><a href="#SIF" class="headerlink" title="SIF"></a>SIF</h3><p>smooth inverse frequency（SIF），原论文<span class="exturl" data-url="aHR0cHM6Ly9vcGVucmV2aWV3Lm5ldC9wZGY/aWQ9U3lLMDB2NXh4">A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS<i class="fa fa-external-link-alt"></i></span>，参考解析<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGF0YWJpbmdvL3AvOTc4ODI0NC5odG1s">论文阅读<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="WMD"><a href="#WMD" class="headerlink" title="WMD"></a>WMD</h3><p>Word Mover’s Distance，论文《From Word Embeddings To Document Distances》提出了一种新的计算文档距离的方法。该方法建立在Word Embeddings基础之上，通过累计计算一个文档中的词travel到另一篇文档中词的最小距离来进行度量。详情参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNTEzNDQ4Njg=">Word Mover’s Distance 论文笔记<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84ODc4ODk2MQ==">对Word Mover’s Distance的理解<i class="fa fa-external-link-alt"></i></span>。 优化算法WCD（Word centroid distance）和RWMD（Relaxed word moving distance）参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85MTYyMTI0MQ==">深入理解WMD距离——一种衡量文本之间差异的度量<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNjQ5NTcyNTc=">WMD系列方法介绍（词移距离方法）<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84ODY5OTc3Ng==">From Word Embeddings To Document Distances 小结<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="Annoy"><a href="#Annoy" class="headerlink" title="Annoy"></a>Annoy</h3><p>Approximate Nearest Neighbors Oh Yeah，Annoy 是 Spotify 开源的高维空间求近似最近邻的库，在 Spotify 使用它进行音乐推荐。Annoy通过将海量数据建立成一个二叉树来使得每个数据查找时间复杂度是$O(log n)$。详情参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlcm9fZmFudGFvL2FydGljbGUvZGV0YWlscy83MDI0NTM4Nw==">海量数据相似查找系列2 — Annoy算法<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="HNSW"><a href="#HNSW" class="headerlink" title="HNSW"></a>HNSW</h3><p>Hierarchcal Navigable Small World graphs，详情参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGFuZ3VpL3AvMTQ2NzUxMjEuaHRtbA==">HNSW<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cucnlhbmxpZ29kLmNvbS8yMDE4LzExLzI3LzIwMTgtMTEtMjclMjBITlNXJTIwJUU0JUJCJThCJUU3JUJCJThELw==">近似最近邻算法 HNSW 学习笔记<i class="fa fa-external-link-alt"></i></span>，代码<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/faiss/blob/13a2d4ef8fcb4aa8b92718ef4b9cc211033e7318/benchs/bench_hnsw.py">facebookresearch<br>/faiss</a>。</p>
<h3 id="KD-Tree"><a href="#KD-Tree" class="headerlink" title="KD Tree"></a>KD Tree</h3><p>K dimentional Tree，详情参考李航的《统计学习方法》中K近邻算法，<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS9rZC10cmVlLzIzMDI1MTU/ZnI9YWxhZGRpbg==">kd-tree<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly9sZWlsZWlsdW9sdW8uY29tL3Bvc3RzL2tkdHJlZS1hbGdvcml0aG0tYW5kLWltcGxlbWVudGF0aW9uLmh0bWw=">k-d tree算法原理及实现<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="LSH"><a href="#LSH" class="headerlink" title="LSH"></a>LSH</h3><p>Locality Sensitive Hashing，详情参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ljdnByL2FydGljbGUvZGV0YWlscy8xMjM0MjE1OQ==">局部敏感哈希(Locality-Sensitive Hashing, LSH)方法介绍<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlcm9fZmFudGFvL2FydGljbGUvZGV0YWlscy83MDI0NTI4ND9zcG09MTAwMS4yMDE0LjMwMDEuNTUwMg==">海量数据相似查找系列1 — Minhashing &amp; LSH &amp; Simhash 技术汇总<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="Faiss工具"><a href="#Faiss工具" class="headerlink" title="Faiss工具"></a>Faiss工具</h2><iframe src="https://nbviewer.org/github/soundmemories/StudyNotes/blob/f42b2aced7dfe7e25f078bf8c8a59725cced6c31/Cheatsheets/Faiss_demo.ipynb" width="1000" height="700"></iframe>

<h1 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h1><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><p>MAP（Mean Average Precision）：平均准确率是相关文档检索出后的准确率的平均值。<br>反映系统在全部相关文档的性能单值指标，检索出来的相关文档越靠前（rank越高），MAP就可能越高。<br><img src="/images/检索和指标/1.png" width="100%"></p>
<p>计算顺序：Precision-&gt;Average Precision-&gt;Mean Average Precision。<br><strong>Precision</strong>：rank结果中的相关文档-&gt;$\dfrac{\text{第几个相关文档}}{\text{文档rank数}}$<br><strong>Average Precision</strong>：$\dfrac{rank结果中的相关文档Precision和}{相关文档总数}$<br><strong>Mean Average Precision</strong>：$\dfrac{每次查询的Average Precision和}{查询次数}$</p>
<p>注意，在Precision中，分子是rank结果中的相关文档是第几个，比如主题1有4个相关网页，序号分别为1234，那么rank排序为1234和4321的Precision结果是一样的，分子都是1234，分母也都是1234。<strong>因为此MAP没有考虑相关文档内部排序</strong>。</p>
<h3 id="NDCG"><a href="#NDCG" class="headerlink" title="NDCG"></a>NDCG</h3><p><strong>NDCG</strong>（Normalized Discounted Cumulative Gain），归一化折损累计增益。衡量和评价搜索结果算法。DCG的两个思想：</p>
<ul>
<li><strong>高度关联的结果比一般关联度的结果更影响最终的指标得分</strong>。</li>
<li><strong>有高关联度的结果出现在更靠前的位置的时候，指标会越高</strong>。</li>
</ul>
<p><strong>CG</strong>（Cumulative Gain），是DCG的前身，只考虑到了相关性的关联程度，没有考虑到位置的因素。它是一个搜素结果相关性分数的总和。如一个搜索结果list页面有P个结果，其CG为：</p>
<script type="math/tex; mode=display">CG_{p}=\sum\limits_{i=1}^{p}rel_i</script><p>其中，$rel_i$ 代表 $i$ 位置上的相关度。<br>CG的统计不受到搜索结果的排序影响，CG得分高只能说明这个结果页面总体的质量比较高并不能说明这个算法做的排序好或差。</p>
<p><strong>DCG</strong>（Discounted CG），就是在每一个CG的结果上除以一个折损值，为什么要这么做呢？目的就是为了让排名越靠前的结果越能影响最后的结果。公式：</p>
<script type="math/tex; mode=display">DCG_p=\sum\limits_{i=1}^{p}\frac{rel_i}{log_2(i+1)}=rel_1+\sum\limits_{i=2}^{p}\frac{rel_i}{log_2(i+1)}</script><p>当然还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式是：</p>
<script type="math/tex; mode=display">DCG_p=\sum\limits_{i=1}^{p} \frac{2^{rel_i}-1}{log_2(i+1)}</script><p><strong>NDCG</strong>（Normalize DCG），由于搜索结果随着检索词的不同，返回的数量是不一致的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理，这里是处以IDCG。</p>
<script type="math/tex; mode=display">nDCG_p=\frac{DCG_p}{IDCG_p}</script><p>IDCG（ideal DCG）为理想情况下最大的DCG值。IDCG如何计算？首先要拿到搜索的结果，人工对这些结果进行排序，排到最好的状态后，算出这个排列下本query的DCG，就是IDCG。</p>
<script type="math/tex; mode=display">\sum\limits_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2(i+1)}</script><p>其中 $|REL|$ 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序。</p>
<h2 id="Point-wise"><a href="#Point-wise" class="headerlink" title="Point-wise"></a>Point-wise</h2><p>Pointwise排序是将训练集中的每个item看作一个样本获取rank函数，主要解决方法是把分类问题转换为单个item的分类或回归问题。</p>
<p>point-wise把排序问题当成一个二分类问题，训练的样本被组织成一个三元组 $(q_i,c_{i,j},y_{i,j})$。$y_{i,j}$ 为一个二进制值，表明 $c_{i,j}$ 是否为 $q_i$ 正确回答。我们就可以训练一个二分类网络：$h_\theta(q_i,c_{i,j}\to y_{i,j})$ ，其中 $0\leq y_{i,j}\leq 1$。训练的目标为最小化数据集中所有问题和候选句子对的交叉熵。</p>
<p><strong>算法</strong>：</p>
<ul>
<li>基于回归的算法：此时，输出空间包含的是实值相关度得分。采用 ML 中传统的回归方法即可。</li>
<li>基于分类的算法：此时，输出空间包含的是无序类别。对于二分类，SVM、LR 等均可；对于多分类，提升树等均可。</li>
<li>基于有序回归的算法：此时，输出空间包含的是有序类别。通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用 PRanking、基于 margin 的方法都可以。</li>
</ul>
<p>常见算法：Subset Ranking, McRank, Prank, OC SVM</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>ranking追求的是排序结果，并不要求精确打分，只要相对打分即可。</li>
<li>pointwise类方法并没有考虑同一个query对应的docs间的内部依赖性。</li>
<li>损失函数也没有利用model预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的docs，即会强调那些排序在后面对用户体验影响小的doc。</li>
<li>query间docs的不平衡，如query1对应500个文档，query2对应10个文档。当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，每组 query 应该都是等价的。</li>
</ul>
<p><strong>优点</strong>：速度快，标注简单，复杂度低。</p>
<p><strong>改进</strong>：Pointwise 类算法也可以再改进，比如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。</p>
<h2 id="Pair-wise-Approach"><a href="#Pair-wise-Approach" class="headerlink" title="Pair-wise Approach"></a>Pair-wise Approach</h2><p>Pairwise排序是将同一个查询中两个不同的item作为一个样本，主要思想是把rank问题转换为二值分类问题。</p>
<p>在pair-wise方法中排序模型 $h_{\theta}$ 让正确的回答的得分明显高于错误的获选答案。给一个提问，pair-wise给定一对候选回答学习并预测哪一个句子才是提问的最佳回答。训练的样例为 $(q_i,c_i^+,c_i^-)$ ，其中 $q_i$ 为提问， $c_i^+$ 为正确的回答，$c_i^-$ 为候选答案中一个错误的回答。</p>
<p><strong>算法</strong>：基于二分类的算法，比如Random Forest，GBDT，RankSVM，RankBoost，RankNet，Lambda Rank, LambdaMart等。RankNet：原本Ranking常见的评价指标都无法求梯度，因此没法直接对评价指标做梯度下降，而它们将不适宜用梯度下降求解的Ranking问题，转化为对偏序概率的交叉熵损失函数的优化问题，从而适用梯度下降方法。</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>doc pair 的数量将是 doc 数量的二次（$C_n^2$），从而 pointwise 方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 方法中进一步放大。</li>
<li>pairwise 方法相对 pointwise 方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。</li>
<li>pairwise 方法仅考虑了 doc pair 的相对位置，损失函数还是没有利用 model 预测排序中的位置信息。</li>
<li>如果人工标注包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。</li>
<li>pairwise 方法只考虑了内部相对位置排序，没有考虑整体排序。</li>
</ul>
<p><strong>改进</strong>：</p>
<ul>
<li>IRSVM，主要针对前述第一个缺陷。</li>
<li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第二个缺陷。</li>
<li>P-norm push，Ordered weighted average ranking，LambdaRank，Sparse ranker，主要针对前述第三个缺陷。</li>
<li>Multiple hyperplane ranker，magnitude-preserving ranking，主要针对前述第四个缺陷。</li>
</ul>
<h2 id="List-wise-Approach"><a href="#List-wise-Approach" class="headerlink" title="List-wise Approach"></a>List-wise Approach</h2><p>List-wise排序是将整个item序列看作一个样本，通过<strong>直接优化信息检索的评价方法</strong>和<strong>定义损失函数</strong>两种方法实现。</p>
<p>pair-wise 和 point-wise 忽视了一个事实就是答案选择，即从一系列候选句子中的预测问题。在list-wise中单一训练样本就：query和它的所有候选句子。在训练过程中给定提问数据 $q_i$ 和它的一系列候选句子 $C(c_{i1},c_{i2},\dots,c_{im})$ 和标签 $Y(y_{i1},y_{i2},\dots,y_{im})$，归一化的得分向量 $S$ 通过如下公式计算：</p>
<script type="math/tex; mode=display">Score_j=h_{\theta}(q_i,c_{ij})</script><script type="math/tex; mode=display">S=softmax([Score_1,Score_2,\dots,Score_m])</script><p><strong>算法</strong>：</p>
<ul>
<li>直接基于评价指标的算法：直接取优化 ranking 的评价指标，但这并不简单，因为评价指标基本都是离散不可微的，具体处理方式：<ul>
<li>优化基于评价指标的 ranking error 的连续可微的近似，如SoftRank，ApproximateRank，SmoothRank。</li>
<li>优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank。</li>
<li>使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP。</li>
</ul>
</li>
<li>非直接基于评价指标的算法：这里，不再使用和评价指标相关的 loss 来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。经典的如 ，ListNet，ListMLE，StructRank，BoltzRank。</li>
</ul>
<p>直接基于评价指标的算法的优化目标都是直接和 ranking 的评价指标有关。现在来考虑一个概念，informativeness。通常认为一个更有信息量的指标，可以产生更有效的排序模型。而多层评价指标（NDCG）相较二元评价（AP）指标通常更富信息量。因此，有时虽然使用信息量更少的指标来评估模型，但仍然可以使用更富信息量的指标来作为 loss 进行模型训练。</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。</li>
<li>listwise 类存在的主要缺陷是：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。</li>
</ul>
<h2 id="CFG"><a href="#CFG" class="headerlink" title="CFG"></a>CFG</h2><p>CFG：Context free grammars，上下文无关文法。是一种形式文法（formal grammar）。形式文法是形式语言（formal language）的文法，由一组产生规则 （production rules）组成，描述该形式语言中所有可能的字符串形式。</p>
<p>上面这段话比价令人费解，我理解，就是每个句子的产生都遵循着一定的规则（规则学习的理念）。在这里面有几个概念：</p>
<ul>
<li>终止符：可以理解为基础符号，词法符号，是不可替 代的，天然存在，不能通过文法规则生成。</li>
<li>非终结符，或者句法变量。</li>
<li>Production rules： grammar 是由终结符集、非终结符集和产生规则共同组成。产生规则定义了符号之间如何转换替代。规则的左侧是规则头，是可以被替代的符号；右侧是规则体，是具体的内容。</li>
</ul>
<p>CFGs的性质：</p>
<ul>
<li>一个CFG定义了一个可能的推导的集合。</li>
<li>一句话如果是可以被CFG定义出来，那么至少有一个推导可以产生这句话。</li>
<li>每一句话的CFG可以是有歧义的（即有多种推导的可能，因为一个非终结符同时存在了多条规则），至于如何解决这个问题，在PCFGs中，也就是概率上下文无关文法中会有介绍，简单来说就是给予每条规则一个概率，再利用这些概率求得概率最大的那棵解析树。</li>
</ul>
<p>CKY算法：CKY处理的CFG必须是CNF形式的。所以算法首先要把非CNF形式的CFG转成CNF形式。</p>
<h1 id="相似度的计算"><a href="#相似度的计算" class="headerlink" title="相似度的计算"></a>相似度的计算</h1><h2 id="统计指标"><a href="#统计指标" class="headerlink" title="统计指标"></a>统计指标</h2><h3 id="Cosine"><a href="#Cosine" class="headerlink" title="Cosine"></a>Cosine</h3><script type="math/tex; mode=display">S = \frac{x\cdot y}{|x||y|}</script><p>两向量越相似，向量夹角越小，cosine绝对值越大；值为负，两向量负相关。</p>
<h3 id="Jaccard"><a href="#Jaccard" class="headerlink" title="Jaccard"></a>Jaccard</h3><script type="math/tex; mode=display">J(A,B)=\frac{|A\cap B|}{|A \cup B|}</script><p>值越大越相似，分子是A和B的交集大小，分母是A和B的并集大小。<br>Jaccard系数主要用于计算符号度量或布尔值度量的个体间的相似度，无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Jaccard系数只关心个体间共同具有的特征是否一致这个问题。</p>
<h3 id="Pearson"><a href="#Pearson" class="headerlink" title="Pearson"></a>Pearson</h3><script type="math/tex; mode=display">r = \frac{\sum\limits_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})}{\sqrt{\sum\limits_{i=1}^n(x_i-\overline{x})^2}\sum\limits_{i=1}^n(y_i-\overline{y})^2}</script><p>两个变量之间的协方差和标准差的商。反映两个变量X和Y的线性相关程度，r值介于-1到1之间，绝对值越大表明相关性越强。</p>
<h3 id="Euclidian"><a href="#Euclidian" class="headerlink" title="Euclidian"></a>Euclidian</h3><script type="math/tex; mode=display">d=\sqrt{\sum\limits_{i=1}^n(x_i-y_i)^2}</script><p>欧氏距离。</p>
<h2 id="文本距离"><a href="#文本距离" class="headerlink" title="文本距离"></a>文本距离</h2><h3 id="ED"><a href="#ED" class="headerlink" title="ED"></a>ED</h3><p>编辑距离（Edit Distance，ED），也叫Levenshtein Distance，是用来度量两个序列相似程度的指标。通俗地来讲，编辑距离指的是在两个单词之间，由其中一个单词转换为另一个单词所需要的<strong>最少单字符编辑</strong>次数。详情参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9hNjE3ZDIwMTYyY2Y=">详解编辑距离(Edit Distance)及其代码实现<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jhb2RyZWFtL2FydGljbGUvZGV0YWlscy84MDQxNzY5NQ==">最小编辑距离算法 Edit Distance（经典DP）<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="LCS"><a href="#LCS" class="headerlink" title="LCS"></a>LCS</h3><p>最长公共子序列（Longest Common Subsequence，LCS），一个序列，如果是两个或多个已知序列的子序列，且是所有子序列中最长的，则为最长公共子序列。</p>
<p>LCS和ED，两者都可以衡量字符串的相近程度。不同之处在于，LCS对两个的长度差异不敏感，编辑距离对两者的长度差异敏感。LCS衡量了两者的重合度，编辑距离衡量了两者的长度和重合度。对编辑距离的增删代价取0，改操作换成相同奖励，就是LCS。</p>
<p>算法详解：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM4ODE2OTI0L2FydGljbGUvZGV0YWlscy84MzI0MzQzNA==">LCS(longest common subsequence)（最长公共子序列）<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="WAM"><a href="#WAM" class="headerlink" title="WAM"></a>WAM</h3><p>句向量表示（Word Averaging Model，WAM），首先对句子进行分词，然后对分好的每一个词获取其对应的 Vector，然后将所有 Vector 相加并求平均，这样就可得到 Sentence Vector。</p>
<h2 id="深度匹配"><a href="#深度匹配" class="headerlink" title="深度匹配"></a>深度匹配</h2><p>使用Bert的序列相似度预测。</p>
<p><strong>Poly-encoders</strong>：开发了一种新的transformer体系结构，即Poly-encoder，该体系结构学习了全局而不是令牌级别的self-attention特征，同时解决了 DSSM 式的 Bi-encoder 匹配质量低的问题和 ARC-II、BERT 等交互式的 Cross-encoder 匹配速度慢的问题。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDE5Njl2Mi5wZGY=">Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring<i class="fa fa-external-link-alt"></i></span>。<br>详解参考：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDIxNDgzNzM=">《Poly-encoders》阅读笔记<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMTk0NDQ2Mzc=">PolyEncoder-Facebook的全新信息匹配架构-提速3000倍(附复现结果与代码)<i class="fa fa-external-link-alt"></i></span>。</p>
<p><strong>Sentence-BERT</strong>：虽然BERT和RoBERTa在很多句子对形式的回归任务（例如文本语义相似度）上达到了SOTA效果，但是它们还存在一些缺点：在这些任务中，它们均需要将比较的两个句子都传入到模型中计算，计算开销过大。BERT模型在一个1W句子集合中，找出最相近的一个句子对，需要5千万次推断计算（约65小时）才能完成，所以BERT并不适合语义相似度搜索等任务。</p>
<p>在该论文中，作者提出了一个新的模型，Sentence-BERT（简称SBERT）。SBERT采用双重或三重BERT网络结构，具体结构介绍会在后文中详细介绍。如果使用的是基于RoBERTa模型，则改造后的模型简称为SRoBERTa。</p>
<p>通过SBERT模型获取到的句子embedding，可以直接通过cos相似度计算两个句子的相似度，这样就大大减少了计算量。因为在使用BERT模型进行句子间相似度的判断时，需要从句子集合中，选出两个句子进行组合，传入BERT中进行计算，而使用SBERT模型，只需要将集合中每个句子单独传入到模型中，得到每个句子的embeding，计算相似度只需要使用cos函数计算两两embeding的cos距离即可。因此，使用BERT/RoBERTa模型需要65h才能完成的寻找最相似句子对任务，SBERT模型完成仅需5s。</p>
<p>作者在一些STS任务和迁移学习任务上评估SBERT模型，该模型达到了新的SOTA水平。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDguMTAwODQucGRm">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。<br>模型地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2JlcnQubmV0Lw==">Sentence-Transformers<i class="fa fa-external-link-alt"></i></span>。<br>详解参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Zlbmd4aW5saW51eC9hcnRpY2xlL2RldGFpbHMvMTA5MTk1NzYy">论文阅读Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。</p>
<p><strong>SimCSE</strong>：句子向量表示一直是NLP领域的一个热门问题，主要是因为其应用范围比较广泛，而且作为很多任务的基石。最近连续出了好几篇关于句子表示的文章，从前段时间的BERT-Flow, BERT-whitening到最近的这个SimCSE。BERT-Flow以及BERT-whitenning其实像是后处理，将bert的输出进行一定的处理来解决各向异性的问题。本篇的这个工作则是采用了自监督来提升模型的句子表示能力，说到自监督最关键的问题应该就是如何构建正负例了。本文的正负例有两种构建方式，对于无监督来说，作者使用了Droupout来构建正例，将一个样本经过encoder两次，就得到了一个正例对，负例则是同一个batch里的其它句子。而对于有监督则采用了SNLI数据集天然的结构，对立类别的是负例，另外两个类别的就是正例。没错就是如此简单的方法催生了新的SOTA，而且提升还非常的明显。<br>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIxMDQuMDg4MjEucGRm">SimCSE: Simple Contrastive Learning of Sentence Embeddings<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC83OTIwMjE1MQ==">BM25算法, Best Matching<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNTI1MjI5MDY=">K近邻算法哪家强？KDTree、Annoy、HNSW原理和使用方法介绍<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NvZnRfenp0aS9hcnRpY2xlL2RldGFpbHMvODc1Mjc5MTk=">18种和“距离(distance)”、“相似度(similarity)”相关的量的小结<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGFuZ3VpL3AvMTQ2NzU1NzUuaHRtbA==">相似度计算方法<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvdGFzWnRaMmRRT1NZdDF0TzdIdXJFZw==">机器学习中的相似性度量总结<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppamlrYW53YS9hcnRpY2xlL2RldGFpbHMvODc5ODAyOTA=">信息检索的评价指标<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYnktZHJlYW0vcC85NDAzOTg0Lmh0bWw=">搜索评价指标——NDCG<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAxMzg3NTgvYXJ0aWNsZS9kZXRhaWxzLzY5OTM2MDQxLw==">信息检索中常用的评价指标：MAP,nDCG,ERR,F-measure<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvMlZjQnd2LW9qNm9mT3l5R1ZpV3hmQQ==">从L2R开始理解一下Xgboost的 ‘objective’: ‘rank:pairwise’参数<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzIwNTY5ODMy">LTR （learning to Rank）<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMzc0NzgzNzM=">推荐- Point wise、pairwise及list wise的比较<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2hlbnhpYW9saW4vcC85NzIzODYwLmh0bWw=">Learning to Rank：Point-wise、Pair-wise 和 List-wise区别<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmVudHV3dXlpbmcvcC82NjgxOTQzLmh0bWw=">Learning to Rank简介<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmVudHV3dXlpbmcvcC82NjkwODM2Lmh0bWw=">Learning to Rank算法介绍：RankNet，LambdaRank，LambdaMart<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zOTgyNjQ1MTQ=">CFG：Context free grammars 上下文无关文法<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoYXNlMTk5OC9hcnRpY2xlL2RldGFpbHMvODQ1MDQxOTE=">基于CYK+PCFG的短语结构句法分析<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/21/NLP/06.%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/21/NLP/06.%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">对话系统简介</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-21 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-21T00:00:00+08:00">2021-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="闲聊式"><a href="#闲聊式" class="headerlink" title="闲聊式"></a>闲聊式</h2><p>情感识别，多轮对话中情感向量生成（Emotion Embedding）、意图识别等。建议参考项目<span class="exturl" data-url="aHR0cHM6Ly9yYXNhLmNvbS8=">Rasa<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="检索式"><a href="#检索式" class="headerlink" title="检索式"></a>检索式</h2><p>涉及到的核心：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入问句：句向量的构建。</span><br><span class="line">粗排：候选问句的范围，重点是速度、召回率。</span><br><span class="line">精排：候选问句基础上精细匹配&#x2F;深度匹配，重点是精准率。</span><br><span class="line">答案：匹配问句对应的答案。</span><br></pre></td></tr></table></figure></p>
<h2 id="知识问答"><a href="#知识问答" class="headerlink" title="知识问答"></a>知识问答</h2><p><img src="/images/对话系统/1.png" width="80%"></p>
<h2 id="任务式"><a href="#任务式" class="headerlink" title="任务式"></a>任务式</h2><p><img src="/images/对话系统/2.png" width="80%"></p>
<p>1、<strong>自然语言理解</strong>(NLU)：<br>(1) 将<strong>非结构化</strong>的<strong>文本</strong>转成<strong>结构化</strong>的<strong>语义</strong>(意图分类、词槽序列标注)。<br>(2) 将无限种可能转成有限的组合。<br>核心：意图识别(Intent)、实体识别(Entity)。</p>
<p>2、<strong>对话管理</strong>(DM, meaning&amp;context)：bot需要通过历史对话中的信息来判断，此时处理方案。<br>(1) 对话跟踪(DST)：记录和更新 对话状态。用户话语中哪些 <strong>变化</strong>、<strong>值</strong> 是我们关心的，对对话处理有影响的要素记录。<br>(2) 对话策略(DP)：根据<strong>历史和当前</strong>的对话状态选择合适的对话策略。<strong>选择哪种动作</strong>(Action)和<strong>执行动作响应后作什么</strong>，和业务相关，比如查询or定业务？成功or失败后做什么决策？。<br><strong>对话策略(Policy)类型</strong>：<br>(1) 基于规则：意图为X，那么直接输出对应的动作Y。比如打招呼。<br>(2) 基于记忆：用户当前对话状态和训练数据中某个story状态完全一致时，可以使用story中后序的动作。<br>(3) 基于神经网络预测：模型分类预测，比如KerasPolicy。<br>(4) 基于编程：自定义脚本处理规则。<br>所有对话策略同时预测，按得分高低做动作。<br><strong>动作执行</strong>：把对话跟踪和对话策略的结果 发送给执行机构，得到返回结果呈现给用户。</p>
<p>3、<strong>自然语言生成</strong>(NLG)：<br>(1) 语义转成文本。绝大数情况下，可用模板解决。</p>
<p><strong>90%看不见的工作</strong>：<br>(1) 对话数据的获取：已有数据or人工造数据。<br>(2) 对话数据的扩充：样本少，数据不均衡。<br>(3) 对话数据的标注：算法实现or业务需求、长尾需求、语义歧义、方言/ASR错误识别、需求变更、无意义句子。<br>(4) 对话数据校验与清洗：错标、漏标。<br>(5) 数据和模板 版本化管理(可复现)：数据迭代(变更追踪)、算法迭代、参数迭代。<br>(6) 模型部署：字典转换、序列编码。<br>(7) 模型效果分析：模型行不行、哪里不行、为什么不行(数据or模型)、怎么解决。</p>
<p>任务型+FAQ：Rasa成熟的开源框架。<br>Rasa x：不断根据客户反馈改进模型。<br>Rasa3.0变化：<br>(1) 支持无向图，可以使用更多的模型。<br>(2) 不再支持markdown配置，改用YAML配置。<br>(3) 需要配置中新增recipe字段，如recipe: default.v1。<br>(4) 训练文件中的version:”2.0”改成version:”3.0”。<br>(5) 3.0彻底移除了2.0准备要删除的api。<br>(6) 2.0的slot mapping是在表单中定义的，现在每个slot的mapping都在slot的配置中指定，原来的slot和实体之间默认是可以进行自动填充的，现在必须显示指定。<br>(7) 原来是线性的pipeline，现在用的是有向无环图(DAG)。训练和推理的逻辑都发生了变化。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuc29odS5jb20vYS8xNjMyNzg1ODhfNTAwNjU5">KBQA从入门到放弃—入门篇<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yMzc0NTI5MTg/dXRtX3NvdXJjZT13ZWNoYXRfc2Vzc2lvbg==">实体关系、实体属性、三元组、SPO三元组及其抽取方案<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMW9yNHkxVTdYUj9zcG1faWRfZnJvbT0zMzMuMzM3LnNlYXJjaC1jYXJkLmFsbC5jbGljayZhbXA7dmRfc291cmNlPTI4MmRjNzZmNDNkNDYxY2NkN2IzM2NmMGY1ZWE2NGI1">【社区说】一起来聊聊 Rasa 3.0<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9yYXNhLmNvbS9kb2NzL3Jhc2Ev">Rasa NLU &amp; Core<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9yYXNhLmNvbS9kb2NzL2FjdGlvbi1zZXJ2ZXIv">Rasa Action Server<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9yYXNhLmNvbS9kb2NzL3Jhc2EteC8=">Rasa X<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnJhc2EuY29tLw==">Rasa Blog<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1Jhc2FIUS9yYXNh">Rasa code<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hvd2wtYW5kZXJzb24=">Rasa 开发者<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/20/NLP/05.Bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/NLP/05.Bert/" class="post-title-link" itemprop="url">Bert</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>word2vec和GloVe都将相同的预训练向量分配给同一个词，而不考虑词的上下文（如果有的话）。考虑到自然语言中丰富的多义现象和复杂的语义，上下文无关表示具有明显的局限性。这推动了“上下文敏感”词表示的发展，其中词的表征取决于它们的上下文。例如，通过将整个序列作为输入，ELMo是为输入序列中的每个单词分配一个表示的函数。具体来说，ELMo将来自预训练的双向长短期记忆网络的所有中间层表示组合为输出表示。然后，ELMo的表示将作为附加特征添加到下游任务的现有监督模型中，例如通过将ELMo的表示和现有模型中词元的原始表示（例如GloVe）连结起来。一方面，在加入ELMo表示后，冻结了预训练的双向LSTM模型中的所有权值。另一方面，现有的监督模型是专门为给定的任务定制的。利用当时不同任务的不同最佳模型，添加ELMo改进了六种自然语言处理任务的技术水平：情感分析、自然语言推理、语义角色标注、共指消解、命名实体识别和问答。</p>
<p>尽管ELMo显著改进了各种自然语言处理任务的解决方案，但每个解决方案仍然依赖于一个特定于任务的结构。然而，为每一个自然语言处理任务设计一个特定的结构实际上并不是一件容易的事。GPT（Generative Pre Training）模型为上下文的敏感表示设计了通用的任务无关模型。GPT建立在Transformer解码器的基础上，预训练了一个用于表示文本序列的语言模型。当将GPT应用于下游任务时，语言模型的输出将被送到一个附加的线性输出层，以预测任务的标签。与ELMo冻结预训练模型的参数不同，GPT在下游任务的监督学习过程中对预训练Transformer解码器中的所有参数进行微调。GPT在自然语言推理、问答、句子相似性和分类等12项任务上进行了评估，并在对模型结构进行最小更改的情况下改善了其中9项任务的最新水平。</p>
<p>然而，由于语言模型的自回归特性，GPT只能向前看（从左到右）。在“i went to the bank to deposit cash”（我去银行存现金）和“i went to the bank to sit down”（我去河岸边坐下）的上下文中，由于“bank”对其左边的上下文敏感，GPT将返回“bank”的相同表示，尽管它有不同的含义。</p>
<p>BERT：把两个最好的结合起来。ELMo对上下文进行双向编码，但使用特定于任务的结构；而GPT是任务无关的，但是从左到右编码上下文。BERT（来自Transformers的双向编码器表示）结合了这两个方面的优点。它对上下文进行双向编码，并且对于大多数的自然语言处理任务，只需要最少的结构改变。通过使用预训练的Transformer编码器，BERT能够基于其双向上下文表示任何词元。在下游任务的监督学习过程中，BERT在两个方面与GPT相似。首先，BERT表示将被输入到一个添加的输出层中，根据任务的性质对模型结构进行最小的更改，例如预测每个词元与预测整个序列。其次，对预训练Transformer编码器的所有参数进行微调，而额外的输出层将从头开始训练。</p>
<h1 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h1><p>1、将预训练模型用于下游任务有两种策略：</p>
<ul>
<li>基于微调的策略。如 GPT，通过简单微调预训练模型的参数来训练下游任务。该策略在预训练期间通过单向语言模型来学习通用语言representation，而单向语言模型严重限制了预训练模型的表达能力。例如，在token 级别的任务（如：词性标注任务），结合两个方向的上下文对模型性能非常重要。</li>
<li>基于特征的策略。如 ELMo ，将预训练模型的representation 作为下游任务模型的额外特征。该策略虽然是双向语言模型，但是该模型是浅层的。</li>
</ul>
<p>与它们不同，BERT是一个<strong>同时利用了左右双向上下文的、深度的</strong>预训练模型，它在11项 nlp 任务中取得最领先的结果。</p>
<p>2、基于特征的方法具有一定优势：</p>
<ul>
<li>并不是所有的 NLP 任务都可以很容易地用 Transformer encoder 架构来表示，因此需要添加特定于任务的模型架构。</li>
<li>如果通过训练数据预先计算一次昂贵的数据表示，然后在该表示的基础上用廉价的模型来完成许多任务，这会带来很大的计算优势。</li>
</ul>
<p>3、单向语言模型可以是从左到右 Left to Right:LTR 或者从右到左 Right to Left :RTL 。BERT 也可以像 ELMO 一样训练独立的 LTR 和 RTL 模型后拼接在一起，但是这么做有两个问题：</p>
<ul>
<li>其训练代价是单个双向模型的两倍。</li>
<li>对于Question - Answer 之类的问题是反直觉的，因为 RTL 模型需要根据答案来反推问题。</li>
<li>BERT 可以自由的组合左侧上下文和右侧上下文。</li>
</ul>
<p>4、BERT 预训练模型包含两个预训练任务：预测被屏蔽的单词、预测下一个句子是否和上一个句子相接。</p>
<p>5、BERT 的预训练语料库必须使用 document-level的语料库，而不是经过混洗的 sentence-level 的语料库。因为混洗句子会破坏句子预测预训练任务。这里的 “句子” 不一定是真实的句子，而是一段话或者几段话，代表了一个 token 序列。</p>
<ul>
<li>BERT 预训练时，每个 ”句子“ 的 token 长度小于等于 512 。</li>
<li>BERT 的训练语料库经过了 WordPiece 词干化。如：engineer-&gt;engine er</li>
</ul>
<p>6、BERT 预训练采用 gelu 激活函数，训练一百万步，bath size = 256 。</p>
<h2 id="MLM"><a href="#MLM" class="headerlink" title="MLM"></a>MLM</h2><p>1、受完形填空任务启发，BERT 通过提出一个新的预训练目标来解决前面提到的单向限制：掩码语言模型masked language model:MLM 。</p>
<p>2、从直觉上，深度双向模型要比深度单向模型、单层双向模型表达能力更强。</p>
<ul>
<li>标准的条件语言模型只能从左到右或者从右到左训练，因为双向条件作用允许每个单词在多层上下文中间接“看到自己”。</li>
<li>MLM 模型从输入中随机屏蔽一些token，目标是基于上下文预测被屏蔽单词。方法是：将被屏蔽的单词替换为 [MASK] 标记，然后被屏蔽的单词作为真实 label 。</li>
<li>与单向语言模型不同，MLM 结合了左右两侧上下文。</li>
</ul>
<p>3、为了训练 MLM，模型随机屏蔽一定百分比（论文中为 15%）的 token，然后仅预测那些被屏蔽的 token 。这种方式有两个缺陷：</p>
<ul>
<li>预训练和微调之间的不匹配。因为在微调阶段，模型永远不会看到 [MASK] 标记。</li>
<li>为了缓解这种状况，MLM 在预训练时并不总是用真的 [MASK] 标记，而是从输入种随机选择 15% 的 token：80% 替换未 [MASK] 标记，10% 替换为一个随机单词，10% 保持原样。</li>
<li>MLM 并不知道哪些词被替换，因此它总是努力的学习每个单词的正确表达。</li>
<li>每个 batch 预测的 token 只有 15%，这意味着模型需要更多的训练步才可能收敛。实验证明MLM 的收敛速度确实比单向语言模型稍慢，但是相对于 MLM 的泛化能力的提升，这种代价是值得的。</li>
</ul>
<h2 id="NSP"><a href="#NSP" class="headerlink" title="NSP"></a>NSP</h2><p>许多重要的下游任务，如：知识问答和自然语言推理，都是基于理解两个句子之间的关系，而这种关系不是由语言模型直接捕获的。<br>为了训练理解句子关系的模型，BERT 训练一个二元化的句子预测任务，称作Next Sentence Prediction:NSP：</p>
<ul>
<li>每个训练样本由一对句子 A 和 B 组成：50% 的样本中 B 是紧跟在 A 之后的句子，50%的样本中二者是随机挑选的。</li>
<li>模型需要预测的是： B 是否是 A 的下一个句子？</li>
</ul>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>1、参考Transformer的encoder部分，Bert是一个多层双向Transformer编码器。双向 self-attention 的 Transformer 也称作 Transformer encoder，而单向 self-attention 的 Transformer 被称作 Transformer decoder 。</p>
<p>2、作者指明L表示层数，H表示每个隐藏单元的维数大小，A表示self-attention头数。BERT有2种大小的模型，分别是BERT_base(L=12, H=768, A=12, Total Parameters=110M)、BERT_large(L=24, H=1024, A=16, Total Parameters=340M)。BERT_base设定为和OpenAI GPT的模型大小相同，以便作比较。需要重点说明的是，BERT Transformer使用双向self-attention，而GPT Transformer 使用带约束的self-attention，每个token只能注意到它左边的上下文。</p>
<p>3、BERT 的模型输入能够表达单个句子或者一对句子。</p>
<ul>
<li>每个 token 的输入 representation 由三个部分相加而成：token embedding、segment embedding、position embedding 。</li>
<li>每个序列的第一个 token 是一个特殊的[CLS]。网络最后一层对应于该位置的一个隐向量作为整个序列的 representation 来用于分类任务。对于非分类任务，该隐向量被忽略。</li>
<li>如果是一对句子，则在句子之间插入特殊的 token：[SEP] 。然后对句子的前后关系学习一个segment embedding，通过这种方式，模型得以学习和区分两个句子的前后关系：<ul>
<li>前一个句子的每个 token 学习和使用 A embedding，代表前后关系的 “前关系” 的表达。</li>
<li>后一个句子的每个 token 学习和使用 B embedding，代表前后关系的 “后关系” 的表达。</li>
</ul>
</li>
<li>对于单个句子，模型仅学习和使用 A embedding 。</li>
<li>position embedding 是模型学习和使用的 input 每个绝对位置的表达。这里不是正弦+余弦方式，而是参数化方式。</li>
<li>token embedding 是模型学习和使用的每个 token 的表达。</li>
</ul>
<p><img src="/images/Bert/1.png" width="90%"></p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>从input(2种)和output(4种)看：</p>
<ul>
<li>input：<ul>
<li>one sentence：输入为1个句子。</li>
<li>multiple sentences：输入为多个句子，用[SEP]分隔。</li>
</ul>
</li>
<li>output：<ul>
<li>one class：[CLS]预训练后的向量输入全连接层，直接判断分类结果（当然，你也可以输入sentence全部向量）。</li>
<li>class for each token：输入的每个token经过预训练后的向量输入全连接层，对每个token分类。</li>
<li>copy from input：经典Q-A问题，这里设计时使用限制的QA(Answer必须在document中)，输入2个向量（代表Answer在document的起始-结束位置），和预训练（输入Question+document）后的document token向量点积+softmax，取最大值token位置即可。</li>
<li>general sequence：作为seq2seq的encoder、作为encoder+decoder（decoder应使用单向Transformer）。</li>
</ul>
</li>
</ul>
<h1 id="如何fine-tune？"><a href="#如何fine-tune？" class="headerlink" title="如何fine-tune？"></a>如何fine-tune？</h1><ol>
<li>固定Bert参数，只训练全连接层。</li>
<li>Bert+全连接层 全部一起训练。</li>
<li>Adaptor：对Bert中添加一部分Layer，训练时只调整这些Layer参数。</li>
</ol>
<p><strong>warmup</strong>：学习率热身。<strong>规定前多少个热身步骤内，对学习率采取逐步递增的过程</strong>。热身步骤之后，会对学习率采用衰减策略。这样训练初期可以避免震荡，后期可以让loss降得更小。<strong>warmup抑制Layer Normalization对学习率参数的敏感度。</strong></p>
<p>除了 batch size、学习率、训练 epoch 不同之外，<strong>其它训练参数与预训练阶段的训练参数相同</strong>。fine-tune阶段通常很快，因此建议<strong>对超参数进行彻底搜索</strong>并选择在验证集上表现最好的模型。<br>论文发现：数据集越小，模型性能对超参数的选择越敏感。大数据集（超过10万的标记样本）对超参数的敏感性要低的多。</p>
<p>对于文本分类，详情参考<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDU1ODMucGRm">How to Fine-Tune BERT for Text Classification?<i class="fa fa-external-link-alt"></i></span>。<br>BERT在NLP任务中效果十分优秀，这篇文章对于BERT在文本分类的应用上做了非常丰富的实验，介绍了一些调参以及改进的经验，进一步挖掘BERT的潜力。</p>
<ul>
<li>微调（fin-tune）策略<ul>
<li>对于长文本，尝试了（1）取头部510 tokens（2）尾部510 tokens（3）头部128 tokens + 尾部382 tokens（4）分片并进行最大池化、平均池化、attention。发现方法（3）最好。因为文章的关键信息一般在开头和结尾。</li>
<li>分层训练，上层对文本分类更加重要。</li>
<li>灾难性遗忘：在下游finetune可能会遗忘预训练的知识。需要设置较小的学习率，如2e-5.</li>
<li>分层衰减学习率（Layer-wise Decreasing Layer Rate），对下层设置更小的学习率可以得到更高的准确率，在lr=2e-5，衰减率$\xi$=0.95</li>
</ul>
</li>
<li>继续预训练（Further Pretraining）<ul>
<li>任务内（within-task） 和同领域（in-domain）的继续预训练可以大大提高准确率，In-domain比within-task要好。</li>
</ul>
</li>
<li>多任务微调（Multi-task Finetuning）<ul>
<li>在单任务微调之前的多任务微调有帮助，但是提升效果小于Further pretraining。</li>
</ul>
</li>
<li>小数据集<ul>
<li>BERT对小数据集提升很大，这个大家都知道的。Further pretraining对小数据集也有帮助。</li>
</ul>
</li>
</ul>
<h1 id="Bert变种"><a href="#Bert变种" class="headerlink" title="Bert变种"></a>Bert变种</h1><h2 id="BERT-WWM"><a href="#BERT-WWM" class="headerlink" title="BERT-WWM"></a>BERT-WWM</h2><p><strong>BERT-WWM</strong>：始版本的 BERT 采用了WordPiece tokenize 来预处理，即把每个单词拆解一些 WordPiece token（比如，loved-&gt;lov ed） ，最初是为了解决谷歌语音识别系统遇到的日语/韩语分割问题。该模型是数据驱动，并且确保任何可能的字符序列的确定性分割。这种预处理为 BERT 带来一个严重的问题：<strong>有可能仅仅对一个单词的某个部分 wordpiece token 执行了 mask。此时 MLM 模型预测的只是单词的一部分，相当于模型对一个错误的目标进行预测。这非常不利于模型的学习</strong>。有鉴于此，谷歌后续发布了 BERT 的 Whole Word Masking:WWM 版本 <strong>BERT-WWM</strong>。在该版本中，一个单词要么没有被 mask、要么该单词所有的 workpiece token 都被 mask 。类似的想法还有ERNIE模型的phrase-level mask和entity-level mask。</p>
<p><strong>BERT-wwm-ext</strong>：是 BERT-WWM 的中文版本(哈工大讯飞联合实验室发布)，该模型对中文的<strong>整个单词</strong>而不是单个字进行mask ，在最新的中文维基百科上训练。</p>
<h2 id="ERNIE"><a href="#ERNIE" class="headerlink" title="ERNIE"></a>ERNIE</h2><p><strong>ERNIE</strong>：BERT 的 MLM 任务在执行 mask 的时候，未能考虑先验知识，如果有学习到与Mask的单词相关的先验知识，则无需借助很长的上下文就可以很容易的预测出Mask的单词。但是 ERNIE 并没有直接添加先验知识，而是通过引入 <strong>entity-level mask</strong> 和 <strong>phrase-level mask</strong> 来引入先验知识，隐式的学习实体间的关系、实体的属性等知识：</p>
<ul>
<li><strong>phrase-level mask</strong>：将一个 phrase 作为一个单元，每个单元通常由几个 token 组成。在训练期间，同一个单元中的所有 token 都会被屏蔽，而不是只有一个 token 被屏蔽。</li>
<li><strong>entity-level mask</strong>：将一个 entity 作为一个单元，…。</li>
</ul>
<p>对于英语，论文使用单词分析和分块工具来获取短语的边界；对于中文，论文使用<strong>分词工具</strong>来获取词的边界。<br>命名实体 entity 包括人名、地名、组织名、产品名等。需要使用NER的方法。</p>
<p><strong>ERNIE</strong> 通过三阶段学习来学得短语或实体的先验知识：</p>
<ul>
<li>第一阶段：Basic-level masking，使用基本的掩码策略，做法与 BERT 完全相同。这个阶段是在基本语言单元的随机 mask 上训练，因此很难对高级语义知识建模。对于英文，基本语言单元是词word；对于中文，基本语言单元是汉字 char 。</li>
<li>第二阶段：Phrase-level masking，使用基本语言单元作为训练输入，但是使用 phrase-level 的掩码策略。这个阶段模型屏蔽和预测同一个短语的所有基本语言单元。</li>
<li>第三阶段：Entity-level masking，使用基本语言单元作为训练输入，但是使用 entity-level 的掩码策略。这个阶段模型屏蔽和预测同一个命名实体的所有基本语言单元 。</li>
</ul>
<p>ERNIE 编码器和 BERT 相同，但是对于中文语料，ERNIE 把 CJK 编码范围内的字符都添加空格来分隔，然后使用 WordPiece（loved-&gt;lov ed） 来对中文语句词干化，WordPiece参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vaHVhbmd5Yy9wLzEwMjIzMDc1Lmh0bWw=">一文读懂BERT中的WordPiece<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="SpanBert"><a href="#SpanBert" class="headerlink" title="SpanBert"></a>SpanBert</h2><p><strong>SpanBert</strong>：一个新的分词级别的预训练方法，提出基于Bert掩码方式，采用不同长度token不同概率的方式（越短的token概率越大）Mask。 其在现有任务中的表现优于 BERT ，并在问答、指代消解等分词选择任务中取得了较大的进展。<br>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDcuMTA1MjkucGRm">SpanBERT: Improving Pre-training by Representing and Predicting Spans<i class="fa fa-external-link-alt"></i></span></p>
<p>主要优化点：</p>
<ul>
<li>Span Masking。</li>
<li>MLM + SBO。</li>
<li>Single-Sequence Training。</li>
</ul>
<p>模型原理如图所示：<br><img src="/images/Bert/10.png" width="90%"></p>
<p><strong>Span Masking</strong><br>提出了更好的 Span Mask 方案，SpanBERT 不再对随机的单个 token 添加 mask，而是对随机对邻接分词添加mask。根据几何分布，先随机选择一段（span）的长度，之后再根据均匀分布随机选择这一段的起始位置，最后按照长度mask。作者设定几何分布取 p=0.2，并裁剪最大长度只能是 10（不应当是长度 10 以上修剪，而应当为丢弃），利用此方案获得平均采样长度分布。因此分词的平均长度为 3.8 。作者还测量了词语（word）中的分词程度，使得添加mask的分词更长。如图，展示了分词mask长度的分布情况。<br><img src="/images/Bert/11.png" width="40%"><br>和在 BERT 中一样，作者将 Y 的规模设定为 X 的15%，其中 80% 使用 [MASK] 进行替换，10% 使用随机单词替换，10%保持不变。与之不同的是，作者是在分词级别进行的这一替换，而非将每个单词单独替换。</p>
<p>不同mask方案对比：<br><img src="/images/Bert/17.png" width="80%"></p>
<p><strong>SBO</strong><br>Span Boundary Objective。分词选择模型一般使用其边界词创建一个固定长度的分词表示。为了于该模型相适应，作者希望结尾分词的表示的总和与中间分词的内容尽量相同。为此，作者引入了 SBO ，其仅使用观测到的边界词来预测带msak的分词的内容。</p>
<p>具体做法是，在训练时取 Span 前后边界的两个词，值得指出，这两个词不在 Span 内，然后用这<strong>两个词向量</strong>加上 Span 中被mask掉词的<strong>位置向量</strong>，来预测当前被mask的词。详细做法是将<strong>词向量</strong>和<strong>位置向量</strong>拼接起来，作者使用一个两层的前馈神经网络作为表示函数，该网络使用 GeLu 激活函数，并使用层正则化。和 MLM 一样使用交叉熵作为损失函数，就是 SBO 目标的损失，之后将这个损失和 BERT 的 MLM 的损失加起来，一起用于训练模型。<br><img src="/images/Bert/14.png" width="20%"><br><img src="/images/Bert/12.png" width="30%"><br><img src="/images/Bert/13.png" width="30%"></p>
<p><strong>Single-Sequence Training</strong><br>没有segment embedding，只有一个长的句子，类似RoBERTa。它没用 Next Sentence Prediction (NSP) 任务，而是直接用 Single-Sequence Training，也就是根本不加入 NSP 任务来判断是否两句是上下句，直接用一句来训练。作者推测其可能原因如下：（a）更长的语境对模型更有利，模型可以获得更长上下文（类似 XLNet 的一部分效果；（b）加入另一个文本的语境信息会给MLM 语言模型带来噪音。</p>
<p>因此，SpanBERT 就没采用 NSP 任务，仅采样一个单独的邻接片段，该片段长度最多为512个单词，其长度与 BERT 使用的两片段的最大长度总和相同，然后 MLM 加上 SBO 任务来进行预训练。</p>
<p>其中主要训练细节是：</p>
<ul>
<li>训练时用了 Dynamic Masking 而不是像 BERT 在预处理时做 Mask；</li>
<li>取消 BERT 中随机采样短句的策略；</li>
<li>对 Adam 优化器中一些参数改变。</li>
</ul>
<p><img src="/images/Bert/17.png" width="80%"></p>
<p>实验结果：<br><img src="/images/Bert/15.png" width="40%"><br><img src="/images/Bert/16.png" width="80%"></p>
<h2 id="Albert"><a href="#Albert" class="headerlink" title="Albert"></a>Albert</h2><p>Albert主要对Bert参数进行优化，在任务结果下降很低的情况的下，使模型更小更适合部署。<br>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDkuMTE5NDIucGRm">ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS<i class="fa fa-external-link-alt"></i></span></p>
<p>主要优化点：</p>
<ul>
<li>Token Embedding projection block<ul>
<li>Parameter size $O(V \times E)$ </li>
</ul>
</li>
<li>Attention feed-forward block<ul>
<li>Parameter size $O(12 \times L \times H \times H)$</li>
</ul>
</li>
</ul>
<p><strong>优化一：Embedding维度分解</strong><br>Token Embedding 采用 $O(V\times E + E \times H)$ 且 $E \ll H$。由于模型结构的限制，WordePiece embedding的大小 $E$ 总是与隐层大小 $H$ 相同。从建模的角度考虑，词嵌入学习的是单词与上下文无关的表示，而隐层则是学习与上下文相关的表示。显然后者更加复杂，需要更多的参数，也就是说模型应当增大隐层大小 $H$ ，或者说满足 $H \gg E$ 。但实际上词汇表的大小 $V$ 通常非常大，如果 $E=H$ 的话，增加隐层大小 $H$ 后将会使embedding matrix的维度 $V \times E$ 非常巨大。</p>
<p>因此Albert想要打破 $E$ 与 $H$ 之间的绑定关系，从而减小模型的参数量，同时提升模型表现。具体做法是将embedding matrix分解为两个大小分别为 $V \times E$ 和 $E \times H$ 矩阵，也就是说先将单词投影到一个低维的embedding空间 $E$ ，再将其投影到高维的隐藏空间 $H$ 。这使得embedding matrix的维度从 $O(V \times E)$ 减小到 $O(V\times E + E \times H)$ 。当 $E \ll H$ 时，参数量减少非常明显。在实现时，随机初始化 $V \times E$ 和 $E \times H$ 两个矩阵，计算某个单词的表示需用一个单词的one-hot向量乘以 $V \times E$ 维的矩阵（也就是lookup），再用得到的结果乘 $E \times H$ 维的矩阵即可。两个矩阵的参数通过模型学习。</p>
<p>从下图实验结果可见，对于不共享参数的情况， $E$ 几乎是越大越好；而共享参数之后， $E$ 太大反而会使模型表现变差， $E=128$ 模型表现最好，因此ALBERT的默认参数设置为此。<br><img src="/images/Bert/2.png" width="90%"></p>
<p><strong>优化二：层权重共享</strong><br>另一个减少参数量的方法就是层之间的参数共享，即多个层使用相同的参数。因为attention-feedforward操作是重复的，都是自注意力机制，所以考虑使用相同的权重来减少参数量，使得block参数变为$O(12 \times  H \times H)$。</p>
<p>参数共享有三种方式：</p>
<ul>
<li>只共享feed-forward network的参数。</li>
<li>只共享attention的参数。</li>
<li>共享全部参数。</li>
</ul>
<p>ALBERT默认是共享全部参数的，在后续实验结果中我们可以看到几种方式的模型表现。</p>
<p>如下图所示，实验表明加入参数共享之后，每一层的输入embedding和输出embedding的L2距离和余弦相似度都比BERT稳定了很多，ALBERT 的结果更加平滑。这证明参数共享能够使模型参数更加稳定。<br><img src="/images/Bert/3.png" width="90%"></p>
<p>如下图所示，可以看出参数共享几乎也是对模型结果有负面影响的。但是考虑到其能够大幅削减参数量，并且对结果影响不是特别大，因此权衡之下选择了参数共享。<br><img src="/images/Bert/4.png" width="90%"></p>
<p><strong>优化三：SOP替代NSP</strong><br>除了减少模型参数外，本外还对BERT的预训练任务<strong>Next-sentence prediction</strong>(NSP)进行了改进。在BERT中，NSP任务的正例是文章中连续的两个句子，而负例则是从两篇文档中各选一个句子构造而成。在先前的研究中，已经证明NSP是并不是一个合适的预训练任务。本文推测其原因是模型在判断两个句子的关系时不仅考虑了两个句子之间的连贯性（coherence），还会考虑到两个句子的话题（topic）。而两篇文档的话题通常不同，模型会更多的通过话题去分析两个句子的关系，而不是句子间的连贯性，这使得NSP任务变成了一个相对简单的任务。</p>
<p>因此本文提出了<strong>Sentence-order prediction</strong>(SOP)来取代NSP。具体来说，其正例与NSP相同，但负例是通过选择一篇文档中的两个连续的句子并将它们的顺序交换构造的。这样两个句子就会有相同的话题，模型学习到的就更多是句子间的连贯性。</p>
<p>如下图实验结果所示，如果不使用NSP或SOP作为预训练任务的话，模型在NSP和SOP两个任务上表现都很差；如果使用NSP作为预训练任务的话，模型确实能很好的解决NSP问题，但是在SOP问题上表现却很差，几乎相当于随机猜，因此说明NSP任务确实很难学到句子间的连贯性；而如果用SOP作为预训练任务，则模型也可以较好的解决NSP问题，同时模型在下游任务上表现也更好。说明SOP确实是更好的预训练任务。<br><img src="/images/Bert/5.png" width="90%"></p>
<h2 id="RoBerta"><a href="#RoBerta" class="headerlink" title="RoBerta"></a>RoBerta</h2><p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDcuMTE2OTIucGRm">RoBERTa: A Robustly Optimized BERT Pretraining Approach<i class="fa fa-external-link-alt"></i></span></p>
<p>预训练模型能够显著的提升任务效果，但是不同预训练模型的比较非常困难。首先，每个预训练模型的训练成本很高，无法一一训练并进行比较。其次，不同预训练模型通常是在不同规模大小的数据集上训练的，难以评估效果的好坏是预训练模型引起的还是预训练数据引起的。最后，超参数的选择对预训练模型的表现影响很大。同一个预训练模型的不同超参数，其比较结果会有很大不同。</p>
<p>RoBERTa 主要工作是复现 BERT，然后对 BERT 的模型架构、训练目标、训练细节（如数据集大小、训练时间）的重要性进行探索，从而提出了改进方案，这个改进方案称为 RoBERTa 。主要修改：</p>
<ul>
<li>更大的 batch size</li>
<li>更多的数据、更长的预训练时间</li>
<li>移除 NSP 任务 + 使用更长的输入序列</li>
<li><strong>使用动态mask</strong></li>
<li>使用BPE方式，减少UNK单词出现次数（英文）</li>
</ul>
<p><strong>更大的 batch size</strong><br>原本的BERTbase 的batch size是256，训练1M个steps。RoBERTa的batch size为8k。为什么要用更大的batch size呢？（除了因为他们有钱玩得起外）作者借鉴了在机器翻译中，用更大的batch size配合更大学习率能提升模型优化速率和模型性能的现象，并且也用实验证明了确实Bert还能用更大的batch size。<br><img src="/images/Bert/6.png" width="40%"></p>
<p><strong>更多的数据、更长的预训练时间</strong><br>借鉴XLNet用了比Bert多10倍的数据，RoBERTa也用了更多的数据。性能确实再次彪升。当然，也需要配合更长时间的训练。<br><img src="/images/Bert/8.png" width="80%"></p>
<p><strong>移除 NSP 任务 + 使用更长的输入序列</strong><br>原本的Bert为了捕捉句子之间的关系，使用了NSP任务进行预训练，就是输入一对句子A和B，判断这两个句子是否是连续的。在训练的数据中，50%的B是A的下一个句子，50%的B是随机抽取的。</p>
<p>而RoBERTa去除了NSP，而是每次输入连续的多个句子，直到最大长度512（可以跨文章）。这种训练方式叫做（FULL - SENTENCES），而原来的Bert每次只输入两个句子。实验表明在MNLI这种推断句子关系的任务上RoBERTa也能有更好性能。<br><img src="/images/Bert/7.png" width="80%"></p>
<p><strong>使用动态mask</strong><br>原来Bert对每一个序列随机选择15%的Tokens替换成[MASK]，为了消除与下游任务的不匹配，还对这15%的Tokens进行（1）80%的时间替换成[MASK]；（2）10%的时间不变；（3）10%的时间替换成其他词。但整个训练过程，这15%的Tokens一旦被选择就不再改变，也就是说从一开始随机选择了这15%的Tokens，之后的N个epoch里都不再改变了。这就叫做静态Masking。</p>
<p>而RoBERTa一开始把预训练的数据复制10份，每一份都随机选择15%的Tokens进行Masking，也就是说，同样的一句话有10种不同的mask方式。然后每份数据都训练N/10个epoch。这就相当于在这N个epoch的训练中，每个序列的被mask的tokens是会变化的。这就叫做动态Masking。</p>
<p>那么这样改变是否真的有效果？作者在只将静态Masking改成动态Masking，其他参数不变的情况下做了实验，动态Masking确实能提高性能。<br><img src="/images/Bert/9.png" width="40%"></p>
<p><strong>使用BPE方式</strong><br>针对的是英文，BERT原型使用的是 character-level BPE vocabulary of size 30K, RoBERTa使用了GPT2的 byte BPE 实现，使用的是byte而不是unicode characters作为subword的单位。</p>
<p>这些针对Bert的预训练优化都使用起来，最终在GLUE, RACE, SQuAD上都达到了SOTA的性能。</p>
<p>RoBERTa 采用 160 G 训练文本，远超 BERT 的 16G 文本，其中包括：</p>
<ul>
<li>BOOKCORPUS 和英文维基百科：原始 BERT 的训练集，大小 16GB 。</li>
<li>CC-NEWS：包含2016年9月到2019年2月爬取的6300万篇英文新闻，大小 76 GB（经过过滤之后）。</li>
<li>OPENWEBTEXT：从 Reddit 上共享的 URL （至少3个点赞）中提取的网页内容，大小 38 GB 。</li>
<li>STORIES：CommonCrawl 数据集的一个子集，包含 Winograd 模式的故事风格，大小 31GB 。</li>
</ul>
<h2 id="SBERT"><a href="#SBERT" class="headerlink" title="SBERT"></a>SBERT</h2><p>虽然BERT和RoBERTa在很多句子对形式的回归任务（例如文本语义相似度）上达到了SOTA效果，但是它们还存在一些缺点：在这些任务中，它们均需要将比较的两个句子都传入到模型中计算，计算开销过大。BERT模型在一个1W句子集合中，找出最相近的一个句子对，需要5千万次推断计算（约65小时）才能完成，所以BERT并不适合语义相似度搜索等任务。</p>
<p>在该论文中，作者提出了一个新的模型，Sentence-BERT（简称SBERT）。SBERT采用双重或三重BERT网络结构，具体结构介绍会在后文中详细介绍。如果使用的是基于RoBERTa模型，则改造后的模型简称为SRoBERTa。</p>
<p>通过SBERT模型获取到的句子embedding，可以直接通过cos相似度计算两个句子的相似度，这样就大大减少了计算量。因为在使用BERT模型进行句子间相似度的判断时，需要从句子集合中，选出两个句子进行组合，传入BERT中进行计算，而使用SBERT模型，只需要将集合中每个句子单独传入到模型中，得到每个句子的embeding，计算相似度只需要使用cos函数计算两两embeding的cos距离即可。因此，使用BERT/RoBERTa模型需要65h才能完成的寻找最相似句子对任务，SBERT模型完成仅需5s。</p>
<p>作者在一些STS任务和迁移学习任务上评估SBERT模型，该模型达到了新的SOTA水平。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDguMTAwODQucGRm">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。<br>模型地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2JlcnQubmV0Lw==">Sentence-Transformers<i class="fa fa-external-link-alt"></i></span>。<br>详解参考：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Zlbmd4aW5saW51eC9hcnRpY2xlL2RldGFpbHMvMTA5MTk1NzYy">论文阅读Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h2><p><strong>XLNet</strong>：使用Transformer-XL模型。</p>
<p>当Bert作为seq2seq的encoder时，输入也要Mask：</p>
<ul>
<li>随机Mask。</li>
<li>删除Delete。</li>
<li>多个句子，换顺序Permuttion。</li>
<li>打乱token，比如后面词放在前面。</li>
<li>插入Mask，Text Infilling。这个效果最好。</li>
</ul>
<h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2><p>只使用Transformer-Decoder端进行序列生成(预测下一个词)。<br>训练使用Few-shot Learning：先给出问题描述和部分示例学习，再给出prompt(引子/问题)，能给出解答。<br>训练时只给出一个示例(one-shot)或不给示例(zero-shot)进行学习。</p>
<p>GPT-2的学习目标是使用无监督的预训练模型做有监督的任务。作者认为，当一个语言模型的容量足够大时，它就足以覆盖所有的有监督任务，也就是说所有的有监督学习都是无监督语言模型的一个子集。GPT-2去掉了fine-tuning层。</p>
<p>GPT-3沿用了GPT-2的结构，但是在网络容量上做了很大的提升。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNTAwMTc0NDM=">词向量之GPT-1，GPT-2和GPT-3<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yMDA5Nzg1Mzg=">GPT-3阅读笔记：Language Models are Few-Shot Learners<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="MASS"><a href="#MASS" class="headerlink" title="MASS"></a>MASS</h2><p>MASS针对的是seq2seq任务。<br>MASS在encoder端对句子随机mask一个长度为k的连续片段，然后通过decoder预测生被mask片段。<br>mask方式：随机删除、打乱词序、旋转词序、插入mask等方式。</p>
<h2 id="UniLM"><a href="#UniLM" class="headerlink" title="UniLM"></a>UniLM</h2><p>UniLM 1.0通过设计不同掩码，支持4种不同的训练目标：从左往右单向LM，从右往左单向LM，双向LM，序列到序列LM。<br>UniLM 2.0支持更多样的factorization order且无需重复构建训练实体。训练时部分自回归使用pseudo mask LM (PMLM)，直译为伪掩码，作为部分自回归训练时占位符，和自编码的<code>[M]</code>任务作为区分。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMjI5OTkxNTM=">微软统一预训练语言模型UniLM 2.0解读<i class="fa fa-external-link-alt"></i></span></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE4MTAuMDQ4MDU=">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDU1ODMucGRm">How to Fine-Tune BERT for Text Classification?<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xNTE5MTgw">BERT论文解读<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmRpX2h1c3QvYXJ0aWNsZS9kZXRhaWxzLzEwNDQ2NTMzNw==">【调优方法】——warmup<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpb24xOTkzMDkyNC9hcnRpY2xlL2RldGFpbHMvMTA0NDY5OTQ0">Bert微调技巧实验大全-How to Fine-Tune BERT for Text Classification<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84NzU2MjkyNg==">【论文阅读】ALBERT<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9lZGRmMDRiYTg1NDU=">改进版的RoBERTa到底改进了什么？<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvTUhtN0F4bWN1RWdGUl9vTmJOcUZrUQ==">BERT模型的优化改进方法！<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/19/NLP/04.Transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/19/NLP/04.Transformer/" class="post-title-link" itemprop="url">Transformer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-19 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-19T00:00:00+08:00">2021-07-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>论文中的 Transformer 架构包含了 encoder 和 decoder 两部分，其架构如下图所示。<br><img src="/images/Transformer/1.png" width="60%"></p>
<ul>
<li>编码器 encoder 包含一组 6 个相同的层 Layer(layer间串行连接) ，每层包含两个子层 SubLayer。<ul>
<li>第一个子层是一个多头自注意力 multi-head self-attention 层。</li>
<li>第二个子层是一个简单的全连接层。</li>
<li>每个子层都使用残差直连，并且残差直连之后跟随一个layer normalization。</li>
<li>假设子层的输入为 $h$，则经过 LN 之后整体的输出为 $LayerNorm(h+Sublayer(h))$ 。为了 Add 直连，论文将内部所有层的输入、输出的向量维度设置为512维。</li>
</ul>
</li>
<li>解码器 decoder 也包含一组 6 个相同的层 Layer，但是每层包含三个子层 SubLayer 。<ul>
<li>第一个子层也是一个多头自注意力 multi-head self-attention 层。但是，在计算位置 $i$ 的 self-attention 时屏蔽掉了位置 $i$ 之后的序列值，这意味着：位置 $i$ 的 attention 只能依赖于它之前的结果，不能依赖它之后的结果。因此，这种 self-attention 也被称作 masked self-attention。</li>
<li>第二个子层是一个多头注意力multi-head attention 层，用于捕获 decoder output 和 encoder output 之间的 attention 。</li>
<li>第三个子层是一个简单的全连接层。</li>
<li>和 encoder 一样：每个子层都使用残差直连，并且残差直连之后跟随一个layer normalization:LN 。decoder 所有层的输入、输出的向量维度也是512维。</li>
</ul>
</li>
</ul>
<h1 id="attention"><a href="#attention" class="headerlink" title="attention"></a>attention</h1><p>编码器和解码器的 attention 都是采用 scaled dot attention (点积)。计算点积后除以 $\sqrt{d_k}$ 是为了降低 $score$ 的数值，防止它落入到 softmax 函数的饱和区间，因为 softmax 函数的饱和区梯度几乎为 0 ，容易发生梯度消失。</p>
<p>一组多个attention 的效果要优于单个 attention，这称作multi-head attention 。将整个 attention 空间拆分成多个 attention 子空间，最后将多个 head 的输出进行拼接，并再经过一个线性映射即可得到多头attention的结果。线性映射目的是确保 multi-head attention 前后的输入输出维度一致。论文中选择 attention 都为512维，为了保证 multi-head attention 的表达空间与 single-head attention 一致。<br>multi-head attention表达能力更强，相当于在整体计算代价几乎保持不变的条件下，引入了更多的非线性从而增强了模型的表达能力。。</p>
<p>在论文中，有三种方式使用多头注意力机制：</p>
<ul>
<li>encoder-decoder attention：query 来自前一个 decoder 层的输出，keys,values 来自 encoder 的输出。其意义是： decoder 的每个位置去查询它与 encoder 的哪些位置相关，并用 encoder 的这些位置的 value 来表示。</li>
<li>encoder self-attention：query,key,value 都来自前一层 encoder 的输出。这允许 encoder 的每个位置关注 encoder 前一层的所有位置。</li>
<li>decoder masked self-attention：query,key,value 都来自前一层 decoder 的输出。这允许 decoder 的每个位置关注 decoder 前一层的、在该位置之前的所有位置。</li>
</ul>
<h1 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h1><p>encoder 和 decoder 还包含有全连接层。对 encoder/decoder 的每个 attention 输出，全连接层通过一个 ReLU 激活函数和一个线性映射。</p>
<p>对于同一个 multi-head attention 的所有输出，采用相同的参数；对于不同的 multi-head attention 的输出，采用不同的参数。</p>
<p>输入和输出的维度保持为512，但是中间向量的维度是2048，这是为了扩充中间层的表示能力，从而抵抗 ReLU 带来的表达能力的下降。</p>
<h1 id="embedding-层"><a href="#embedding-层" class="headerlink" title="embedding 层"></a>embedding 层</h1><p>网络涉及三个 embedding 层：</p>
<ul>
<li>encoder 输入 embedding 层：将 encoder 输入 token 转化为512维的向量。</li>
<li>decoder 输入 embedding 层：将 decoder 输入 token 转化为512维的向量。</li>
<li>decoder 输出 embedding 层：将 decoder 输出 token 转化为512维的向量。</li>
</ul>
<p>在论文中这三个 embedding 矩阵是共享的，并且论文中在 embedding 层将该矩阵乘以一个常量 $\sqrt{d_{model}}$  来放大每个权重。</p>
<h1 id="position-embedding"><a href="#position-embedding" class="headerlink" title="position embedding"></a>position embedding</h1><p>从 attention 的计算公式可知：调整输入的顺序对 attention 的结果没有任何影响，attention 的输出中不包含任何顺序信息。<br>论文通过将位置编码添加到 encoder 和 decoder 底部的输入 embedding 来解决问题。对于同一个输入序列如果打乱序列顺序，则不同 token 的 attention 权重发生改变使得 attention 的结果不同。</p>
<p>位置编码有两种选择：</p>
<ul>
<li><strong>functional(函数式)</strong>：论文中使用 <strong>正弦+余弦</strong> 方式设定position embedding。<ul>
<li>不同的维度对应不同的波长的正弦曲线，波长从 $2\pi$ 到 $2000\pi$ 。</li>
<li>选择这样的函数是因为：不同位置之间的embedding 可以简单的相互表示。这意味着模型可以捕获到位置之间的相对位置关系。</li>
</ul>
</li>
<li><strong>parametric(参数式)</strong>：可以自己学习，比如bert。</li>
</ul>
<h1 id="补充阅读"><a href="#补充阅读" class="headerlink" title="补充阅读"></a>补充阅读</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDIuMDQ3NDU=">On Layer Normalization in the Transformer Architecture<i class="fa fa-external-link-alt"></i></span>：<br>我们知道，在原始的Transformer中，Layer Norm在跟在Residual之后的，我们把这个称为Post-LN Transformer。</p>
<p>而且用Transformer调过参的也知道，Post-LN Transformer对参数非常敏感，需要很仔细地调参才能取得好的结果，比如必备的warm-up学习率策略，这会非常耗时间。<br>所以现在问题来了，为什么warm-up是必须的？能不能把它去掉？<br>本文的出发点是：既然warm-up是训练的初始阶段使用的，那肯定是训练的初始阶段优化有问题，包括模型的初始化。</p>
<p>从而，作者发现，Post-LN Transformer在训练的初始阶段，输出层附近的期望梯度非常大，所以，如果没有warm-up，模型优化过程就会炸裂，非常不稳定。<br>既然如此，本文作者尝试把LayerNorm换个位置，比如放在Residual的过程之中（称为Pre-LN Transformer），再观察训练初始阶段的梯度变化，发现比Post-LN Transformer不知道好到哪里去了，甚至不需要warm-up，从而进一步减少训练时间，这一结果的确令人震惊。</p>
<p>本文别出心裁，用实验和理论验证了Pre-LN Transformer结构不需要使用warm-up的可能性，其根源是LN层的位置导致层次梯度范数的增长，进而导致了Post-LN Transformer训练的不稳定性。<br>本文第一次将warm-up、LayerNorm、gradient和initialization联系起来，非常值得一读！</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDMuMDc4NDU=">PowerNorm: Rethinking Batch Normalization in Transformers<i class="fa fa-external-link-alt"></i></span>：<br>本文探讨了Transformer为什么使用layer normalization，为什么不用batch normalization，然后根据batch normalization出现的问题提出了power normalization代替layer normalization。<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMjY3NDkzMTE/ZnJvbV92b3RlcnNfcGFnZT10cnVl">BatchNorm在NLP任务中的问题与改进<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE3MDYuMDM3NjIucGRm">Attention is All You Need<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25vY21sL2FydGljbGUvZGV0YWlscy8xMDMwODI2MDA=">Transformer—论文翻译：Attention Is All You Need 中文版<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ubHAuc2Vhcy5oYXJ2YXJkLmVkdS8yMDE4LzA0LzAzL2F0dGVudGlvbi5odG1s">The Annotated Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cDovL2phbGFtbWFyLmdpdGh1Yi5pby9pbGx1c3RyYXRlZC10cmFuc2Zvcm1lci8=">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3Mvc05Uc3ZVamNmRVJ3VlA2RFRwLVR2QQ==">Transformer十问十答<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aC12Mi5kMmwuYWkvY2hhcHRlcl9hdHRlbnRpb24tbWVjaGFuaXNtcy9zZWxmLWF0dGVudGlvbi1hbmQtcG9zaXRpb25hbC1lbmNvZGluZy5odG1s">动手学-自注意力和位置编码<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aC12Mi5kMmwuYWkvY2hhcHRlcl9hdHRlbnRpb24tbWVjaGFuaXNtcy90cmFuc2Zvcm1lci5odG1s">动手学-Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVd2NDExaDdrTj9wPTIz">(强推)李宏毅2021春机器学习课程<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvUkx4V2V2VldIWGdYLVVjb3hEUzcwdw==">细讲 | Attention Is All You Need<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDEyMTM3OA==">【NLP】Transformer模型原理详解<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/18/Paper/03.Get%20To%20The%20Point.%20Summarization%20with%20Pointer-Generator%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/18/Paper/03.Get%20To%20The%20Point.%20Summarization%20with%20Pointer-Generator%20Networks/" class="post-title-link" itemprop="url">Get To The Point. Summarization with Pointer-Generator Networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-18T00:00:00+08:00">2021-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>把seq2seq模型应用于摘要生成时存在两个主要的问题：<br>（1）难以准确复述原文的事实细节、无法处理原文中的未登录词(OOV)；<br>（2）生成的摘要中存在重复的片段。</p>
<p>针对存在的问题提出对应解决之道，在标准seq2seq+attention的基础之上做了改进：<br>（1）采用Pointer-Generator Network（抽取+生成），在保留生成新词的同时，还可以从原文中抽取内容，促使生成更准确的摘要。<br>（2）覆盖率机制(coverage mechanism)，使用Coverage记录已经生成的内容，从而减少内容重复。</p>
<p><img src="/images/PGN/结构.png" width="90%"></p>
<h1 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h1><p>标准的seq2seq模型+Attention机制：<br>encoder使用Bi-LSTM，序列单词按顺序喂给encoder中，产生一系列编码器的隐状态 $h_i$。decoder使用LSTM，在每个时间步 $t$，接收前一个词（训练时采用teacher forcing方式，预测时是前一时刻decoder输出词），decoder隐状态为 $s_t$。Attention计算采用Bahdanau方式，但这里采用decoder的当前时刻 $t$ 的隐状态 $s_t$ 作为 query 计算attention，得到context vector 和 当前时刻的隐状态拼接后作为全连接层输入。也可使用context上一时刻隐状态作为query，但得到context vector要与输入拼接作为decoder输入(Bahdanau Attention)。</p>
<p><img src="/images/PGN/1+2.png" width="40%"></p>
<p>编码器隐藏状态的加权和，称为上下文向量（context vector） $h_t^*$。<br><img src="/images/PGN/3.png" width="30%"></p>
<p>上下文向量可以被看作是在当前时间步 $t$ 看encoder的哪些部分，与解码器隐状态 $s_t$ 拼接，通过两个线性层产生词汇分布 $P_{\text{vocab}}$。<br><img src="/images/PGN/4.png" width="40%"></p>
<p>$P_{\text{vocab}}$ 是词汇表中所有单词的概率分布，它提供了预测单词 $w$ 的最终分布。<br><img src="/images/PGN/5.png" width="30%"></p>
<p>在训练过程中，时间步长 $t$ 的损失是 $t$ 的目标词 $w_t^*$ 的负对数似然。<br><img src="/images/PGN/6.png" width="30%"></p>
<p>整个序列的损失是：<br><img src="/images/PGN/7.png" width="30%"></p>
<h1 id="Pointer-Generator-Network"><a href="#Pointer-Generator-Network" class="headerlink" title="Pointer-Generator Network"></a>Pointer-Generator Network</h1><p>通过Pointer-Generator可以从输入中复制单词，需要一个软开关 $P_{\text{gen}}$ 来融合baseline 和 Pointer-Generator。<br>根据上下文向量 $h_t^*$，解码器隐状态 $s_t$，解码器输入 $x_t$，计算得到时间步 $t$ 的生成概率 $P_{\text{gen}}\in [0,1]$。<br><img src="/images/PGN/8.png" width="40%"></p>
<p>使用软开关 $P_{\text{gen}}$ 来融合baseline 和 Pointer-Generator。需要维护一个扩展词表（extended vocabulary）表示原始词表和出现在source中的所有词汇的联合，在扩展词表上得到以下概率分布，$a_i^t$ 表示通过attention weight来确定从source中拷贝词的概率分布。因为attention weight包括了所有source中单词出现的概率，即使是原始词表中oov的词(该词在src_oov中能找到)，也能通过attention weight从source扩展词表src_oov中抽取复制。<br><img src="/images/PGN/9.png" width="40%"><br>注意，如果单词 $w$ 是原始词表OOV单词，那么 $P_{\text{vocab}}$ 一定为零，要是这个词也没出现在source中(即也没在扩展词表)，那么 $a_i^t$ 也是零。</p>
<h1 id="Coverage-mechanism"><a href="#Coverage-mechanism" class="headerlink" title="Coverage mechanism"></a>Coverage mechanism</h1><p>重复序列是一个常见问题，本文维护一个覆盖向量（coverage vector） $c^t$，它是所有先前decoder时间步的Attention值 $a_i^t$ 的累加和：<br><img src="/images/PGN/10.png" width="30%"><br>目的是用先前的注意力权重决策来影响当前注意力权重的决策（累加的某个值大代表一直关注它，要减少这个值，不让模型总关注它），这样就避免在同一位置重复，从而避免重复生成文本。</p>
<p>$c^t$ 是source中单词的分布，表示这些单词从注意力机制到目前时间步的覆盖程度。 $c^0$ 是一个零向量。覆盖向量被引入到注意力机制中：<br><img src="/images/PGN/11.png" width="40%"><br>作者认为有必要额外定义覆盖损失（coverage loss）处罚重复出现的参考位置，使注意力更分散，即对过往时刻或当前时刻受到注意力较多的单词进行惩罚：<br><img src="/images/PGN/12.png" width="35%"><br>最后融合为复合损失函数：<br><img src="/images/PGN/13.png" width="45%"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>根据评价指标来看，提升效果明显，普遍提高2个百分点。</p>
<p>作者还说了直接加coverage效果并不好，所以实际应用时采用fine-tuning训练。</p>
<p>实际使用时建议增加weight_tying和scheduled_sampling尝试效果。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE3MDQuMDQzNjgucGRm">Get To The Point: Summarization with Pointer-Generator Networks<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMjMwMDg0Ng==">Get To The Point: Summarization with Pointer-Generator Networks 译文<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/16/NLP/03.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/16/NLP/03.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/" class="post-title-link" itemprop="url">基于LSTM的机器翻译</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-16 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-16T00:00:00+08:00">2021-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><figcaption><span>utils.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> torchtext.data <span class="keyword">import</span> Field, BucketIterator</span><br><span class="line"><span class="keyword">from</span> torchtext.datasets <span class="keyword">import</span> Multi30k</span><br><span class="line"></span><br><span class="line"><span class="comment"># manual create date ( token 2 index , index to token)</span></span><br><span class="line"><span class="comment"># dataset dataloader   PADDING BATCH SHUFFLE</span></span><br><span class="line"><span class="comment"># torchtext</span></span><br><span class="line"><span class="comment"># ALLENNLP (Field)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [&quot;&lt;sos&gt;&quot; 3 ,&quot;word&quot;1 ,&quot;peace&quot; 2,&quot;&lt;eos&gt;&quot; 4 ]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    spacy_de = spacy.load(<span class="string">&#x27;de&#x27;</span>)</span><br><span class="line">    spacy_en = spacy.load(<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">    url = re.<span class="built_in">compile</span>(<span class="string">&#x27;(&lt;url&gt;.*&lt;/url&gt;)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(url.sub(<span class="string">&#x27;@URL@&#x27;</span>, text))]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(url.sub(<span class="string">&#x27;@URL@&#x27;</span>, text))]</span><br><span class="line"></span><br><span class="line">    DE = Field(tokenize=tokenize_de, include_lengths=<span class="literal">True</span>,</span><br><span class="line">               init_token=<span class="string">&#x27;&lt;sos&gt;&#x27;</span>, eos_token=<span class="string">&#x27;&lt;eos&gt;&#x27;</span>)</span><br><span class="line">    EN = Field(tokenize=tokenize_en, include_lengths=<span class="literal">True</span>,</span><br><span class="line">               init_token=<span class="string">&#x27;&lt;sos&gt;&#x27;</span>, eos_token=<span class="string">&#x27;&lt;eos&gt;&#x27;</span>)</span><br><span class="line">    train, val, test = Multi30k.splits(exts=(<span class="string">&#x27;.de&#x27;</span>, <span class="string">&#x27;.en&#x27;</span>), fields=(DE, EN))</span><br><span class="line">    DE.build_vocab(train.src, min_freq=<span class="number">2</span>)</span><br><span class="line">    EN.build_vocab(train.trg, max_size=<span class="number">10000</span>)</span><br><span class="line">    train_iter, val_iter, test_iter = BucketIterator.splits(</span><br><span class="line">            (train, val, test), batch_size=batch_size, repeat=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, val_iter, test_iter, DE, EN</span><br><span class="line"></span><br><span class="line">load_dataset(<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>model.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, embed_size, hidden_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_layers=<span class="number">1</span>, dropout=<span class="number">0.5</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        self.embed = nn.Embedding(input_size, embed_size)</span><br><span class="line">        self.gru = nn.GRU(embed_size, hidden_size, n_layers,</span><br><span class="line">                          dropout=dropout, bidirectional=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, src, hidden=<span class="literal">None</span></span>):</span>   <span class="comment">#A  ---&gt; B</span></span><br><span class="line">        embedded = self.embed(src)</span><br><span class="line">        outputs, hidden = self.gru(embedded, hidden)</span><br><span class="line">        <span class="comment"># sum bidirectional outputs</span></span><br><span class="line">        outputs = (outputs[:, :, :self.hidden_size] +</span><br><span class="line">                   outputs[:, :, self.hidden_size:])</span><br><span class="line">        <span class="keyword">return</span> outputs, hidden</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size * <span class="number">2</span>, hidden_size)</span><br><span class="line">        self.v = nn.Parameter(torch.rand(hidden_size))</span><br><span class="line">        stdv = <span class="number">1.</span> / math.sqrt(self.v.size(<span class="number">0</span>))</span><br><span class="line">        self.v.data.uniform_(-stdv, stdv)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, hidden, encoder_outputs</span>):</span></span><br><span class="line">        timestep = encoder_outputs.size(<span class="number">0</span>)</span><br><span class="line">        h = hidden.repeat(timestep, <span class="number">1</span>, <span class="number">1</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        encoder_outputs = encoder_outputs.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># [B*T*H]</span></span><br><span class="line">        attn_energies = self.score(h, encoder_outputs)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(attn_energies, dim=<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, hidden, encoder_outputs</span>):</span></span><br><span class="line">        <span class="comment"># [B*T*2H]-&gt;[B*T*H]</span></span><br><span class="line">        energy = F.relu(self.attn(torch.cat([hidden, encoder_outputs], <span class="number">2</span>)))</span><br><span class="line">        energy = energy.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B*H*T]</span></span><br><span class="line">        v = self.v.repeat(encoder_outputs.size(<span class="number">0</span>), <span class="number">1</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># [B*1*H]</span></span><br><span class="line">        energy = torch.bmm(v, energy)  <span class="comment"># [B*1*T]</span></span><br><span class="line">        <span class="keyword">return</span> energy.squeeze(<span class="number">1</span>)  <span class="comment"># [B*T]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, embed_size, hidden_size, output_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_layers=<span class="number">1</span>, dropout=<span class="number">0.2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line"></span><br><span class="line">        self.embed = nn.Embedding(output_size, embed_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout, inplace=<span class="literal">True</span>)</span><br><span class="line">        self.attention = Attention(hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size + embed_size, hidden_size,</span><br><span class="line">                          n_layers, dropout=dropout)</span><br><span class="line">        self.out = nn.Linear(hidden_size * <span class="number">2</span>, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, last_hidden, encoder_outputs</span>):</span></span><br><span class="line">        <span class="comment"># Get the embedding of the current input word (last output word)</span></span><br><span class="line">        embedded = self.embed(<span class="built_in">input</span>).unsqueeze(<span class="number">0</span>)  <span class="comment"># (1,B,N)</span></span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line">        <span class="comment"># Calculate attention weights and apply to encoder outputs</span></span><br><span class="line">        attn_weights = self.attention(last_hidden[<span class="number">-1</span>], encoder_outputs)</span><br><span class="line">        context = attn_weights.bmm(encoder_outputs.transpose(<span class="number">0</span>, <span class="number">1</span>))  <span class="comment"># (B,1,N)</span></span><br><span class="line">        context = context.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># (1,B,N)</span></span><br><span class="line">        <span class="comment"># Combine embedded input word and attended context, run through RNN</span></span><br><span class="line">        rnn_input = torch.cat([embedded, context], <span class="number">2</span>)</span><br><span class="line">        output, hidden = self.gru(rnn_input, last_hidden)</span><br><span class="line">        output = output.squeeze(<span class="number">0</span>)  <span class="comment"># (1,B,N) -&gt; (B,N)</span></span><br><span class="line">        context = context.squeeze(<span class="number">0</span>)</span><br><span class="line">        output = self.out(torch.cat([output, context], <span class="number">1</span>))</span><br><span class="line">        output = F.log_softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2Seq</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, encoder, decoder</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Seq2Seq, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, src, trg, teacher_forcing_ratio=<span class="number">0.5</span></span>):</span></span><br><span class="line">        batch_size = src.size(<span class="number">1</span>)</span><br><span class="line">        max_len = trg.size(<span class="number">0</span>)</span><br><span class="line">        vocab_size = self.decoder.output_size</span><br><span class="line">        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size))</span><br><span class="line"></span><br><span class="line">        encoder_output, hidden = self.encoder(src)</span><br><span class="line">        hidden = hidden[:self.decoder.n_layers]</span><br><span class="line">        output = Variable(trg.data[<span class="number">0</span>, :])  <span class="comment"># sos   EOS</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, max_len):</span><br><span class="line">            output, hidden, attn_weights = self.decoder(</span><br><span class="line">                    output, hidden, encoder_output)</span><br><span class="line">            outputs[t] = output</span><br><span class="line">            is_teacher = random.random() &lt; teacher_forcing_ratio</span><br><span class="line">            top1 = output.data.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            output = Variable(trg.data[t] <span class="keyword">if</span> is_teacher <span class="keyword">else</span> top1)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>train.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils <span class="keyword">import</span> clip_grad_norm</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Encoder, Decoder, Seq2Seq</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_arguments</span>():</span></span><br><span class="line">    p = argparse.ArgumentParser(description=<span class="string">&#x27;Hyperparams&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;number of epochs for train&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">32</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;number of epochs for train&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;initial learning rate&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-grad_clip&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">10.0</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;in case of gradient explosion&#x27;</span>)</span><br><span class="line">    <span class="comment"># p.add_argument(&#x27;-hidden_size&#x27;,type=int,default=10,help=&quot; the size of hidden tensor&quot;)</span></span><br><span class="line">    <span class="keyword">return</span> p.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">model, val_iter, vocab_size, DE, EN</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    pad = EN.vocab.stoi[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> b, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_iter):</span><br><span class="line">        src, len_src = batch.src</span><br><span class="line">        trg, len_trg = batch.trg</span><br><span class="line">        src = Variable(src.data, volatile=<span class="literal">True</span>)</span><br><span class="line">        trg = Variable(trg.data, volatile=<span class="literal">True</span>)</span><br><span class="line">        output = model(src, trg, teacher_forcing_ratio=<span class="number">0.0</span>)</span><br><span class="line">        loss = F.nll_loss(output[<span class="number">1</span>:].view(<span class="number">-1</span>, vocab_size),</span><br><span class="line">                               trg[<span class="number">1</span>:].contiguous().view(<span class="number">-1</span>),</span><br><span class="line">                               ignore_index=pad)</span><br><span class="line">        total_loss += loss.data.item()</span><br><span class="line">    <span class="keyword">return</span> total_loss / <span class="built_in">len</span>(val_iter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">e, model, optimizer, train_iter, vocab_size, grad_clip, DE, EN</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    pad = EN.vocab.stoi[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> b, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">        src, len_src = batch.src</span><br><span class="line">        trg, len_trg = batch.trg</span><br><span class="line">        src, trg = src, trg</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(src, trg)</span><br><span class="line">        loss = F.nll_loss(output[<span class="number">1</span>:].view(<span class="number">-1</span>, vocab_size),</span><br><span class="line">                               trg[<span class="number">1</span>:].contiguous().view(<span class="number">-1</span>),</span><br><span class="line">                               ignore_index=pad)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        clip_grad_norm(model.parameters(), grad_clip)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss += loss.data.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> b % <span class="number">100</span> == <span class="number">0</span> <span class="keyword">and</span> b != <span class="number">0</span>:</span><br><span class="line">            total_loss = total_loss / <span class="number">100</span></span><br><span class="line">            print(<span class="string">&quot;[%d][loss:%5.2f][pp:%5.2f]&quot;</span> %</span><br><span class="line">                  (b, total_loss, math.exp(total_loss)))</span><br><span class="line">            total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    args = parse_arguments()</span><br><span class="line">    hidden_size = <span class="number">512</span></span><br><span class="line">    embed_size = <span class="number">256</span></span><br><span class="line">    <span class="comment"># assert torch.cuda.is_available()</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;[!] preparing dataset...&quot;</span>)</span><br><span class="line">    train_iter, val_iter, test_iter, DE, EN = load_dataset(args.batch_size)</span><br><span class="line">    de_size, en_size = <span class="built_in">len</span>(DE.vocab), <span class="built_in">len</span>(EN.vocab)</span><br><span class="line">    print(<span class="string">&quot;[TRAIN]:%d (dataset:%d)\t[TEST]:%d (dataset:%d)&quot;</span></span><br><span class="line">          % (<span class="built_in">len</span>(train_iter), <span class="built_in">len</span>(train_iter.dataset),</span><br><span class="line">             <span class="built_in">len</span>(test_iter), <span class="built_in">len</span>(test_iter.dataset)))</span><br><span class="line">    print(<span class="string">&quot;[DE_vocab]:%d [en_vocab]:%d&quot;</span> % (de_size, en_size))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;[!] Instantiating models...&quot;</span>)</span><br><span class="line">    encoder = Encoder(de_size, embed_size, hidden_size,</span><br><span class="line">                      n_layers=<span class="number">2</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line">    decoder = Decoder(embed_size, hidden_size, en_size,</span><br><span class="line">                      n_layers=<span class="number">1</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line">    seq2seq = Seq2Seq(encoder, decoder)</span><br><span class="line">    optimizer = optim.Adam(seq2seq.parameters(), lr=args.lr)</span><br><span class="line">    print(seq2seq)</span><br><span class="line"></span><br><span class="line">    best_val_loss = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs+<span class="number">1</span>):</span><br><span class="line">        train(e, seq2seq, optimizer, train_iter,</span><br><span class="line">              en_size, args.grad_clip, DE, EN)</span><br><span class="line">        val_loss = evaluate(seq2seq, val_iter, en_size, DE, EN)</span><br><span class="line">        print(<span class="string">&quot;[Epoch:%d] val_loss:%5.3f | val_pp:%5.2fS&quot;</span></span><br><span class="line">              % (e, val_loss, math.exp(val_loss)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save the model if the validation loss is the best we&#x27;ve seen so far.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> best_val_loss <span class="keyword">or</span> val_loss &lt; best_val_loss:</span><br><span class="line">            print(<span class="string">&quot;[!] saving model...&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(<span class="string">&quot;.save&quot;</span>):</span><br><span class="line">                os.makedirs(<span class="string">&quot;.save&quot;</span>)</span><br><span class="line">            torch.save(seq2seq.state_dict(), <span class="string">&#x27;./.save/seq2seq_%d.pt&#x27;</span> % (e))</span><br><span class="line">            best_val_loss = val_loss</span><br><span class="line">    test_loss = evaluate(seq2seq, test_iter, en_size, DE, EN)</span><br><span class="line">    print(<span class="string">&quot;[TEST] loss:%5.2f&quot;</span> % test_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">&quot;[STOP]&quot;</span>, e)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>bleu.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> bleu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_data</span>(<span class="params">cand, ref</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Store each reference and candidate sentences as a list &quot;&quot;&quot;</span></span><br><span class="line">    references = []</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;.txt&#x27;</span> <span class="keyword">in</span> ref:</span><br><span class="line">        reference_file = codecs.<span class="built_in">open</span>(ref, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        references.append(reference_file.readlines())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(ref):</span><br><span class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">                reference_file = codecs.<span class="built_in">open</span>(os.path.join(root, f), <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">                references.append(reference_file.readlines())</span><br><span class="line">    candidate_file = codecs.<span class="built_in">open</span>(cand, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    candidate = candidate_file.readlines()</span><br><span class="line">    <span class="keyword">return</span> candidate, references</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># candidate = [[&quot;word peace],[&#x27;make china great again !&#x27;]]</span></span><br><span class="line"><span class="comment"># reference [[&quot;world war&quot;],[&#x27;make USA great again&#x27;]]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_ngram</span>(<span class="params">candidate, references, n</span>):</span></span><br><span class="line">    clipped_count = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    r = <span class="number">0</span>   <span class="comment">#用来记录reference</span></span><br><span class="line">    c = <span class="number">0</span>  <span class="comment">#用来记录 candidates的长度</span></span><br><span class="line">    <span class="keyword">for</span> si <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(candidate)):  <span class="comment"># 遍历每一个CANDIDATES</span></span><br><span class="line">        <span class="comment"># Calculate precision for each sentence</span></span><br><span class="line">        <span class="comment"># print si</span></span><br><span class="line">        ref_counts = []   <span class="comment">#统计ref 中的，每个n-gram 的数字</span></span><br><span class="line">        ref_lengths = []  <span class="comment">#统计 REF 的长度，length</span></span><br><span class="line">        <span class="comment"># print references</span></span><br><span class="line">        <span class="comment"># Build dictionary of ngram counts</span></span><br><span class="line">        <span class="keyword">for</span> reference <span class="keyword">in</span> references:  <span class="comment"># 遍历每一个REFERENCE</span></span><br><span class="line">            <span class="comment"># print &#x27;reference&#x27; + reference</span></span><br><span class="line">            ref_sentence = reference[si]</span><br><span class="line">            ngram_d = &#123;&#125;</span><br><span class="line">            words = ref_sentence.strip().split()</span><br><span class="line">            ref_lengths.append(<span class="built_in">len</span>(words))</span><br><span class="line">            limits = <span class="built_in">len</span>(words) - n + <span class="number">1</span>      <span class="comment"># [1,2,3,4,5,6,7]</span></span><br><span class="line">            <span class="comment"># loop through the sentance consider the ngram length</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(limits):</span><br><span class="line">                ngram = <span class="string">&#x27; &#x27;</span>.join(words[i:i + n]).lower()</span><br><span class="line">                <span class="keyword">if</span> ngram <span class="keyword">in</span> ngram_d.keys():</span><br><span class="line">                    ngram_d[ngram] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    ngram_d[ngram] = <span class="number">1</span></span><br><span class="line">            ref_counts.append(ngram_d)</span><br><span class="line">        <span class="comment"># candidate</span></span><br><span class="line">        cand_sentence = candidate[si]  <span class="comment"># 遍历 CANDIDATE</span></span><br><span class="line">        cand_dict = &#123;&#125;</span><br><span class="line">        words = cand_sentence.strip().split()</span><br><span class="line">        limits = <span class="built_in">len</span>(words) - n + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, limits):</span><br><span class="line">            ngram = <span class="string">&#x27; &#x27;</span>.join(words[i:i + n]).lower()</span><br><span class="line">            <span class="keyword">if</span> ngram <span class="keyword">in</span> cand_dict:</span><br><span class="line">                cand_dict[ngram] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cand_dict[ngram] = <span class="number">1</span></span><br><span class="line">        clipped_count += clip_count(cand_dict, ref_counts)</span><br><span class="line">        count += limits</span><br><span class="line">        r += best_length_match(ref_lengths, <span class="built_in">len</span>(words))</span><br><span class="line">        c += <span class="built_in">len</span>(words)</span><br><span class="line">    <span class="keyword">if</span> clipped_count == <span class="number">0</span>:</span><br><span class="line">        pr = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pr = <span class="built_in">float</span>(clipped_count) / count</span><br><span class="line">    bp = brevity_penalty(c, r)</span><br><span class="line">    <span class="keyword">return</span> pr, bp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_count</span>(<span class="params">cand_d, ref_ds</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Count the clip count for each ngram considering all references&quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> cand_d.keys():</span><br><span class="line">        m_w = cand_d[m]</span><br><span class="line">        m_max = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> ref <span class="keyword">in</span> ref_ds:</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">in</span> ref:</span><br><span class="line">                m_max = <span class="built_in">max</span>(m_max, ref[m])</span><br><span class="line">        m_w = <span class="built_in">min</span>(m_w, m_max)</span><br><span class="line">        count += m_w</span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_length_match</span>(<span class="params">ref_l, cand_l</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Find the closest length of reference to that of candidate&quot;&quot;&quot;</span></span><br><span class="line">    least_diff = <span class="built_in">abs</span>(cand_l - ref_l[<span class="number">0</span>])</span><br><span class="line">    best = ref_l[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ref <span class="keyword">in</span> ref_l:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(cand_l - ref) &lt; least_diff:</span><br><span class="line">            least_diff = <span class="built_in">abs</span>(cand_l - ref)</span><br><span class="line">            best = ref</span><br><span class="line">    <span class="keyword">return</span> best</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">brevity_penalty</span>(<span class="params">c, r</span>):</span></span><br><span class="line">    <span class="keyword">if</span> c &gt; r:</span><br><span class="line">        bp = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bp = math.exp(<span class="number">1</span> - (<span class="built_in">float</span>(r) / c))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geometric_mean</span>(<span class="params">precisions</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (reduce(operator.mul, precisions)) ** (<span class="number">1.0</span> / <span class="built_in">len</span>(precisions))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BLEU</span>(<span class="params">candidate, references</span>):</span></span><br><span class="line">    precisions = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        pr, bp = count_ngram(candidate, references, i + <span class="number">1</span>)</span><br><span class="line">        precisions.append(pr)</span><br><span class="line">        <span class="built_in">print</span></span><br><span class="line">        <span class="string">&#x27;P&#x27;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>), <span class="string">&#x27; = &#x27;</span>, <span class="built_in">round</span>(pr, <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span></span><br><span class="line">    <span class="string">&#x27;BP = &#x27;</span>, <span class="built_in">round</span>(bp, <span class="number">2</span>)</span><br><span class="line">    bleu = geometric_mean(precisions) * bp</span><br><span class="line">    <span class="keyword">return</span> bleu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    candidate, references = fetch_data(sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>])</span><br><span class="line">    bleu = BLEU(candidate, references)</span><br><span class="line">    <span class="built_in">print</span></span><br><span class="line">    <span class="string">&#x27;BLEU = &#x27;</span>, <span class="built_in">round</span>(bleu, <span class="number">4</span>)</span><br><span class="line">    out = <span class="built_in">open</span>(<span class="string">&#x27;bleu_out.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    out.write(<span class="built_in">str</span>(bleu))</span><br><span class="line">    out.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.translate.bleu_score <span class="keyword">import</span> sentence_bleu</span><br><span class="line">reference = [[<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;test&#x27;</span>], [<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span> <span class="string">&#x27;test&#x27;</span>]]</span><br><span class="line">candidate = [<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">score = sentence_bleu(reference, candidate)</span><br><span class="line">print(score)</span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2tlb24vc2VxMnNlcQ==">mini seq2seq<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/15/NLP/02.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/15/NLP/02.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">基于LSTM的情感分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-15T00:00:00+08:00">2021-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>本项目使用了word2vec的中文预训练向量</strong><br><strong>模型分别有BiLSTM-attention和普通的LSTM两种，自行选择</strong></p>
<p><strong>使用说明</strong>：<br>1、在<strong>Config</strong>中配置相关参数</p>
<p>2、然后运行<strong>DataProcess.py</strong>，生成相应的word2id，word2vec等文件</p>
<p>3、运行主函数<strong>main.py</strong>，得到训练好的模型，并保存模型</p>
<p>4、运行<strong>eval.py</strong>，读取模型，并得到评价</p>
<p>5、模型<strong>准确率平均85%左右</strong></p>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_Config.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Config</span>():</span></span><br><span class="line">    update_w2v = <span class="literal">True</span>          <span class="comment"># 是否在训练中更新w2v</span></span><br><span class="line">    vocab_size = <span class="number">54848</span>          <span class="comment"># 词汇量，与word2id中的词汇量一致</span></span><br><span class="line">    n_class = <span class="number">2</span>                 <span class="comment"># 分类数：分别为pos和neg</span></span><br><span class="line">    max_sen_len = <span class="number">65</span>           <span class="comment"># 句子最大长度</span></span><br><span class="line">    embedding_dim = <span class="number">50</span>          <span class="comment"># 词向量维度</span></span><br><span class="line">    batch_size =<span class="number">64</span>            <span class="comment"># 批处理尺寸</span></span><br><span class="line">    hidden_dim=<span class="number">100</span>           <span class="comment"># 隐藏层节点数</span></span><br><span class="line">    n_epoch = <span class="number">30</span>            <span class="comment"># 训练迭代周期，即遍历整个训练样本的次数</span></span><br><span class="line">    lr = <span class="number">0.0001</span>               <span class="comment"># 学习率；若opt=‘adadelta&#x27;，则不需要定义学习率</span></span><br><span class="line">    drop_keep_prob = <span class="number">0.2</span>        <span class="comment"># dropout层，参数keep的比例</span></span><br><span class="line">    num_layers = <span class="number">2</span>              <span class="comment"># LSTM层数</span></span><br><span class="line">    bidirectional=<span class="literal">True</span>         <span class="comment">#是否使用双向LSTM</span></span><br><span class="line">    train_path = <span class="string">&#x27;./word2vec_data/train.txt&#x27;</span></span><br><span class="line">    val_path = <span class="string">&#x27;./word2vec_data/validation.txt&#x27;</span></span><br><span class="line">    test_path = <span class="string">&#x27;./word2vec_data/test.txt&#x27;</span></span><br><span class="line">    pre_path =<span class="string">&#x27;./word2vec_data/pre.txt&#x27;</span></span><br><span class="line">    word2id_path = <span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span></span><br><span class="line">    pre_word2vec_path = <span class="string">&#x27;./word2vec_data/wiki_word2vec_50.bin&#x27;</span></span><br><span class="line">    corpus_word2vec_path = <span class="string">&#x27;./word2vec_data/word_vec.txt&#x27;</span></span><br><span class="line">    model_state_dict_path=<span class="string">&#x27;./word2vec_data/sen_model.pkl&#x27;</span><span class="comment"># 训练模型保存的地址</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_DataProcess.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Data_set</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, Data, Label</span>):</span></span><br><span class="line">        self.Data = Data</span><br><span class="line">        <span class="keyword">if</span> Label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:<span class="comment">#考虑对测试集的使用</span></span><br><span class="line">            self.Label = Label</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.Data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.Label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data = torch.from_numpy(self.Data[index])</span><br><span class="line">            label = torch.from_numpy(self.Label[index])</span><br><span class="line">            <span class="keyword">return</span> data, label</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data = torch.from_numpy(self.Data[index])</span><br><span class="line">            <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stopwordslist</span>():</span><span class="comment">#创建停用词表</span></span><br><span class="line">    stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;word2vec_data/stopword.txt&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2id</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param file: word2id保存地址</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#num_50=0#统计长度大于50的句子数</span></span><br><span class="line">    stopwords = stopwordslist()</span><br><span class="line">    word2id = &#123;<span class="string">&#x27;_PAD_&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line">    path = [Config.train_path, Config.val_path]</span><br><span class="line">    <span class="comment">#print(path)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _path <span class="keyword">in</span> path:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                out_list = []</span><br><span class="line">                <span class="comment"># 去停用词</span></span><br><span class="line">                sp = line.strip().split()</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> sp[<span class="number">1</span>:]:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">                        rt = re.findall(<span class="string">&#x27;[a-zA-Z]+&#x27;</span>, word)</span><br><span class="line">                        <span class="keyword">if</span> word != <span class="string">&#x27;\t&#x27;</span>:</span><br><span class="line">                            <span class="comment"># if is_number(word):</span></span><br><span class="line">                            <span class="comment"># continue</span></span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(rt) == <span class="number">1</span>:</span><br><span class="line">                                <span class="keyword">continue</span></span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                out_list.append(word)</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> out_list:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word2id.keys():</span><br><span class="line">                        word2id[word] = <span class="built_in">len</span>(word2id)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> word2id:</span><br><span class="line">            f.write(w+<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            f.write(<span class="built_in">str</span>(word2id[w]))</span><br><span class="line">            f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2vec</span>(<span class="params">fname, word2id, save_to_path=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param fname: 预训练的word2vec.</span></span><br><span class="line"><span class="string">    :param word2id: 语料文本中包含的词汇集.</span></span><br><span class="line"><span class="string">    :param save_to_path: 保存训练语料库中的词组对应的word2vec到本地</span></span><br><span class="line"><span class="string">    :return: 语料文本中词汇集对应的word2vec向量&#123;id: word2vec&#125;.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n_words = <span class="built_in">max</span>(word2id.values()) + <span class="number">1</span></span><br><span class="line">    model = gensim.models.KeyedVectors.load_word2vec_format(fname, binary=<span class="literal">True</span>)</span><br><span class="line">    word_vecs = np.array(np.random.uniform(<span class="number">-1.</span>, <span class="number">1.</span>, [n_words, model.vector_size]))</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word2id.keys():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            word_vecs[word2id[word]] = model[word]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">if</span> save_to_path:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(save_to_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> vec <span class="keyword">in</span> word_vecs:</span><br><span class="line">                vec = [<span class="built_in">str</span>(w) <span class="keyword">for</span> w <span class="keyword">in</span> vec]</span><br><span class="line">                f.write(<span class="string">&#x27; &#x27;</span>.join(vec))</span><br><span class="line">                f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> word_vecs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_to_array</span>(<span class="params">word2id,seq_lenth ,path</span>):</span>  <span class="comment"># 文本转为索引数字模式,</span></span><br><span class="line"></span><br><span class="line">    lable_array=[]</span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    sa=[]</span><br><span class="line">    <span class="comment">#获取句子个数</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f1:</span><br><span class="line">        <span class="keyword">for</span> l1 <span class="keyword">in</span> f1.readlines():</span><br><span class="line">            s= l1.strip().split()</span><br><span class="line">            s1=s[<span class="number">1</span>:]</span><br><span class="line">            new_s = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> s1]  <span class="comment"># 单词转索引数字</span></span><br><span class="line">            sa.append(new_s)</span><br><span class="line">        <span class="comment">#print(len(sa))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        sentences_array=np.zeros(shape=(<span class="built_in">len</span>(sa),seq_lenth))<span class="comment">#行：句子个数 列：句子长度</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sl1 = line.strip().split()</span><br><span class="line">            sen=sl1[<span class="number">1</span>:]</span><br><span class="line">            new_sen = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> sen]  <span class="comment"># 单词转索引数字,不存在则为0</span></span><br><span class="line">            new_sen_np=np.array(new_sen).reshape(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#补齐每个句子长度，多余补零，少了就直接赋值,0填在前面。</span></span><br><span class="line">            <span class="keyword">if</span> np.size(new_sen_np,<span class="number">1</span>)&lt;seq_lenth:</span><br><span class="line">                sentences_array[i,seq_lenth-np.size(new_sen_np,<span class="number">1</span>):]=new_sen_np[<span class="number">0</span>,:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sentences_array[i, <span class="number">0</span>:seq_lenth]=new_sen_np[<span class="number">0</span>,<span class="number">0</span>:seq_lenth]</span><br><span class="line"></span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">            lable=<span class="built_in">int</span>(sl1[<span class="number">0</span>])<span class="comment">#标签</span></span><br><span class="line">            lable_array.append(lable)</span><br><span class="line">    <span class="keyword">return</span> np.array(sentences_array),lable_array</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_to_array_nolable</span>(<span class="params">word2id,seq_lenth ,path</span>):</span>  <span class="comment"># 文本转为索引数字模式,</span></span><br><span class="line"></span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    sa=[]</span><br><span class="line">    <span class="comment">#获取句子个数</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f1:</span><br><span class="line">        <span class="keyword">for</span> l1 <span class="keyword">in</span> f1.readlines():</span><br><span class="line">            s= l1.strip().split()</span><br><span class="line">            s1=s[<span class="number">1</span>:]</span><br><span class="line">            new_s = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> s1]  <span class="comment"># 单词转索引数字</span></span><br><span class="line">            sa.append(new_s)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        sentences_array=np.zeros(shape=(<span class="built_in">len</span>(sa),seq_lenth))<span class="comment">#行：句子个数 列：句子长度</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sl1 = line.strip().split()</span><br><span class="line">            sen=sl1[<span class="number">1</span>:]</span><br><span class="line">            new_sen = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> sen]  <span class="comment"># 单词转索引数字,不存在则为0</span></span><br><span class="line">            new_sen_np=np.array(new_sen).reshape(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">if</span> np.size(new_sen_np,<span class="number">1</span>)&lt;seq_lenth:</span><br><span class="line">                sentences_array[i,seq_lenth-np.size(new_sen_np,<span class="number">1</span>):]=new_sen_np[<span class="number">0</span>,:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sentences_array[i, <span class="number">0</span>:seq_lenth]=new_sen_np[<span class="number">0</span>,<span class="number">0</span>:seq_lenth]</span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> np.array(sentences_array)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_categorical</span>(<span class="params">y, num_classes=<span class="literal">None</span></span>):</span><span class="comment">#将类别转化为one-hot编码</span></span><br><span class="line">    y = np.array(y, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">    input_shape = y.shape</span><br><span class="line">    <span class="keyword">if</span> input_shape <span class="keyword">and</span> input_shape[<span class="number">-1</span>] == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(input_shape) &gt; <span class="number">1</span>:</span><br><span class="line">        input_shape = <span class="built_in">tuple</span>(input_shape[:<span class="number">-1</span>])</span><br><span class="line">    y = y.ravel()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> num_classes:</span><br><span class="line">        num_classes = np.<span class="built_in">max</span>(y) + <span class="number">1</span></span><br><span class="line">    n = y.shape[<span class="number">0</span>]</span><br><span class="line">    categorical = np.zeros((n, num_classes))</span><br><span class="line">    categorical[np.arange(n), y] = <span class="number">1</span></span><br><span class="line">    output_shape = input_shape + (num_classes,)</span><br><span class="line">    categorical = np.reshape(categorical, output_shape)</span><br><span class="line">    <span class="keyword">return</span> categorical</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_data</span>(<span class="params">w2id, train_path,val_path,test_path,seq_lenth</span>):</span><span class="comment">#得到数字索引表示的句子和标签</span></span><br><span class="line">    train_array,train_lable = text_to_array(w2id,seq_lenth= seq_lenth,path=train_path)</span><br><span class="line">    val_array,val_lable  = text_to_array(w2id,seq_lenth=seq_lenth,path= val_path)</span><br><span class="line">    test_array,test_lable=text_to_array(w2id,seq_lenth=seq_lenth,path=test_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#标签为[1, 1, 1, 1, 1, 1, 1, 1, 0, 0...]将标签转为onehot</span></span><br><span class="line">    <span class="comment">#train_lable=to_categorical(train_lable,num_classes=2)</span></span><br><span class="line">    <span class="comment">#val_lable=to_categorical(val_lable,num_classes=2)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;for i in train_lable:</span></span><br><span class="line"><span class="string">        np.array([i])&quot;&quot;&quot;</span></span><br><span class="line">    train_lable=np.array([train_lable]).T</span><br><span class="line">    val_lable=np.array([val_lable]).T</span><br><span class="line">    test_lable=np.array([test_lable]).T</span><br><span class="line">    <span class="string">&quot;&quot;&quot;转换后标签</span></span><br><span class="line"><span class="string">            [[0. 1.]</span></span><br><span class="line"><span class="string">            [0. 1.]</span></span><br><span class="line"><span class="string">            [0. 1.]</span></span><br><span class="line"><span class="string">            ...</span></span><br><span class="line"><span class="string">            [1. 0.]</span></span><br><span class="line"><span class="string">            [1. 0.]</span></span><br><span class="line"><span class="string">            [1. 0.]]&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#print(train_lab,&quot;\nval\n&quot;,val_lab)</span></span><br><span class="line">    <span class="keyword">return</span> train_array ,train_lable,val_array,val_lable,test_array,test_lable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#建立word2id</span></span><br><span class="line">build_word2id(<span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span>)<span class="comment">#建立词toid</span></span><br><span class="line">splist=[]</span><br><span class="line">word2id=&#123;&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sp = line.strip().split()<span class="comment">#去掉\n \t 等</span></span><br><span class="line">            splist.append(sp)</span><br><span class="line">        word2id=<span class="built_in">dict</span>(splist)<span class="comment">#转成字典</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> word2id:<span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">    word2id[key]=<span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line">id2word=&#123;&#125;<span class="comment">#得到id2word</span></span><br><span class="line"><span class="keyword">for</span> key,val <span class="keyword">in</span> word2id.items():</span><br><span class="line">    id2word[val]=key</span><br><span class="line"><span class="comment">#建立word2vec</span></span><br><span class="line">w2vec=build_word2vec(Config.pre_word2vec_path,word2id,Config.corpus_word2vec_path)</span><br><span class="line"></span><br><span class="line"><span class="comment">#得到句子id表示和标签</span></span><br><span class="line">train_array,train_lable,val_array,val_lable,test_array,test_label=prepare_data(word2id,</span><br><span class="line">                                                         train_path=Config.train_path,</span><br><span class="line">                                                         val_path=Config.val_path,</span><br><span class="line">                                                         test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line"></span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/train_data.txt&#x27;</span>, train_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/val_data.txt&#x27;</span>, val_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/test_data.txt&#x27;</span>, test_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_model.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim,pretrained_weight, update_w2v,hidden_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_layers,drop_keep_prob,n_class,bidirectional, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LSTMModel, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.n_class = n_class</span><br><span class="line"></span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(pretrained_weight)</span><br><span class="line">        self.embedding.weight.requires_grad = update_w2v</span><br><span class="line">        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim,</span><br><span class="line">                               num_layers=num_layers, bidirectional=self.bidirectional,</span><br><span class="line">                               dropout=drop_keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bidirectional:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">4</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        embeddings = self.embedding(inputs)<span class="comment"># [batch, seq_len] =&gt; [batch, seq_len, embed_dim][64,75,50]</span></span><br><span class="line">        states, hidden = self.encoder(embeddings.permute([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]))<span class="comment">#[75,32,50],[seq_len, batch, embed_dim]</span></span><br><span class="line"></span><br><span class="line">        encoding = torch.cat([states[<span class="number">0</span>], states[<span class="number">-1</span>]], dim=<span class="number">1</span>)<span class="comment">#张量拼接[32,512]</span></span><br><span class="line">        outputs = self.decoder1(encoding)</span><br><span class="line">        <span class="comment">#outputs = F.softmax(outputs, dim=1)</span></span><br><span class="line">        outputs=self.decoder2(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTM_attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim,pretrained_weight, update_w2v,hidden_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_layers,drop_keep_prob,n_class,bidirectional, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LSTM_attention, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.n_class = n_class</span><br><span class="line"></span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(pretrained_weight)</span><br><span class="line">        self.embedding.weight.requires_grad = update_w2v</span><br><span class="line">        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim,</span><br><span class="line">                               num_layers=num_layers, bidirectional=self.bidirectional,</span><br><span class="line">                               dropout=drop_keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#TODO</span></span><br><span class="line">        <span class="comment"># What is nn. Parameter ? Explain</span></span><br><span class="line">        self.weight_W = nn.Parameter(torch.Tensor(<span class="number">2</span>*hidden_dim, <span class="number">2</span>*hidden_dim))</span><br><span class="line">        self.weight_proj = nn.Parameter(torch.Tensor(<span class="number">2</span>*hidden_dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bidirectional:</span><br><span class="line">            <span class="comment">#self.decoder1 = nn.Linear(hidden_dim * 2, n_class)</span></span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line"></span><br><span class="line">        nn.init.uniform_(self.weight_W, <span class="number">-0.1</span>, <span class="number">0.1</span>)</span><br><span class="line">        nn.init.uniform_(self.weight_proj, <span class="number">-0.1</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span><span class="number">0</span></span><br><span class="line">        embeddings = self.embedding(inputs)<span class="comment"># [batch, seq_len] =&gt; [batch, seq_len, embed_dim][64,75,50]</span></span><br><span class="line"></span><br><span class="line">        states, hidden = self.encoder(embeddings.permute([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]))<span class="comment">#[batch, seq_len, embed_dim]</span></span><br><span class="line">        <span class="comment">#attention</span></span><br><span class="line"></span><br><span class="line">        u = torch.tanh(torch.matmul(states, self.weight_W))</span><br><span class="line">        att = torch.matmul(u, self.weight_proj)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        att_score = F.softmax(att, dim=<span class="number">1</span>)</span><br><span class="line">        scored_x = states * att_score</span><br><span class="line">        encoding = torch.<span class="built_in">sum</span>(scored_x, dim=<span class="number">1</span>)</span><br><span class="line">        outputs = self.decoder1(encoding)</span><br><span class="line">        outputs=self.decoder2(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_main.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_DataProcess <span class="keyword">import</span> prepare_data,build_word2vec,Data_set</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,f1_score,recall_score</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Sentiment_model <span class="keyword">import</span> LSTMModel,LSTM_attention</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_eval <span class="keyword">import</span> val_accuary</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_dataloader,model, device, epoches, lr</span>):</span></span><br><span class="line"></span><br><span class="line">        model.train()</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        print(model)</span><br><span class="line">        optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        <span class="comment"># scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)  # 学习率调整</span></span><br><span class="line">        best_acc = <span class="number">0.85</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoches):  <span class="comment"># 一个epoch可以认为是一次训练循环</span></span><br><span class="line">            train_loss = <span class="number">0.0</span></span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            train_dataloader = tqdm.tqdm(train_dataloader)</span><br><span class="line">            <span class="comment"># train_dataloader.set_description(&#x27;[%s%04d/%04d %s%f]&#x27; % </span></span><br><span class="line">            <span class="comment">#                                 (&#x27;Epoch:&#x27;, epoch + 1, epoches, &#x27;lr:&#x27;, scheduler.get_last_lr()[0]))</span></span><br><span class="line">            <span class="keyword">for</span> i, data_ <span class="keyword">in</span> (<span class="built_in">enumerate</span>(train_dataloader)):</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                input_, target = data_[<span class="number">0</span>], data_[<span class="number">1</span>]</span><br><span class="line">                input_=input_.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">                target=target.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">                input_=input_.to(device)</span><br><span class="line">                target=target.to(device)</span><br><span class="line">                output= model(input_)</span><br><span class="line">                <span class="comment"># 经过模型对象就产生了输出</span></span><br><span class="line">                target=target.squeeze(<span class="number">1</span>)</span><br><span class="line">                loss = criterion(output, target)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">                train_loss+= loss.item()</span><br><span class="line">                _, predicted = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)</span><br><span class="line">                <span class="comment">#print(predicted.shape)</span></span><br><span class="line">                total += target.size(<span class="number">0</span>)  <span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">                <span class="comment">#print(target.shape)</span></span><br><span class="line">                correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">                F1=f1_score(target.cpu(),predicted.cpu(),average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">                Recall=recall_score(target.cpu(),predicted.cpu(),average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">                <span class="comment">#CM=confusion_matrix(target.cpu(),predicted.cpu())</span></span><br><span class="line">                postfix = &#123;<span class="string">&#x27;train_loss: &#123;:.5f&#125;,train_acc:&#123;:.3f&#125;%&#x27;</span></span><br><span class="line">                           <span class="string">&#x27;,F1: &#123;:.3f&#125;%,Recall:&#123;:.3f&#125;%&#x27;</span> .<span class="built_in">format</span>(train_loss / (i + <span class="number">1</span>),</span><br><span class="line">                                                                        <span class="number">100</span> * correct / total, <span class="number">100</span>*F1 , <span class="number">100</span>* Recall)&#125;</span><br><span class="line">                train_dataloader.set_postfix(log=postfix)</span><br><span class="line"></span><br><span class="line">            acc=val_accuary(model,val_dataloader,device,criterion)</span><br><span class="line">            <span class="keyword">if</span> acc&gt;best_acc:</span><br><span class="line">                best_acc = acc</span><br><span class="line">                <span class="keyword">if</span> os.path.exists(Config.model_state_dict_path) == <span class="literal">False</span>:</span><br><span class="line">                    os.mkdir(Config.model_state_dict_path)</span><br><span class="line">                torch.save(model,<span class="string">&#x27;./word2vec_data/sen_model_best.pkl&#x27;</span> )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    splist=[]</span><br><span class="line">    word2id=&#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(Config.word2id_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                sp = line.strip().split()<span class="comment">#去掉\n \t 等</span></span><br><span class="line">                splist.append(sp)</span><br><span class="line">            word2id=<span class="built_in">dict</span>(splist)<span class="comment">#转成字典</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> word2id:<span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">        word2id[key]=<span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    id2word=&#123;&#125;<span class="comment">#得到id2word</span></span><br><span class="line">    <span class="keyword">for</span> key,val <span class="keyword">in</span> word2id.items():</span><br><span class="line">        id2word[val]=key</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_array,train_lable,val_array,val_lable,test_array,test_lable=prepare_data(word2id,</span><br><span class="line">                                                             train_path=Config.train_path,</span><br><span class="line">                                                             val_path=Config.val_path,</span><br><span class="line">                                                             test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_loader = Data_set(train_array, train_lable)</span><br><span class="line">    train_dataloader = DataLoader(train_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)<span class="comment">#用了workers反而变慢了</span></span><br><span class="line"></span><br><span class="line">    val_loader = Data_set(val_array, val_lable)</span><br><span class="line">    val_dataloader = DataLoader(val_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    test_loader = Data_set(test_array, test_lable)</span><br><span class="line">    test_dataloader = DataLoader(test_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line">    w2vec=build_word2vec(Config.pre_word2vec_path,word2id,<span class="literal">None</span>)<span class="comment">#生成word2vec</span></span><br><span class="line">    w2vec=torch.from_numpy(w2vec)</span><br><span class="line">    w2vec=w2vec.<span class="built_in">float</span>()<span class="comment">#CUDA接受float32，不接受float64</span></span><br><span class="line">    model=LSTM_attention(Config.vocab_size,Config.embedding_dim,w2vec,Config.update_w2v,</span><br><span class="line">                    Config.hidden_dim,Config.num_layers,Config.drop_keep_prob,Config.n_class,Config.bidirectional)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">    train(train_dataloader,model=model,device=device,epoches=Config.n_epoch,lr=Config.lr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(Config.model_state_dict_path) == <span class="literal">False</span>:</span><br><span class="line">           os.mkdir(Config.model_state_dict_path)</span><br><span class="line">    torch.save(model, Config.model_state_dict_path)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_eval.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,f1_score,recall_score,precision_score</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Sentiment_model <span class="keyword">import</span> LSTMModel,LSTM_attention</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_DataProcess <span class="keyword">import</span> prepare_data,build_word2vec,text_to_array_nolable,Data_set</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_accuary</span>(<span class="params">model,val_dataloader,device,criterion</span>):</span></span><br><span class="line">    model = model.to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct1 = <span class="number">0</span></span><br><span class="line">        total1 = <span class="number">0</span></span><br><span class="line">        val_loss=<span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> j, data_1 <span class="keyword">in</span> (<span class="built_in">enumerate</span>(val_dataloader, <span class="number">0</span>)):</span><br><span class="line">            input1, target1 = data_1[<span class="number">0</span>], data_1[<span class="number">1</span>]</span><br><span class="line">            input1= input1.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target1 = target1.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target1=target1.squeeze(<span class="number">1</span>)<span class="comment">#从[64,1]到[64]</span></span><br><span class="line">            input1 = input1.to(device)</span><br><span class="line">            target1 = target1.to(device)</span><br><span class="line">            output1 = model(input1)</span><br><span class="line">            loss1 = criterion(output1, target1)</span><br><span class="line">            val_loss += loss1.item()</span><br><span class="line">            _, predicted1 = torch.<span class="built_in">max</span>(output1, <span class="number">1</span>)</span><br><span class="line">            total1 += target1.size(<span class="number">0</span>)<span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">            correct1 += (predicted1 == target1).<span class="built_in">sum</span>().item()</span><br><span class="line">            F1 = f1_score(target1.cpu(), predicted1.cpu(), average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">            Recall = recall_score(target1.cpu(), predicted1.cpu(), average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">            <span class="comment">#CM = confusion_matrix(target1.cpu(), predicted1.cpu())</span></span><br><span class="line">        print(<span class="string">&#x27;\nVal accuracy : &#123;:.3f&#125;%,val_loss:&#123;:.3f&#125;, F1_score：&#123;:.3f&#125;%, Recall：&#123;:.3f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span>*correct1/total1,val_loss,<span class="number">100</span>*F1,<span class="number">100</span>*Recall))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">100</span>*correct1/total1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_accuary</span>(<span class="params">model,test_dataloader,device</span>):</span></span><br><span class="line">    model = model.to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k, data_test <span class="keyword">in</span> (<span class="built_in">enumerate</span>(test_dataloader, <span class="number">0</span>)):</span><br><span class="line">            input_test, target_ = data_test[<span class="number">0</span>], data_test[<span class="number">1</span>]</span><br><span class="line">            input_test= input_test.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target_ = target_.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target_=target_.squeeze(<span class="number">1</span>)<span class="comment">#从[64,1]到[64]</span></span><br><span class="line">            input_test = input_test.to(device)</span><br><span class="line">            target_ = target_.to(device)</span><br><span class="line">            output2 = model(input_test)</span><br><span class="line">            _, predicted_test = torch.<span class="built_in">max</span>(output2, <span class="number">1</span>)</span><br><span class="line">            total += target_.size(<span class="number">0</span>)<span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">            correct += (predicted_test == target_).<span class="built_in">sum</span>().item()</span><br><span class="line">            F1 = f1_score(target_.cpu(), predicted_test.cpu(), average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">            Recall = recall_score(target_.cpu(), predicted_test.cpu(), average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">            CM = confusion_matrix(target_.cpu(), predicted_test.cpu())</span><br><span class="line">        print(<span class="string">&#x27;test accuracy : &#123;:.3f&#125;%, F1_score：&#123;:.3f&#125;%, Recall：&#123;:.3f&#125;%,Confusion_matrix：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span>*correct/total,<span class="number">100</span>*F1,<span class="number">100</span>*Recall,CM))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre</span>(<span class="params">word2id,model,seq_lenth ,path</span>):</span></span><br><span class="line">    model.cpu()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_array=text_to_array_nolable(word2id,seq_lenth,path)</span><br><span class="line">        <span class="comment">#sen_p = sen_p.type(torch.LongTensor)</span></span><br><span class="line">        sen_p = torch.from_numpy(input_array)</span><br><span class="line">        sen_p=sen_p.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">        output_p = model(sen_p)</span><br><span class="line">        _, pred = torch.<span class="built_in">max</span>(output_p, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> pred:</span><br><span class="line">            print(<span class="string">&#x27;预测类别为&#x27;</span>,i.item())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    splist = []</span><br><span class="line">    word2id = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(Config.word2id_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sp = line.strip().split()  <span class="comment"># 去掉\n \t 等</span></span><br><span class="line">            splist.append(sp)</span><br><span class="line">        word2id = <span class="built_in">dict</span>(splist)  <span class="comment"># 转成字典</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> word2id:  <span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">        word2id[key] = <span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    train_array, train_lable, val_array, val_lable, test_array, test_lable = prepare_data(word2id,</span><br><span class="line">                                                                                          train_path=Config.train_path,</span><br><span class="line">                                                                                          val_path=Config.val_path,</span><br><span class="line">                                                                                          test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line">    test_loader = Data_set(test_array, test_lable)</span><br><span class="line">    test_dataloader = DataLoader(test_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line">    w2vec = build_word2vec(Config.pre_word2vec_path,</span><br><span class="line">                           word2id,</span><br><span class="line">                          <span class="literal">None</span>)  <span class="comment"># 生成word2vec</span></span><br><span class="line">    w2vec = torch.from_numpy(w2vec)</span><br><span class="line">    w2vec = w2vec.<span class="built_in">float</span>()  <span class="comment"># CUDA接受float32，不接受float64</span></span><br><span class="line"></span><br><span class="line">    model=LSTM_attention(Config.vocab_size,Config.embedding_dim,w2vec,Config.update_w2v,</span><br><span class="line">                        Config.hidden_dim,Config.num_layers,Config.drop_keep_prob,Config.n_class,Config.bidirectional)</span><br><span class="line">    <span class="comment"># 读取模型</span></span><br><span class="line">    <span class="comment">#model1 = torch.load(Config.model_state_dict_path)</span></span><br><span class="line">    model = torch.load(<span class="string">&#x27;./word2vec_data/sen_model_best.pkl&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#model.load_state_dict(torch.load(Config.model_state_dict_path)) #仅保存参数</span></span><br><span class="line">    <span class="comment">#验证</span></span><br><span class="line">    <span class="comment">#val_accuary(model1, val_dataloader, device)</span></span><br><span class="line">    <span class="comment">#测试</span></span><br><span class="line">    test_accuary(model,test_dataloader,device)</span><br><span class="line">    <span class="comment">#预测</span></span><br><span class="line">    pre(word2id,model,Config.max_sen_len,Config.pre_path)</span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vaHUteWFuZ2dhbmcvU2VudGltZW50LUFuYWx5c2lzLUNoaW5lc2UtcHl0b3JjaCMlRTUlOEUlOUYlRTUlODglOUIlRTQlQjglOEQlRTYlOTglOTMlRTUlQTYlODIlRTYlOUUlOUMlRTUlQTUlQkQlRTclOTQlQTglRTglQUYlQjclRTclQkIlOTklRTQlQjglQUFzdGFyJUU4JUIwJUEyJUU4JUIwJUEyJUU0JUJBJTg2LSVFNCVCRCU5QyVFOCU4MCU4NSVFNiU5RCU4RSVFNyU4QiU5NyVFNSU5NyVBOA==">Sentiment-Analysis-Chinese-pytorch<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/06/25/Paper/02.XGBoost%20A%20Scalable%20Tree%20Boosting%20System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/25/Paper/02.XGBoost%20A%20Scalable%20Tree%20Boosting%20System/" class="post-title-link" itemprop="url">XGBoost A Scalable Tree Boosting System</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-25 00:00:00" itemprop="dateCreated datePublished" datetime="2021-06-25T00:00:00+08:00">2021-06-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>提出名为XGBoost的树提升系统。<br>提出一种新颖的稀疏数据感知算法用于稀疏数据，一种带权值的分位数略图(weighted quantile sketch) 来近似实现树的学习。<br>提出有关缓存访问模式，数据压缩和分片的见解，以构建有延展性的提升树系统。</p>
<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h1><p>机器学习方法里，GradientTree Boosting（GBDT）是一个在很多应用里都很出彩的技术。提升树方法在很多有标准分类基准的情况下表现很出色。本文提出了一个可扩展的提升树机器学习系统（XGBoost）。XGBoost在2015年的29场比赛获胜队伍中，有17个都使用了XGBoost。</p>
<p>主要贡献：<br>1、设计和构建高度可扩展的端到端提升树系统。（树的个数能灵活的增加或减少）<br>2、提出了一个理论上合理的加权分位法。（推荐分割点的时候用，能不用遍历所有的点，只用部分点就行）<br>3、引入了一种新颖的稀疏感知算法用于并行树学习。（令缺失值有默认方向，稀疏数据处理方法和并行计算）<br>4、提出了一个有效的用于核外树形学习的缓存感知块结构。（有效使用缓存块处理数据）</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><h2 id="Regularized-Learning-Objective"><a href="#Regularized-Learning-Objective" class="headerlink" title="Regularized Learning Objective"></a>Regularized Learning Objective</h2><p>给定一个数据集$\mathcal{D}$，$ n$个样本，每个样本有$ m$个特征：</p>
<script type="math/tex; mode=display">
\mathcal{D}= \{(x_i,y_i)\}(|\mathcal{D}|= n,x_i\in \Bbb{R}^m, y_i\in \Bbb{R})</script><p>第 $ k$ 棵树对于输入 $ x_i$ 的样本预测结果为$ f_k(x_i)$：</p>
<script type="math/tex; mode=display">
 \hat{y}_i=\varnothing(x_i)=\sum\limits_{k=1}^{K}f_k(x_i),\quad f_k\in \mathcal{F}</script><p>其中，$\mathcal{F}= \{f(x)=w_{q(x)}\}(q:\Bbb{R}^m\to T,w\in \Bbb{R}^T)$ 是CART回归树。$ q(x)$ 表示映射样本 $ x$ 到叶子节点的下标。$ T$是叶子节点数量。$ w$ 是叶子节点最优解（$ w_i$表示第$i$个叶子节点的最优解）。每一棵树都有独立的 $ q$  和 $ w$。</p>
<h2 id="Gradient-Tree-Boosting"><a href="#Gradient-Tree-Boosting" class="headerlink" title="Gradient Tree Boosting"></a>Gradient Tree Boosting</h2><p>以上定义了树模型的预测函数，那么接下来定义整个损失函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\varnothing)= \sum\limits_i l(\hat{y}_i,y_i)+\sum\limits_k \Omega(f_k)\\</script><script type="math/tex; mode=display">
\text{where} \quad \Omega( f)=\gamma  T + \frac{1}{2}\lambda||w||^2</script><p>其中，$ l$ 函数是一个可导的凸函数，用来表示预测值 $\hat{y}_i$ 和真实值 $ y_i$ 之间的差异。$\Omega$ 是是惩罚项（正则化），用来防止树的结构过于复杂。<br>损失函数 $\mathcal{L}$ 参数中包含了函数，所以不能用传统的优化算法来优化。假设 $\hat{y}_i^{t}$ 是 $ x_i$ 在第 $ t$ 次迭代中的预测值。那么则有：</p>
<script type="math/tex; mode=display">
\mathcal{L}^{( t)}= \sum\limits_{i= 1}^{n}l(y_i,\hat{y}_i^{(t-1)}+f_t(x_i))+\Omega(f_t)</script><p>把 $ y_i,\hat{y}_i^{(t-1)}$ 看成 $x$ ，把 $ f_t(x_i))$ 看成 $\Delta x$ ，对上式近似为二阶泰勒级展开：</p>
<script type="math/tex; mode=display">
\mathcal{L}^{( t)}\simeq \sum\limits_{i= 1}^{n}[l(y_i,\hat{y}_i^{(t-1)})+g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)</script><script type="math/tex; mode=display">
\text{where} \quad  g_i=\partial_{\hat{y}^{(t-1)}}l(y_i,\hat{y}_i^{(t-1)})\quad \text{and} \quad h_i=\partial_{\hat{y}^{(t-1)}}^{ 2}l(y_i,\hat{y}_i^{(t-1)})</script><p>其中，$ g_i$$ h_i$是一阶偏导和二阶偏导。由于$ l(y_i,\hat{y}_i^{(t-1)})$为常数项，可以去除。<br>定义 $ I_j=\{i|q(x_i)=j\}$ 作为样本 $ x_i$ 被分割到第 $ j$ 个叶子节点下的样本下标集合（样本集合）。那么上面公式可以由<strong>对每棵树的样本求和</strong>转成<strong>对每棵树的叶子节点求和</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\tilde{\mathcal{L}}^{( t)}&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{i= 1}^{n}[g_iw_{q(x_i)}+\frac{1}{2} h_i(w_{q(x_i)})^{ 2}]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{j= 1}^{T}[\sum\limits_{i\in I_j}g_iw_{j}+\frac{1}{2}\sum\limits_{i\in  I_j} h_i(w_{j})^{ 2}]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{j= 1}^{T}[(\sum\limits_{i\in I_j}g_i)w_{j}+\frac{1}{2}(\sum\limits_{i\in  I_j} h_i+\lambda)w_{j}^{ 2}]+\gamma  T 
\end{aligned}</script><p><strong>1、如何求出每个叶子节点的最优解？</strong><br>对上式求极值点（它是凸函数，求的是极小值），即对 $ w_j$ 求一阶导数等于零（也可以看成二元一次方程求解），解得：</p>
<script type="math/tex; mode=display">
 w_j^*=-\frac{\sum_{i\in I_j}g_i}{\sum_{i\in I_j}h_i+\lambda}</script><p>带入 $\tilde{\mathcal{L}}^{( t)}$ 求得最优值（最小值）：</p>
<script type="math/tex; mode=display">
 \tilde{\mathcal{L}}^{( t)}=-\frac{1}{2}\sum\limits_{j= 1}^{T}\frac{(\sum_{i\in I_j}g_i)^{ 2}}{\sum_{i\in I_j}h_i+\lambda}+\gamma  T</script><p>可以用这个公式来来衡量决策树的质量。有点像决策树信息熵一个道理。</p>
<p><strong>2、对当前决策树做子树分裂时，如何选择哪个特征和特征值进行分裂，使损失函数最小？</strong><br>如果想要划分后损失函数得到最小值，意味这在做每次划分的时候，要尽量保证划分后的score比划分前的score要更小。那么应该找到 (划分前的score - 划分后的score) 这个差最大的切分点作为我们这一次的划分点。假设 $ I_L$和 $ I_R$ 为一个节点 $ I$ 划分后的左子集和右子集，节点 $ I=I_L \cup I_R$ ，则得到以下公式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
 \mathcal{L}_{split}&=- \dfrac{1}{2}[\frac{(\sum_{i\in I}g_i)^{ 2}}{\sum_{i\in I}h_i+\lambda}-\frac{(\sum_{i\in I_L}g_i)^{ 2}}{\sum_{i\in I_L}h_i+\lambda}-\frac{(\sum_{i\in I_R}g_i)^{ 2}}{\sum_{i\in I_R}h_i+\lambda}]-\gamma\\
&= \dfrac{1}{2}  [\frac{(\sum_{i\in I_L}g_i)^{ 2}}{\sum_{i\in I_L}h_i+\lambda}+\frac{(\sum_{i\in I_R}g_i)^{ 2}}{\sum_{i\in I_R}h_i+\lambda}-\frac{(\sum_{i\in I}g_i)^{ 2}}{\sum_{i\in I}h_i+\lambda}]-\gamma
\end{aligned}</script><p>可以用这个公式来衡量是否当前节点是否再应该继续划分下去。每次用不同的特征，计算分数，然后用最大的值那个特征，作为当前树节点的划分点。</p>
<p>相对于GBDT，XGBoost一次性求解出<strong>最优解叶子节点区域</strong>和<strong>每个叶子节点区域最优解</strong>。而GBDT是基于残差（一阶泰勒）拟合一颗CART书，得到<strong>最优叶子节点区域</strong>，再求出<strong>每个叶子节点区域最优解</strong>。</p>
<h2 id="Shrinkage-and-Column-Subsampling"><a href="#Shrinkage-and-Column-Subsampling" class="headerlink" title="Shrinkage and Column Subsampling"></a>Shrinkage and Column Subsampling</h2><p>除了之前提过的添加正则化的项来防止模型的过拟合之外，还可以用两种方式来防止过拟合：<br>（1）添加类似梯度下降优化问题中的学习率 $ \eta$ ，这个可以收缩每棵树的权重，让每棵树的生长更加稳定。<br>（2）对样本的特征子采样（随机森林用到过）。每次生成树的时候，只用其中一部分抽样的特征。这样子也能降低过拟合的风险。</p>
<p><strong>精准的贪心算法</strong><br>贪心算法就是每次都希望找到最优的结果，但这样需每次都遍历所有的特征，对每个特征，又遍历所有划分的可能。然后通过 $ \mathcal{L}_{split}$ 的分数，计算每次划分后的score，取最大的score的对应的特征来进行划分。<br><img src="/images/XGB/01.png" width="60%"></p>
<p><strong>近似的贪心算法</strong><br>用上面贪心算法来寻找最佳划分点，准确度非常不错，但是时间复杂度和空间复杂度都太高了，特别是对于连续值的变量来说，简直是一个大灾难。作者提出一种近似法分位法，先对数据进行分桶(Bucket)，然后桶内的数据相加起来，作为一个代表来进行计算。</p>
<p>那我们应该在什么时候对数据进行分桶呢？有两种方式。<br>（1）全局分桶（Global Bucket），可以一开始就对全部的数据进行分桶。后面进行划分的时候只需要使用分桶数据就可以了。<br>（2）局部分桶（Local Bucket），每次需要对当前leaf node进行划分的时候，对当前节点里面的数据进行分桶。然后再划分。当然这个时间复杂度也会变的比较高。</p>
<p>具体划分的伪代码如下：<br>（1）先计算1到M个特征，找出每个特征的分桶的候选点。<br>（2）然后将候选点之间的数据的g和h求和，装入到Bucket里面，代表这些数据。<br>（3）后面流程就跟精确的弹性分割算法一样。只是将每个Bucket看成一个x。<br><img src="/images/XGB/02.png" width="60%"></p>
<p>下面是作者测试对几种不同的切分算法的AUC结果比较图。可以看得出，当eps=0.05，也就是将数据分成20个Bucket的时候，AUC的分数跟精准的贪心算法一样。<br><img src="/images/XGB/03.png" width="60%"></p>
<h2 id="SPLIT-FINDING-ALGORITHMS"><a href="#SPLIT-FINDING-ALGORITHMS" class="headerlink" title="SPLIT FINDING ALGORITHMS"></a>SPLIT FINDING ALGORITHMS</h2><p>提出一种新的分桶的方法<strong>Weighted Quantile Sketch</strong>（加权分位法）。</p>
<p><strong>加权分位法</strong><br>上面我们讨论了对数据分成Bucket，再来计算他的节点的split分数。来减少我们的计算量。那么我们如何对数据分桶，才能够比较合理呢？</p>
<p>作者按照对loss的影响权重来进行分桶，让数据分桶后，每个桶对loss的影响权重相同。<br>定义一个数据集 $ \mathcal{D}_k=\{(x_{1k},h_1),(x_{2k},h_2),…,(x_{nk},h_n)\}$ ，$ k$ 为样本 $x$ 的特征数。<br>定义一个排序函数 $ r_k:\Bbb{R}\sim [0,\infty)$，则：</p>
<script type="math/tex; mode=display">
 r_k(z)=\frac{1}{\sum_{(x,h)\in \mathcal{D}_k}h}\sum_{(x,h)\in \mathcal{D}_k,x<z}h</script><p>切分点集合 $ \{s_{k1}, s_{k2},…,s_{kl}\}$，满足：</p>
<script type="math/tex; mode=display">
|r_k(s_{k,j})-r_k(s_{k,j+1})|<\epsilon, \quad s_{k1}=\min\limits_i x_{ik},s_{kl}=\max\limits_i x_{ik}</script><p>这里 $\epsilon$ 用来衡量划分区间的大小（每个Bucket不能太大，以免错过最优切分点）。这个意味这数据集大约被分为 $\frac{1}{\epsilon}$ 个候选点。</p>
<p>那么 $h_i$ 为什么能够代表 $x_i$ 的权重来进行排序呢？将公式 ${\tilde{\mathcal{L}}}^{(t)}$ 对 $ h_i$ 进行提取，可得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\tilde{\mathcal{L}}^{( t)}&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}[\frac{1}{2} h_i\frac{ 2* g_if_t(x_i)}{h_i}+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i[ 2\times \frac{g_i}{h_i}f_t(x_i)+f_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i[ 2\times \frac{g_i}{h_i}f_t(x_i)+f_t^{ 2}(x_i)+(\frac{g_i}{h_i})^2-(\frac{g_i}{h_i})^2]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i(f_t(x_i)+\frac{g_i}{h_i})^{ 2}+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i(f_t(x_i)-(-\frac{g_i}{h_i}))^{ 2}+\Omega(f_t)+\text{constant}
\end{aligned}</script><p>发现 $ h_i$ 对结果影响最大，所以用它来进行排序。</p>
<h2 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h2><p>对稀疏数据的处理，重点是针对特征为空时的处理，对<strong>精准的贪心算法</strong>做了改进：<br><img src="/images/XGB/04.png" width="60%"></p>
<p>简单来讲，通过两轮遍历可以确保稀疏值位于左子树和右子树的情形，就是对该特征划分为左节点还是右节点做了一次比较，哪个效果好就把它放在哪。</p>
<h2 id="SYSTEM-DESIGN"><a href="#SYSTEM-DESIGN" class="headerlink" title="SYSTEM DESIGN"></a>SYSTEM DESIGN</h2><p>重点是优化：<br>（1）<strong>预排序</strong>：这个算法大量时间消耗在排序上。只需在最开始对每个特征排一次序即可。<br>这里XGB将所有的列数据都预先排了序。以压缩形式分别存到block里，不同的block可以分布式存储，甚至存到硬盘里。在特征选择的时候，可以并行的处理这些列数据，XGB就是在这实现的并行化，用多线程来实现加速。同时这里还用cache加了一个底层优化：当数据排序后，索引值是乱序的，可能指向了不同的内存地址，找的时候数据是不连续的，这里加了个缓存，让以后找的时候能找到小批量的连续地址，以实现加速！这里是在每个线程里申请了一个internal buffer来实现的！这个优化在小数据下看不出来，数据越多越明显。</p>
<p>（2）<strong>预取</strong>：尽可能的把数据保存在缓存中，这样不用去磁盘进行读取，减少时间开销。并且给出了对比结果：<br><img src="/images/XGB/05.png" width="100%"></p>
<p>（3）内存块的大小也会影响缓存速率。<br><img src="/images/XGB/06.png" width="50%"></p>
<p>针对磁盘存储优化。磁盘block不大的情况下：<br>1.把block数据进行压缩，让它没有那么大。<br>2.把block数据放在多个磁盘，增大磁盘带宽，让读取速度更。</p>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>如果$\textbf{X}$是一个离散型随机变量，取空间值为$\Bbb{R}$，其概率分布为$ p(x)=P(\textbf{X}=x),x\in\Bbb{R}$。那么，$\textbf{X}$的熵$H(\textbf{X})$定义为：</p>
<script type="math/tex; mode=display">
H(\textbf{X})=-\sum\limits_{x\in\Bbb{R}} p(x) log p(x)</script><p>其中，$H(\textbf{X})$可以写成$H( p)$。</p>
<p><strong>熵又称为子信息（self-information），可以视为描述一个随机变量的不确定性的数量</strong>。它表示信源$\textbf{X}$每发一个符号（不论发什么符号）所提供的平均信息量。<strong>一个随机变量的熵越大，它的不确定性越大，那么，正确估计其值的可能性就越小。越不确定的随机变量越需要大的信息量用以确定其值。</strong></p>
<p><strong>熵定义了随机变量的不确定性，当熵最大时，随机变量最不确定，最难准确地预测其行为。也就是说，在已知部分知识的前提下，关于未知分布最合理的推断应该是符合已知知识最不确定或最大随机的推断。</strong> </p>
<h2 id="联合熵和条件熵"><a href="#联合熵和条件熵" class="headerlink" title="联合熵和条件熵"></a>联合熵和条件熵</h2><p>如果$\textbf{X},\textbf{Y}$是一对离散型随机变量$\textbf{X},\textbf{Y}\sim p(x,y)$，$\textbf{X},\textbf{Y}$的联合熵（joint entropy）$H(\textbf{X},\textbf{Y})$定义为：</p>
<script type="math/tex; mode=display">
H(\textbf{X},\textbf{Y})=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(x,y)</script><p>联合熵实际上就是描述一对随机变量平均所需要的信息量。</p>
<p>给定随机变量$\textbf{X}$的情况下， 随机变量$\textbf{Y}$的条件熵（conditionalentropy）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H(\textbf{Y}|\textbf{X})&=\sum\limits_{ x\in\textbf{X}} p(x) H(\textbf{Y}|\textbf{X}= x)\\
&=\sum\limits_{ x\in\textbf{X}} p(x)[-\sum\limits_{ y\in\textbf{Y}} p(y|x) log p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)
\end{aligned}</script><p>将其中的联合概率$log p(x,y)$展开，可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H(\textbf{X},\textbf{Y})&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log[ p(x)p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) [log p(x) + log p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(x)-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)\\
&=-\sum\limits_{ x\in\textbf{X}} p(x) log p(x)-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)\\
&=H(\textbf{X})+H(\textbf{Y}|\textbf{X})
\end{aligned}</script><p>我们称上式为熵的连锁规则。推广到一般情况，有：</p>
<script type="math/tex; mode=display">
H(\textbf{X}_1,\textbf{X}_2,...,\textbf{X}_n)=H(\textbf{X}_1)+H(\textbf{X}_2|\textbf{X}_1)+...+H(\textbf{X}_n|\textbf{X}_1,\textbf{X}_2,...,\textbf{X}_{n-1})</script><h2 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h2><p>根据熵的连锁规则， 有：</p>
<script type="math/tex; mode=display">
H(\textbf{X},\textbf{Y})=H(\textbf{X})+H(\textbf{Y}|\textbf{X})=H(\textbf{Y})+H(\textbf{X}|\textbf{Y})</script><p>因此：</p>
<script type="math/tex; mode=display">
H(\textbf{X})-H(\textbf{X}|\textbf{Y})=H(\textbf{Y})-H(\textbf{Y}|\textbf{X})</script><p>这个差叫做$\textbf{X}$和$\textbf{Y}$的互信息（mutual information, MI），记作$I(\textbf{X};\textbf{Y})$。<br>或者定义为：如果$(\textbf{X},\textbf{Y})\sim  p(x,y)$，则$\textbf{X},\textbf{Y}$之间的互信息$I(\textbf{X};\textbf{Y})=H(\textbf{X})-H(\textbf{X}|\textbf{Y})$。</p>
<p><strong>$I(\textbf{X};\textbf{Y})$反映的是在知道了$\textbf{Y}$的值以后$\textbf{X}$的不确定性的减少量。可以理解为$\textbf{Y}$的值透露了多少关于$\textbf{X}$的信息量。</strong><br>互信息和熵之间的关系：<br><img src="/images/XGB/互信息.png" width="40%"></p>
<p>如果将定义中的$H(\textbf{X})$和$H(\textbf{X}|\textbf{Y})$展开，可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
I(\textbf{X};\textbf{Y})&=H(\textbf{X})-H(\textbf{X}|\textbf{Y})\\
&=H(\textbf{X})+H(\textbf{Y})-H(\textbf{X},\textbf{Y})\\
&=\sum\limits_{ x} p(x) log \frac{1}{p(x)}  + \sum\limits_{ y} p(y) log \frac{1}{p(y)}  + \sum\limits_{ x,y} p(x,y) log p(x,y) \\
&=\sum\limits_{ x,y} p(x,y) log \frac{p(x,y)}{p(x)p(y)} \\
\end{aligned}</script><p>由于$H(\textbf{X}|\textbf{X})=0$， 因此，</p>
<script type="math/tex; mode=display">
H(\textbf{X})=H(\textbf{X})-H(\textbf{X}|\textbf{X})=I(\textbf{X};\textbf{X})</script><p>这一方面说明了为什么熵又称为自信息，另一方面说明了两个完全相互依赖的变量之间的互信息并不是一个常量，而是取决于它们的熵。</p>
<p>实际上，互信息体现了两变量之间的依赖程度：<br>如果$I(\textbf{X};\textbf{Y})≫0$，表明$\textbf{X}$和$\textbf{Y}$是高度相关的；<br>如果$I(\textbf{X};\textbf{Y})=0$，表明$\textbf{X}$和$\textbf{Y}$是相互独立的；<br>如果$I(\textbf{X};\textbf{Y})≪0$，表明$\textbf{Y}$的出现不但未使$\textbf{X}$的不确定性减小，反而增大了$\textbf{X}$的不确定性，是非常是不利的。</p>
<h2 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h2><p>相对熵（relative entropy）又称Kullback-Leibler差异（KullbackLeibler divergence），或简称KL距离，是<strong>衡量相同事件空间里两个概率分布相对差距的测度</strong>。两个概率分布$ p(x)$和$ q(x)$的相对熵定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
D( p||q)&=\sum\limits_{ x\in\textbf{X}} p(x) log\frac{ p(x)}{ q(x)}\\
&=\sum\limits_{ x\in\textbf{X}} p(x) log  p(x)  - \sum\limits_{ x\in\textbf{X}} p(x) log q(x)\\
&=-H( p)+H( p,q)
\end{aligned}</script><p>其中，$H( p)$恒不变，只需考虑交叉熵$H( p,q)$即可。$ q(x)$ 分布越接近 $ p(x)$，那么散度值越小。<br>有时会将KL散度称为KL距离，但它并不满足距离的性质：KL散度不是对称的；KL散度不满足三角不等式。</p>
<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>根据前面熵的定义，知道熵是一个不确定性的测度，也就是说，我们对于某件事情知道得越多，那么，熵就越小，因而对于试验的结果我们越不感到意外。<strong>交叉熵的概念就是用来衡量估计模型与真实概率分布之间差异情况的。</strong><br>如果一个随机变量$\textbf{X}\sim p(x)$，$ q(x)$为用于近似$ p(x)$的概率分布，那么，随机变量$\textbf{X}$和模型$ p(x)$之间的交叉熵（cross entropy）定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H( p,q)&=H( p)+D( p||q)\\
&=-\sum\limits_{ x\in\textbf{X}} p(x) log  q(x)\\
\end{aligned}</script><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8yOTM5NjcyLjI5Mzk3ODU=">XGBoost: A Scalable Tree Boosting System<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvMTA5Nzk4MDguaHRtbA==">XGBoost算法原理小结<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FkYnN6c2ovYXJ0aWNsZS9kZXRhaWxzLzc5NjE1NzEy">XGBoost 论文翻译+个人注释<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84OTU4OTIyMg==">XGBoost论文详解<i class="fa fa-external-link-alt"></i></span><br>[统计自然语言处理（第二版），宗成庆]</p>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvRHk0cnRiX0JqMmI3Q0FCVEVWNFRuUQ==">Xgboost · 十三问十三答<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/06/20/Paper/01.Unsupervised%20Data%20Augmentation%20for%20Consistency%20Training/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/20/Paper/01.Unsupervised%20Data%20Augmentation%20for%20Consistency%20Training/" class="post-title-link" itemprop="url">Unsupervised Data Augmentation for Consistency Training</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-06-20T00:00:00+08:00">2021-06-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景：深度学习的模型训练通常依赖大量的标签数据（如Bert、XLNet），在只有少量数据上通常表现不好。由此产生了数据增强，但以前的研究都是基于监督学习的，并且效果不是特别理想。</p>
<p>贡献：本文提出了一种对无监督（无标签）数据增强方式（半监督学习中无标签数据的增强），简称UDA。UDA方法生成的无监督数据与原始无监督数据具备<strong>分布的一致性</strong>，而以前的方法通常只是应用高斯噪声和dropout噪声（无法保证一致性）。</p>
<p>效果：使用这种数据增强方法，在极少量数据集上，六种语言任务和三种视觉任务都得到了明显的提升。IMDb数据分类任务上，仅仅使用20个带标签数据加UDA方法，就超过了25000个带标签数据的训练模型，错误率达到了4.2%。在CIFAR-10上仅用4000张标签图片就达到了2.7%的错误率。在SVHN任务上，仅仅用250个标签数据就达到了2.85%的错误率，这相当于用全数据集才能达到的正确率，而它们的数量级差别达到了1或2（差10倍或100倍）。在大量标签数据集上，UDA同样表现优秀，在ImageNet任务上，使用10%带标签数据，UDA方法就将Top1和Top5的准确率分别由55.1%提高到77.3%，68.7提高到88.5%。在全数据集上，则分别由78.3%提高到94.4%，79%提高到94.5%。</p>
<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h1><p>深度学习需要大量带标签数据，但是实际工程中很难满足，这就需要数据标注，但数据标注是一项耗时耗力的工作。所以，充分利用未标注数据是一个很有意义的研究方向。而半监督方法，是最有前景的方法之一，当前半监督方法可归结为三类：<br>（1）基于图卷积和图嵌入的图标签传播方法。<br>（2）将目标数据作为潜变量进行预测。<br>（3）强制一致/平滑。这种方法在许多任务中被证明具有较好的效果。</p>
<p>强制平滑方法只是使得模型对应较小的噪声不那么敏感。常用方法就是：对于一个样本，添加一些噪声（例如高斯噪声）然后强制让模型对于加噪和不加噪的数据的输出尽量的相似。直观而言就是一个好的模型，应该能够适应各种小的、不改变样本性质的扰动。通常由于扰动函数的不同会有各种不同的方案。</p>
<p>本文在Sajjadi、 Laine等人的研究的基础上，从有监督数据中学习扰动函数，从而得到最优的数据增强方法。良好的数据增强方法能够大大提高模型的结果，并且数据增强方法能应用于各领域。<strong>本文使用的优化方法是最小化增强数据与真实数据之间的KL散度</strong>。虽然有监督数据的数据增强取得了很多成功，但是大量的无监督数据使得UDA这种无监督数据增强方法拥有更广阔前景。</p>
<p>主要贡献：<br>（1）提出一种TSA方法，该方法能够在无标签数据大于标签数据的时候防止过拟合。<br>（2）证明<strong>针对性的数据增强</strong>（如AutoAugment）效果明显优于无针对性的数据增强。<br>（3）验证了本文方法在NLP任务上（如Bert）上的有效性。<br>（4）在CV和NLP任务中，本文方法都表现优异。<br>（5）研究一种能应用于分类数据中有标签数据和无标签数据不匹配情况的方法（数据不平衡处理方法）。</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><h2 id="有监督数据增强"><a href="#有监督数据增强" class="headerlink" title="有监督数据增强"></a>有监督数据增强</h2><p>在保持标签相同（同一类别）的情况下，通过某种转换方法扩充出类似于真实数据的训练数据。简单而言就是，有一个样本$x$，通过转换函数$q(x)$生成新数据$\hat{x}$，新旧数据有相同的数据标签$y(\hat{x})=y(x)$。通常为了得到的增强数据与原始数据相似，使用的是最大似然估计方法。</p>
<p>数据增强方法可以看成是从有标签数据中扩充出更多的有标签数据，然后用扩充数据进行模型训练。因此，扩充数据相对于原始数据必须是有效的变换（例如图片缩放对图片识别可能有效，图片旋转可能无效）。也因此，如何设计转换函数至关重要。</p>
<p>目前，针对NLP任务的有监督数据增强方法已经取得了很大进展。虽然有成果，但是它通常被比喻成“蛋糕上的樱桃”，只是提高有限的性能，这是由于监督数据通常都是少量的。因此，本文研究了一种基于大量数据的无监督数据增强方法。</p>
<h2 id="无监督数据增强"><a href="#无监督数据增强" class="headerlink" title="无监督数据增强"></a>无监督数据增强</h2><p>本文研究了一种利用无监督数据的强制平滑方法（类似VAT）。工作流程如下：<br><img src="/images/UDA/UDA.png" width="90%"></p>
<p>（1）监督学习部分，使用交叉熵损失函数，模型是$p_\theta(y|x)$。<br>（2）无监督学习部分，使用强制平滑损失函数，对无标签数据进行数据增强，使增强前和增强后的数据分布越相近越好。增强前模型$p_{\tilde{\theta}}(y|x)$，增强后模型$p_\theta(y|\hat{x})$。<br>（3）最后，同时使用有标签和无标签数据，把二者模型结合起来，得到Final Loss。</p>
<p>本文使用最小化<strong>增强后的无标签数据</strong>和<strong>增强前无标签数据</strong>的KL散度。公式如下：<br><img src="/images/UDA/UDA_loss1.png" width="60%"></p>
<p>为了同时使用带标签数据和无标签数据，作者在计算带标签数据时上加上交叉熵损失和权重$\lambda$。<br><img src="/images/UDA/UDA_loss2.png" width="40%"></p>
<p>其中$\it q(\hat{x}|x)$是数据增强变换，$\tilde{\theta}$是当前参数$\theta$的固定副本，表明梯度像Miyato等人所建议的那样，不是通过$\tilde{\theta}$传播的。这里使用的数据增强与监督数据增强中使用的增强方法相同。由于数据增强耗时比较大，所以数据增强是离线生成的，单个原始样本会生成多个增强样本。</p>
<p>在无监督学习时，使用了针对性的数据增强：<br>（1）<strong>Back-translation</strong>：回译能够在保证语义不变的情况下，生成多样的句式。实验证明，在QANet上，这种策略取得了良好的效果。因此作者在情感分类问题等数据集，如IMDb，Yelp-2，Yelp-5，Amazon-2，Amazon-5上采用了这种策略，同时，他们发现，句式的多样性比较有效性更重要。所以使用了<strong>RandAugument</strong>。<br>（2）<strong>RandAugument</strong>：随机抽样增强，加入噪声。采用随机抽样代替集束搜索策略（一种贪心策略）。具体而言，作者使用WMT14语料库来训练英语到法语和法语到英语的翻译模型，并对每个句子执行回译，而不是整个段落，因为WMT14中的并行数据是用于句子级翻译，而情感分类语料库中的输入类型是段落。<br>（3）<strong>TF-IDF word replacement</strong>：虽然回译能够很好的进行数据扩充，但是它并不能保证扩充的句子包含关键词。而对于某些任务，如DBPedia任务，它的目标是预测某些句子属于维基百科的哪个词条。因此关键字非常重要，本文研究了一种在保留TF-IDF高的关键字，用其他非关键字替代TF-IDF分数低的非关键字扩充方案，详细见论文附录B。<br>增强结果如图所示：<br><img src="/images/UDA/trans.png" width="80%"></p>
<p>当然，对CV任务用了<strong>AutoAugument</strong>：用强化学习来搜索图像增强的“最优”组合，其性能明显优于任何人工设计的优化方法。作者使用已发现的增强策略，在CIFAR-10， SVHN和ImageNet上进行了实验，并在CIFAR-10，SVHN上组合应用了Cutout技术。<br>增强结果如图所示：<br><img src="/images/UDA/trans2.png" width="80%"></p>
<h2 id="数据增强在多样性和有效性上的平衡"><a href="#数据增强在多样性和有效性上的平衡" class="headerlink" title="数据增强在多样性和有效性上的平衡"></a>数据增强在多样性和有效性上的平衡</h2><p>虽然在一些非常优秀的数据增强方法中，能够得到很好的多样性和有效性。但是，由于多样性是通过改变原始数据得到的，所以，它存在改变数据类别的风险，所以，多样性和有效性是存在一定矛盾的。</p>
<p>对于图像分类，AutoAugment算法在有监督的环境下，根据验证集的性能进行优化，从而自动找到多样性和有效性之间的最佳点。</p>
<p>对于文本分类，作者调整随机抽样的强度。一方面，当强度为0时，随机抽样解码退化为贪婪方法，产生完全有效但完全相同的样本。另一方面，当作者使用1的强度时，随机抽样会产生非常不同但几乎不可读的样本。作者发现，设置Softmax强度为0.7、0.8或0.9的表现最好。</p>
<h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><p>要介绍一些针对不同问题，不同场景下的训练技巧。</p>
<p><strong>Training Signal Annealing（TSA）</strong>：针对标签数据与未标签数据不平衡时的场景。由于有大量的未标签数据需要UDA处理，所以需要一个较大模型，但是由于较大模型很容易在少量标签数据下过拟合，所以，提出了本方法用于解决该问题。<br>TSA原理就是在训练过程中，随着未标签数据的增加，逐步去除带标签数据，从而避免模型过拟合到带标签的训练数据。具体而言，就是在训练的$t$时刻，设置一个阈值$\eta_t$，当$\frac{1}{k}\leqslant\eta_t\leqslant 1$，其中$k$是类别数。当某个标签计算的$p_\theta(y^*|x)$大于阈值$\eta_t$，就将该标签数据移除出计算损失的过程，而只计算miniBatch里面的其余数据。假定miniBatch样本记作B，那么该策略计算损失如下：<br><img src="/images/UDA/TSA.png" width="40%"><br>过滤后的样本集合：<br><img src="/images/UDA/TSA2.png" width="40%"></p>
<p>阈值$\eta_t$用于防止模型过拟合到标签数据。随着$\eta_t$向1靠近，模型只能缓慢地从标注的实例中得到监督，大大缓解了过拟合问题。假设T是总训练步数，t是当前的训练步数。为了考虑未标记数据和标记数据的不同比率，有以下三种$\eta_t$更新计算方式：<br><img src="/images/UDA/TSA3.png" width="90%"></p>
<p>对于数据量少，容易过拟合的情况，使用指数形式比较好。对于标签数据不容易过拟合的情况，比如标签数据比较多或者使用了有效的正则化手段时，使用对数形式会比较好。使用不同更新方式的效果：<br><img src="/images/UDA/TSA4.png" width="50%"></p>
<p><strong>Sharpening Predictions</strong><br>当标签数据很少时，未标签数据和预测的未标签数据分布会很平坦。因此，在计算KL散度时，主要贡献的部分来自于标签数据。例如在Imagenet任务中，使用10%标签数据下，未标签数据的分布明显比标签数据的分布更加平坦。而比较丰富的数据分布是比较有利于模型训练的，因此，提出以下三种锐化方案：<br>（1）基于置信度的mask：对模型预测效果不好的，预测的概率小于一定阈值的标签，不计算一致性损失。<br>（2）最小化熵：最小化熵就是使得预测的增广数据能够拥有一个较低的熵，因此，需要在计算损失时，加上熵的计算。<br>（3）Softmax控制：通过调整Softmax控制输出， $p_{\tilde{\theta}}(y|x)$通过$Softmax(l(x)/\tau)$计算，其中$l(x)$表示结果逻辑分布概率，$\tau$表示强度。$\tau$越小，分布越锐化。</p>
<p><strong>Domain-relevance Data Filtering</strong><br>通常，作者希望能够运用领域外的数据，因为它比较容易获取。但是，一般领域外的数据和领域内的数据不匹配。由于数据分布的不匹配，使用领域外的数据往往对模型是有负面影响的。为了获取与当前任务相关的域数据，本文采用一种通用的检测领域外数据的技术。作者用领域内的数据训练了一个模型，让后用它去评估领域外的数据，然后过滤掉置信度低的数据。具体说就是，对于分类任务，对所有领域外数据进行概率计算，只使用其中分类正确且概率高的数据。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>本文对文本分类和视觉相关任务，运用UDA进行了实验。包括六项文本分类任务和三项图片分类任务。</p>
<h3 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h3><p>实验是基于Bert进行的，因为它在许多NLP任务中表现都很好。具体实验设置请看原始论文，实验结果如下：<br><img src="/images/UDA/01.png" width="80%"></p>
<p>实验结果表明，运用UDA后，基本都取得了较大的提高。同时，作者还实验了<strong>不同数量的标签</strong>对结果的影响，结果如下：<br><img src="/images/UDA/02.png" width="80%"></p>
<p>作者实验对比了UDA与半监督方法，结果显示，UDA结果明显更优。<br><img src="/images/UDA/03.png" width="90%"></p>
<p>同时，作者还对比实验了不同模型的情况：<br><img src="/images/UDA/04.png" width="80%"></p>
<h3 id="图像任务"><a href="#图像任务" class="headerlink" title="图像任务"></a>图像任务</h3><p>ImageNet之所以要单独拿出来，是因为它是一个很有挑战性的任务，而且数据量很大。作者使用10%标签数据和全数据分别做了对比（图片尺寸224）。<strong>10%标签数据</strong>，ImageNet对比实验结果：<br><img src="/images/UDA/05.png" width="50%"></p>
<p><strong>全数据</strong>，ImageNet对比实验结果：<br><img src="/images/UDA/06.png" width="50%"></p>
<p>作者做了<strong>使用不同训练策略</strong>下的情况，TSA对比实验结果：<br><img src="/images/UDA/07.png" width="50%"></p>
<p>最后，作者做了<strong>消融实验，对比不同策略的重要性</strong>。不同模块的消融实验结果：<br><img src="/images/UDA/08.png" width="50%"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文提供了一种无监督数据（无标签）数据增强方式，通过<strong>Back-translation</strong>、<strong>RandAugument</strong>、<strong>TF-IDF word replacement</strong>方法对无监督文本数据增强，使用<strong>AutoAugument</strong>对图像数据进行增强，最后使用KL散度使新生成的样本数据和原样本数据分布一致，最后结合有监督数据（有标签）形成最终的损失函数，通过<strong>TSA</strong>处理了无标签数据大于有标签数据的过拟合问题。</p>
<p>本文重要的是使用了针对性的数据增强，并且效果很好，不同于传统的高斯噪声、dropout噪声、或者简单的仿射变换，这种针对性的增强能生成更有效的噪声。并且对扰动的有效性和多样性进行了平衡。</p>
<p>这种针对性的思想值得学习，并且考虑分布影响，结合可以利用的增强方式，比如EDA中提到的同义词替换（synonym replacement）和随机插入（random Insertion，RI）。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMTI4NDh2Mi5wZGY=">Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMTI4NDgucGRmP3JlZj1oYWNrZXJub29uLmNvbQ==">Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDEuMTExOTYucGRm">EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9zZXZlbm9sZC5naXRodWIuaW8vMjAyMC8wNi90ZXh0X0VEQS8=">自然语言处理之文本数据增强<i class="fa fa-external-link-alt"></i></span><br>Github：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS1yZXNlYXJjaC91ZGE=">uda<i class="fa fa-external-link-alt"></i></span><br>Github：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3poYW5sYW9iYW4vRURBX05MUF9mb3JfQ2hpbmVzZQ==">EDA_NLP_for_Chinese<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC81ZDRlMThiOGRlMDQ=">谷歌惊艳的无监督数据增强方法—Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SoundMemories</span>
</div>
  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '.page-configurations',
    '.main-inner',
    '.post-toc-wrap',
    '.languages',
    '.pjax'
  ],
  analytics: false,
  cacheBust: false,
  scrollRestoration: false,
  scrollTo: !CONFIG.bookmark.enable
});

document.addEventListener('pjax:success', () => {
  pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  const hasTOC = document.querySelector('.post-toc');
  document.querySelector('.sidebar-inner').classList.toggle('sidebar-nav-active', hasTOC);
  document.querySelector(hasTOC ? '.sidebar-nav-toc' : '.sidebar-nav-overview').click();
  NexT.utils.updateSidebarPosition();
});
</script>


  




  <script src="/js/local-search.js"></script>








<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  const url = element.dataset.target;
  const pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  const pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  const fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>


<script data-pjax>
if (document.querySelectorAll('.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8.8.2/dist/mermaid.min.js', () => {
    mermaid.init({
      theme    : 'neutral',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    }, '.mermaid');
  }, window.mermaid);
}
</script>





  








    <div class="pjax">
  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@2.0.0/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink.listen({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://soundmemories.github.io/',]
      });
      });
  </script>

    </div>
</body>
</html>
