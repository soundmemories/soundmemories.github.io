<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.0.2","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="今日事，今日毕">
<meta property="og:type" content="website">
<meta property="og:title" content="SoundMemories">
<meta property="og:url" content="https://soundmemories.github.io/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="今日事，今日毕">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="SoundMemories">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://soundmemories.github.io/">


<script data-pjax class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>SoundMemories</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SoundMemories</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-归档">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
	   
		  
      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">113</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">
      

      
    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/23/NLP/08.%E8%92%B8%E9%A6%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/23/NLP/08.%E8%92%B8%E9%A6%8F/" class="post-title-link" itemprop="url">蒸馏</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-23 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-23T00:00:00+08:00">2021-07-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>66</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9wYWRkbGVwZWRpYS5yZWFkdGhlZG9jcy5pby9lbi9sYXRlc3QvdHV0b3JpYWxzL21vZGVsX2NvbXByZXNzL2luZGV4Lmh0bWw=">模型压缩+模型蒸馏<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80MTk2Nzk3MDI=">TextBrewer 通用蒸馏配置说明与工作流程介绍<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cDovL3d1amlhd2VuLnh5ei8yMDIxLzEwLzA5L2Rpc3RpbGwv">bert蒸馏小综述<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvdEtmSHE0OWhlYWt2ak0wRVZRUGdIdw==">BERT蒸馏完全指南｜原理/技巧/代码<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/22/NLP/07.%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/22/NLP/07.%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87/" class="post-title-link" itemprop="url">检索系统和常见指标</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-22T00:00:00+08:00">2021-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="检索式"><a href="#检索式" class="headerlink" title="检索式"></a>检索式</h1><h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>核心为<strong>信息检索</strong>（Information Retrieval，IR），即从大规模<strong>非结构化数据</strong>（通常为文本）的集合（通常保存在计算机上）中找出<strong>满足用户信息需求</strong>的资料（通常是文档）的过程。是研究信息的获取（acquisition）、表示（representation）、存储（storage）、组织（organization）和访问（access）的一门学问。</p>
<p>信息检索不仅仅是搜索，信息检索系统也不仅仅是搜索引擎。比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">返回与信息检索相关的网页-&gt;搜索引擎（SearchEngine，SE）</span><br><span class="line">姚明是谁？-&gt;问答系统（Question Answering，QA）</span><br><span class="line">返回Ipad的各类型号、配置等-&gt;信息抽取（Information Extraction，IE）</span><br><span class="line">使用Google Reader订阅新闻，并获取推荐-&gt;信息过滤（Information Filtering）、信息推荐（Information Recommending）</span><br></pre></td></tr></table></figure></p>
<h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><p>一个例子：《莎士比亚全集》这本大头书，我们想知道：哪些剧本包含Brutus和Caesar但是不包含Calpurnia？一种方式是采用Unix下的grep程序，先找出所有包含Brutus和Caesar的剧本，然后再将包含Calpurnia的剧本排除。但是很多情况下，采用上述线性扫描的方式是远远不够的。可以考虑用<strong>空间换取时间</strong>。</p>
<p><strong>词项文档索引</strong><br>词项-文档关联矩阵（incidence matrix），采用非线性的扫描方式，事先给文档建立索引。比如行索引为人名，列索引为书名，如果此人在书中出现过就是1，否则为0。这种方法要很大的存储空间。遇到更大的数据集根本不可用这种方法。</p>
<p><strong>倒排索引</strong><br>对于每一个词项，存储包含整个词项的文档的一个列表，一个文档用一个序列号docID来表示。我们能用一个固定长度的数据来存储它吗？不能， 不利于增删。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Brutus-&gt;[1,2,4,11,31,45,173,174]</span><br><span class="line">Caesar-&gt;[1,2,4,5,6,16,57,132]</span><br><span class="line">Calpurnia-&gt;[2,31,54,101]</span><br></pre></td></tr></table></figure><br>如果Caesar被添加到14号文档中，固定长度数组就不行了，所以使用可变长度的记录列表：<br>1、在硬盘上，一串<strong>连续的记录</strong>是正常的，也是最好的。<br>2、在内存里，可以使用<strong>链表</strong>，或者可变长度的整数。</p>
<p>上面所说的<strong>docID链表</strong>（排序后的结果）就是<strong>倒排记录表</strong>（inverted list），人名构成的词项就是<strong>词项词典</strong>。词项-&gt;文档。</p>
<p>建立步骤：<br>1、建立<strong>词条</strong>和<strong>docID</strong>序列。<br>2、排序（<strong>先按照词条排序，再按照docID排序</strong>）。<br><img src="/images/对话系统/3.png" width="40%"></p>
<p>考虑查询Brutus和Caesar：<br>1、在字典中找到Brutus，得到它的倒排记录表。<br>2、在字典中找到Caesar，得到它的倒排记录表。<br>3、两个倒排记录表取交集（使用双指针查询，O(n)）。</p>
<h1 id="近邻搜索-召回"><a href="#近邻搜索-召回" class="headerlink" title="近邻搜索(召回)"></a>近邻搜索(召回)</h1><h2 id="字符级别"><a href="#字符级别" class="headerlink" title="字符级别"></a>字符级别</h2><h3 id="BM25"><a href="#BM25" class="headerlink" title="BM25"></a>BM25</h3><p>bm25 是一种用来评价搜索词和文档之间相关性的算法，它是一种基于<strong>概率检索模型</strong>提出的算法，再用简单的话来描述下bm25算法：我们有一个 $query$ 和一批文档 $Ds$ ，现在要计算 $query$ 和每篇文档 $D$ 之间的相关性分数，我们的做法是，先对 $query$ 进行切分，得到单词 $q_i$ ，然后单词的分数由3部分组成：</p>
<ul>
<li>每个单词的权重。</li>
<li>相关性分数 $R$：单词和 $D$ 之间的相关性，单词和 $query$ 之间的相关性。</li>
</ul>
<p>最后对于每个单词的分数我们做一个求和，就得到了query和文档之间的分数。</p>
<script type="math/tex; mode=display">Score(Q,d)=\sum\limits^nW_iR(q_i,d)</script><p>其中，$W_i$代表单词 $q_i$ 权重，$R(q_i,d)$ 代表单词 $q_i$ 和文档 $d$ 相关性。</p>
<p><strong>每个单词的权重</strong><br>$N$ 表示所有文档数目，$n(q_i)$ 为单词 $q_i$ 出现的文档数目，0.5主要是做平滑处理。</p>
<script type="math/tex; mode=display">IDF(q_i)=log(\frac{N-n(q_i)+0.5}{n(q_i)+0.5})</script><p>依据IDF的作用，对于某个 $q_i$ ，包含 $q_i$ 的文档数越多，说明 $q_i$ 重要性越小，或者区分度越低，IDF越小，因此IDF可以用来刻画 $q_i$ 与文档的相似性。</p>
<p><strong>相关性分数</strong><br>BM25的设计依据一个重要的发现：词频和相关性之间的关系是非线性的，也就是说，每个词对于文档的相关性分数不会超过一个特定的阈值，当词出现的次数达到一个阈值后，其影响就不在线性增加了，而这个阈值会跟文档本身有关。</p>
<script type="math/tex; mode=display">R(q_i,d)=\frac{f_i\cdot (k_1+1)}{f_i+K}\cdot\frac{qf_i\cdot(k_2+1)}{qf_i+k_2}</script><script type="math/tex; mode=display">K=k_1\cdot(1-b+b\cdot\frac{dl}{avgdl})</script><p>其中，$f_i$ 为单词 $q_i$ 在文档 $d$ 中的词频。$qf_i$ 为单词 $q_i$ 在 $query$ 中出现的频率。$dl$ 是文档 $d$ 的长度，$avgdl$ 是所有文档的平均长度。$k_1$ 是一个正的参数（一般为2），用来标准化文章词频的范围，$k_1$ 越大，我们越看重单词在文档d中词频的影响。$k_2$ 越大，越看重单词在query中的词频，$k_2$ 一般为1。$b$为0~1之间的值（一般为0.75），决定使用文档长度来表示信息量的范围。</p>
<h3 id="WAND"><a href="#WAND" class="headerlink" title="WAND"></a>WAND</h3><p>wand（weak and）算法，通过计算每个词的贡献上限来估计文档的相关性上限，并与预设的阈值比较，进而跳过一些相关性一定达不到要求的文档，从而得到提速效果（$query$比较长的时候使用）。</p>
<p>wand 算法首先要估计<strong>每个词对相关性贡献的上限（upper bound）</strong>，最简单的相关性就是TF-IDF，一般IDF是固定的，因此只需要估计一个词在各个文档中的词频TF上限（即这个词在各个文档中最大的TF），该步骤通过线下计算即可完成。线下计算出各个词的相关性上限，可以计算出一个 $query$ 和一个文档的相关性上限值，就是它们共同出现的词的相关性上限值的和，通过与预设的阈值比较，如果 $query$ 与文档的相关性大于阈值，则进行下一步的计算，否则丢弃。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">query：the quick brown fox     </span><br><span class="line">with top k&#x3D;2</span><br></pre></td></tr></table></figure><br>根据倒排索引表，计算每个词的相关性贡献上限，即 TF-IDF，取每个词的最大值即可，如下表中max值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">        max  倒排索引</span><br><span class="line">the     0.9  [2,3,7,8,9,10,11,12,13,17,18,19...]</span><br><span class="line">qucik   1.9  [5,6,9,11,14,18]</span><br><span class="line">brown   2.3  [2,4,5,15,42,84,96]</span><br><span class="line">fox     7.1  [5,7,8,13]</span><br></pre></td></tr></table></figure><br>根据max可得到 $query$ 和文档的相关性上限。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">the和brown都出现在2文档，假设2文档中the的tfidf为0.1，brown为1。</span><br><span class="line">the只出现在3文档，假设3文档中the的tfidf为0.5。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 2.0 | 2 |</span><br><span class="line">2 | 0.5 | 3 |</span><br><span class="line">一般用heap维持k个。</span><br></pre></td></tr></table></figure><br>维持top-2这个heap堆，不停的这样寻找。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">当走到4的时候，只有brown出在4中，且max为2.3，那么文档4的score可能战胜0.5，计算文档4的tfidf，假设为1.4，替换掉0.5。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 2.0 | 2 |</span><br><span class="line">2 | 1.4 | 4 |</span><br><span class="line"></span><br><span class="line">同理，走到文档5的时候，brown、quick、fox都出现在文档5中，假设score计算为6.3，替换掉1.4。</span><br><span class="line"># |score|id|</span><br><span class="line">------------</span><br><span class="line">1 | 6.3 | 5 |</span><br><span class="line">2 | 2.0 | 2 |</span><br><span class="line"></span><br><span class="line">走到文档6的时候，只有quick出现在文档6中，且max为1.9，不可能超过heap中最小的score，所以跳过不用计算。</span><br></pre></td></tr></table></figure><br>预设的阈值，就是heap中最小score值，每次都是和它比较。</p>
<h2 id="向量级别"><a href="#向量级别" class="headerlink" title="向量级别"></a>向量级别</h2><h3 id="SIF"><a href="#SIF" class="headerlink" title="SIF"></a>SIF</h3><p>smooth inverse frequency（SIF），原论文<span class="exturl" data-url="aHR0cHM6Ly9vcGVucmV2aWV3Lm5ldC9wZGY/aWQ9U3lLMDB2NXh4">A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS<i class="fa fa-external-link-alt"></i></span>，参考解析<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGF0YWJpbmdvL3AvOTc4ODI0NC5odG1s">论文阅读<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="WMD"><a href="#WMD" class="headerlink" title="WMD"></a>WMD</h3><p>Word Mover’s Distance，论文《From Word Embeddings To Document Distances》提出了一种新的计算文档距离的方法。该方法建立在Word Embeddings基础之上，通过累计计算一个文档中的词travel到另一篇文档中词的最小距离来进行度量。详情参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNTEzNDQ4Njg=">Word Mover’s Distance 论文笔记<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84ODc4ODk2MQ==">对Word Mover’s Distance的理解<i class="fa fa-external-link-alt"></i></span>。 优化算法WCD（Word centroid distance）和RWMD（Relaxed word moving distance）参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85MTYyMTI0MQ==">深入理解WMD距离——一种衡量文本之间差异的度量<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNjQ5NTcyNTc=">WMD系列方法介绍（词移距离方法）<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84ODY5OTc3Ng==">From Word Embeddings To Document Distances 小结<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="Annoy"><a href="#Annoy" class="headerlink" title="Annoy"></a>Annoy</h3><p>Approximate Nearest Neighbors Oh Yeah，Annoy 是 Spotify 开源的高维空间求近似最近邻的库，在 Spotify 使用它进行音乐推荐。Annoy通过将海量数据建立成一个二叉树来使得每个数据查找时间复杂度是$O(log n)$。详情参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlcm9fZmFudGFvL2FydGljbGUvZGV0YWlscy83MDI0NTM4Nw==">海量数据相似查找系列2 — Annoy算法<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="HNSW"><a href="#HNSW" class="headerlink" title="HNSW"></a>HNSW</h3><p>Hierarchcal Navigable Small World graphs，详情参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGFuZ3VpL3AvMTQ2NzUxMjEuaHRtbA==">HNSW<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cucnlhbmxpZ29kLmNvbS8yMDE4LzExLzI3LzIwMTgtMTEtMjclMjBITlNXJTIwJUU0JUJCJThCJUU3JUJCJThELw==">近似最近邻算法 HNSW 学习笔记<i class="fa fa-external-link-alt"></i></span>，代码<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/faiss/blob/13a2d4ef8fcb4aa8b92718ef4b9cc211033e7318/benchs/bench_hnsw.py">facebookresearch<br>/faiss</a>。</p>
<h3 id="KD-Tree"><a href="#KD-Tree" class="headerlink" title="KD Tree"></a>KD Tree</h3><p>K dimentional Tree，详情参考李航的《统计学习方法》中K近邻算法，<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS9rZC10cmVlLzIzMDI1MTU/ZnI9YWxhZGRpbg==">kd-tree<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly9sZWlsZWlsdW9sdW8uY29tL3Bvc3RzL2tkdHJlZS1hbGdvcml0aG0tYW5kLWltcGxlbWVudGF0aW9uLmh0bWw=">k-d tree算法原理及实现<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="LSH"><a href="#LSH" class="headerlink" title="LSH"></a>LSH</h3><p>Locality Sensitive Hashing，详情参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ljdnByL2FydGljbGUvZGV0YWlscy8xMjM0MjE1OQ==">局部敏感哈希(Locality-Sensitive Hashing, LSH)方法介绍<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlcm9fZmFudGFvL2FydGljbGUvZGV0YWlscy83MDI0NTI4ND9zcG09MTAwMS4yMDE0LjMwMDEuNTUwMg==">海量数据相似查找系列1 — Minhashing &amp; LSH &amp; Simhash 技术汇总<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="Faiss工具"><a href="#Faiss工具" class="headerlink" title="Faiss工具"></a>Faiss工具</h2><iframe src="https://nbviewer.org/github/soundmemories/StudyNotes/blob/f42b2aced7dfe7e25f078bf8c8a59725cced6c31/Cheatsheets/Faiss_demo.ipynb" width="1000" height="700"></iframe>

<h1 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h1><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><p>MAP（Mean Average Precision）：平均准确率是相关文档检索出后的准确率的平均值。<br>反映系统在全部相关文档的性能单值指标，检索出来的相关文档越靠前（rank越高），MAP就可能越高。<br><img src="/images/检索和指标/1.png" width="100%"></p>
<p>计算顺序：Precision-&gt;Average Precision-&gt;Mean Average Precision。<br><strong>Precision</strong>：rank结果中的相关文档-&gt;$\dfrac{\text{第几个相关文档}}{\text{文档rank数}}$<br><strong>Average Precision</strong>：$\dfrac{rank结果中的相关文档Precision和}{相关文档总数}$<br><strong>Mean Average Precision</strong>：$\dfrac{每次查询的Average Precision和}{查询次数}$</p>
<p>注意，在Precision中，分子是rank结果中的相关文档是第几个，比如主题1有4个相关网页，序号分别为1234，那么rank排序为1234和4321的Precision结果是一样的，分子都是1234，分母也都是1234。<strong>因为此MAP没有考虑相关文档内部排序</strong>。</p>
<h3 id="NDCG"><a href="#NDCG" class="headerlink" title="NDCG"></a>NDCG</h3><p><strong>NDCG</strong>（Normalized Discounted Cumulative Gain），归一化折损累计增益。衡量和评价搜索结果算法。DCG的两个思想：</p>
<ul>
<li><strong>高度关联的结果比一般关联度的结果更影响最终的指标得分</strong>。</li>
<li><strong>有高关联度的结果出现在更靠前的位置的时候，指标会越高</strong>。</li>
</ul>
<p><strong>CG</strong>（Cumulative Gain），是DCG的前身，只考虑到了相关性的关联程度，没有考虑到位置的因素。它是一个搜素结果相关性分数的总和。如一个搜索结果list页面有P个结果，其CG为：</p>
<script type="math/tex; mode=display">CG_{p}=\sum\limits_{i=1}^{p}rel_i</script><p>其中，$rel_i$ 代表 $i$ 位置上的相关度。<br>CG的统计不受到搜索结果的排序影响，CG得分高只能说明这个结果页面总体的质量比较高并不能说明这个算法做的排序好或差。</p>
<p><strong>DCG</strong>（Discounted CG），就是在每一个CG的结果上除以一个折损值，为什么要这么做呢？目的就是为了让排名越靠前的结果越能影响最后的结果。公式：</p>
<script type="math/tex; mode=display">DCG_p=\sum\limits_{i=1}^{p}\frac{rel_i}{log_2(i+1)}=rel_1+\sum\limits_{i=2}^{p}\frac{rel_i}{log_2(i+1)}</script><p>当然还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式是：</p>
<script type="math/tex; mode=display">DCG_p=\sum\limits_{i=1}^{p} \frac{2^{rel_i}-1}{log_2(i+1)}</script><p><strong>NDCG</strong>（Normalize DCG），由于搜索结果随着检索词的不同，返回的数量是不一致的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理，这里是处以IDCG。</p>
<script type="math/tex; mode=display">nDCG_p=\frac{DCG_p}{IDCG_p}</script><p>IDCG（ideal DCG）为理想情况下最大的DCG值。IDCG如何计算？首先要拿到搜索的结果，人工对这些结果进行排序，排到最好的状态后，算出这个排列下本query的DCG，就是IDCG。</p>
<script type="math/tex; mode=display">\sum\limits_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2(i+1)}</script><p>其中 $|REL|$ 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序。</p>
<h2 id="Point-wise"><a href="#Point-wise" class="headerlink" title="Point-wise"></a>Point-wise</h2><p>Pointwise排序是将训练集中的每个item看作一个样本获取rank函数，主要解决方法是把分类问题转换为单个item的分类或回归问题。</p>
<p>point-wise把排序问题当成一个二分类问题，训练的样本被组织成一个三元组 $(q_i,c_{i,j},y_{i,j})$。$y_{i,j}$ 为一个二进制值，表明 $c_{i,j}$ 是否为 $q_i$ 正确回答。我们就可以训练一个二分类网络：$h_\theta(q_i,c_{i,j}\to y_{i,j})$ ，其中 $0\leq y_{i,j}\leq 1$。训练的目标为最小化数据集中所有问题和候选句子对的交叉熵。</p>
<p><strong>算法</strong>：</p>
<ul>
<li>基于回归的算法：此时，输出空间包含的是实值相关度得分。采用 ML 中传统的回归方法即可。</li>
<li>基于分类的算法：此时，输出空间包含的是无序类别。对于二分类，SVM、LR 等均可；对于多分类，提升树等均可。</li>
<li>基于有序回归的算法：此时，输出空间包含的是有序类别。通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用 PRanking、基于 margin 的方法都可以。</li>
</ul>
<p>常见算法：Subset Ranking, McRank, Prank, OC SVM</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>ranking追求的是排序结果，并不要求精确打分，只要相对打分即可。</li>
<li>pointwise类方法并没有考虑同一个query对应的docs间的内部依赖性。</li>
<li>损失函数也没有利用model预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的docs，即会强调那些排序在后面对用户体验影响小的doc。</li>
<li>query间docs的不平衡，如query1对应500个文档，query2对应10个文档。当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，每组 query 应该都是等价的。</li>
</ul>
<p><strong>优点</strong>：速度快，标注简单，复杂度低。</p>
<p><strong>改进</strong>：Pointwise 类算法也可以再改进，比如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。</p>
<h2 id="Pair-wise-Approach"><a href="#Pair-wise-Approach" class="headerlink" title="Pair-wise Approach"></a>Pair-wise Approach</h2><p>Pairwise排序是将同一个查询中两个不同的item作为一个样本，主要思想是把rank问题转换为二值分类问题。</p>
<p>在pair-wise方法中排序模型 $h_{\theta}$ 让正确的回答的得分明显高于错误的获选答案。给一个提问，pair-wise给定一对候选回答学习并预测哪一个句子才是提问的最佳回答。训练的样例为 $(q_i,c_i^+,c_i^-)$ ，其中 $q_i$ 为提问， $c_i^+$ 为正确的回答，$c_i^-$ 为候选答案中一个错误的回答。</p>
<p><strong>算法</strong>：基于二分类的算法，比如Random Forest，GBDT，RankSVM，RankBoost，RankNet，Lambda Rank, LambdaMart等。RankNet：原本Ranking常见的评价指标都无法求梯度，因此没法直接对评价指标做梯度下降，而它们将不适宜用梯度下降求解的Ranking问题，转化为对偏序概率的交叉熵损失函数的优化问题，从而适用梯度下降方法。</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>doc pair 的数量将是 doc 数量的二次（$C_n^2$），从而 pointwise 方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 方法中进一步放大。</li>
<li>pairwise 方法相对 pointwise 方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。</li>
<li>pairwise 方法仅考虑了 doc pair 的相对位置，损失函数还是没有利用 model 预测排序中的位置信息。</li>
<li>如果人工标注包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。</li>
<li>pairwise 方法只考虑了内部相对位置排序，没有考虑整体排序。</li>
</ul>
<p><strong>改进</strong>：</p>
<ul>
<li>IRSVM，主要针对前述第一个缺陷。</li>
<li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第二个缺陷。</li>
<li>P-norm push，Ordered weighted average ranking，LambdaRank，Sparse ranker，主要针对前述第三个缺陷。</li>
<li>Multiple hyperplane ranker，magnitude-preserving ranking，主要针对前述第四个缺陷。</li>
</ul>
<h2 id="List-wise-Approach"><a href="#List-wise-Approach" class="headerlink" title="List-wise Approach"></a>List-wise Approach</h2><p>List-wise排序是将整个item序列看作一个样本，通过<strong>直接优化信息检索的评价方法</strong>和<strong>定义损失函数</strong>两种方法实现。</p>
<p>pair-wise 和 point-wise 忽视了一个事实就是答案选择，即从一系列候选句子中的预测问题。在list-wise中单一训练样本就：query和它的所有候选句子。在训练过程中给定提问数据 $q_i$ 和它的一系列候选句子 $C(c_{i1},c_{i2},\dots,c_{im})$ 和标签 $Y(y_{i1},y_{i2},\dots,y_{im})$，归一化的得分向量 $S$ 通过如下公式计算：</p>
<script type="math/tex; mode=display">Score_j=h_{\theta}(q_i,c_{ij})</script><script type="math/tex; mode=display">S=softmax([Score_1,Score_2,\dots,Score_m])</script><p><strong>算法</strong>：</p>
<ul>
<li>直接基于评价指标的算法：直接取优化 ranking 的评价指标，但这并不简单，因为评价指标基本都是离散不可微的，具体处理方式：<ul>
<li>优化基于评价指标的 ranking error 的连续可微的近似，如SoftRank，ApproximateRank，SmoothRank。</li>
<li>优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank。</li>
<li>使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP。</li>
</ul>
</li>
<li>非直接基于评价指标的算法：这里，不再使用和评价指标相关的 loss 来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。经典的如 ，ListNet，ListMLE，StructRank，BoltzRank。</li>
</ul>
<p>直接基于评价指标的算法的优化目标都是直接和 ranking 的评价指标有关。现在来考虑一个概念，informativeness。通常认为一个更有信息量的指标，可以产生更有效的排序模型。而多层评价指标（NDCG）相较二元评价（AP）指标通常更富信息量。因此，有时虽然使用信息量更少的指标来评估模型，但仍然可以使用更富信息量的指标来作为 loss 进行模型训练。</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。</li>
<li>listwise 类存在的主要缺陷是：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。</li>
</ul>
<h2 id="CFG"><a href="#CFG" class="headerlink" title="CFG"></a>CFG</h2><p>CFG：Context free grammars，上下文无关文法。是一种形式文法（formal grammar）。形式文法是形式语言（formal language）的文法，由一组产生规则 （production rules）组成，描述该形式语言中所有可能的字符串形式。</p>
<p>上面这段话比价令人费解，我理解，就是每个句子的产生都遵循着一定的规则（规则学习的理念）。在这里面有几个概念：</p>
<ul>
<li>终止符：可以理解为基础符号，词法符号，是不可替 代的，天然存在，不能通过文法规则生成。</li>
<li>非终结符，或者句法变量。</li>
<li>Production rules： grammar 是由终结符集、非终结符集和产生规则共同组成。产生规则定义了符号之间如何转换替代。规则的左侧是规则头，是可以被替代的符号；右侧是规则体，是具体的内容。</li>
</ul>
<p>CFGs的性质：</p>
<ul>
<li>一个CFG定义了一个可能的推导的集合。</li>
<li>一句话如果是可以被CFG定义出来，那么至少有一个推导可以产生这句话。</li>
<li>每一句话的CFG可以是有歧义的（即有多种推导的可能，因为一个非终结符同时存在了多条规则），至于如何解决这个问题，在PCFGs中，也就是概率上下文无关文法中会有介绍，简单来说就是给予每条规则一个概率，再利用这些概率求得概率最大的那棵解析树。</li>
</ul>
<p>CKY算法：CKY处理的CFG必须是CNF形式的。所以算法首先要把非CNF形式的CFG转成CNF形式。</p>
<h1 id="相似度的计算"><a href="#相似度的计算" class="headerlink" title="相似度的计算"></a>相似度的计算</h1><h2 id="统计指标"><a href="#统计指标" class="headerlink" title="统计指标"></a>统计指标</h2><h3 id="Cosine"><a href="#Cosine" class="headerlink" title="Cosine"></a>Cosine</h3><script type="math/tex; mode=display">S = \frac{x\cdot y}{|x||y|}</script><p>两向量越相似，向量夹角越小，cosine绝对值越大；值为负，两向量负相关。</p>
<h3 id="Jaccard"><a href="#Jaccard" class="headerlink" title="Jaccard"></a>Jaccard</h3><script type="math/tex; mode=display">J(A,B)=\frac{|A\cap B|}{|A \cup B|}</script><p>值越大越相似，分子是A和B的交集大小，分母是A和B的并集大小。<br>Jaccard系数主要用于计算符号度量或布尔值度量的个体间的相似度，无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Jaccard系数只关心个体间共同具有的特征是否一致这个问题。</p>
<h3 id="Pearson"><a href="#Pearson" class="headerlink" title="Pearson"></a>Pearson</h3><script type="math/tex; mode=display">r = \frac{\sum\limits_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})}{\sqrt{\sum\limits_{i=1}^n(x_i-\overline{x})^2}\sum\limits_{i=1}^n(y_i-\overline{y})^2}</script><p>两个变量之间的协方差和标准差的商。反映两个变量X和Y的线性相关程度，r值介于-1到1之间，绝对值越大表明相关性越强。</p>
<h3 id="Euclidian"><a href="#Euclidian" class="headerlink" title="Euclidian"></a>Euclidian</h3><script type="math/tex; mode=display">d=\sqrt{\sum\limits_{i=1}^n(x_i-y_i)^2}</script><p>欧氏距离。</p>
<h2 id="文本距离"><a href="#文本距离" class="headerlink" title="文本距离"></a>文本距离</h2><h3 id="ED"><a href="#ED" class="headerlink" title="ED"></a>ED</h3><p>编辑距离（Edit Distance，ED），也叫Levenshtein Distance，是用来度量两个序列相似程度的指标。通俗地来讲，编辑距离指的是在两个单词之间，由其中一个单词转换为另一个单词所需要的<strong>最少单字符编辑</strong>次数。详情参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9hNjE3ZDIwMTYyY2Y=">详解编辑距离(Edit Distance)及其代码实现<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jhb2RyZWFtL2FydGljbGUvZGV0YWlscy84MDQxNzY5NQ==">最小编辑距离算法 Edit Distance（经典DP）<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="LCS"><a href="#LCS" class="headerlink" title="LCS"></a>LCS</h3><p>最长公共子序列（Longest Common Subsequence，LCS），一个序列，如果是两个或多个已知序列的子序列，且是所有子序列中最长的，则为最长公共子序列。</p>
<p>LCS和ED，两者都可以衡量字符串的相近程度。不同之处在于，LCS对两个的长度差异不敏感，编辑距离对两者的长度差异敏感。LCS衡量了两者的重合度，编辑距离衡量了两者的长度和重合度。对编辑距离的增删代价取0，改操作换成相同奖励，就是LCS。</p>
<p>算法详解：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM4ODE2OTI0L2FydGljbGUvZGV0YWlscy84MzI0MzQzNA==">LCS(longest common subsequence)（最长公共子序列）<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="WAM"><a href="#WAM" class="headerlink" title="WAM"></a>WAM</h3><p>句向量表示（Word Averaging Model，WAM），首先对句子进行分词，然后对分好的每一个词获取其对应的 Vector，然后将所有 Vector 相加并求平均，这样就可得到 Sentence Vector。</p>
<h2 id="深度匹配"><a href="#深度匹配" class="headerlink" title="深度匹配"></a>深度匹配</h2><p>使用Bert的序列相似度预测。</p>
<p><strong>Poly-encoders</strong>：开发了一种新的transformer体系结构，即Poly-encoder，该体系结构学习了全局而不是令牌级别的self-attention特征，同时解决了 DSSM 式的 Bi-encoder 匹配质量低的问题和 ARC-II、BERT 等交互式的 Cross-encoder 匹配速度慢的问题。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDE5Njl2Mi5wZGY=">Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring<i class="fa fa-external-link-alt"></i></span>。<br>详解参考：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDIxNDgzNzM=">《Poly-encoders》阅读笔记<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMTk0NDQ2Mzc=">PolyEncoder-Facebook的全新信息匹配架构-提速3000倍(附复现结果与代码)<i class="fa fa-external-link-alt"></i></span>。</p>
<p><strong>Sentence-BERT</strong>：虽然BERT和RoBERTa在很多句子对形式的回归任务（例如文本语义相似度）上达到了SOTA效果，但是它们还存在一些缺点：在这些任务中，它们均需要将比较的两个句子都传入到模型中计算，计算开销过大。BERT模型在一个1W句子集合中，找出最相近的一个句子对，需要5千万次推断计算（约65小时）才能完成，所以BERT并不适合语义相似度搜索等任务。</p>
<p>在该论文中，作者提出了一个新的模型，Sentence-BERT（简称SBERT）。SBERT采用双重或三重BERT网络结构，具体结构介绍会在后文中详细介绍。如果使用的是基于RoBERTa模型，则改造后的模型简称为SRoBERTa。</p>
<p>通过SBERT模型获取到的句子embedding，可以直接通过cos相似度计算两个句子的相似度，这样就大大减少了计算量。因为在使用BERT模型进行句子间相似度的判断时，需要从句子集合中，选出两个句子进行组合，传入BERT中进行计算，而使用SBERT模型，只需要将集合中每个句子单独传入到模型中，得到每个句子的embeding，计算相似度只需要使用cos函数计算两两embeding的cos距离即可。因此，使用BERT/RoBERTa模型需要65h才能完成的寻找最相似句子对任务，SBERT模型完成仅需5s。</p>
<p>作者在一些STS任务和迁移学习任务上评估SBERT模型，该模型达到了新的SOTA水平。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDguMTAwODQucGRm">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。<br>模型地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2JlcnQubmV0Lw==">Sentence-Transformers<i class="fa fa-external-link-alt"></i></span>。<br>详解参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Zlbmd4aW5saW51eC9hcnRpY2xlL2RldGFpbHMvMTA5MTk1NzYy">论文阅读Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。</p>
<p><strong>SimCSE</strong>：句子向量表示一直是NLP领域的一个热门问题，主要是因为其应用范围比较广泛，而且作为很多任务的基石。最近连续出了好几篇关于句子表示的文章，从前段时间的BERT-Flow, BERT-whitening到最近的这个SimCSE。BERT-Flow以及BERT-whitenning其实像是后处理，将bert的输出进行一定的处理来解决各向异性的问题。本篇的这个工作则是采用了自监督来提升模型的句子表示能力，说到自监督最关键的问题应该就是如何构建正负例了。本文的正负例有两种构建方式，对于无监督来说，作者使用了Droupout来构建正例，将一个样本经过encoder两次，就得到了一个正例对，负例则是同一个batch里的其它句子。而对于有监督则采用了SNLI数据集天然的结构，对立类别的是负例，另外两个类别的就是正例。没错就是如此简单的方法催生了新的SOTA，而且提升还非常的明显。<br>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIxMDQuMDg4MjEucGRm">SimCSE: Simple Contrastive Learning of Sentence Embeddings<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC83OTIwMjE1MQ==">BM25算法, Best Matching<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNTI1MjI5MDY=">K近邻算法哪家强？KDTree、Annoy、HNSW原理和使用方法介绍<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NvZnRfenp0aS9hcnRpY2xlL2RldGFpbHMvODc1Mjc5MTk=">18种和“距离(distance)”、“相似度(similarity)”相关的量的小结<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGFuZ3VpL3AvMTQ2NzU1NzUuaHRtbA==">相似度计算方法<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppamlrYW53YS9hcnRpY2xlL2RldGFpbHMvODc5ODAyOTA=">信息检索的评价指标<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYnktZHJlYW0vcC85NDAzOTg0Lmh0bWw=">搜索评价指标——NDCG<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAxMzg3NTgvYXJ0aWNsZS9kZXRhaWxzLzY5OTM2MDQxLw==">信息检索中常用的评价指标：MAP,nDCG,ERR,F-measure<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMzc0NzgzNzM=">推荐- Point wise、pairwise及list wise的比较<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2hlbnhpYW9saW4vcC85NzIzODYwLmh0bWw=">Learning to Rank：Point-wise、Pair-wise 和 List-wise区别<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmVudHV3dXlpbmcvcC82NjgxOTQzLmh0bWw=">Learning to Rank简介<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmVudHV3dXlpbmcvcC82NjkwODM2Lmh0bWw=">Learning to Rank算法介绍：RankNet，LambdaRank，LambdaMart<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zOTgyNjQ1MTQ=">CFG：Context free grammars 上下文无关文法<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoYXNlMTk5OC9hcnRpY2xlL2RldGFpbHMvODQ1MDQxOTE=">基于CYK+PCFG的短语结构句法分析<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/21/NLP/06.%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/21/NLP/06.%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">对话系统简介</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-21 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-21T00:00:00+08:00">2021-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>397</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="闲聊式"><a href="#闲聊式" class="headerlink" title="闲聊式"></a>闲聊式</h2><p>情感识别，多轮对话中情感向量生成（Emotion Embedding）、意图识别等。建议参考项目<span class="exturl" data-url="aHR0cHM6Ly9yYXNhLmNvbS8=">Rasa<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="检索式"><a href="#检索式" class="headerlink" title="检索式"></a>检索式</h2><p>涉及到的核心：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入问句：句向量的构建。</span><br><span class="line">粗排：候选问句的范围，重点是速度、召回率。</span><br><span class="line">精排：候选问句基础上精细匹配&#x2F;深度匹配，重点是精准率。</span><br><span class="line">答案：匹配问句对应的答案。</span><br></pre></td></tr></table></figure></p>
<h2 id="知识问答"><a href="#知识问答" class="headerlink" title="知识问答"></a>知识问答</h2><p><img src="/images/对话系统/1.png" width="80%"></p>
<p>架构一般为KBQA，详情参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29odS5jb20vYS8xNjMyNzg1ODhfNTAwNjU5">KBQA从入门到放弃—入门篇<i class="fa fa-external-link-alt"></i></span>。</p>
<p>知识图谱、问题解析、查询、答案生成等。需要实体识别、关系识别，SPO三元组((subject, predicate, object)等，详情参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yMzc0NTI5MTg/dXRtX3NvdXJjZT13ZWNoYXRfc2Vzc2lvbg==">实体关系、实体属性、三元组、SPO三元组及其抽取方案<i class="fa fa-external-link-alt"></i></span>。</p>
<p>NL2SQL也会涉及到一些，将用户的自然语句转为可执行SQL语句的技术，用于自动问答、知识查询，针对目的清晰的问答。</p>
<h2 id="任务式"><a href="#任务式" class="headerlink" title="任务式"></a>任务式</h2><p><img src="/images/对话系统/2.png" width="80%"></p>
<p>四大模块：自然语言理解、对话状态追踪、对话策略、自然语言生成。</p>
<p>意图识别、情感识别、命名实体识别、强化学习、文本生成等。</p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/20/NLP/05.Bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/NLP/05.Bert/" class="post-title-link" itemprop="url">Bert</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>word2vec和GloVe都将相同的预训练向量分配给同一个词，而不考虑词的上下文（如果有的话）。考虑到自然语言中丰富的多义现象和复杂的语义，上下文无关表示具有明显的局限性。这推动了“上下文敏感”词表示的发展，其中词的表征取决于它们的上下文。例如，通过将整个序列作为输入，ELMo是为输入序列中的每个单词分配一个表示的函数。具体来说，ELMo将来自预训练的双向长短期记忆网络的所有中间层表示组合为输出表示。然后，ELMo的表示将作为附加特征添加到下游任务的现有监督模型中，例如通过将ELMo的表示和现有模型中词元的原始表示（例如GloVe）连结起来。一方面，在加入ELMo表示后，冻结了预训练的双向LSTM模型中的所有权值。另一方面，现有的监督模型是专门为给定的任务定制的。利用当时不同任务的不同最佳模型，添加ELMo改进了六种自然语言处理任务的技术水平：情感分析、自然语言推理、语义角色标注、共指消解、命名实体识别和问答。</p>
<p>尽管ELMo显著改进了各种自然语言处理任务的解决方案，但每个解决方案仍然依赖于一个特定于任务的结构。然而，为每一个自然语言处理任务设计一个特定的结构实际上并不是一件容易的事。GPT（Generative Pre Training）模型为上下文的敏感表示设计了通用的任务无关模型。GPT建立在Transformer解码器的基础上，预训练了一个用于表示文本序列的语言模型。当将GPT应用于下游任务时，语言模型的输出将被送到一个附加的线性输出层，以预测任务的标签。与ELMo冻结预训练模型的参数不同，GPT在下游任务的监督学习过程中对预训练Transformer解码器中的所有参数进行微调。GPT在自然语言推理、问答、句子相似性和分类等12项任务上进行了评估，并在对模型结构进行最小更改的情况下改善了其中9项任务的最新水平。</p>
<p>然而，由于语言模型的自回归特性，GPT只能向前看（从左到右）。在“i went to the bank to deposit cash”（我去银行存现金）和“i went to the bank to sit down”（我去河岸边坐下）的上下文中，由于“bank”对其左边的上下文敏感，GPT将返回“bank”的相同表示，尽管它有不同的含义。</p>
<p>BERT：把两个最好的结合起来。ELMo对上下文进行双向编码，但使用特定于任务的结构；而GPT是任务无关的，但是从左到右编码上下文。BERT（来自Transformers的双向编码器表示）结合了这两个方面的优点。它对上下文进行双向编码，并且对于大多数的自然语言处理任务，只需要最少的结构改变。通过使用预训练的Transformer编码器，BERT能够基于其双向上下文表示任何词元。在下游任务的监督学习过程中，BERT在两个方面与GPT相似。首先，BERT表示将被输入到一个添加的输出层中，根据任务的性质对模型结构进行最小的更改，例如预测每个词元与预测整个序列。其次，对预训练Transformer编码器的所有参数进行微调，而额外的输出层将从头开始训练。</p>
<h1 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h1><p>1、将预训练模型用于下游任务有两种策略：</p>
<ul>
<li>基于微调的策略。如 GPT，通过简单微调预训练模型的参数来训练下游任务。该策略在预训练期间通过单向语言模型来学习通用语言representation，而单向语言模型严重限制了预训练模型的表达能力。例如，在token 级别的任务（如：词性标注任务），结合两个方向的上下文对模型性能非常重要。</li>
<li>基于特征的策略。如 ELMo ，将预训练模型的representation 作为下游任务模型的额外特征。该策略虽然是双向语言模型，但是该模型是浅层的。</li>
</ul>
<p>与它们不同，BERT是一个<strong>同时利用了左右双向上下文的、深度的</strong>预训练模型，它在11项 nlp 任务中取得最领先的结果。</p>
<p>2、基于特征的方法具有一定优势：</p>
<ul>
<li>并不是所有的 NLP 任务都可以很容易地用 Transformer encoder 架构来表示，因此需要添加特定于任务的模型架构。</li>
<li>如果通过训练数据预先计算一次昂贵的数据表示，然后在该表示的基础上用廉价的模型来完成许多任务，这会带来很大的计算优势。</li>
</ul>
<p>3、单向语言模型可以是从左到右 Left to Right:LTR 或者从右到左 Right to Left :RTL 。BERT 也可以像 ELMO 一样训练独立的 LTR 和 RTL 模型后拼接在一起，但是这么做有两个问题：</p>
<ul>
<li>其训练代价是单个双向模型的两倍。</li>
<li>对于Question - Answer 之类的问题是反直觉的，因为 RTL 模型需要根据答案来反推问题。</li>
<li>BERT 可以自由的组合左侧上下文和右侧上下文。</li>
</ul>
<p>4、BERT 预训练模型包含两个预训练任务：预测被屏蔽的单词、预测下一个句子是否和上一个句子相接。</p>
<p>5、BERT 的预训练语料库必须使用 document-level的语料库，而不是经过混洗的 sentence-level 的语料库。因为混洗句子会破坏句子预测预训练任务。这里的 “句子” 不一定是真实的句子，而是一段话或者几段话，代表了一个 token 序列。</p>
<ul>
<li>BERT 预训练时，每个 ”句子“ 的 token 长度小于等于 512 。</li>
<li>BERT 的训练语料库经过了 WordPiece 词干化。如：engineer-&gt;engine er</li>
</ul>
<p>6、BERT 预训练采用 gelu 激活函数，训练一百万步，bath size = 256 。</p>
<h2 id="MLM"><a href="#MLM" class="headerlink" title="MLM"></a>MLM</h2><p>1、受完形填空任务启发，BERT 通过提出一个新的预训练目标来解决前面提到的单向限制：掩码语言模型masked language model:MLM 。</p>
<p>2、从直觉上，深度双向模型要比深度单向模型、单层双向模型表达能力更强。</p>
<ul>
<li>标准的条件语言模型只能从左到右或者从右到左训练，因为双向条件作用允许每个单词在多层上下文中间接“看到自己”。</li>
<li>MLM 模型从输入中随机屏蔽一些token，目标是基于上下文预测被屏蔽单词。方法是：将被屏蔽的单词替换为 [MASK] 标记，然后被屏蔽的单词作为真实 label 。</li>
<li>与单向语言模型不同，MLM 结合了左右两侧上下文。</li>
</ul>
<p>3、为了训练 MLM，模型随机屏蔽一定百分比（论文中为 15%）的 token，然后仅预测那些被屏蔽的 token 。这种方式有两个缺陷：</p>
<ul>
<li>预训练和微调之间的不匹配。因为在微调阶段，模型永远不会看到 [MASK] 标记。</li>
<li>为了缓解这种状况，MLM 在预训练时并不总是用真的 [MASK] 标记，而是从输入种随机选择 15% 的 token：80% 替换未 [MASK] 标记，10% 替换为一个随机单词，10% 保持原样。</li>
<li>MLM 并不知道哪些词被替换，因此它总是努力的学习每个单词的正确表达。</li>
<li>每个 batch 预测的 token 只有 15%，这意味着模型需要更多的训练步才可能收敛。实验证明MLM 的收敛速度确实比单向语言模型稍慢，但是相对于 MLM 的泛化能力的提升，这种代价是值得的。</li>
</ul>
<h2 id="NSP"><a href="#NSP" class="headerlink" title="NSP"></a>NSP</h2><p>许多重要的下游任务，如：知识问答和自然语言推理，都是基于理解两个句子之间的关系，而这种关系不是由语言模型直接捕获的。<br>为了训练理解句子关系的模型，BERT 训练一个二元化的句子预测任务，称作Next Sentence Prediction:NSP：</p>
<ul>
<li>每个训练样本由一对句子 A 和 B 组成：50% 的样本中 B 是紧跟在 A 之后的句子，50%的样本中二者是随机挑选的。</li>
<li>模型需要预测的是： B 是否是 A 的下一个句子？</li>
</ul>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>1、参考Transformer的encoder部分，Bert是一个多层双向Transformer编码器。双向 self-attention 的 Transformer 也称作 Transformer encoder，而单向 self-attention 的 Transformer 被称作 Transformer decoder 。</p>
<p>2、作者指明L表示层数，H表示每个隐藏单元的维数大小，A表示self-attention头数。BERT有2种大小的模型，分别是BERT_base(L=12, H=768, A=12, Total Parameters=110M)、BERT_large(L=24, H=1024, A=16, Total Parameters=340M)。BERT_base设定为和OpenAI GPT的模型大小相同，以便作比较。需要重点说明的是，BERT Transformer使用双向self-attention，而GPT Transformer 使用带约束的self-attention，每个token只能注意到它左边的上下文。</p>
<p>3、BERT 的模型输入能够表达单个句子或者一对句子。</p>
<ul>
<li>每个 token 的输入 representation 由三个部分相加而成：token embedding、segment embedding、position embedding 。</li>
<li>每个序列的第一个 token 是一个特殊的[CLS]。网络最后一层对应于该位置的一个隐向量作为整个序列的 representation 来用于分类任务。对于非分类任务，该隐向量被忽略。</li>
<li>如果是一对句子，则在句子之间插入特殊的 token：[SEP] 。然后对句子的前后关系学习一个segment embedding，通过这种方式，模型得以学习和区分两个句子的前后关系：<ul>
<li>前一个句子的每个 token 学习和使用 A embedding，代表前后关系的 “前关系” 的表达。</li>
<li>后一个句子的每个 token 学习和使用 B embedding，代表前后关系的 “后关系” 的表达。</li>
</ul>
</li>
<li>对于单个句子，模型仅学习和使用 A embedding 。</li>
<li>position embedding 是模型学习和使用的 input 每个绝对位置的表达。这里不是正弦+余弦方式，而是参数化方式。</li>
<li>token embedding 是模型学习和使用的每个 token 的表达。</li>
</ul>
<p><img src="/images/Bert/1.png" width="90%"></p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>从input(2种)和output(4种)看：</p>
<ul>
<li>input：<ul>
<li>one sentence：输入为1个句子。</li>
<li>multiple sentences：输入为多个句子，用[SEP]分隔。</li>
</ul>
</li>
<li>output：<ul>
<li>one class：[CLS]预训练后的向量输入全连接层，直接判断分类结果（当然，你也可以输入sentence全部向量）。</li>
<li>class for each token：输入的每个token经过预训练后的向量输入全连接层，对每个token分类。</li>
<li>copy from input：经典Q-A问题，这里设计时使用限制的QA(Answer必须在document中)，输入2个向量（代表Answer在document的起始-结束位置），和预训练（输入Question+document）后的document token向量点积+softmax，取最大值token位置即可。</li>
<li>general sequence：作为seq2seq的encoder、作为encoder+decoder（decoder应使用单向Transformer）。</li>
</ul>
</li>
</ul>
<h1 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h1><h2 id="fine-tune"><a href="#fine-tune" class="headerlink" title="fine-tune"></a>fine-tune</h2><ol>
<li>固定Bert参数，只训练全连接层。</li>
<li>Bert+全连接层 全部一起训练。</li>
<li>Adaptor：对Bert中添加一部分Layer，训练时只调整这些Layer参数。</li>
</ol>
<p><strong>warmup</strong>：学习率热身。<strong>规定前多少个热身步骤内，对学习率采取逐步递增的过程</strong>。热身步骤之后，会对学习率采用衰减策略。这样训练初期可以避免震荡，后期可以让loss降得更小。<strong>warmup抑制Layer Normalization对学习率参数的敏感度。</strong></p>
<p>除了 batch size、学习率、训练 epoch 不同之外，<strong>其它训练参数与预训练阶段的训练参数相同</strong>。fine-tune阶段通常很快，因此建议<strong>对超参数进行彻底搜索</strong>并选择在验证集上表现最好的模型。<br>论文发现：数据集越小，模型性能对超参数的选择越敏感。大数据集（超过10万的标记样本）对超参数的敏感性要低的多。</p>
<p>对于文本分类，详情参考<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDU1ODMucGRm">How to Fine-Tune BERT for Text Classification?<i class="fa fa-external-link-alt"></i></span>。<br>BERT在NLP任务中效果十分优秀，这篇文章对于BERT在文本分类的应用上做了非常丰富的实验，介绍了一些调参以及改进的经验，进一步挖掘BERT的潜力。</p>
<ul>
<li>微调（fin-tune）策略<ul>
<li>对于长文本，尝试了（1）取头部510 tokens，（2）尾部510 tokens，（3）头部128 tokens + 尾部382 tokens，（4）分片并进行最大池化、平均池化、attention，发现方法（3）最好。因为文章的关键信息一般在开头和结尾。</li>
<li>分层训练，上层对文本分类更加重要。</li>
<li>灾难性遗忘：在下游finetune可能会遗忘预训练的知识。需要设置较小的学习率，如2e-5.</li>
<li>分层衰减学习率（Layer-wise Decreasing Layer Rate），对下层设置更小的学习率可以得到更高的准确率，在lr=2e-5，衰减率ξ \xiξ=0.95</li>
</ul>
</li>
<li>继续预训练（Further Pretraining）<ul>
<li>任务内（within-task） 和同领域（in-domain）的继续预训练可以大大提高准确率，In-domain比within-task要好。</li>
</ul>
</li>
<li>多任务微调（Multi-task Finetuning）<ul>
<li>在单任务微调之前的多任务微调有帮助，但是提升效果小于Further pretraining。</li>
</ul>
</li>
<li>小数据集<ul>
<li>BERT对小数据集提升很大，这个大家都知道的。Further pretraining对小数据集也有帮助。</li>
</ul>
</li>
</ul>
<h2 id="mask方式"><a href="#mask方式" class="headerlink" title="mask方式"></a>mask方式</h2><p><strong>BERT-WWM</strong>：始版本的 BERT 采用了WordPiece tokenize 来预处理，即把每个单词拆解一些 WordPiece token（比如，loved-&gt;lov ed） ，最初是为了解决谷歌语音识别系统遇到的日语/韩语分割问题。该模型是数据驱动，并且确保任何可能的字符序列的确定性分割。这种预处理为 BERT 带来一个严重的问题：<strong>有可能仅仅对一个单词的某个部分 wordpiece token 执行了 mask。此时 MLM 模型预测的只是单词的一部分，相当于模型对一个错误的目标进行预测。这非常不利于模型的学习</strong>。有鉴于此，谷歌后续发布了 BERT 的 Whole Word Masking:WWM 版本 <strong>BERT-WWM</strong>。在该版本中，一个单词要么没有被 mask、要么该单词所有的 workpiece token 都被 mask 。类似的想法还有ERNIE模型的phrase-level mask和entity-level mask。</p>
<p><strong>BERT-wwm-ext</strong>：是 BERT-WWM 的中文版本，该模型对中文的<strong>整个汉语单词</strong>而不是单个汉字进行mask ，在最新的中文维基百科上训练。</p>
<hr>
<p><strong>ERNIE</strong>：BERT 的 MLM 任务在执行 mask 的时候，未能考虑先验知识，如果有学习到与Mask的单词相关的先验知识，则无需借助很长的上下文就可以很容易的预测出Mask的单词。但是 ERNIE 并没有直接添加先验知识，而是通过引入 <strong>entity-level mask</strong> 和 <strong>phrase-level mask</strong> 来引入先验知识，隐式的学习实体间的关系、实体的属性等知识：</p>
<ul>
<li><strong>phrase-level mask</strong>：将一个 phrase 作为一个单元，每个单元通常由几个 token 组成。在训练期间，同一个单元中的所有 token 都会被屏蔽，而不是只有一个 token 被屏蔽。</li>
<li><strong>entity-level mask</strong>：将一个 entity 作为一个单元，…。</li>
</ul>
<p>对于英语，论文使用单词分析和分块工具来获取短语的边界；对于中文，论文使用<strong>分词工具</strong>来获取词的边界。<br>命名实体 entity 包括人名、地名、组织名、产品名等。需要使用NER的方法。</p>
<p><strong>ERNIE</strong> 通过三阶段学习来学得短语或实体的先验知识：</p>
<ul>
<li>第一阶段：Basic-level masking，使用基本的掩码策略，做法与 BERT 完全相同。这个阶段是在基本语言单元的随机 mask 上训练，因此很难对高级语义知识建模。对于英文，基本语言单元是词word；对于中文，基本语言单元是汉字 char 。</li>
<li>第二阶段：Phrase-level masking，使用基本语言单元作为训练输入，但是使用 phrase-level 的掩码策略。这个阶段模型屏蔽和预测同一个短语的所有基本语言单元。</li>
<li>第三阶段：Entity-level masking，使用基本语言单元作为训练输入，但是使用 entity-level 的掩码策略。这个阶段模型屏蔽和预测同一个命名实体的所有基本语言单元 。</li>
</ul>
<p>ERNIE 编码器和 BERT 相同，但是对于中文语料，ERNIE 把 CJK 编码范围内的字符都添加空格来分隔，然后使用 WordPiece（loved-&gt;lov ed） 来对中文语句词干化，WordPiece参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vaHVhbmd5Yy9wLzEwMjIzMDc1Lmh0bWw=">一文读懂BERT中的WordPiece<i class="fa fa-external-link-alt"></i></span>。</p>
<hr>
<p><strong>SpanBert</strong>：提出基于Bert掩码方式，采用不同长度token不同概率的方式（越短的token概率越大）Mask。<br><strong>XLNet</strong>：使用Transformer-XL模型。</p>
<p>当Bert作为seq2seq的encoder时，输入也要Mask：</p>
<ul>
<li>随机Mask。</li>
<li>删除Delete。</li>
<li>多个句子，换顺序Permuttion。</li>
<li>打乱token，比如后面词放在前面。</li>
<li>插入Mask，Text Infilling。这个效果最好。</li>
</ul>
<p>后续 RoBerta和Albert使用 sentence order prediction:SOP 任务来预训练了。</p>
<h2 id="语义相似度任务"><a href="#语义相似度任务" class="headerlink" title="语义相似度任务"></a>语义相似度任务</h2><p>虽然BERT和RoBERTa在很多句子对形式的回归任务（例如文本语义相似度）上达到了SOTA效果，但是它们还存在一些缺点：在这些任务中，它们均需要将比较的两个句子都传入到模型中计算，计算开销过大。BERT模型在一个1W句子集合中，找出最相近的一个句子对，需要5千万次推断计算（约65小时）才能完成，所以BERT并不适合语义相似度搜索等任务。</p>
<p>在该论文中，作者提出了一个新的模型，Sentence-BERT（简称SBERT）。SBERT采用双重或三重BERT网络结构，具体结构介绍会在后文中详细介绍。如果使用的是基于RoBERTa模型，则改造后的模型简称为SRoBERTa。</p>
<p>通过SBERT模型获取到的句子embedding，可以直接通过cos相似度计算两个句子的相似度，这样就大大减少了计算量。因为在使用BERT模型进行句子间相似度的判断时，需要从句子集合中，选出两个句子进行组合，传入BERT中进行计算，而使用SBERT模型，只需要将集合中每个句子单独传入到模型中，得到每个句子的embeding，计算相似度只需要使用cos函数计算两两embeding的cos距离即可。因此，使用BERT/RoBERTa模型需要65h才能完成的寻找最相似句子对任务，SBERT模型完成仅需5s。</p>
<p>作者在一些STS任务和迁移学习任务上评估SBERT模型，该模型达到了新的SOTA水平。</p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDguMTAwODQucGRm">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。<br>模型地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2JlcnQubmV0Lw==">Sentence-Transformers<i class="fa fa-external-link-alt"></i></span>。<br>详解参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Zlbmd4aW5saW51eC9hcnRpY2xlL2RldGFpbHMvMTA5MTk1NzYy">论文阅读Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE4MTAuMDQ4MDU=">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDU1ODMucGRm">How to Fine-Tune BERT for Text Classification?<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xNTE5MTgw">BERT论文解读<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmRpX2h1c3QvYXJ0aWNsZS9kZXRhaWxzLzEwNDQ2NTMzNw==">【调优方法】——warmup<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpb24xOTkzMDkyNC9hcnRpY2xlL2RldGFpbHMvMTA0NDY5OTQ0">Bert微调技巧实验大全-How to Fine-Tune BERT for Text Classification<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/19/NLP/04.Transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/19/NLP/04.Transformer/" class="post-title-link" itemprop="url">Transformer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-19 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-19T00:00:00+08:00">2021-07-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>论文中的 Transformer 架构包含了 encoder 和 decoder 两部分，其架构如下图所示。<br><img src="/images/Transformer/1.png" width="60%"></p>
<ul>
<li>编码器 encoder 包含一组 6 个相同的层 Layer ，每层包含两个子层 SubLayer。<ul>
<li>第一个子层是一个多头自注意力 multi-head self-attention 层。</li>
<li>第二个子层是一个简单的全连接层。</li>
<li>每个子层都使用残差直连，并且残差直连之后跟随一个layer normalization:LN 。</li>
<li>假设子层的输入为 $h$，则经过 LN 之后整体的输出为 $LayerNorm(h+Sublayer(h))$ 。为了 Add 直连，论文将内部所有层的输入、输出的向量维度设置为512维。</li>
</ul>
</li>
<li>解码器 decoder 也包含一组 6 个相同的层 Layer，但是每层包含三个子层 SubLayer 。<ul>
<li>第一个子层也是一个多头自注意力 multi-head self-attention 层。但是，在计算位置 $i$ 的 self-attention 时屏蔽掉了位置 $i$ 之后的序列值，这意味着：位置 $i$ 的 attention 只能依赖于它之前的结果，不能依赖它之后的结果。因此，这种 self-attention 也被称作 masked self-attention。</li>
<li>第二个子层是一个多头注意力multi-head attention 层，用于捕获 decoder output 和 encoder output 之间的 attention 。</li>
<li>第三个子层是一个简单的全连接层。</li>
<li>和 encoder 一样：每个子层都使用残差直连，并且残差直连之后跟随一个layer normalization:LN 。decoder 所有层的输入、输出的向量维度也是512维。</li>
</ul>
</li>
</ul>
<h1 id="attention"><a href="#attention" class="headerlink" title="attention"></a>attention</h1><p>编码器和解码器的 attention 都是采用 scaled dot attention 。<br>注意，公式中除以 $\sqrt{d_k}$ 是为了降低 $score$ 的数值，防止它落入到 softmax 函数的饱和区间。因为 softmax 函数的饱和区梯度几乎为 0 ，容易发生梯度消失。</p>
<p>一组多个attention 的效果要优于单个 attention，这称作multi-head attention 。将多个 head 的输出进行拼接，并再经过一个线性映射即可得到多头attention的结果。线性映射目的是确保 multi-head attention 前后的输入输出维度一致。论文中选择 attention 都为512维，为了保证 multi-head attention 的表达空间与 single-head attention 一致。</p>
<p>multi-head attention 将整个 attention 空间拆分成多个 attention 子空间，其表达能力更强。<br>从原理上看，multi-head 相当于在整体计算代价几乎保持不变的条件下，引入了更多的非线性从而增强了模型的表达能力。</p>
<p>在论文中，有三种方式使用多头注意力机制：</p>
<ul>
<li>encoder-decoder attention：query 来自前一个 decoder 层的输出，keys,values 来自 encoder 的输出。其意义是： decoder 的每个位置去查询它与 encoder 的哪些位置相关，并用 encoder 的这些位置的 value 来表示。</li>
<li>encoder self-attention：query,key,value 都来自前一层 encoder 的输出。这允许 encoder 的每个位置关注 encoder 前一层的所有位置。</li>
<li>decoder masked self-attention：query,key,value 都来自前一层 decoder 的输出。这允许 decoder 的每个位置关注 decoder 前一层的、在该位置之前的所有位置。</li>
</ul>
<h1 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h1><p>encoder 和 decoder 还包含有全连接层。对 encoder/decoder 的每个 attention 输出，全连接层通过一个 ReLU 激活函数和一个线性映射。</p>
<p>对于同一个 multi-head attention 的所有输出，采用相同的参数；对于不同的 multi-head attention 的输出，采用不同的参数。</p>
<p>输入和输出的维度保持为512，但是中间向量的维度是2048，这是为了扩充中间层的表示能力，从而抵抗 ReLU 带来的表达能力的下降。</p>
<h1 id="embedding-层"><a href="#embedding-层" class="headerlink" title="embedding 层"></a>embedding 层</h1><p>网络涉及三个 embedding 层：</p>
<ul>
<li>encoder 输入 embedding 层：将 encoder 输入 token 转化为512维的向量。</li>
<li>decoder 输入 embedding 层：将 decoder 输入 token 转化为512维的向量。</li>
<li>decoder 输出 embedding 层：将 decoder 输出 token 转化为512维的向量。</li>
</ul>
<p>在论文中这三个 embedding 矩阵是共享的，并且论文中在 embedding 层将该矩阵乘以一个常量 $\sqrt{d_{model}}$  来放大每个权重。</p>
<h1 id="position-embedding"><a href="#position-embedding" class="headerlink" title="position embedding"></a>position embedding</h1><p>从 attention 的计算公式可知：调整输入的顺序对 attention 的结果没有任何影响。即：attention 的输出中不包含任何顺序信息。<br>论文通过将位置编码添加到 encoder 和 decoder 底部的输入 embedding 来解决问题。对于同一个输入序列如果打乱序列顺序，则不同 token 的 attention 权重发生改变使得 attention 的结果不同。</p>
<p>位置编码有两种选择：</p>
<ul>
<li>可以作为参数来学习，即：将 encoder 的每个输入的位置embedding 、decoder 的每个输入的位置embedding 作为网络的参数，这些参数都从训练中学得。</li>
<li>也可以人工设定固定值。论文中使用：正弦+余弦方式设定position embedding。<ul>
<li>不同的维度对应不同的波长的正弦曲线，波长从 $2\pi$ 到 $2000\pi$ 。</li>
<li>选择这样的函数是因为：不同位置之间的embedding 可以简单的相互表示。这意味着模型可以捕获到位置之间的相对位置关系。</li>
</ul>
</li>
</ul>
<p>论文的实验表明：通过参数学习的position embedding 的效果和采用固定的position embedding 相差无几。<br>另外，固定方式的 position embedding 可以在测试阶段处理那些超过训练序列长度的测试序列。</p>
<h1 id="补充阅读"><a href="#补充阅读" class="headerlink" title="补充阅读"></a>补充阅读</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDIuMDQ3NDU=">On Layer Normalization in the Transformer Architecture<i class="fa fa-external-link-alt"></i></span>：<br>我们知道，在原始的Transformer中，Layer Norm在跟在Residual之后的，我们把这个称为Post-LN Transformer。</p>
<p>而且用Transformer调过参的也知道，Post-LN Transformer对参数非常敏感，需要很仔细地调参才能取得好的结果，比如必备的warm-up学习率策略，这会非常耗时间。<br>所以现在问题来了，为什么warm-up是必须的？能不能把它去掉？<br>本文的出发点是：既然warm-up是训练的初始阶段使用的，那肯定是训练的初始阶段优化有问题，包括模型的初始化。</p>
<p>从而，作者发现，Post-LN Transformer在训练的初始阶段，输出层附近的期望梯度非常大，所以，如果没有warm-up，模型优化过程就会炸裂，非常不稳定。<br>既然如此，本文作者尝试把LayerNorm换个位置，比如放在Residual的过程之中（称为Pre-LN Transformer），再观察训练初始阶段的梯度变化，发现比Post-LN Transformer不知道好到哪里去了，甚至不需要warm-up，从而进一步减少训练时间，这一结果的确令人震惊。</p>
<p>本文别出心裁，用实验和理论验证了Pre-LN Transformer结构不需要使用warm-up的可能性，其根源是LN层的位置导致层次梯度范数的增长，进而导致了Post-LN Transformer训练的不稳定性。<br>本文第一次将warm-up、LayerNorm、gradient和initialization联系起来，非常值得一读！</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIwMDMuMDc4NDU=">PowerNorm: Rethinking Batch Normalization in Transformers<i class="fa fa-external-link-alt"></i></span>：<br>本文探讨了Transformer为什么使用layer normalization，为什么不用batch normalization，然后根据batch normalization出现的问题提出了power normalization代替layer normalization。<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMjY3NDkzMTE/ZnJvbV92b3RlcnNfcGFnZT10cnVl">BatchNorm在NLP任务中的问题与改进<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE3MDYuMDM3NjIucGRm">Attention is All You Need<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25vY21sL2FydGljbGUvZGV0YWlscy8xMDMwODI2MDA=">Transformer—论文翻译：Attention Is All You Need 中文版<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ubHAuc2Vhcy5oYXJ2YXJkLmVkdS8yMDE4LzA0LzAzL2F0dGVudGlvbi5odG1s">The Annotated Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cDovL2phbGFtbWFyLmdpdGh1Yi5pby9pbGx1c3RyYXRlZC10cmFuc2Zvcm1lci8=">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aC12Mi5kMmwuYWkvY2hhcHRlcl9hdHRlbnRpb24tbWVjaGFuaXNtcy9zZWxmLWF0dGVudGlvbi1hbmQtcG9zaXRpb25hbC1lbmNvZGluZy5odG1s">自注意力和位置编码<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aC12Mi5kMmwuYWkvY2hhcHRlcl9hdHRlbnRpb24tbWVjaGFuaXNtcy90cmFuc2Zvcm1lci5odG1s">Transformer<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVd2NDExaDdrTj9wPTIz">(强推)李宏毅2021春机器学习课程<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvUkx4V2V2VldIWGdYLVVjb3hEUzcwdw==">细讲 | Attention Is All You Need<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDEyMTM3OA==">【NLP】Transformer模型原理详解<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/18/Paper/03.Get%20To%20The%20Point.%20Summarization%20with%20Pointer-Generator%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/18/Paper/03.Get%20To%20The%20Point.%20Summarization%20with%20Pointer-Generator%20Networks/" class="post-title-link" itemprop="url">Get To The Point. Summarization with Pointer-Generator Networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-18T00:00:00+08:00">2021-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>把seq2seq模型应用于摘要生成时存在两个主要的问题：<br>（1）难以准确复述原文的事实细节、无法处理原文中的未登录词(OOV)；<br>（2）生成的摘要中存在重复的片段。</p>
<p>针对存在的问题提出对应解决之道，在标准seq2seq+attention的基础之上做了改进：<br>（1）采用Pointer-Generator Network（抽取+生成），在保留生成新词的同时，还可以从原文中抽取内容，促使生成更准确的摘要。<br>（2）覆盖率机制(coverage mechanism)，使用Coverage记录已经生成的内容，从而减少内容重复。</p>
<p><img src="/images/PGN/结构.png" width="90%"></p>
<h1 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h1><p>标准的seq2seq模型+Attention机制：<br>encoder使用Bi-LSTM，序列单词按顺序喂给encoder中，产生一系列编码器的隐状态 $h_i$。decoder使用LSTM，在每个时间步 $t$，接收前一个词（训练时采用teacher forcing方式，预测时是前一时刻decoder输出词），decoder隐状态为 $s_t$。Attention计算采用Bahdanau方式，注意这里采用decoder的当前时刻 $t$ 的隐状态 $s_t$ 作为query。</p>
<p><img src="/images/PGN/1+2.png" width="40%"></p>
<p>编码器隐藏状态的加权和，称为上下文向量（context vector） $h_t^*$。<br><img src="/images/PGN/3.png" width="30%"></p>
<p>上下文向量可以被看作是在当前时间步 $t$ 看encoder的哪些部分，与解码器隐状态 $s_t$ 拼接，通过两个线性层产生词汇分布 $P_{\text{vocab}}$。<br><img src="/images/PGN/4.png" width="40%"></p>
<p>$P_{\text{vocab}}$ 是词汇表中所有单词的概率分布，它提供了预测单词 $w$ 的最终分布。<br><img src="/images/PGN/5.png" width="30%"></p>
<p>在训练过程中，时间步长 $t$ 的损失是 $t$ 的目标词 $w_t^*$ 的负对数似然。<br><img src="/images/PGN/6.png" width="30%"></p>
<p>整个序列的损失是：<br><img src="/images/PGN/7.png" width="30%"></p>
<h1 id="Pointer-Generator-Network"><a href="#Pointer-Generator-Network" class="headerlink" title="Pointer-Generator Network"></a>Pointer-Generator Network</h1><p>通过Pointer-Generator可以从输入中复制单词，需要一个软开关 $P_{\text{gen}}$ 来融合baseline 和 Pointer-Generator。<br>根据上下文向量 $h_t^*$，解码器隐状态 $s_t$，解码器输入 $x_t$，计算得到时间步 $t$ 的生成概率 $P_{\text{gen}}\in [0,1]$。<br><img src="/images/PGN/8.png" width="40%"></p>
<p>使用软开关 $P_{\text{gen}}$ 来融合baseline 和 Pointer-Generator。需要维护一个扩展词表（extended vocabulary）表示原始词表和出现在source中的所有词汇的联合，在扩展词表上得到以下概率分布，$a_i^t$ 表示通过Attention值来确定从source中拷贝词的概率分布。<br><img src="/images/PGN/9.png" width="40%"><br>注意，如果单词 $w$ 是OOV单词，那么 $P_{\text{vocab}}$ 一定为零，要是这个词也没出现在source中，那么 $a_i^t$ 也是零。</p>
<h1 id="Coverage-mechanism"><a href="#Coverage-mechanism" class="headerlink" title="Coverage mechanism"></a>Coverage mechanism</h1><p>重复序列是一个常见问题，本文维护一个覆盖向量（coverage vector） $c^t$，它是所有先前decoder时间步的Attention值 $a_i^t$ 的累加和：<br><img src="/images/PGN/10.png" width="30%"><br>目的是用先前的注意力权重决策来影响当前注意力权重的决策（累加的某个值大代表一直关注它，要减少这个值，不让模型总关注它），这样就避免在同一位置重复，从而避免重复生成文本。</p>
<p>$c^t$ 是source中单词的分布，表示这些单词从注意力机制到目前时间步的覆盖程度。 $c^0$ 是一个零向量。覆盖向量被引入到注意力机制中：<br><img src="/images/PGN/11.png" width="40%"></p>
<p>作者认为有必要额外定义覆盖损失（coverage loss）处罚重复出现的参考位置，使注意力更分散：<br><img src="/images/PGN/12.png" width="35%"><br>如果覆盖向量每个值都大于/小于1，则最终覆盖向量都将受到惩罚。</p>
<p>最后融合为复合损失函数：<br><img src="/images/PGN/13.png" width="45%"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>根据评价指标来看，提升效果明显，普遍提高2个百分点。</p>
<p>作者还说了直接加coverage效果并不好，所以实际应用时采用fine-tuning训练。</p>
<p>实际使用时建议增加weight_tying和scheduled_sampling尝试效果。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE3MDQuMDQzNjgucGRm">Get To The Point: Summarization with Pointer-Generator Networks<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMjMwMDg0Ng==">Get To The Point: Summarization with Pointer-Generator Networks 译文<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/16/NLP/03.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/16/NLP/03.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/" class="post-title-link" itemprop="url">基于LSTM的机器翻译</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-16 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-16T00:00:00+08:00">2021-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><figcaption><span>utils.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> torchtext.data <span class="keyword">import</span> Field, BucketIterator</span><br><span class="line"><span class="keyword">from</span> torchtext.datasets <span class="keyword">import</span> Multi30k</span><br><span class="line"></span><br><span class="line"><span class="comment"># manual create date ( token 2 index , index to token)</span></span><br><span class="line"><span class="comment"># dataset dataloader   PADDING BATCH SHUFFLE</span></span><br><span class="line"><span class="comment"># torchtext</span></span><br><span class="line"><span class="comment"># ALLENNLP (Field)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [&quot;&lt;sos&gt;&quot; 3 ,&quot;word&quot;1 ,&quot;peace&quot; 2,&quot;&lt;eos&gt;&quot; 4 ]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    spacy_de = spacy.load(<span class="string">&#x27;de&#x27;</span>)</span><br><span class="line">    spacy_en = spacy.load(<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">    url = re.<span class="built_in">compile</span>(<span class="string">&#x27;(&lt;url&gt;.*&lt;/url&gt;)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(url.sub(<span class="string">&#x27;@URL@&#x27;</span>, text))]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(url.sub(<span class="string">&#x27;@URL@&#x27;</span>, text))]</span><br><span class="line"></span><br><span class="line">    DE = Field(tokenize=tokenize_de, include_lengths=<span class="literal">True</span>,</span><br><span class="line">               init_token=<span class="string">&#x27;&lt;sos&gt;&#x27;</span>, eos_token=<span class="string">&#x27;&lt;eos&gt;&#x27;</span>)</span><br><span class="line">    EN = Field(tokenize=tokenize_en, include_lengths=<span class="literal">True</span>,</span><br><span class="line">               init_token=<span class="string">&#x27;&lt;sos&gt;&#x27;</span>, eos_token=<span class="string">&#x27;&lt;eos&gt;&#x27;</span>)</span><br><span class="line">    train, val, test = Multi30k.splits(exts=(<span class="string">&#x27;.de&#x27;</span>, <span class="string">&#x27;.en&#x27;</span>), fields=(DE, EN))</span><br><span class="line">    DE.build_vocab(train.src, min_freq=<span class="number">2</span>)</span><br><span class="line">    EN.build_vocab(train.trg, max_size=<span class="number">10000</span>)</span><br><span class="line">    train_iter, val_iter, test_iter = BucketIterator.splits(</span><br><span class="line">            (train, val, test), batch_size=batch_size, repeat=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, val_iter, test_iter, DE, EN</span><br><span class="line"></span><br><span class="line">load_dataset(<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>model.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, embed_size, hidden_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_layers=<span class="number">1</span>, dropout=<span class="number">0.5</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        self.embed = nn.Embedding(input_size, embed_size)</span><br><span class="line">        self.gru = nn.GRU(embed_size, hidden_size, n_layers,</span><br><span class="line">                          dropout=dropout, bidirectional=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, src, hidden=<span class="literal">None</span></span>):</span>   <span class="comment">#A  ---&gt; B</span></span><br><span class="line">        embedded = self.embed(src)</span><br><span class="line">        outputs, hidden = self.gru(embedded, hidden)</span><br><span class="line">        <span class="comment"># sum bidirectional outputs</span></span><br><span class="line">        outputs = (outputs[:, :, :self.hidden_size] +</span><br><span class="line">                   outputs[:, :, self.hidden_size:])</span><br><span class="line">        <span class="keyword">return</span> outputs, hidden</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size * <span class="number">2</span>, hidden_size)</span><br><span class="line">        self.v = nn.Parameter(torch.rand(hidden_size))</span><br><span class="line">        stdv = <span class="number">1.</span> / math.sqrt(self.v.size(<span class="number">0</span>))</span><br><span class="line">        self.v.data.uniform_(-stdv, stdv)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, hidden, encoder_outputs</span>):</span></span><br><span class="line">        timestep = encoder_outputs.size(<span class="number">0</span>)</span><br><span class="line">        h = hidden.repeat(timestep, <span class="number">1</span>, <span class="number">1</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        encoder_outputs = encoder_outputs.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># [B*T*H]</span></span><br><span class="line">        attn_energies = self.score(h, encoder_outputs)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(attn_energies, dim=<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, hidden, encoder_outputs</span>):</span></span><br><span class="line">        <span class="comment"># [B*T*2H]-&gt;[B*T*H]</span></span><br><span class="line">        energy = F.relu(self.attn(torch.cat([hidden, encoder_outputs], <span class="number">2</span>)))</span><br><span class="line">        energy = energy.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B*H*T]</span></span><br><span class="line">        v = self.v.repeat(encoder_outputs.size(<span class="number">0</span>), <span class="number">1</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># [B*1*H]</span></span><br><span class="line">        energy = torch.bmm(v, energy)  <span class="comment"># [B*1*T]</span></span><br><span class="line">        <span class="keyword">return</span> energy.squeeze(<span class="number">1</span>)  <span class="comment"># [B*T]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, embed_size, hidden_size, output_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_layers=<span class="number">1</span>, dropout=<span class="number">0.2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line"></span><br><span class="line">        self.embed = nn.Embedding(output_size, embed_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout, inplace=<span class="literal">True</span>)</span><br><span class="line">        self.attention = Attention(hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size + embed_size, hidden_size,</span><br><span class="line">                          n_layers, dropout=dropout)</span><br><span class="line">        self.out = nn.Linear(hidden_size * <span class="number">2</span>, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, last_hidden, encoder_outputs</span>):</span></span><br><span class="line">        <span class="comment"># Get the embedding of the current input word (last output word)</span></span><br><span class="line">        embedded = self.embed(<span class="built_in">input</span>).unsqueeze(<span class="number">0</span>)  <span class="comment"># (1,B,N)</span></span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line">        <span class="comment"># Calculate attention weights and apply to encoder outputs</span></span><br><span class="line">        attn_weights = self.attention(last_hidden[<span class="number">-1</span>], encoder_outputs)</span><br><span class="line">        context = attn_weights.bmm(encoder_outputs.transpose(<span class="number">0</span>, <span class="number">1</span>))  <span class="comment"># (B,1,N)</span></span><br><span class="line">        context = context.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># (1,B,N)</span></span><br><span class="line">        <span class="comment"># Combine embedded input word and attended context, run through RNN</span></span><br><span class="line">        rnn_input = torch.cat([embedded, context], <span class="number">2</span>)</span><br><span class="line">        output, hidden = self.gru(rnn_input, last_hidden)</span><br><span class="line">        output = output.squeeze(<span class="number">0</span>)  <span class="comment"># (1,B,N) -&gt; (B,N)</span></span><br><span class="line">        context = context.squeeze(<span class="number">0</span>)</span><br><span class="line">        output = self.out(torch.cat([output, context], <span class="number">1</span>))</span><br><span class="line">        output = F.log_softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2Seq</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, encoder, decoder</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Seq2Seq, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, src, trg, teacher_forcing_ratio=<span class="number">0.5</span></span>):</span></span><br><span class="line">        batch_size = src.size(<span class="number">1</span>)</span><br><span class="line">        max_len = trg.size(<span class="number">0</span>)</span><br><span class="line">        vocab_size = self.decoder.output_size</span><br><span class="line">        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size))</span><br><span class="line"></span><br><span class="line">        encoder_output, hidden = self.encoder(src)</span><br><span class="line">        hidden = hidden[:self.decoder.n_layers]</span><br><span class="line">        output = Variable(trg.data[<span class="number">0</span>, :])  <span class="comment"># sos   EOS</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, max_len):</span><br><span class="line">            output, hidden, attn_weights = self.decoder(</span><br><span class="line">                    output, hidden, encoder_output)</span><br><span class="line">            outputs[t] = output</span><br><span class="line">            is_teacher = random.random() &lt; teacher_forcing_ratio</span><br><span class="line">            top1 = output.data.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            output = Variable(trg.data[t] <span class="keyword">if</span> is_teacher <span class="keyword">else</span> top1)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>train.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils <span class="keyword">import</span> clip_grad_norm</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Encoder, Decoder, Seq2Seq</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_arguments</span>():</span></span><br><span class="line">    p = argparse.ArgumentParser(description=<span class="string">&#x27;Hyperparams&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;number of epochs for train&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">32</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;number of epochs for train&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;initial learning rate&#x27;</span>)</span><br><span class="line">    p.add_argument(<span class="string">&#x27;-grad_clip&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">10.0</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;in case of gradient explosion&#x27;</span>)</span><br><span class="line">    <span class="comment"># p.add_argument(&#x27;-hidden_size&#x27;,type=int,default=10,help=&quot; the size of hidden tensor&quot;)</span></span><br><span class="line">    <span class="keyword">return</span> p.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">model, val_iter, vocab_size, DE, EN</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    pad = EN.vocab.stoi[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> b, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_iter):</span><br><span class="line">        src, len_src = batch.src</span><br><span class="line">        trg, len_trg = batch.trg</span><br><span class="line">        src = Variable(src.data, volatile=<span class="literal">True</span>)</span><br><span class="line">        trg = Variable(trg.data, volatile=<span class="literal">True</span>)</span><br><span class="line">        output = model(src, trg, teacher_forcing_ratio=<span class="number">0.0</span>)</span><br><span class="line">        loss = F.nll_loss(output[<span class="number">1</span>:].view(<span class="number">-1</span>, vocab_size),</span><br><span class="line">                               trg[<span class="number">1</span>:].contiguous().view(<span class="number">-1</span>),</span><br><span class="line">                               ignore_index=pad)</span><br><span class="line">        total_loss += loss.data.item()</span><br><span class="line">    <span class="keyword">return</span> total_loss / <span class="built_in">len</span>(val_iter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">e, model, optimizer, train_iter, vocab_size, grad_clip, DE, EN</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    pad = EN.vocab.stoi[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> b, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">        src, len_src = batch.src</span><br><span class="line">        trg, len_trg = batch.trg</span><br><span class="line">        src, trg = src, trg</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(src, trg)</span><br><span class="line">        loss = F.nll_loss(output[<span class="number">1</span>:].view(<span class="number">-1</span>, vocab_size),</span><br><span class="line">                               trg[<span class="number">1</span>:].contiguous().view(<span class="number">-1</span>),</span><br><span class="line">                               ignore_index=pad)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        clip_grad_norm(model.parameters(), grad_clip)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss += loss.data.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> b % <span class="number">100</span> == <span class="number">0</span> <span class="keyword">and</span> b != <span class="number">0</span>:</span><br><span class="line">            total_loss = total_loss / <span class="number">100</span></span><br><span class="line">            print(<span class="string">&quot;[%d][loss:%5.2f][pp:%5.2f]&quot;</span> %</span><br><span class="line">                  (b, total_loss, math.exp(total_loss)))</span><br><span class="line">            total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    args = parse_arguments()</span><br><span class="line">    hidden_size = <span class="number">512</span></span><br><span class="line">    embed_size = <span class="number">256</span></span><br><span class="line">    <span class="comment"># assert torch.cuda.is_available()</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;[!] preparing dataset...&quot;</span>)</span><br><span class="line">    train_iter, val_iter, test_iter, DE, EN = load_dataset(args.batch_size)</span><br><span class="line">    de_size, en_size = <span class="built_in">len</span>(DE.vocab), <span class="built_in">len</span>(EN.vocab)</span><br><span class="line">    print(<span class="string">&quot;[TRAIN]:%d (dataset:%d)\t[TEST]:%d (dataset:%d)&quot;</span></span><br><span class="line">          % (<span class="built_in">len</span>(train_iter), <span class="built_in">len</span>(train_iter.dataset),</span><br><span class="line">             <span class="built_in">len</span>(test_iter), <span class="built_in">len</span>(test_iter.dataset)))</span><br><span class="line">    print(<span class="string">&quot;[DE_vocab]:%d [en_vocab]:%d&quot;</span> % (de_size, en_size))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;[!] Instantiating models...&quot;</span>)</span><br><span class="line">    encoder = Encoder(de_size, embed_size, hidden_size,</span><br><span class="line">                      n_layers=<span class="number">2</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line">    decoder = Decoder(embed_size, hidden_size, en_size,</span><br><span class="line">                      n_layers=<span class="number">1</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line">    seq2seq = Seq2Seq(encoder, decoder)</span><br><span class="line">    optimizer = optim.Adam(seq2seq.parameters(), lr=args.lr)</span><br><span class="line">    print(seq2seq)</span><br><span class="line"></span><br><span class="line">    best_val_loss = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs+<span class="number">1</span>):</span><br><span class="line">        train(e, seq2seq, optimizer, train_iter,</span><br><span class="line">              en_size, args.grad_clip, DE, EN)</span><br><span class="line">        val_loss = evaluate(seq2seq, val_iter, en_size, DE, EN)</span><br><span class="line">        print(<span class="string">&quot;[Epoch:%d] val_loss:%5.3f | val_pp:%5.2fS&quot;</span></span><br><span class="line">              % (e, val_loss, math.exp(val_loss)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save the model if the validation loss is the best we&#x27;ve seen so far.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> best_val_loss <span class="keyword">or</span> val_loss &lt; best_val_loss:</span><br><span class="line">            print(<span class="string">&quot;[!] saving model...&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(<span class="string">&quot;.save&quot;</span>):</span><br><span class="line">                os.makedirs(<span class="string">&quot;.save&quot;</span>)</span><br><span class="line">            torch.save(seq2seq.state_dict(), <span class="string">&#x27;./.save/seq2seq_%d.pt&#x27;</span> % (e))</span><br><span class="line">            best_val_loss = val_loss</span><br><span class="line">    test_loss = evaluate(seq2seq, test_iter, en_size, DE, EN)</span><br><span class="line">    print(<span class="string">&quot;[TEST] loss:%5.2f&quot;</span> % test_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">&quot;[STOP]&quot;</span>, e)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>bleu.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> bleu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_data</span>(<span class="params">cand, ref</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Store each reference and candidate sentences as a list &quot;&quot;&quot;</span></span><br><span class="line">    references = []</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;.txt&#x27;</span> <span class="keyword">in</span> ref:</span><br><span class="line">        reference_file = codecs.<span class="built_in">open</span>(ref, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        references.append(reference_file.readlines())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(ref):</span><br><span class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">                reference_file = codecs.<span class="built_in">open</span>(os.path.join(root, f), <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">                references.append(reference_file.readlines())</span><br><span class="line">    candidate_file = codecs.<span class="built_in">open</span>(cand, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    candidate = candidate_file.readlines()</span><br><span class="line">    <span class="keyword">return</span> candidate, references</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># candidate = [[&quot;word peace],[&#x27;make china great again !&#x27;]]</span></span><br><span class="line"><span class="comment"># reference [[&quot;world war&quot;],[&#x27;make USA great again&#x27;]]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_ngram</span>(<span class="params">candidate, references, n</span>):</span></span><br><span class="line">    clipped_count = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    r = <span class="number">0</span>   <span class="comment">#用来记录reference</span></span><br><span class="line">    c = <span class="number">0</span>  <span class="comment">#用来记录 candidates的长度</span></span><br><span class="line">    <span class="keyword">for</span> si <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(candidate)):  <span class="comment"># 遍历每一个CANDIDATES</span></span><br><span class="line">        <span class="comment"># Calculate precision for each sentence</span></span><br><span class="line">        <span class="comment"># print si</span></span><br><span class="line">        ref_counts = []   <span class="comment">#统计ref 中的，每个n-gram 的数字</span></span><br><span class="line">        ref_lengths = []  <span class="comment">#统计 REF 的长度，length</span></span><br><span class="line">        <span class="comment"># print references</span></span><br><span class="line">        <span class="comment"># Build dictionary of ngram counts</span></span><br><span class="line">        <span class="keyword">for</span> reference <span class="keyword">in</span> references:  <span class="comment"># 遍历每一个REFERENCE</span></span><br><span class="line">            <span class="comment"># print &#x27;reference&#x27; + reference</span></span><br><span class="line">            ref_sentence = reference[si]</span><br><span class="line">            ngram_d = &#123;&#125;</span><br><span class="line">            words = ref_sentence.strip().split()</span><br><span class="line">            ref_lengths.append(<span class="built_in">len</span>(words))</span><br><span class="line">            limits = <span class="built_in">len</span>(words) - n + <span class="number">1</span>      <span class="comment"># [1,2,3,4,5,6,7]</span></span><br><span class="line">            <span class="comment"># loop through the sentance consider the ngram length</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(limits):</span><br><span class="line">                ngram = <span class="string">&#x27; &#x27;</span>.join(words[i:i + n]).lower()</span><br><span class="line">                <span class="keyword">if</span> ngram <span class="keyword">in</span> ngram_d.keys():</span><br><span class="line">                    ngram_d[ngram] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    ngram_d[ngram] = <span class="number">1</span></span><br><span class="line">            ref_counts.append(ngram_d)</span><br><span class="line">        <span class="comment"># candidate</span></span><br><span class="line">        cand_sentence = candidate[si]  <span class="comment"># 遍历 CANDIDATE</span></span><br><span class="line">        cand_dict = &#123;&#125;</span><br><span class="line">        words = cand_sentence.strip().split()</span><br><span class="line">        limits = <span class="built_in">len</span>(words) - n + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, limits):</span><br><span class="line">            ngram = <span class="string">&#x27; &#x27;</span>.join(words[i:i + n]).lower()</span><br><span class="line">            <span class="keyword">if</span> ngram <span class="keyword">in</span> cand_dict:</span><br><span class="line">                cand_dict[ngram] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cand_dict[ngram] = <span class="number">1</span></span><br><span class="line">        clipped_count += clip_count(cand_dict, ref_counts)</span><br><span class="line">        count += limits</span><br><span class="line">        r += best_length_match(ref_lengths, <span class="built_in">len</span>(words))</span><br><span class="line">        c += <span class="built_in">len</span>(words)</span><br><span class="line">    <span class="keyword">if</span> clipped_count == <span class="number">0</span>:</span><br><span class="line">        pr = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pr = <span class="built_in">float</span>(clipped_count) / count</span><br><span class="line">    bp = brevity_penalty(c, r)</span><br><span class="line">    <span class="keyword">return</span> pr, bp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_count</span>(<span class="params">cand_d, ref_ds</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Count the clip count for each ngram considering all references&quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> cand_d.keys():</span><br><span class="line">        m_w = cand_d[m]</span><br><span class="line">        m_max = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> ref <span class="keyword">in</span> ref_ds:</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">in</span> ref:</span><br><span class="line">                m_max = <span class="built_in">max</span>(m_max, ref[m])</span><br><span class="line">        m_w = <span class="built_in">min</span>(m_w, m_max)</span><br><span class="line">        count += m_w</span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_length_match</span>(<span class="params">ref_l, cand_l</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Find the closest length of reference to that of candidate&quot;&quot;&quot;</span></span><br><span class="line">    least_diff = <span class="built_in">abs</span>(cand_l - ref_l[<span class="number">0</span>])</span><br><span class="line">    best = ref_l[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ref <span class="keyword">in</span> ref_l:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(cand_l - ref) &lt; least_diff:</span><br><span class="line">            least_diff = <span class="built_in">abs</span>(cand_l - ref)</span><br><span class="line">            best = ref</span><br><span class="line">    <span class="keyword">return</span> best</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">brevity_penalty</span>(<span class="params">c, r</span>):</span></span><br><span class="line">    <span class="keyword">if</span> c &gt; r:</span><br><span class="line">        bp = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bp = math.exp(<span class="number">1</span> - (<span class="built_in">float</span>(r) / c))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geometric_mean</span>(<span class="params">precisions</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (reduce(operator.mul, precisions)) ** (<span class="number">1.0</span> / <span class="built_in">len</span>(precisions))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BLEU</span>(<span class="params">candidate, references</span>):</span></span><br><span class="line">    precisions = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        pr, bp = count_ngram(candidate, references, i + <span class="number">1</span>)</span><br><span class="line">        precisions.append(pr)</span><br><span class="line">        <span class="built_in">print</span></span><br><span class="line">        <span class="string">&#x27;P&#x27;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>), <span class="string">&#x27; = &#x27;</span>, <span class="built_in">round</span>(pr, <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span></span><br><span class="line">    <span class="string">&#x27;BP = &#x27;</span>, <span class="built_in">round</span>(bp, <span class="number">2</span>)</span><br><span class="line">    bleu = geometric_mean(precisions) * bp</span><br><span class="line">    <span class="keyword">return</span> bleu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    candidate, references = fetch_data(sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>])</span><br><span class="line">    bleu = BLEU(candidate, references)</span><br><span class="line">    <span class="built_in">print</span></span><br><span class="line">    <span class="string">&#x27;BLEU = &#x27;</span>, <span class="built_in">round</span>(bleu, <span class="number">4</span>)</span><br><span class="line">    out = <span class="built_in">open</span>(<span class="string">&#x27;bleu_out.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    out.write(<span class="built_in">str</span>(bleu))</span><br><span class="line">    out.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.translate.bleu_score <span class="keyword">import</span> sentence_bleu</span><br><span class="line">reference = [[<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;test&#x27;</span>], [<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span> <span class="string">&#x27;test&#x27;</span>]]</span><br><span class="line">candidate = [<span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">score = sentence_bleu(reference, candidate)</span><br><span class="line">print(score)</span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2tlb24vc2VxMnNlcQ==">mini seq2seq<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/07/15/NLP/02.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/15/NLP/02.%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">基于LSTM的情感分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-15T00:00:00+08:00">2021-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>本项目使用了word2vec的中文预训练向量</strong><br><strong>模型分别有BiLSTM-attention和普通的LSTM两种，自行选择</strong></p>
<p><strong>使用说明</strong>：<br>1、在<strong>Config</strong>中配置相关参数</p>
<p>2、然后运行<strong>DataProcess.py</strong>，生成相应的word2id，word2vec等文件</p>
<p>3、运行主函数<strong>main.py</strong>，得到训练好的模型，并保存模型</p>
<p>4、运行<strong>eval.py</strong>，读取模型，并得到评价</p>
<p>5、模型<strong>准确率平均85%左右</strong></p>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_Config.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Config</span>():</span></span><br><span class="line">    update_w2v = <span class="literal">True</span>          <span class="comment"># 是否在训练中更新w2v</span></span><br><span class="line">    vocab_size = <span class="number">54848</span>          <span class="comment"># 词汇量，与word2id中的词汇量一致</span></span><br><span class="line">    n_class = <span class="number">2</span>                 <span class="comment"># 分类数：分别为pos和neg</span></span><br><span class="line">    max_sen_len = <span class="number">65</span>           <span class="comment"># 句子最大长度</span></span><br><span class="line">    embedding_dim = <span class="number">50</span>          <span class="comment"># 词向量维度</span></span><br><span class="line">    batch_size =<span class="number">64</span>            <span class="comment"># 批处理尺寸</span></span><br><span class="line">    hidden_dim=<span class="number">100</span>           <span class="comment"># 隐藏层节点数</span></span><br><span class="line">    n_epoch = <span class="number">30</span>            <span class="comment"># 训练迭代周期，即遍历整个训练样本的次数</span></span><br><span class="line">    lr = <span class="number">0.0001</span>               <span class="comment"># 学习率；若opt=‘adadelta&#x27;，则不需要定义学习率</span></span><br><span class="line">    drop_keep_prob = <span class="number">0.2</span>        <span class="comment"># dropout层，参数keep的比例</span></span><br><span class="line">    num_layers = <span class="number">2</span>              <span class="comment"># LSTM层数</span></span><br><span class="line">    bidirectional=<span class="literal">True</span>         <span class="comment">#是否使用双向LSTM</span></span><br><span class="line">    train_path = <span class="string">&#x27;./word2vec_data/train.txt&#x27;</span></span><br><span class="line">    val_path = <span class="string">&#x27;./word2vec_data/validation.txt&#x27;</span></span><br><span class="line">    test_path = <span class="string">&#x27;./word2vec_data/test.txt&#x27;</span></span><br><span class="line">    pre_path =<span class="string">&#x27;./word2vec_data/pre.txt&#x27;</span></span><br><span class="line">    word2id_path = <span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span></span><br><span class="line">    pre_word2vec_path = <span class="string">&#x27;./word2vec_data/wiki_word2vec_50.bin&#x27;</span></span><br><span class="line">    corpus_word2vec_path = <span class="string">&#x27;./word2vec_data/word_vec.txt&#x27;</span></span><br><span class="line">    model_state_dict_path=<span class="string">&#x27;./word2vec_data/sen_model.pkl&#x27;</span><span class="comment"># 训练模型保存的地址</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_DataProcess.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Data_set</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, Data, Label</span>):</span></span><br><span class="line">        self.Data = Data</span><br><span class="line">        <span class="keyword">if</span> Label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:<span class="comment">#考虑对测试集的使用</span></span><br><span class="line">            self.Label = Label</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.Data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.Label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data = torch.from_numpy(self.Data[index])</span><br><span class="line">            label = torch.from_numpy(self.Label[index])</span><br><span class="line">            <span class="keyword">return</span> data, label</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data = torch.from_numpy(self.Data[index])</span><br><span class="line">            <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stopwordslist</span>():</span><span class="comment">#创建停用词表</span></span><br><span class="line">    stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;word2vec_data/stopword.txt&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2id</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param file: word2id保存地址</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#num_50=0#统计长度大于50的句子数</span></span><br><span class="line">    stopwords = stopwordslist()</span><br><span class="line">    word2id = &#123;<span class="string">&#x27;_PAD_&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line">    path = [Config.train_path, Config.val_path]</span><br><span class="line">    <span class="comment">#print(path)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _path <span class="keyword">in</span> path:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                out_list = []</span><br><span class="line">                <span class="comment"># 去停用词</span></span><br><span class="line">                sp = line.strip().split()</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> sp[<span class="number">1</span>:]:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">                        rt = re.findall(<span class="string">&#x27;[a-zA-Z]+&#x27;</span>, word)</span><br><span class="line">                        <span class="keyword">if</span> word != <span class="string">&#x27;\t&#x27;</span>:</span><br><span class="line">                            <span class="comment"># if is_number(word):</span></span><br><span class="line">                            <span class="comment"># continue</span></span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(rt) == <span class="number">1</span>:</span><br><span class="line">                                <span class="keyword">continue</span></span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                out_list.append(word)</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> out_list:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word2id.keys():</span><br><span class="line">                        word2id[word] = <span class="built_in">len</span>(word2id)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> word2id:</span><br><span class="line">            f.write(w+<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            f.write(<span class="built_in">str</span>(word2id[w]))</span><br><span class="line">            f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2vec</span>(<span class="params">fname, word2id, save_to_path=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param fname: 预训练的word2vec.</span></span><br><span class="line"><span class="string">    :param word2id: 语料文本中包含的词汇集.</span></span><br><span class="line"><span class="string">    :param save_to_path: 保存训练语料库中的词组对应的word2vec到本地</span></span><br><span class="line"><span class="string">    :return: 语料文本中词汇集对应的word2vec向量&#123;id: word2vec&#125;.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n_words = <span class="built_in">max</span>(word2id.values()) + <span class="number">1</span></span><br><span class="line">    model = gensim.models.KeyedVectors.load_word2vec_format(fname, binary=<span class="literal">True</span>)</span><br><span class="line">    word_vecs = np.array(np.random.uniform(<span class="number">-1.</span>, <span class="number">1.</span>, [n_words, model.vector_size]))</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word2id.keys():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            word_vecs[word2id[word]] = model[word]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">if</span> save_to_path:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(save_to_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> vec <span class="keyword">in</span> word_vecs:</span><br><span class="line">                vec = [<span class="built_in">str</span>(w) <span class="keyword">for</span> w <span class="keyword">in</span> vec]</span><br><span class="line">                f.write(<span class="string">&#x27; &#x27;</span>.join(vec))</span><br><span class="line">                f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> word_vecs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_to_array</span>(<span class="params">word2id,seq_lenth ,path</span>):</span>  <span class="comment"># 文本转为索引数字模式,</span></span><br><span class="line"></span><br><span class="line">    lable_array=[]</span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    sa=[]</span><br><span class="line">    <span class="comment">#获取句子个数</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f1:</span><br><span class="line">        <span class="keyword">for</span> l1 <span class="keyword">in</span> f1.readlines():</span><br><span class="line">            s= l1.strip().split()</span><br><span class="line">            s1=s[<span class="number">1</span>:]</span><br><span class="line">            new_s = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> s1]  <span class="comment"># 单词转索引数字</span></span><br><span class="line">            sa.append(new_s)</span><br><span class="line">        <span class="comment">#print(len(sa))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        sentences_array=np.zeros(shape=(<span class="built_in">len</span>(sa),seq_lenth))<span class="comment">#行：句子个数 列：句子长度</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sl1 = line.strip().split()</span><br><span class="line">            sen=sl1[<span class="number">1</span>:]</span><br><span class="line">            new_sen = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> sen]  <span class="comment"># 单词转索引数字,不存在则为0</span></span><br><span class="line">            new_sen_np=np.array(new_sen).reshape(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#补齐每个句子长度，多余补零，少了就直接赋值,0填在前面。</span></span><br><span class="line">            <span class="keyword">if</span> np.size(new_sen_np,<span class="number">1</span>)&lt;seq_lenth:</span><br><span class="line">                sentences_array[i,seq_lenth-np.size(new_sen_np,<span class="number">1</span>):]=new_sen_np[<span class="number">0</span>,:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sentences_array[i, <span class="number">0</span>:seq_lenth]=new_sen_np[<span class="number">0</span>,<span class="number">0</span>:seq_lenth]</span><br><span class="line"></span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">            lable=<span class="built_in">int</span>(sl1[<span class="number">0</span>])<span class="comment">#标签</span></span><br><span class="line">            lable_array.append(lable)</span><br><span class="line">    <span class="keyword">return</span> np.array(sentences_array),lable_array</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_to_array_nolable</span>(<span class="params">word2id,seq_lenth ,path</span>):</span>  <span class="comment"># 文本转为索引数字模式,</span></span><br><span class="line"></span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    sa=[]</span><br><span class="line">    <span class="comment">#获取句子个数</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f1:</span><br><span class="line">        <span class="keyword">for</span> l1 <span class="keyword">in</span> f1.readlines():</span><br><span class="line">            s= l1.strip().split()</span><br><span class="line">            s1=s[<span class="number">1</span>:]</span><br><span class="line">            new_s = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> s1]  <span class="comment"># 单词转索引数字</span></span><br><span class="line">            sa.append(new_s)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        sentences_array=np.zeros(shape=(<span class="built_in">len</span>(sa),seq_lenth))<span class="comment">#行：句子个数 列：句子长度</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sl1 = line.strip().split()</span><br><span class="line">            sen=sl1[<span class="number">1</span>:]</span><br><span class="line">            new_sen = [word2id.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> sen]  <span class="comment"># 单词转索引数字,不存在则为0</span></span><br><span class="line">            new_sen_np=np.array(new_sen).reshape(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">if</span> np.size(new_sen_np,<span class="number">1</span>)&lt;seq_lenth:</span><br><span class="line">                sentences_array[i,seq_lenth-np.size(new_sen_np,<span class="number">1</span>):]=new_sen_np[<span class="number">0</span>,:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sentences_array[i, <span class="number">0</span>:seq_lenth]=new_sen_np[<span class="number">0</span>,<span class="number">0</span>:seq_lenth]</span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> np.array(sentences_array)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_categorical</span>(<span class="params">y, num_classes=<span class="literal">None</span></span>):</span><span class="comment">#将类别转化为one-hot编码</span></span><br><span class="line">    y = np.array(y, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">    input_shape = y.shape</span><br><span class="line">    <span class="keyword">if</span> input_shape <span class="keyword">and</span> input_shape[<span class="number">-1</span>] == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(input_shape) &gt; <span class="number">1</span>:</span><br><span class="line">        input_shape = <span class="built_in">tuple</span>(input_shape[:<span class="number">-1</span>])</span><br><span class="line">    y = y.ravel()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> num_classes:</span><br><span class="line">        num_classes = np.<span class="built_in">max</span>(y) + <span class="number">1</span></span><br><span class="line">    n = y.shape[<span class="number">0</span>]</span><br><span class="line">    categorical = np.zeros((n, num_classes))</span><br><span class="line">    categorical[np.arange(n), y] = <span class="number">1</span></span><br><span class="line">    output_shape = input_shape + (num_classes,)</span><br><span class="line">    categorical = np.reshape(categorical, output_shape)</span><br><span class="line">    <span class="keyword">return</span> categorical</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_data</span>(<span class="params">w2id, train_path,val_path,test_path,seq_lenth</span>):</span><span class="comment">#得到数字索引表示的句子和标签</span></span><br><span class="line">    train_array,train_lable = text_to_array(w2id,seq_lenth= seq_lenth,path=train_path)</span><br><span class="line">    val_array,val_lable  = text_to_array(w2id,seq_lenth=seq_lenth,path= val_path)</span><br><span class="line">    test_array,test_lable=text_to_array(w2id,seq_lenth=seq_lenth,path=test_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#标签为[1, 1, 1, 1, 1, 1, 1, 1, 0, 0...]将标签转为onehot</span></span><br><span class="line">    <span class="comment">#train_lable=to_categorical(train_lable,num_classes=2)</span></span><br><span class="line">    <span class="comment">#val_lable=to_categorical(val_lable,num_classes=2)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;for i in train_lable:</span></span><br><span class="line"><span class="string">        np.array([i])&quot;&quot;&quot;</span></span><br><span class="line">    train_lable=np.array([train_lable]).T</span><br><span class="line">    val_lable=np.array([val_lable]).T</span><br><span class="line">    test_lable=np.array([test_lable]).T</span><br><span class="line">    <span class="string">&quot;&quot;&quot;转换后标签</span></span><br><span class="line"><span class="string">            [[0. 1.]</span></span><br><span class="line"><span class="string">            [0. 1.]</span></span><br><span class="line"><span class="string">            [0. 1.]</span></span><br><span class="line"><span class="string">            ...</span></span><br><span class="line"><span class="string">            [1. 0.]</span></span><br><span class="line"><span class="string">            [1. 0.]</span></span><br><span class="line"><span class="string">            [1. 0.]]&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#print(train_lab,&quot;\nval\n&quot;,val_lab)</span></span><br><span class="line">    <span class="keyword">return</span> train_array ,train_lable,val_array,val_lable,test_array,test_lable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#建立word2id</span></span><br><span class="line">build_word2id(<span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span>)<span class="comment">#建立词toid</span></span><br><span class="line">splist=[]</span><br><span class="line">word2id=&#123;&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./word2vec_data/word2id.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sp = line.strip().split()<span class="comment">#去掉\n \t 等</span></span><br><span class="line">            splist.append(sp)</span><br><span class="line">        word2id=<span class="built_in">dict</span>(splist)<span class="comment">#转成字典</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> word2id:<span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">    word2id[key]=<span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line">id2word=&#123;&#125;<span class="comment">#得到id2word</span></span><br><span class="line"><span class="keyword">for</span> key,val <span class="keyword">in</span> word2id.items():</span><br><span class="line">    id2word[val]=key</span><br><span class="line"><span class="comment">#建立word2vec</span></span><br><span class="line">w2vec=build_word2vec(Config.pre_word2vec_path,word2id,Config.corpus_word2vec_path)</span><br><span class="line"></span><br><span class="line"><span class="comment">#得到句子id表示和标签</span></span><br><span class="line">train_array,train_lable,val_array,val_lable,test_array,test_label=prepare_data(word2id,</span><br><span class="line">                                                         train_path=Config.train_path,</span><br><span class="line">                                                         val_path=Config.val_path,</span><br><span class="line">                                                         test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line"></span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/train_data.txt&#x27;</span>, train_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/val_data.txt&#x27;</span>, val_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;./word2vec_data/test_data.txt&#x27;</span>, test_array,fmt=<span class="string">&#x27;%d&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_model.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim,pretrained_weight, update_w2v,hidden_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_layers,drop_keep_prob,n_class,bidirectional, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LSTMModel, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.n_class = n_class</span><br><span class="line"></span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(pretrained_weight)</span><br><span class="line">        self.embedding.weight.requires_grad = update_w2v</span><br><span class="line">        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim,</span><br><span class="line">                               num_layers=num_layers, bidirectional=self.bidirectional,</span><br><span class="line">                               dropout=drop_keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bidirectional:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">4</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        embeddings = self.embedding(inputs)<span class="comment"># [batch, seq_len] =&gt; [batch, seq_len, embed_dim][64,75,50]</span></span><br><span class="line">        states, hidden = self.encoder(embeddings.permute([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]))<span class="comment">#[75,32,50],[seq_len, batch, embed_dim]</span></span><br><span class="line"></span><br><span class="line">        encoding = torch.cat([states[<span class="number">0</span>], states[<span class="number">-1</span>]], dim=<span class="number">1</span>)<span class="comment">#张量拼接[32,512]</span></span><br><span class="line">        outputs = self.decoder1(encoding)</span><br><span class="line">        <span class="comment">#outputs = F.softmax(outputs, dim=1)</span></span><br><span class="line">        outputs=self.decoder2(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTM_attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim,pretrained_weight, update_w2v,hidden_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_layers,drop_keep_prob,n_class,bidirectional, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LSTM_attention, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.n_class = n_class</span><br><span class="line"></span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(pretrained_weight)</span><br><span class="line">        self.embedding.weight.requires_grad = update_w2v</span><br><span class="line">        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim,</span><br><span class="line">                               num_layers=num_layers, bidirectional=self.bidirectional,</span><br><span class="line">                               dropout=drop_keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#TODO</span></span><br><span class="line">        <span class="comment"># What is nn. Parameter ? Explain</span></span><br><span class="line">        self.weight_W = nn.Parameter(torch.Tensor(<span class="number">2</span>*hidden_dim, <span class="number">2</span>*hidden_dim))</span><br><span class="line">        self.weight_proj = nn.Parameter(torch.Tensor(<span class="number">2</span>*hidden_dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.bidirectional:</span><br><span class="line">            <span class="comment">#self.decoder1 = nn.Linear(hidden_dim * 2, n_class)</span></span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.decoder1 = nn.Linear(hidden_dim * <span class="number">2</span>, hidden_dim)</span><br><span class="line">            self.decoder2 = nn.Linear(hidden_dim,n_class)</span><br><span class="line"></span><br><span class="line">        nn.init.uniform_(self.weight_W, <span class="number">-0.1</span>, <span class="number">0.1</span>)</span><br><span class="line">        nn.init.uniform_(self.weight_proj, <span class="number">-0.1</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span><span class="number">0</span></span><br><span class="line">        embeddings = self.embedding(inputs)<span class="comment"># [batch, seq_len] =&gt; [batch, seq_len, embed_dim][64,75,50]</span></span><br><span class="line"></span><br><span class="line">        states, hidden = self.encoder(embeddings.permute([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]))<span class="comment">#[batch, seq_len, embed_dim]</span></span><br><span class="line">        <span class="comment">#attention</span></span><br><span class="line"></span><br><span class="line">        u = torch.tanh(torch.matmul(states, self.weight_W))</span><br><span class="line">        att = torch.matmul(u, self.weight_proj)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        att_score = F.softmax(att, dim=<span class="number">1</span>)</span><br><span class="line">        scored_x = states * att_score</span><br><span class="line">        encoding = torch.<span class="built_in">sum</span>(scored_x, dim=<span class="number">1</span>)</span><br><span class="line">        outputs = self.decoder1(encoding)</span><br><span class="line">        outputs=self.decoder2(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_main.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_DataProcess <span class="keyword">import</span> prepare_data,build_word2vec,Data_set</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,f1_score,recall_score</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Sentiment_model <span class="keyword">import</span> LSTMModel,LSTM_attention</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_eval <span class="keyword">import</span> val_accuary</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_dataloader,model, device, epoches, lr</span>):</span></span><br><span class="line"></span><br><span class="line">        model.train()</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        print(model)</span><br><span class="line">        optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        <span class="comment"># scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)  # 学习率调整</span></span><br><span class="line">        best_acc = <span class="number">0.85</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoches):  <span class="comment"># 一个epoch可以认为是一次训练循环</span></span><br><span class="line">            train_loss = <span class="number">0.0</span></span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            train_dataloader = tqdm.tqdm(train_dataloader)</span><br><span class="line">            <span class="comment"># train_dataloader.set_description(&#x27;[%s%04d/%04d %s%f]&#x27; % </span></span><br><span class="line">            <span class="comment">#                                 (&#x27;Epoch:&#x27;, epoch + 1, epoches, &#x27;lr:&#x27;, scheduler.get_last_lr()[0]))</span></span><br><span class="line">            <span class="keyword">for</span> i, data_ <span class="keyword">in</span> (<span class="built_in">enumerate</span>(train_dataloader)):</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                input_, target = data_[<span class="number">0</span>], data_[<span class="number">1</span>]</span><br><span class="line">                input_=input_.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">                target=target.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">                input_=input_.to(device)</span><br><span class="line">                target=target.to(device)</span><br><span class="line">                output= model(input_)</span><br><span class="line">                <span class="comment"># 经过模型对象就产生了输出</span></span><br><span class="line">                target=target.squeeze(<span class="number">1</span>)</span><br><span class="line">                loss = criterion(output, target)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">                train_loss+= loss.item()</span><br><span class="line">                _, predicted = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)</span><br><span class="line">                <span class="comment">#print(predicted.shape)</span></span><br><span class="line">                total += target.size(<span class="number">0</span>)  <span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">                <span class="comment">#print(target.shape)</span></span><br><span class="line">                correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">                F1=f1_score(target.cpu(),predicted.cpu(),average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">                Recall=recall_score(target.cpu(),predicted.cpu(),average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">                <span class="comment">#CM=confusion_matrix(target.cpu(),predicted.cpu())</span></span><br><span class="line">                postfix = &#123;<span class="string">&#x27;train_loss: &#123;:.5f&#125;,train_acc:&#123;:.3f&#125;%&#x27;</span></span><br><span class="line">                           <span class="string">&#x27;,F1: &#123;:.3f&#125;%,Recall:&#123;:.3f&#125;%&#x27;</span> .<span class="built_in">format</span>(train_loss / (i + <span class="number">1</span>),</span><br><span class="line">                                                                        <span class="number">100</span> * correct / total, <span class="number">100</span>*F1 , <span class="number">100</span>* Recall)&#125;</span><br><span class="line">                train_dataloader.set_postfix(log=postfix)</span><br><span class="line"></span><br><span class="line">            acc=val_accuary(model,val_dataloader,device,criterion)</span><br><span class="line">            <span class="keyword">if</span> acc&gt;best_acc:</span><br><span class="line">                best_acc = acc</span><br><span class="line">                <span class="keyword">if</span> os.path.exists(Config.model_state_dict_path) == <span class="literal">False</span>:</span><br><span class="line">                    os.mkdir(Config.model_state_dict_path)</span><br><span class="line">                torch.save(model,<span class="string">&#x27;./word2vec_data/sen_model_best.pkl&#x27;</span> )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    splist=[]</span><br><span class="line">    word2id=&#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(Config.word2id_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                sp = line.strip().split()<span class="comment">#去掉\n \t 等</span></span><br><span class="line">                splist.append(sp)</span><br><span class="line">            word2id=<span class="built_in">dict</span>(splist)<span class="comment">#转成字典</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> word2id:<span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">        word2id[key]=<span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    id2word=&#123;&#125;<span class="comment">#得到id2word</span></span><br><span class="line">    <span class="keyword">for</span> key,val <span class="keyword">in</span> word2id.items():</span><br><span class="line">        id2word[val]=key</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_array,train_lable,val_array,val_lable,test_array,test_lable=prepare_data(word2id,</span><br><span class="line">                                                             train_path=Config.train_path,</span><br><span class="line">                                                             val_path=Config.val_path,</span><br><span class="line">                                                             test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_loader = Data_set(train_array, train_lable)</span><br><span class="line">    train_dataloader = DataLoader(train_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)<span class="comment">#用了workers反而变慢了</span></span><br><span class="line"></span><br><span class="line">    val_loader = Data_set(val_array, val_lable)</span><br><span class="line">    val_dataloader = DataLoader(val_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    test_loader = Data_set(test_array, test_lable)</span><br><span class="line">    test_dataloader = DataLoader(test_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line">    w2vec=build_word2vec(Config.pre_word2vec_path,word2id,<span class="literal">None</span>)<span class="comment">#生成word2vec</span></span><br><span class="line">    w2vec=torch.from_numpy(w2vec)</span><br><span class="line">    w2vec=w2vec.<span class="built_in">float</span>()<span class="comment">#CUDA接受float32，不接受float64</span></span><br><span class="line">    model=LSTM_attention(Config.vocab_size,Config.embedding_dim,w2vec,Config.update_w2v,</span><br><span class="line">                    Config.hidden_dim,Config.num_layers,Config.drop_keep_prob,Config.n_class,Config.bidirectional)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">    train(train_dataloader,model=model,device=device,epoches=Config.n_epoch,lr=Config.lr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(Config.model_state_dict_path) == <span class="literal">False</span>:</span><br><span class="line">           os.mkdir(Config.model_state_dict_path)</span><br><span class="line">    torch.save(model, Config.model_state_dict_path)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Sentiment_Analysis_eval.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,f1_score,recall_score,precision_score</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Sentiment_model <span class="keyword">import</span> LSTMModel,LSTM_attention</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_Config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> Sentiment_Analysis_DataProcess <span class="keyword">import</span> prepare_data,build_word2vec,text_to_array_nolable,Data_set</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_accuary</span>(<span class="params">model,val_dataloader,device,criterion</span>):</span></span><br><span class="line">    model = model.to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct1 = <span class="number">0</span></span><br><span class="line">        total1 = <span class="number">0</span></span><br><span class="line">        val_loss=<span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> j, data_1 <span class="keyword">in</span> (<span class="built_in">enumerate</span>(val_dataloader, <span class="number">0</span>)):</span><br><span class="line">            input1, target1 = data_1[<span class="number">0</span>], data_1[<span class="number">1</span>]</span><br><span class="line">            input1= input1.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target1 = target1.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target1=target1.squeeze(<span class="number">1</span>)<span class="comment">#从[64,1]到[64]</span></span><br><span class="line">            input1 = input1.to(device)</span><br><span class="line">            target1 = target1.to(device)</span><br><span class="line">            output1 = model(input1)</span><br><span class="line">            loss1 = criterion(output1, target1)</span><br><span class="line">            val_loss += loss1.item()</span><br><span class="line">            _, predicted1 = torch.<span class="built_in">max</span>(output1, <span class="number">1</span>)</span><br><span class="line">            total1 += target1.size(<span class="number">0</span>)<span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">            correct1 += (predicted1 == target1).<span class="built_in">sum</span>().item()</span><br><span class="line">            F1 = f1_score(target1.cpu(), predicted1.cpu(), average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">            Recall = recall_score(target1.cpu(), predicted1.cpu(), average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">            <span class="comment">#CM = confusion_matrix(target1.cpu(), predicted1.cpu())</span></span><br><span class="line">        print(<span class="string">&#x27;\nVal accuracy : &#123;:.3f&#125;%,val_loss:&#123;:.3f&#125;, F1_score：&#123;:.3f&#125;%, Recall：&#123;:.3f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span>*correct1/total1,val_loss,<span class="number">100</span>*F1,<span class="number">100</span>*Recall))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">100</span>*correct1/total1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_accuary</span>(<span class="params">model,test_dataloader,device</span>):</span></span><br><span class="line">    model = model.to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k, data_test <span class="keyword">in</span> (<span class="built_in">enumerate</span>(test_dataloader, <span class="number">0</span>)):</span><br><span class="line">            input_test, target_ = data_test[<span class="number">0</span>], data_test[<span class="number">1</span>]</span><br><span class="line">            input_test= input_test.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target_ = target_.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">            target_=target_.squeeze(<span class="number">1</span>)<span class="comment">#从[64,1]到[64]</span></span><br><span class="line">            input_test = input_test.to(device)</span><br><span class="line">            target_ = target_.to(device)</span><br><span class="line">            output2 = model(input_test)</span><br><span class="line">            _, predicted_test = torch.<span class="built_in">max</span>(output2, <span class="number">1</span>)</span><br><span class="line">            total += target_.size(<span class="number">0</span>)<span class="comment"># 此处的size()类似numpy的shape: np.shape(train_images)[0]</span></span><br><span class="line">            correct += (predicted_test == target_).<span class="built_in">sum</span>().item()</span><br><span class="line">            F1 = f1_score(target_.cpu(), predicted_test.cpu(), average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">            Recall = recall_score(target_.cpu(), predicted_test.cpu(), average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">            CM = confusion_matrix(target_.cpu(), predicted_test.cpu())</span><br><span class="line">        print(<span class="string">&#x27;test accuracy : &#123;:.3f&#125;%, F1_score：&#123;:.3f&#125;%, Recall：&#123;:.3f&#125;%,Confusion_matrix：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span>*correct/total,<span class="number">100</span>*F1,<span class="number">100</span>*Recall,CM))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre</span>(<span class="params">word2id,model,seq_lenth ,path</span>):</span></span><br><span class="line">    model.cpu()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_array=text_to_array_nolable(word2id,seq_lenth,path)</span><br><span class="line">        <span class="comment">#sen_p = sen_p.type(torch.LongTensor)</span></span><br><span class="line">        sen_p = torch.from_numpy(input_array)</span><br><span class="line">        sen_p=sen_p.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">        output_p = model(sen_p)</span><br><span class="line">        _, pred = torch.<span class="built_in">max</span>(output_p, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> pred:</span><br><span class="line">            print(<span class="string">&#x27;预测类别为&#x27;</span>,i.item())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    splist = []</span><br><span class="line">    word2id = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(Config.word2id_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            sp = line.strip().split()  <span class="comment"># 去掉\n \t 等</span></span><br><span class="line">            splist.append(sp)</span><br><span class="line">        word2id = <span class="built_in">dict</span>(splist)  <span class="comment"># 转成字典</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> word2id:  <span class="comment"># 将字典的值，从str转成int</span></span><br><span class="line">        word2id[key] = <span class="built_in">int</span>(word2id[key])</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    train_array, train_lable, val_array, val_lable, test_array, test_lable = prepare_data(word2id,</span><br><span class="line">                                                                                          train_path=Config.train_path,</span><br><span class="line">                                                                                          val_path=Config.val_path,</span><br><span class="line">                                                                                          test_path=Config.test_path,seq_lenth=Config.max_sen_len)</span><br><span class="line">    test_loader = Data_set(test_array, test_lable)</span><br><span class="line">    test_dataloader = DataLoader(test_loader,</span><br><span class="line">                                 batch_size=Config.batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=<span class="number">0</span>)</span><br><span class="line">    w2vec = build_word2vec(Config.pre_word2vec_path,</span><br><span class="line">                           word2id,</span><br><span class="line">                          <span class="literal">None</span>)  <span class="comment"># 生成word2vec</span></span><br><span class="line">    w2vec = torch.from_numpy(w2vec)</span><br><span class="line">    w2vec = w2vec.<span class="built_in">float</span>()  <span class="comment"># CUDA接受float32，不接受float64</span></span><br><span class="line"></span><br><span class="line">    model=LSTM_attention(Config.vocab_size,Config.embedding_dim,w2vec,Config.update_w2v,</span><br><span class="line">                        Config.hidden_dim,Config.num_layers,Config.drop_keep_prob,Config.n_class,Config.bidirectional)</span><br><span class="line">    <span class="comment"># 读取模型</span></span><br><span class="line">    <span class="comment">#model1 = torch.load(Config.model_state_dict_path)</span></span><br><span class="line">    model = torch.load(<span class="string">&#x27;./word2vec_data/sen_model_best.pkl&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#model.load_state_dict(torch.load(Config.model_state_dict_path)) #仅保存参数</span></span><br><span class="line">    <span class="comment">#验证</span></span><br><span class="line">    <span class="comment">#val_accuary(model1, val_dataloader, device)</span></span><br><span class="line">    <span class="comment">#测试</span></span><br><span class="line">    test_accuary(model,test_dataloader,device)</span><br><span class="line">    <span class="comment">#预测</span></span><br><span class="line">    pre(word2id,model,Config.max_sen_len,Config.pre_path)</span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vaHUteWFuZ2dhbmcvU2VudGltZW50LUFuYWx5c2lzLUNoaW5lc2UtcHl0b3JjaCMlRTUlOEUlOUYlRTUlODglOUIlRTQlQjglOEQlRTYlOTglOTMlRTUlQTYlODIlRTYlOUUlOUMlRTUlQTUlQkQlRTclOTQlQTglRTglQUYlQjclRTclQkIlOTklRTQlQjglQUFzdGFyJUU4JUIwJUEyJUU4JUIwJUEyJUU0JUJBJTg2LSVFNCVCRCU5QyVFOCU4MCU4NSVFNiU5RCU4RSVFNyU4QiU5NyVFNSU5NyVBOA==">Sentiment-Analysis-Chinese-pytorch<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/06/25/Paper/02.XGBoost%20A%20Scalable%20Tree%20Boosting%20System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/25/Paper/02.XGBoost%20A%20Scalable%20Tree%20Boosting%20System/" class="post-title-link" itemprop="url">XGBoost A Scalable Tree Boosting System</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-25 00:00:00" itemprop="dateCreated datePublished" datetime="2021-06-25T00:00:00+08:00">2021-06-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>提出名为XGBoost的树提升系统。<br>提出一种新颖的稀疏数据感知算法用于稀疏数据，一种带权值的分位数略图(weighted quantile sketch) 来近似实现树的学习。<br>提出有关缓存访问模式，数据压缩和分片的见解，以构建有延展性的提升树系统。</p>
<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h1><p>机器学习方法里，GradientTree Boosting（GBDT）是一个在很多应用里都很出彩的技术。提升树方法在很多有标准分类基准的情况下表现很出色。本文提出了一个可扩展的提升树机器学习系统（XGBoost）。XGBoost在2015年的29场比赛获胜队伍中，有17个都使用了XGBoost。</p>
<p>主要贡献：<br>1、设计和构建高度可扩展的端到端提升树系统。（树的个数能灵活的增加或减少）<br>2、提出了一个理论上合理的加权分位法。（推荐分割点的时候用，能不用遍历所有的点，只用部分点就行）<br>3、引入了一种新颖的稀疏感知算法用于并行树学习。（令缺失值有默认方向，稀疏数据处理方法和并行计算）<br>4、提出了一个有效的用于核外树形学习的缓存感知块结构。（有效使用缓存块处理数据）</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><h2 id="Regularized-Learning-Objective"><a href="#Regularized-Learning-Objective" class="headerlink" title="Regularized Learning Objective"></a>Regularized Learning Objective</h2><p>给定一个数据集$\mathcal{D}$，$ n$个样本，每个样本有$ m$个特征：</p>
<script type="math/tex; mode=display">
\mathcal{D}= \{(x_i,y_i)\}(|\mathcal{D}|= n,x_i\in \Bbb{R}^m, y_i\in \Bbb{R})</script><p>第 $ k$ 棵树对于输入 $ x_i$ 的样本预测结果为$ f_k(x_i)$：</p>
<script type="math/tex; mode=display">
 \hat{y}_i=\varnothing(x_i)=\sum\limits_{k=1}^{K}f_k(x_i),\quad f_k\in \mathcal{F}</script><p>其中，$\mathcal{F}= \{f(x)=w_{q(x)}\}(q:\Bbb{R}^m\to T,w\in \Bbb{R}^T)$ 是CART回归树。$ q(x)$ 表示映射样本 $ x$ 到叶子节点的下标。$ T$是叶子节点数量。$ w$ 是叶子节点最优解（$ w_i$表示第$i$个叶子节点的最优解）。每一棵树都有独立的 $ q$  和 $ w$。</p>
<h2 id="Gradient-Tree-Boosting"><a href="#Gradient-Tree-Boosting" class="headerlink" title="Gradient Tree Boosting"></a>Gradient Tree Boosting</h2><p>以上定义了树模型的预测函数，那么接下来定义整个损失函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\varnothing)= \sum\limits_i l(\hat{y}_i,y_i)+\sum\limits_k \Omega(f_k)\\</script><script type="math/tex; mode=display">
\text{where} \quad \Omega( f)=\gamma  T + \frac{1}{2}\lambda||w||^2</script><p>其中，$ l$ 函数是一个可导的凸函数，用来表示预测值 $\hat{y}_i$ 和真实值 $ y_i$ 之间的差异。$\Omega$ 是是惩罚项（正则化），用来防止树的结构过于复杂。<br>损失函数 $\mathcal{L}$ 参数中包含了函数，所以不能用传统的优化算法来优化。假设 $\hat{y}_i^{t}$ 是 $ x_i$ 在第 $ t$ 次迭代中的预测值。那么则有：</p>
<script type="math/tex; mode=display">
\mathcal{L}^{( t)}= \sum\limits_{i= 1}^{n}l(y_i,\hat{y}_i^{(t-1)}+f_t(x_i))+\Omega(f_t)</script><p>把 $ y_i,\hat{y}_i^{(t-1)}$ 看成 $x$ ，把 $ f_t(x_i))$ 看成 $\Delta x$ ，对上式近似为二阶泰勒级展开：</p>
<script type="math/tex; mode=display">
\mathcal{L}^{( t)}\simeq \sum\limits_{i= 1}^{n}[l(y_i,\hat{y}_i^{(t-1)})+g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)</script><script type="math/tex; mode=display">
\text{where} \quad  g_i=\partial_{\hat{y}^{(t-1)}}l(y_i,\hat{y}_i^{(t-1)})\quad \text{and} \quad h_i=\partial_{\hat{y}^{(t-1)}}^{ 2}l(y_i,\hat{y}_i^{(t-1)})</script><p>其中，$ g_i$$ h_i$是一阶偏导和二阶偏导。由于$ l(y_i,\hat{y}_i^{(t-1)})$为常数项，可以去除。<br>定义 $ I_j=\{i|q(x_i)=j\}$ 作为样本 $ x_i$ 被分割到第 $ j$ 个叶子节点下的样本下标集合（样本集合）。那么上面公式可以由<strong>对每棵树的样本求和</strong>转成<strong>对每棵树的叶子节点求和</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\tilde{\mathcal{L}}^{( t)}&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{i= 1}^{n}[g_iw_{q(x_i)}+\frac{1}{2} h_i(w_{q(x_i)})^{ 2}]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{j= 1}^{T}[\sum\limits_{i\in I_j}g_iw_{j}+\frac{1}{2}\sum\limits_{i\in  I_j} h_i(w_{j})^{ 2}]+\gamma  T + \frac{1}{2}\lambda \sum\limits_{ j= 1}^{T}w_j^{ 2}\\
&= \sum\limits_{j= 1}^{T}[(\sum\limits_{i\in I_j}g_i)w_{j}+\frac{1}{2}(\sum\limits_{i\in  I_j} h_i+\lambda)w_{j}^{ 2}]+\gamma  T 
\end{aligned}</script><p><strong>1、如何求出每个叶子节点的最优解？</strong><br>对上式求极值点（它是凸函数，求的是极小值），即对 $ w_j$ 求一阶导数等于零（也可以看成二元一次方程求解），解得：</p>
<script type="math/tex; mode=display">
 w_j^*=-\frac{\sum_{i\in I_j}g_i}{\sum_{i\in I_j}h_i+\lambda}</script><p>带入 $\tilde{\mathcal{L}}^{( t)}$ 求得最优值（最小值）：</p>
<script type="math/tex; mode=display">
 \tilde{\mathcal{L}}^{( t)}=-\frac{1}{2}\sum\limits_{j= 1}^{T}\frac{(\sum_{i\in I_j}g_i)^{ 2}}{\sum_{i\in I_j}h_i+\lambda}+\gamma  T</script><p>可以用这个公式来来衡量决策树的质量。有点像决策树信息熵一个道理。</p>
<p><strong>2、对当前决策树做子树分裂时，如何选择哪个特征和特征值进行分裂，使损失函数最小？</strong><br>如果想要划分后损失函数得到最小值，意味这在做每次划分的时候，要尽量保证划分后的score比划分前的score要更小。那么应该找到 (划分前的score - 划分后的score) 这个差最大的切分点作为我们这一次的划分点。假设 $ I_L$和 $ I_R$ 为一个节点 $ I$ 划分后的左子集和右子集，节点 $ I=I_L \cup I_R$ ，则得到以下公式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
 \mathcal{L}_{split}&=- \dfrac{1}{2}[\frac{(\sum_{i\in I}g_i)^{ 2}}{\sum_{i\in I}h_i+\lambda}-\frac{(\sum_{i\in I_L}g_i)^{ 2}}{\sum_{i\in I_L}h_i+\lambda}-\frac{(\sum_{i\in I_R}g_i)^{ 2}}{\sum_{i\in I_R}h_i+\lambda}]-\gamma\\
&= \dfrac{1}{2}  [\frac{(\sum_{i\in I_L}g_i)^{ 2}}{\sum_{i\in I_L}h_i+\lambda}+\frac{(\sum_{i\in I_R}g_i)^{ 2}}{\sum_{i\in I_R}h_i+\lambda}-\frac{(\sum_{i\in I}g_i)^{ 2}}{\sum_{i\in I}h_i+\lambda}]-\gamma
\end{aligned}</script><p>可以用这个公式来衡量是否当前节点是否再应该继续划分下去。每次用不同的特征，计算分数，然后用最大的值那个特征，作为当前树节点的划分点。</p>
<p>相对于GBDT，XGBoost一次性求解出<strong>最优解叶子节点区域</strong>和<strong>每个叶子节点区域最优解</strong>。而GBDT是基于残差（一阶泰勒）拟合一颗CART书，得到<strong>最优叶子节点区域</strong>，再求出<strong>每个叶子节点区域最优解</strong>。</p>
<h2 id="Shrinkage-and-Column-Subsampling"><a href="#Shrinkage-and-Column-Subsampling" class="headerlink" title="Shrinkage and Column Subsampling"></a>Shrinkage and Column Subsampling</h2><p>除了之前提过的添加正则化的项来防止模型的过拟合之外，还可以用两种方式来防止过拟合：<br>（1）添加类似梯度下降优化问题中的学习率 $ \eta$ ，这个可以收缩每棵树的权重，让每棵树的生长更加稳定。<br>（2）对样本的特征子采样（随机森林用到过）。每次生成树的时候，只用其中一部分抽样的特征。这样子也能降低过拟合的风险。</p>
<p><strong>精准的贪心算法</strong><br>贪心算法就是每次都希望找到最优的结果，但这样需每次都遍历所有的特征，对每个特征，又遍历所有划分的可能。然后通过 $ \mathcal{L}_{split}$ 的分数，计算每次划分后的score，取最大的score的对应的特征来进行划分。<br><img src="/images/XGB/01.png" width="60%"></p>
<p><strong>近似的贪心算法</strong><br>用上面贪心算法来寻找最佳划分点，准确度非常不错，但是时间复杂度和空间复杂度都太高了，特别是对于连续值的变量来说，简直是一个大灾难。作者提出一种近似法分位法，先对数据进行分桶(Bucket)，然后桶内的数据相加起来，作为一个代表来进行计算。</p>
<p>那我们应该在什么时候对数据进行分桶呢？有两种方式。<br>（1）全局分桶（Global Bucket），可以一开始就对全部的数据进行分桶。后面进行划分的时候只需要使用分桶数据就可以了。<br>（2）局部分桶（Local Bucket），每次需要对当前leaf node进行划分的时候，对当前节点里面的数据进行分桶。然后再划分。当然这个时间复杂度也会变的比较高。</p>
<p>具体划分的伪代码如下：<br>（1）先计算1到M个特征，找出每个特征的分桶的候选点。<br>（2）然后将候选点之间的数据的g和h求和，装入到Bucket里面，代表这些数据。<br>（3）后面流程就跟精确的弹性分割算法一样。只是将每个Bucket看成一个x。<br><img src="/images/XGB/02.png" width="60%"></p>
<p>下面是作者测试对几种不同的切分算法的AUC结果比较图。可以看得出，当eps=0.05，也就是将数据分成20个Bucket的时候，AUC的分数跟精准的贪心算法一样。<br><img src="/images/XGB/03.png" width="60%"></p>
<h2 id="SPLIT-FINDING-ALGORITHMS"><a href="#SPLIT-FINDING-ALGORITHMS" class="headerlink" title="SPLIT FINDING ALGORITHMS"></a>SPLIT FINDING ALGORITHMS</h2><p>提出一种新的分桶的方法<strong>Weighted Quantile Sketch</strong>（加权分位法）。</p>
<p><strong>加权分位法</strong><br>上面我们讨论了对数据分成Bucket，再来计算他的节点的split分数。来减少我们的计算量。那么我们如何对数据分桶，才能够比较合理呢？</p>
<p>作者按照对loss的影响权重来进行分桶，让数据分桶后，每个桶对loss的影响权重相同。<br>定义一个数据集 $ \mathcal{D}_k=\{(x_{1k},h_1),(x_{2k},h_2),…,(x_{nk},h_n)\}$ ，$ k$ 为样本 $x$ 的特征数。<br>定义一个排序函数 $ r_k:\Bbb{R}\sim [0,\infty)$，则：</p>
<script type="math/tex; mode=display">
 r_k(z)=\frac{1}{\sum_{(x,h)\in \mathcal{D}_k}h}\sum_{(x,h)\in \mathcal{D}_k,x<z}h</script><p>切分点集合 $ \{s_{k1}, s_{k2},…,s_{kl}\}$，满足：</p>
<script type="math/tex; mode=display">
|r_k(s_{k,j})-r_k(s_{k,j+1})|<\epsilon, \quad s_{k1}=\min\limits_i x_{ik},s_{kl}=\max\limits_i x_{ik}</script><p>这里 $\epsilon$ 用来衡量划分区间的大小（每个Bucket不能太大，以免错过最优切分点）。这个意味这数据集大约被分为 $\frac{1}{\epsilon}$ 个候选点。</p>
<p>那么 $h_i$ 为什么能够代表 $x_i$ 的权重来进行排序呢？将公式 ${\tilde{\mathcal{L}}}^{(t)}$ 对 $ h_i$ 进行提取，可得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\tilde{\mathcal{L}}^{( t)}&= \sum\limits_{i= 1}^{n}[g_if_t(x_i)+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}[\frac{1}{2} h_i\frac{ 2* g_if_t(x_i)}{h_i}+\frac{1}{2} h_if_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i[ 2\times \frac{g_i}{h_i}f_t(x_i)+f_t^{ 2}(x_i)]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i[ 2\times \frac{g_i}{h_i}f_t(x_i)+f_t^{ 2}(x_i)+(\frac{g_i}{h_i})^2-(\frac{g_i}{h_i})^2]+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i(f_t(x_i)+\frac{g_i}{h_i})^{ 2}+\Omega(f_t)\\
&= \sum\limits_{i= 1}^{n}\frac{1}{2} h_i(f_t(x_i)-(-\frac{g_i}{h_i}))^{ 2}+\Omega(f_t)+\text{constant}
\end{aligned}</script><p>发现 $ h_i$ 对结果影响最大，所以用它来进行排序。</p>
<h2 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h2><p>对稀疏数据的处理，重点是针对特征为空时的处理，对<strong>精准的贪心算法</strong>做了改进：<br><img src="/images/XGB/04.png" width="60%"></p>
<p>简单来讲，通过两轮遍历可以确保稀疏值位于左子树和右子树的情形，就是对该特征划分为左节点还是右节点做了一次比较，哪个效果好就把它放在哪。</p>
<h2 id="SYSTEM-DESIGN"><a href="#SYSTEM-DESIGN" class="headerlink" title="SYSTEM DESIGN"></a>SYSTEM DESIGN</h2><p>重点是优化：<br>（1）<strong>预排序</strong>：这个算法大量时间消耗在排序上。只需在最开始对每个特征排一次序即可。<br>这里XGB将所有的列数据都预先排了序。以压缩形式分别存到block里，不同的block可以分布式存储，甚至存到硬盘里。在特征选择的时候，可以并行的处理这些列数据，XGB就是在这实现的并行化，用多线程来实现加速。同时这里还用cache加了一个底层优化：当数据排序后，索引值是乱序的，可能指向了不同的内存地址，找的时候数据是不连续的，这里加了个缓存，让以后找的时候能找到小批量的连续地址，以实现加速！这里是在每个线程里申请了一个internal buffer来实现的！这个优化在小数据下看不出来，数据越多越明显。</p>
<p>（2）<strong>预取</strong>：尽可能的把数据保存在缓存中，这样不用去磁盘进行读取，减少时间开销。并且给出了对比结果：<br><img src="/images/XGB/05.png" width="100%"></p>
<p>（3）内存块的大小也会影响缓存速率。<br><img src="/images/XGB/06.png" width="50%"></p>
<p>针对磁盘存储优化。磁盘block不大的情况下：<br>1.把block数据进行压缩，让它没有那么大。<br>2.把block数据放在多个磁盘，增大磁盘带宽，让读取速度更。</p>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>如果$\textbf{X}$是一个离散型随机变量，取空间值为$\Bbb{R}$，其概率分布为$ p(x)=P(\textbf{X}=x),x\in\Bbb{R}$。那么，$\textbf{X}$的熵$H(\textbf{X})$定义为：</p>
<script type="math/tex; mode=display">
H(\textbf{X})=-\sum\limits_{x\in\Bbb{R}} p(x) log p(x)</script><p>其中，$H(\textbf{X})$可以写成$H( p)$。</p>
<p><strong>熵又称为子信息（self-information），可以视为描述一个随机变量的不确定性的数量</strong>。它表示信源$\textbf{X}$每发一个符号（不论发什么符号）所提供的平均信息量。<strong>一个随机变量的熵越大，它的不确定性越大，那么，正确估计其值的可能性就越小。越不确定的随机变量越需要大的信息量用以确定其值。</strong></p>
<p><strong>熵定义了随机变量的不确定性，当熵最大时，随机变量最不确定，最难准确地预测其行为。也就是说，在已知部分知识的前提下，关于未知分布最合理的推断应该是符合已知知识最不确定或最大随机的推断。</strong> </p>
<h2 id="联合熵和条件熵"><a href="#联合熵和条件熵" class="headerlink" title="联合熵和条件熵"></a>联合熵和条件熵</h2><p>如果$\textbf{X},\textbf{Y}$是一对离散型随机变量$\textbf{X},\textbf{Y}\sim p(x,y)$，$\textbf{X},\textbf{Y}$的联合熵（joint entropy）$H(\textbf{X},\textbf{Y})$定义为：</p>
<script type="math/tex; mode=display">
H(\textbf{X},\textbf{Y})=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(x,y)</script><p>联合熵实际上就是描述一对随机变量平均所需要的信息量。</p>
<p>给定随机变量$\textbf{X}$的情况下， 随机变量$\textbf{Y}$的条件熵（conditionalentropy）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H(\textbf{Y}|\textbf{X})&=\sum\limits_{ x\in\textbf{X}} p(x) H(\textbf{Y}|\textbf{X}= x)\\
&=\sum\limits_{ x\in\textbf{X}} p(x)[-\sum\limits_{ y\in\textbf{Y}} p(y|x) log p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)
\end{aligned}</script><p>将其中的联合概率$log p(x,y)$展开，可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H(\textbf{X},\textbf{Y})&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log[ p(x)p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) [log p(x) + log p(y|x)]\\
&=-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(x)-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)\\
&=-\sum\limits_{ x\in\textbf{X}} p(x) log p(x)-\sum\limits_{ x\in\textbf{X}}\sum\limits_{ y\in\textbf{Y}} p(x,y) log p(y|x)\\
&=H(\textbf{X})+H(\textbf{Y}|\textbf{X})
\end{aligned}</script><p>我们称上式为熵的连锁规则。推广到一般情况，有：</p>
<script type="math/tex; mode=display">
H(\textbf{X}_1,\textbf{X}_2,...,\textbf{X}_n)=H(\textbf{X}_1)+H(\textbf{X}_2|\textbf{X}_1)+...+H(\textbf{X}_n|\textbf{X}_1,\textbf{X}_2,...,\textbf{X}_{n-1})</script><h2 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h2><p>根据熵的连锁规则， 有：</p>
<script type="math/tex; mode=display">
H(\textbf{X},\textbf{Y})=H(\textbf{X})+H(\textbf{Y}|\textbf{X})=H(\textbf{Y})+H(\textbf{X}|\textbf{Y})</script><p>因此：</p>
<script type="math/tex; mode=display">
H(\textbf{X})-H(\textbf{X}|\textbf{Y})=H(\textbf{Y})-H(\textbf{Y}|\textbf{X})</script><p>这个差叫做$\textbf{X}$和$\textbf{Y}$的互信息（mutual information, MI），记作$I(\textbf{X};\textbf{Y})$。<br>或者定义为：如果$(\textbf{X},\textbf{Y})\sim  p(x,y)$，则$\textbf{X},\textbf{Y}$之间的互信息$I(\textbf{X};\textbf{Y})=H(\textbf{X})-H(\textbf{X}|\textbf{Y})$。</p>
<p><strong>$I(\textbf{X};\textbf{Y})$反映的是在知道了$\textbf{Y}$的值以后$\textbf{X}$的不确定性的减少量。可以理解为$\textbf{Y}$的值透露了多少关于$\textbf{X}$的信息量。</strong><br>互信息和熵之间的关系：<br><img src="/images/XGB/互信息.png" width="40%"></p>
<p>如果将定义中的$H(\textbf{X})$和$H(\textbf{X}|\textbf{Y})$展开，可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
I(\textbf{X};\textbf{Y})&=H(\textbf{X})-H(\textbf{X}|\textbf{Y})\\
&=H(\textbf{X})+H(\textbf{Y})-H(\textbf{X},\textbf{Y})\\
&=\sum\limits_{ x} p(x) log \frac{1}{p(x)}  + \sum\limits_{ y} p(y) log \frac{1}{p(y)}  + \sum\limits_{ x,y} p(x,y) log p(x,y) \\
&=\sum\limits_{ x,y} p(x,y) log \frac{p(x,y)}{p(x)p(y)} \\
\end{aligned}</script><p>由于$H(\textbf{X}|\textbf{X})=0$， 因此，</p>
<script type="math/tex; mode=display">
H(\textbf{X})=H(\textbf{X})-H(\textbf{X}|\textbf{X})=I(\textbf{X};\textbf{X})</script><p>这一方面说明了为什么熵又称为自信息，另一方面说明了两个完全相互依赖的变量之间的互信息并不是一个常量，而是取决于它们的熵。</p>
<p>实际上，互信息体现了两变量之间的依赖程度：<br>如果$I(\textbf{X};\textbf{Y})≫0$，表明$\textbf{X}$和$\textbf{Y}$是高度相关的；<br>如果$I(\textbf{X};\textbf{Y})=0$，表明$\textbf{X}$和$\textbf{Y}$是相互独立的；<br>如果$I(\textbf{X};\textbf{Y})≪0$，表明$\textbf{Y}$的出现不但未使$\textbf{X}$的不确定性减小，反而增大了$\textbf{X}$的不确定性，是非常是不利的。</p>
<h2 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h2><p>相对熵（relative entropy）又称Kullback-Leibler差异（KullbackLeibler divergence），或简称KL距离，是<strong>衡量相同事件空间里两个概率分布相对差距的测度</strong>。两个概率分布$ p(x)$和$ q(x)$的相对熵定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
D( p||q)&=\sum\limits_{ x\in\textbf{X}} p(x) log\frac{ p(x)}{ q(x)}\\
&=\sum\limits_{ x\in\textbf{X}} p(x) log  p(x)  - \sum\limits_{ x\in\textbf{X}} p(x) log q(x)\\
&=-H( p)+H( p,q)
\end{aligned}</script><p>其中，$H( p)$恒不变，只需考虑交叉熵$H( p,q)$即可。$ q(x)$ 分布越接近 $ p(x)$，那么散度值越小。<br>有时会将KL散度称为KL距离，但它并不满足距离的性质：KL散度不是对称的；KL散度不满足三角不等式。</p>
<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>根据前面熵的定义，知道熵是一个不确定性的测度，也就是说，我们对于某件事情知道得越多，那么，熵就越小，因而对于试验的结果我们越不感到意外。<strong>交叉熵的概念就是用来衡量估计模型与真实概率分布之间差异情况的。</strong><br>如果一个随机变量$\textbf{X}\sim p(x)$，$ q(x)$为用于近似$ p(x)$的概率分布，那么，随机变量$\textbf{X}$和模型$ p(x)$之间的交叉熵（cross entropy）定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
H( p,q)&=H( p)+D( p||q)\\
&=-\sum\limits_{ x\in\textbf{X}} p(x) log  q(x)\\
\end{aligned}</script><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8yOTM5NjcyLjI5Mzk3ODU=">XGBoost: A Scalable Tree Boosting System<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvMTA5Nzk4MDguaHRtbA==">XGBoost算法原理小结<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FkYnN6c2ovYXJ0aWNsZS9kZXRhaWxzLzc5NjE1NzEy">XGBoost 论文翻译+个人注释<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84OTU4OTIyMg==">XGBoost论文详解<i class="fa fa-external-link-alt"></i></span><br>[统计自然语言处理（第二版），宗成庆]</p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/06/20/Paper/01.Unsupervised%20Data%20Augmentation%20for%20Consistency%20Training/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/20/Paper/01.Unsupervised%20Data%20Augmentation%20for%20Consistency%20Training/" class="post-title-link" itemprop="url">Unsupervised Data Augmentation for Consistency Training</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-06-20T00:00:00+08:00">2021-06-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>背景：深度学习的模型训练通常依赖大量的标签数据（如Bert、XLNet），在只有少量数据上通常表现不好。由此产生了数据增强，但以前的研究都是基于监督学习的，并且效果不是特别理想。</p>
<p>贡献：本文提出了一种对无监督（无标签）数据增强方式（半监督学习中无标签数据的增强），简称UDA。UDA方法生成的无监督数据与原始无监督数据具备<strong>分布的一致性</strong>，而以前的方法通常只是应用高斯噪声和dropout噪声（无法保证一致性）。</p>
<p>效果：使用这种数据增强方法，在极少量数据集上，六种语言任务和三种视觉任务都得到了明显的提升。IMDb数据分类任务上，仅仅使用20个带标签数据加UDA方法，就超过了25000个带标签数据的训练模型，错误率达到了4.2%。在CIFAR-10上仅用4000张标签图片就达到了2.7%的错误率。在SVHN任务上，仅仅用250个标签数据就达到了2.85%的错误率，这相当于用全数据集才能达到的正确率，而它们的数量级差别达到了1或2（差10倍或100倍）。在大量标签数据集上，UDA同样表现优秀，在ImageNet任务上，使用10%带标签数据，UDA方法就将Top1和Top5的准确率分别由55.1%提高到77.3%，68.7提高到88.5%。在全数据集上，则分别由78.3%提高到94.4%，79%提高到94.5%。</p>
<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h1><p>深度学习需要大量带标签数据，但是实际工程中很难满足，这就需要数据标注，但数据标注是一项耗时耗力的工作。所以，充分利用未标注数据是一个很有意义的研究方向。而半监督方法，是最有前景的方法之一，当前半监督方法可归结为三类：<br>（1）基于图卷积和图嵌入的图标签传播方法。<br>（2）将目标数据作为潜变量进行预测。<br>（3）强制一致/平滑。这种方法在许多任务中被证明具有较好的效果。</p>
<p>强制平滑方法只是使得模型对应较小的噪声不那么敏感。常用方法就是：对于一个样本，添加一些噪声（例如高斯噪声）然后强制让模型对于加噪和不加噪的数据的输出尽量的相似。直观而言就是一个好的模型，应该能够适应各种小的、不改变样本性质的扰动。通常由于扰动函数的不同会有各种不同的方案。</p>
<p>本文在Sajjadi、 Laine等人的研究的基础上，从有监督数据中学习扰动函数，从而得到最优的数据增强方法。良好的数据增强方法能够大大提高模型的结果，并且数据增强方法能应用于各领域。<strong>本文使用的优化方法是最小化增强数据与真实数据之间的KL散度</strong>。虽然有监督数据的数据增强取得了很多成功，但是大量的无监督数据使得UDA这种无监督数据增强方法拥有更广阔前景。</p>
<p>主要贡献：<br>（1）提出一种TSA方法，该方法能够在无标签数据大于标签数据的时候防止过拟合。<br>（2）证明<strong>针对性的数据增强</strong>（如AutoAugment）效果明显优于无针对性的数据增强。<br>（3）验证了本文方法在NLP任务上（如Bert）上的有效性。<br>（4）在CV和NLP任务中，本文方法都表现优异。<br>（5）研究一种能应用于分类数据中有标签数据和无标签数据不匹配情况的方法（数据不平衡处理方法）。</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><h2 id="有监督数据增强"><a href="#有监督数据增强" class="headerlink" title="有监督数据增强"></a>有监督数据增强</h2><p>在保持标签相同（同一类别）的情况下，通过某种转换方法扩充出类似于真实数据的训练数据。简单而言就是，有一个样本$x$，通过转换函数$q(x)$生成新数据$\hat{x}$，新旧数据有相同的数据标签$y(\hat{x})=y(x)$。通常为了得到的增强数据与原始数据相似，使用的是最大似然估计方法。</p>
<p>数据增强方法可以看成是从有标签数据中扩充出更多的有标签数据，然后用扩充数据进行模型训练。因此，扩充数据相对于原始数据必须是有效的变换（例如图片缩放对图片识别可能有效，图片旋转可能无效）。也因此，如何设计转换函数至关重要。</p>
<p>目前，针对NLP任务的有监督数据增强方法已经取得了很大进展。虽然有成果，但是它通常被比喻成“蛋糕上的樱桃”，只是提高有限的性能，这是由于监督数据通常都是少量的。因此，本文研究了一种基于大量数据的无监督数据增强方法。</p>
<h2 id="无监督数据增强"><a href="#无监督数据增强" class="headerlink" title="无监督数据增强"></a>无监督数据增强</h2><p>本文研究了一种利用无监督数据的强制平滑方法（类似VAT）。工作流程如下：<br><img src="/images/UDA/UDA.png" width="90%"></p>
<p>（1）监督学习部分，使用交叉熵损失函数，模型是$p_\theta(y|x)$。<br>（2）无监督学习部分，使用强制平滑损失函数，对无标签数据进行数据增强，使增强前和增强后的数据分布越相近越好。增强前模型$p_{\tilde{\theta}}(y|x)$，增强后模型$p_\theta(y|\hat{x})$。<br>（3）最后，同时使用有标签和无标签数据，把二者模型结合起来，得到Final Loss。</p>
<p>本文使用最小化<strong>增强后的无标签数据</strong>和<strong>增强前无标签数据</strong>的KL散度。公式如下：<br><img src="/images/UDA/UDA_loss1.png" width="60%"></p>
<p>为了同时使用带标签数据和无标签数据，作者在计算带标签数据时上加上交叉熵损失和权重$\lambda$。<br><img src="/images/UDA/UDA_loss2.png" width="40%"></p>
<p>其中$\it q(\hat{x}|x)$是数据增强变换，$\tilde{\theta}$是当前参数$\theta$的固定副本，表明梯度像Miyato等人所建议的那样，不是通过$\tilde{\theta}$传播的。这里使用的数据增强与监督数据增强中使用的增强方法相同。由于数据增强耗时比较大，所以数据增强是离线生成的，单个原始样本会生成多个增强样本。</p>
<p>在无监督学习时，使用了针对性的数据增强：<br>（1）<strong>Back-translation</strong>：回译能够在保证语义不变的情况下，生成多样的句式。实验证明，在QANet上，这种策略取得了良好的效果。因此作者在情感分类问题等数据集，如IMDb，Yelp-2，Yelp-5，Amazon-2，Amazon-5上采用了这种策略，同时，他们发现，句式的多样性比较有效性更重要。所以使用了<strong>RandAugument</strong>。<br>（2）<strong>RandAugument</strong>：随机抽样增强，加入噪声。采用随机抽样代替集束搜索策略（一种贪心策略）。具体而言，作者使用WMT14语料库来训练英语到法语和法语到英语的翻译模型，并对每个句子执行回译，而不是整个段落，因为WMT14中的并行数据是用于句子级翻译，而情感分类语料库中的输入类型是段落。<br>（3）<strong>TF-IDF word replacement</strong>：虽然回译能够很好的进行数据扩充，但是它并不能保证扩充的句子包含关键词。而对于某些任务，如DBPedia任务，它的目标是预测某些句子属于维基百科的哪个词条。因此关键字非常重要，本文研究了一种在保留TF-IDF高的关键字，用其他非关键字替代TF-IDF分数低的非关键字扩充方案，详细见论文附录B。<br>增强结果如图所示：<br><img src="/images/UDA/trans.png" width="80%"></p>
<p>当然，对CV任务用了<strong>AutoAugument</strong>：用强化学习来搜索图像增强的“最优”组合，其性能明显优于任何人工设计的优化方法。作者使用已发现的增强策略，在CIFAR-10， SVHN和ImageNet上进行了实验，并在CIFAR-10，SVHN上组合应用了Cutout技术。<br>增强结果如图所示：<br><img src="/images/UDA/trans2.png" width="80%"></p>
<h2 id="数据增强在多样性和有效性上的平衡"><a href="#数据增强在多样性和有效性上的平衡" class="headerlink" title="数据增强在多样性和有效性上的平衡"></a>数据增强在多样性和有效性上的平衡</h2><p>虽然在一些非常优秀的数据增强方法中，能够得到很好的多样性和有效性。但是，由于多样性是通过改变原始数据得到的，所以，它存在改变数据类别的风险，所以，多样性和有效性是存在一定矛盾的。</p>
<p>对于图像分类，AutoAugment算法在有监督的环境下，根据验证集的性能进行优化，从而自动找到多样性和有效性之间的最佳点。</p>
<p>对于文本分类，作者调整随机抽样的强度。一方面，当强度为0时，随机抽样解码退化为贪婪方法，产生完全有效但完全相同的样本。另一方面，当作者使用1的强度时，随机抽样会产生非常不同但几乎不可读的样本。作者发现，设置Softmax强度为0.7、0.8或0.9的表现最好。</p>
<h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><p>要介绍一些针对不同问题，不同场景下的训练技巧。</p>
<p><strong>Training Signal Annealing（TSA）</strong>：针对标签数据与未标签数据不平衡时的场景。由于有大量的未标签数据需要UDA处理，所以需要一个较大模型，但是由于较大模型很容易在少量标签数据下过拟合，所以，提出了本方法用于解决该问题。<br>TSA原理就是在训练过程中，随着未标签数据的增加，逐步去除带标签数据，从而避免模型过拟合到带标签的训练数据。具体而言，就是在训练的$t$时刻，设置一个阈值$\eta_t$，当$\frac{1}{k}\leqslant\eta_t\leqslant 1$，其中$k$是类别数。当某个标签计算的$p_\theta(y^*|x)$大于阈值$\eta_t$，就将该标签数据移除出计算损失的过程，而只计算miniBatch里面的其余数据。假定miniBatch样本记作B，那么该策略计算损失如下：<br><img src="/images/UDA/TSA.png" width="40%"><br>过滤后的样本集合：<br><img src="/images/UDA/TSA2.png" width="40%"></p>
<p>阈值$\eta_t$用于防止模型过拟合到标签数据。随着$\eta_t$向1靠近，模型只能缓慢地从标注的实例中得到监督，大大缓解了过拟合问题。假设T是总训练步数，t是当前的训练步数。为了考虑未标记数据和标记数据的不同比率，有以下三种$\eta_t$更新计算方式：<br><img src="/images/UDA/TSA3.png" width="90%"></p>
<p>对于数据量少，容易过拟合的情况，使用指数形式比较好。对于标签数据不容易过拟合的情况，比如标签数据比较多或者使用了有效的正则化手段时，使用对数形式会比较好。使用不同更新方式的效果：<br><img src="/images/UDA/TSA4.png" width="50%"></p>
<p><strong>Sharpening Predictions</strong><br>当标签数据很少时，未标签数据和预测的未标签数据分布会很平坦。因此，在计算KL散度时，主要贡献的部分来自于标签数据。例如在Imagenet任务中，使用10%标签数据下，未标签数据的分布明显比标签数据的分布更加平坦。而比较丰富的数据分布是比较有利于模型训练的，因此，提出以下三种锐化方案：<br>（1）基于置信度的mask：对模型预测效果不好的，预测的概率小于一定阈值的标签，不计算一致性损失。<br>（2）最小化熵：最小化熵就是使得预测的增广数据能够拥有一个较低的熵，因此，需要在计算损失时，加上熵的计算。<br>（3）Softmax控制：通过调整Softmax控制输出， $p_{\tilde{\theta}}(y|x)$通过$Softmax(l(x)/\tau)$计算，其中$l(x)$表示结果逻辑分布概率，$\tau$表示强度。$\tau$越小，分布越锐化。</p>
<p><strong>Domain-relevance Data Filtering</strong><br>通常，作者希望能够运用领域外的数据，因为它比较容易获取。但是，一般领域外的数据和领域内的数据不匹配。由于数据分布的不匹配，使用领域外的数据往往对模型是有负面影响的。为了获取与当前任务相关的域数据，本文采用一种通用的检测领域外数据的技术。作者用领域内的数据训练了一个模型，让后用它去评估领域外的数据，然后过滤掉置信度低的数据。具体说就是，对于分类任务，对所有领域外数据进行概率计算，只使用其中分类正确且概率高的数据。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>本文对文本分类和视觉相关任务，运用UDA进行了实验。包括六项文本分类任务和三项图片分类任务。</p>
<h3 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h3><p>实验是基于Bert进行的，因为它在许多NLP任务中表现都很好。具体实验设置请看原始论文，实验结果如下：<br><img src="/images/UDA/01.png" width="80%"></p>
<p>实验结果表明，运用UDA后，基本都取得了较大的提高。同时，作者还实验了<strong>不同数量的标签</strong>对结果的影响，结果如下：<br><img src="/images/UDA/02.png" width="80%"></p>
<p>作者实验对比了UDA与半监督方法，结果显示，UDA结果明显更优。<br><img src="/images/UDA/03.png" width="90%"></p>
<p>同时，作者还对比实验了不同模型的情况：<br><img src="/images/UDA/04.png" width="80%"></p>
<h3 id="图像任务"><a href="#图像任务" class="headerlink" title="图像任务"></a>图像任务</h3><p>ImageNet之所以要单独拿出来，是因为它是一个很有挑战性的任务，而且数据量很大。作者使用10%标签数据和全数据分别做了对比（图片尺寸224）。<strong>10%标签数据</strong>，ImageNet对比实验结果：<br><img src="/images/UDA/05.png" width="50%"></p>
<p><strong>全数据</strong>，ImageNet对比实验结果：<br><img src="/images/UDA/06.png" width="50%"></p>
<p>作者做了<strong>使用不同训练策略</strong>下的情况，TSA对比实验结果：<br><img src="/images/UDA/07.png" width="50%"></p>
<p>最后，作者做了<strong>消融实验，对比不同策略的重要性</strong>。不同模块的消融实验结果：<br><img src="/images/UDA/08.png" width="50%"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文提供了一种无监督数据（无标签）数据增强方式，通过<strong>Back-translation</strong>、<strong>RandAugument</strong>、<strong>TF-IDF word replacement</strong>方法对无监督文本数据增强，使用<strong>AutoAugument</strong>对图像数据进行增强，最后使用KL散度使新生成的样本数据和原样本数据分布一致，最后结合有监督数据（有标签）形成最终的损失函数，通过<strong>TSA</strong>处理了无标签数据大于有标签数据的过拟合问题。</p>
<p>本文重要的是使用了针对性的数据增强，并且效果很好，不同于传统的高斯噪声、dropout噪声、或者简单的仿射变换，这种针对性的增强能生成更有效的噪声。并且对扰动的有效性和多样性进行了平衡。</p>
<p>这种针对性的思想值得学习，并且考虑分布影响，结合可以利用的增强方式，比如EDA中提到的同义词替换（synonym replacement）和随机插入（random Insertion，RI）。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMTI4NDh2Mi5wZGY=">Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMTI4NDgucGRmP3JlZj1oYWNrZXJub29uLmNvbQ==">Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDEuMTExOTYucGRm">EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9zZXZlbm9sZC5naXRodWIuaW8vMjAyMC8wNi90ZXh0X0VEQS8=">自然语言处理之文本数据增强<i class="fa fa-external-link-alt"></i></span><br>Github：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS1yZXNlYXJjaC91ZGE=">uda<i class="fa fa-external-link-alt"></i></span><br>Github：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3poYW5sYW9iYW4vRURBX05MUF9mb3JfQ2hpbmVzZQ==">EDA_NLP_for_Chinese<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC81ZDRlMThiOGRlMDQ=">谷歌惊艳的无监督数据增强方法—Unsupervised Data Augmentation for Consistency Training<i class="fa fa-external-link-alt"></i></span></p>

      
    </div>

    
    
    
      


    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SoundMemories</span>
</div>
  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '.page-configurations',
    '.main-inner',
    '.post-toc-wrap',
    '.languages',
    '.pjax'
  ],
  analytics: false,
  cacheBust: false,
  scrollRestoration: false,
  scrollTo: !CONFIG.bookmark.enable
});

document.addEventListener('pjax:success', () => {
  pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  const hasTOC = document.querySelector('.post-toc');
  document.querySelector('.sidebar-inner').classList.toggle('sidebar-nav-active', hasTOC);
  document.querySelector(hasTOC ? '.sidebar-nav-toc' : '.sidebar-nav-overview').click();
  NexT.utils.updateSidebarPosition();
});
</script>


  




  <script src="/js/local-search.js"></script>








<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  const url = element.dataset.target;
  const pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  const pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  const fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>


<script data-pjax>
if (document.querySelectorAll('.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8.8.2/dist/mermaid.min.js', () => {
    mermaid.init({
      theme    : 'neutral',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    }, '.mermaid');
  }, window.mermaid);
}
</script>





  








    <div class="pjax">
  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@2.0.0/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink.listen({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://soundmemories.github.io/',]
      });
      });
  </script>

    </div>
</body>
</html>
