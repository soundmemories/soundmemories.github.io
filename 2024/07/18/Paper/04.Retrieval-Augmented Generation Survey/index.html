<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.17.1","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Retrieval-Augmented Generation for Natural Language Processing: A Survey 摘要 1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识。 2.检索增强生成（RAG，Retrieval-Augment">
<meta property="og:type" content="article">
<meta property="og:title" content="Retrieval-Augmented Generation Survey">
<meta property="og:url" content="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="Retrieval-Augmented Generation for Natural Language Processing: A Survey 摘要 1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识。 2.检索增强生成（RAG，Retrieval-Augment">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/1.RAG%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0%E5%9B%BE.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/2.%E6%A3%80%E7%B4%A2%E5%99%A8%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/3.%E5%88%9B%E5%BB%BA%E6%A3%80%E7%B4%A2%E5%99%A8%E4%BC%AA%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/4.%E6%9F%A5%E8%AF%A2%E6%A3%80%E7%B4%A2%E5%99%A8%E4%BC%AA%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/5.%E6%A3%80%E7%B4%A2%E8%9E%8D%E5%90%88%E5%88%86%E7%B1%BB.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/6.query_base_fusions.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/7.logits_base_funsions.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/8.latent_funsions.png">
<meta property="article:published_time" content="2024-07-17T16:00:00.000Z">
<meta property="article:modified_time" content="2024-11-10T11:30:13.345Z">
<meta property="article:author" content="SoundMemories">
<meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soundmemories.github.io/images/RAG/1.RAG%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0%E5%9B%BE.png">


<link rel="canonical" href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":"","permalink":"https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/","path":"2024/07/18/Paper/04.Retrieval-Augmented Generation Survey/","title":"Retrieval-Augmented Generation Survey"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Retrieval-Augmented Generation Survey | SoundMemories</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SoundMemories</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">10</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">10</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">128</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#retrieval-augmented-generation-for-natural-language-processing-a-survey"><span class="nav-number">1.</span> <span class="nav-text">Retrieval-Augmented
Generation for Natural Language Processing: A Survey</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0-%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E7%AC%AC%E4%BA%8C%E8%8A%82"><span class="nav-number">1.3.</span> <span class="nav-text">概述-检索,增强,生成（第二节）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E5%99%A8%E7%AC%AC%E4%B8%89%E8%8A%82"><span class="nav-number">1.4.</span> <span class="nav-text">检索器（第三节）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E8%9E%8D%E5%90%88%E7%AC%AC4%E8%8A%82"><span class="nav-number">1.5.</span> <span class="nav-text">检索融合（第4节）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%99%A8%E7%AC%AC5%E8%8A%82"><span class="nav-number">1.6.</span> <span class="nav-text">生成器（第5节）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#retrieval-augmented-generation-for-ai-generated-content-a-survey"><span class="nav-number">2.</span> <span class="nav-text">Retrieval-Augmented
Generation for AI-Generated Content: A Survey</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81-1"><span class="nav-number">2.1.</span> <span class="nav-text">摘要</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">3.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="/images/avstar.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">128</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avstar.png">
      <meta itemprop="name" content="SoundMemories">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Retrieval-Augmented Generation Survey | SoundMemories">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Retrieval-Augmented Generation Survey
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2024-07-18T00:00:00+08:00">2024-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1
id="retrieval-augmented-generation-for-natural-language-processing-a-survey">Retrieval-Augmented
Generation for Natural Language Processing: A Survey</h1>
<h2 id="摘要">摘要</h2>
<p>1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如<strong>幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识</strong>。<br />
2.检索增强生成（RAG，Retrieval-Augmented
Generation）<strong>利用外部知识数据库来增强LLMs</strong>，弥补了LLMs的这些缺点。<br />
3.本文回顾了RAG的所有<strong>重要技术</strong>，特别时在<strong>检索器（retriever）</strong>、<strong>检索融合（retrieval
fusions）</strong>方面。<br />
4.此外，还<strong>提供</strong>了实现<strong>RAG中代表性技术</strong>的教程<strong>代码</strong>。<br />
5.进一步讨论了RAG训练，包括在<strong>有无数据仓库更新</strong>的情况下RAG的效果。<br />
6.介绍了RAG在<strong>代表性NLP任务</strong>、<strong>工业场景</strong>中的应用。<br />
7.讨论了RAG的<strong>未来方向和挑战</strong>，以促进其发展。</p>
<h2 id="介绍">介绍</h2>
<p>1.大语言模型（LLMs）通常是在<strong>大量的自然语言语料库上进行预训练</strong>的，然后<strong>在特定的下游任务的数据集上进行微调</strong>。LLMs的成功可以解释为语言模型作为知识库，在<strong>参数中隐含地存储了从训练数据集中学到的知识</strong>，作为内部记忆，并通过从记忆中检索答案来生成响应。<br />
2.目前为了存储更多的知识以获得更好的生成性能，现有的方法<strong>通常通过增加参数的体积来扩大存储容量</strong>，从而记忆更多的知识。</p>
<p>1.尽管LLMs已经展示出巨大能力，但仍有几个问题阻碍了LLMs的发展：<br />
（1）最突出的问题是<strong>幻觉问题</strong>，它指定是<strong>LLMs倾向于生成连贯、流畅但事实错误的响应</strong>。<br />
（2）另一个巨大挑战是<strong>知识更新问题</strong>，它指定是<strong>LLMs内部知识的更新，那么这就需要重新/微调LLMs，这就需要花费大量money</strong>。<br />
（3）另一个挑战是<strong>LLMs缺乏特定领域的专业知识</strong>，如果训练一个特定领域的LLMs，这就<strong>需要耗费大量人力来收集这些特定领域的数据</strong>。</p>
<p>1.为了<strong>应对这些问题和挑战</strong>，最近的研究<strong>建议利用外部知识数据库来增强LLMs，这就是RAG</strong>。<br />
（1）RAG通过<strong>从外部数据库检索的相关事实信息</strong>，可以在<strong>一定程度上缓解幻觉问题</strong>。<br />
（2）<strong>知识更新问题</strong>，可以通过<strong>更新外部数据库的知识信息</strong>，从而<strong>增强LLMs的知识实时性</strong>。<br />
（3）RAG通过<strong>构建和利用特定领域知识数据库</strong>，将<strong>通用LLMs扩展到特定领域</strong>，从而<strong>增强LLMs的特定领域专业知识</strong>。</p>
<p>1.本文回顾了涉及RAG涉及的所有技术，尽管已经由很多篇调查论文，但本文仍然提供了一些关键见解：<br />
（1）本文<strong>系统介绍了RAG的各个组成部分</strong>，包括<strong>检索器从构建到查询的细节</strong>，以及<strong>检索融合的指导性代码</strong>。<br />
（2）本文<strong>展示了不同的RAG训练策略</strong>，包括<strong>有/没有数据存储更新</strong>的RAG。<br />
（3）本文进一步讨论了<strong>RAG在下游NLP任务</strong>和<strong>实际NLP场景</strong>中的应用。<br />
（4）本文最终确定了<strong>未来有希望的探索方向</strong>和<strong>需要解决的主要挑战</strong>。</p>
<p>1.文章结构：<br />
（1）第二节给出了<strong>RAG概述</strong>。<br />
（2）第三、四节介绍了<strong>检索器</strong>和<strong>检索融合</strong>中使用的所有技术细节。<br />
（3）第五节介绍了<strong>生成器</strong>。<br />
（4）第六节介绍了<strong>如何训练有/没有数据存储更新的RAG</strong>。<br />
（7）第七节介绍了<strong>代表性的NLP任务中使用的技术</strong>。<br />
（8）第八节展示了<strong>RAG在实际NLP场景中的应用</strong>。<br />
（9）第九节讨论<strong>RAG的未来方向</strong>。<br />
（10）第十节对本文做出了<strong>最终结论</strong>。</p>
<h2 id="概述-检索增强生成第二节">概述-检索,增强,生成（第二节）</h2>
<p>RAG技术应用在NLP任务处理概述：<br />
<img src="/images/RAG/1.RAG处理流程概述图.png" width="75%"></p>
<p>如图1所示，RAG主要包含三个模块：<strong>检索器（Retriever）、生成器（Generator）、检索融合（Retrieval
Fusions）</strong>。</p>
<p>1.<strong>检索器（Retriever）</strong>：主要包含三个部分：<br />
（1）<strong>编码器（encoder）</strong>：encoder将inputs编码为embeddings。<br />
（2）<strong>索引（index）</strong>：用来支持近似最近邻高效搜索的索引。<br />
（3）<strong>数据存储（datastore）</strong>：kv对形式存储外部知识的数据库。<br />
2.检索器主要挑战在于<strong>检索效率和检索质量之间，找到最佳的权衡</strong>。<br />
3.<strong>检索效率</strong>：指获取相关信息的速度有多快，这涉及到<strong>加速编码、高效索引、在数据库中批量查询等</strong>。<br />
4.<strong>检索质量</strong>：指的是信息的关联性如何，这涉及到<strong>块表示学习、高级近似近邻搜索算法等</strong>。</p>
<p>1.<strong>检索融合（Retrieval
Fusions）</strong>：利用检索信息来增强生成。<br />
2.<strong>融合技术</strong>，主要包含三种：<br />
（1）<strong>基于查询的融合（Query-based
Fusion）</strong>：在将检索信息输入生成器之前增强输入。<br />
（2）<strong>基于逻辑的融合（Logits-based
Fusion）</strong>：侧重于生成器的输出逻辑，并融合检索的逻辑以获得更稳健的逻辑输出。<br />
（3）<strong>潜在融合（Latent
Fusion）</strong>：将检索表示引入生成器的潜在表示中，从而隐式地提高模型的性能。</p>
<p>1.<strong>生成器（Generator）</strong>：生成器模块可以分为两个分支:<br />
（1）<strong>默认生成器</strong>：预训练/微调的LLMs，如GPT系列、Gemini系列。<br />
（2）<strong>检索增强(RA)生成器</strong>：预训练/微调生成器，融合了检索模块，比如RETRO、ENCDEC。潜在融合使用的时RA生成器。<br />
2.<strong>RAG的工作流程</strong>包括三个步骤：<br />
（1）根据给定的输入从外部数据库检索相关信息。<br />
（2）根据融合技术将检索到的信息与输入或中间状态融合。<br />
（3）根据输入和相应的检索结果由生成器进行预测。</p>
<h2 id="检索器第三节">检索器（第三节）</h2>
<p><img src="/images/RAG/2.检索器处理流程.png" width="85%"></p>
<p>如图2展示了检索器的两个步骤：1.<strong>构建检索器</strong>。2.<strong>查询检索器</strong>。</p>
<p>1.<strong>构建检索器</strong>：涉及三个步骤（图2,a）：<br />
（1）<strong>语料分块</strong>：将输入的大文件，分块成小的文本块。<br />
（2）<strong>块编码</strong>：将文本块数字化为向量表示（embedding）。<br />
（3）<strong>向量数据库构建</strong>：包括<strong>ANN索引构建</strong>、<strong>kv对形式的数据存储</strong>。</p>
<p>1.<strong>语料分块</strong>：<br />
（1）<strong>用于索引的文本或embedding应该在语义上是独立的</strong>。注意，短文本易产生歧义，比如"苹果"可以指水果或公司。<br />
（2）编码整个文档（长文本）导致资源开销大。<strong>而处理短文本，可以加速编码过程、节省内存开销</strong>。<br />
（3）分块主要挑战在于，<strong>找到最佳的分块大小，在文本语义和编码效率之间做出权衡</strong>。<br />
2.<strong>决定分块大小时</strong>，主要考虑三个要点：<br />
（1）<strong>任务属性</strong>：<strong>不同的检索快有益于不同任务</strong>，比如问答任务更喜欢简短的短语，摘要任务可能喜欢长文档。<br />
（2）<strong>编码属性</strong>：<strong>不同的编码器对不同长度的文本效果有很大区别</strong>。例如，sentence-transformer
[125]中的模型在单个句子上表现更好，而 text-embedding-ada-002
[113]则擅长较长的文本。<br />
（3）<strong>查询属性</strong>：<strong>用户查询的长度应与分块大小保持一致</strong>。这隐式地将块中的上下文信息量与查询中的上下文信息量对齐，从而提高查询和检索之间的相关性。例如，基于短语构建的检索数据库对于长文档的查询可能毫无用处。<br />
3.<strong>基础的分块技术</strong>，主要有三种：<br />
（1）<strong>固定长度分块</strong>：使用长度超参数按顺序分割文档的最简单方法。<br />
（2）<strong>基于语义分块</strong>：根据语义来切割文档，例如代表句子结尾的字符或换行符。NLTK[112]和spaCy[33]提供了方便的句子切割方法。<br />
（3）<strong>基于内容的分块</strong>：根据独特的结构特征对文档进行分块。例如，电子病历可以轻松地根据小节进行分块，编程代码可以根据功能块进行分块。</p>
<p>1.<strong>块编码</strong>：指的是将文本块编码为向量表示（embedding）。这些embedding通常能捕获块的语义，使<strong>检索器</strong>能够<strong>基于内容相关性</strong>而<strong>不是仅是关键字匹配</strong>来执行相似性搜索。<br />
2.根据embedding的<strong>稀疏性</strong>，有两种编码方法：<br />
（1）<strong>稀疏编码（sparse
encoding）</strong>：稀疏编码创建的向量，大多数元素为零。此种编码<strong>无法捕捉更深层的语义含义</strong>。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">one-hot[<span class="number">50</span>]：向量维度为词表大小，句子中出现的单词，其对应的向量位，置<span class="number">1</span>。</span><br><span class="line">Bag of Words (BoW)[<span class="number">51</span>]：改进one-hot编码，使用词频代替零，但仍忽略了文档中语法和词序信息，专注统计信息，只能表达有限的语义。</span><br><span class="line">TF-IDF[<span class="number">120</span>]：除了计算词频，还根据单词在所有文档中的常见程度（逆文档频率）来调整结果，更倾向于强调描述文档内容的单词。</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>稠密编码（dense
encoding）</strong>：稠密编码创建的向量，每个维度都可以捕获一系列语义特征，并且大多数元素是非零浮点数。通常由DNN模型产生的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BERT及其变体：Bert[<span class="number">29</span>]是一种来自Transformers的双向编码器，典型的预训练模型，可以捕捉上下问信息，使用稠密向量表示语义信息。其他变体RoBERTa[<span class="number">99</span>]、DistilBERT[<span class="number">128</span>]、ELECTRA[<span class="number">19</span>]进一步改进了语义表示。</span><br><span class="line">孪生编码器（siamese encoder）：这是一种旨在学习输入之间相似性的神经网络，通常通过对比学习进行训练。</span><br><span class="line">    现有最先进的孪生编码器是DPR[<span class="number">79</span>]、SimCSE[<span class="number">40</span>]。</span><br><span class="line">基于LLM的编码器：LLMs在涵盖广泛主题的大数据上进行预训练，具有强大的语义理解能力。</span><br><span class="line">    典型的基于LLMs的编码器是text-embedding-ada-002[<span class="number">113</span>]、bge-embedding[<span class="number">156</span>]、mxbai-embedding[<span class="number">130</span>]。</span><br></pre></td></tr></table></figure></p>
<p>3.与稀疏编码相比，稠密编码利用深层神经网络，尤其是Transformer[140]来捕获更广泛的语言和语义信息。目前，此类编码广泛应用于大多数语义表示场景。</p>
<p>1.<strong>创建索引</strong>：<br />
创建索引的目的：加速处理query
embedding和表示知识的高维embedding之间的相似性搜索。<br />
向量数据库中的索引主要侧重于支持高效的近似近邻（ANN）搜索[32,47,77]，而不是插入、删除和更新等事务操作。<br />
索引的难点在于<strong>搜索质量</strong>和<strong>搜索效率</strong>之间取得良好的平衡。<br />
为解决这一难题，在算法和系统两方面都有各种具体的优化方案有待探索，包括相似度指标的选择、embeddings降维（DR）、高级ANN索引、系统级优化、硬件感知优化等。<br />
本文只讲<strong>明显影响</strong>，<strong>搜索质量</strong>和<strong>搜索效率</strong>的优化：<br />
（1）<strong>相似度指标的选择</strong>：相似性度量是检索器中的基本组件，它测量query
embedding和chunk
embedding之间的相关程度。相似性度量会影响搜索质量。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常见的相似度指标</span></span><br><span class="line">cosine similarity</span><br><span class="line">Euclidean similarity</span><br><span class="line">Manhattan distance</span><br><span class="line">Jaccard similarity</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>embeddings降维（DR）</strong>：降低embedding维度可以提高搜索效率，但存在损害语义表示的风险。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主成分分析（PCA，Principal Component Analysis）：它将原始数据转换到新的坐标系，同时保留最重要的特征。</span><br><span class="line">局部敏感哈希（LSH，Locality Sensitive Hashing）：它将数据映射到哈希桶中来降维，保留了和输入数据的相似性。</span><br><span class="line">乘积量化（PQ，Product Quantization）[<span class="number">68</span>]：将高维空间划分为更小的、独立量化的子空间，每个子空间都会创建一个由不同量化整数组成的编码本，以形成具有代表性的紧凑向量。</span><br><span class="line">最新的是一种名为AutoCompressor[<span class="number">17</span>]的新技术：通过将原始上下文压缩为语义上更短的嵌入来减少嵌入的维度。</span><br></pre></td></tr></table></figure></p>
<p>（3）<strong>高级ANN索引</strong>：ANN
索引通常是指用于组织和管理数据的方法或结构，以便优化近似最近邻搜索过程以提高检索质量和检索效率。本文将介绍几种先进的
ANN 索引技术。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The InVerted File system <span class="keyword">with</span> Product Quantization(IVFPQ)：首先对数据进行聚类，进行粗粒度划分；然后对每个聚类内的数据进行压缩，形成子向量，进行细粒度量化。</span><br><span class="line">    粗粒度聚类（IVF 组件）显著减少了搜索空间。</span><br><span class="line">    细粒度量化（PQ 组件）确保了较高的检索性能。</span><br><span class="line">The Hierarchical Navigable Small World (HNSW) ：使用分层图结构在高维空间中高效地执行 ANN 搜索。</span><br><span class="line">    将高向量视为节点，并将它们与其最近的邻居连接起来。</span><br><span class="line">    多层图结构是按概率确定的，以确保较高层的节点较少，从而实现高效搜索。</span><br><span class="line">tree-based Indexing：将高维向量组织成树状结构。例如KD 树 [<span class="number">123</span>]、Ball 树 [<span class="number">62</span>] 和 VP 树 [<span class="number">98</span>]。</span><br><span class="line">    典型的基于树的索引是近似最近邻ANN[<span class="number">135</span>]，它使用基于随机预测建立的树森林，将向量空间分离成多个超平面，以实现高效的ANN搜索。</span><br></pre></td></tr></table></figure></p>
<p>以上三种是<strong>明显影响</strong>，<strong>搜索质量</strong>和<strong>搜索效率</strong>的优化。</p>
<p>1.<strong>创建kv对形式的数据存储</strong>：向量数据使用专用的数据库存储，它将数据作为kv对集合进行存储和管理，其中k是高维embedding唯一标识符，v是特定领域的知识。<br />
2.由于数据存储中存储的数据量可能非常大，因此存储引擎（例如LMDB[100]或RocksDB[35]）应该能够高效检索和数据持久化。<br />
3.存储的关键在于，把什么样的数据作为v进行存储，这有助于后续的生成过程。比如，问答任务中，可以把问题embedding作为k，问题对作为v进行存储。<br />
5.最近的工作提出了各种最先进的向量数据库，包括索引和数据存储，例如Milvus[46,143]、FAISS[32,77]、LlamaIndex[95]等。</p>
<p>1.<strong>创建检索器的伪代码</strong>：<br />
<img src="/images/RAG/3.创建检索器伪代码.png" width="55%"></p>
<p>2.第2~9行展示了将多个文档分块、编码的过程。<br />
3.第6行将当前块和下一个块concatenate在一起作为v值存储，注意，不同任务v值得选择会有所不同。<br />
4.实际任务中，所有kv值的内存消耗可能超过服务器内存容量，因此建议将kv持久化到磁盘上，以减少内存消耗。</p>
<hr />
<p>1.<strong>查询检索器</strong>（图2,b）：如何查询预构建的检索器，三个步骤：<br />
（1）<strong>编码查询</strong>：将输入的query编码为向量表示（embedding）。<br />
（2）<strong>ANN搜索</strong>：利用预先构建index，使用近似搜索算法，找到与query相似的key，然后获取对应的value。<br />
（3）<strong>后处理</strong>：对检索到的value重新排序（reorder）。</p>
<p>1.<strong>编码查询</strong>：为了与预先构建index的embedding空间一致，使用相同的编码器对query进行编码。</p>
<p>1.<strong>ANN搜索</strong>：具体指搜索预先构建的index，找到前k个最近邻的key。<br />
2.最近邻搜索取决于使用的索引算法和结构：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以IVFPQ为例，搜索过程：</span></span><br><span class="line">首先将query embedding与粗粒度的聚类embedding进行比较，并选择几个候选聚类进行进一步搜索。</span><br><span class="line">然后在每个候选聚类内，对query embedding执行相同的乘积量化，并根据距离找到前 k 个最近邻。</span><br><span class="line">最后合并所有最近邻候选者，并对最终的前 k 个最近邻的所有候选者重新排序。</span><br></pre></td></tr></table></figure></p>
<p>3.根据找到k个最近邻的key，从向量数据库中取对应的value。</p>
<p>1.<strong>后处理</strong>：根据特定任务目标细化、增强、调整检索结果。一些经典的后处理技术：<br />
<strong>重排（rerank）</strong>：根据任务特定的目标，对检索到的知识进行重新排序。直观理解是，基于和任务无关的指标，对知识进行排序，比如欧式距离。现有的重新排序方法[18、56、85、141]大多设计不同的架构或策略来对检索到的知识进行重新排序。</p>
<p>1.<strong>查询检索器的伪代码</strong>：<br />
<img src="/images/RAG/4.查询检索器伪代码.png" width="55%"></p>
<p>2.第1行：将query编码为向量表示。<br />
3.第2行：执行最近邻搜索ANN，使用预先构建的index，找到前k个最近邻的key。<br />
4.第3行：根据找到的key，从向量数据库中取对应的value。<br />
5.第4行：对检索到的value进行后处理，比如重排。</p>
<h2 id="检索融合第4节">检索融合（第4节）</h2>
<p>1.<strong>检索融合（Retrieval
Fusions</strong>）：指得是如何有效的利用检索到的知识，以提高生成器（generator）的性能。<br />
2.基本上检索融合分为前面介绍的三类：query-based fusions, logits-based
fusions, latent fusions。<br />
<img src="/images/RAG/5.检索融合分类.png" width="75%"></p>
<p>3.图3展示了检索融合的分类和每个类别下的代表性方法。</p>
<p>1.<strong>Query-based
fusions</strong>：这是最简单直接的一种融合方式，它将检索到的信息与输入查询信息相集成来生成响应。<br />
根据连接信息的方式，分为两个类别：text concatenation、feature
concatenation。<br />
（1）<strong>text
concatenation</strong>：涉及检索结果与原始文本合并，使其特别适合GPT-4等当代LLM。这些模型充当黑盒系统，交互能力有限，通常只向用户提供API接口。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当前的研究工作[<span class="number">49</span>,<span class="number">87</span>,<span class="number">122</span>]直接将输入与检索最多的句子/文档连接起来以形成生成器的查询语句。</span><br><span class="line">为了更好的利用LLMs上下文学习能力，一些研究工作[<span class="number">34</span>,<span class="number">90</span>,<span class="number">141</span>,<span class="number">145</span>]设计了有效的prompt templates来整合输入和检索的信息。</span><br><span class="line">为了解决拼接检索信息导致输入过长的问题，最近的一些研究[<span class="number">5</span>,<span class="number">96</span>,<span class="number">101</span>,<span class="number">150</span>,<span class="number">159</span>]提出了在检索知识结果的基础上，为每个结果中的元素分配重要性权重，并基于此权重，过滤弱相关的检索结果。</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>feature
concatenation</strong>：涉及编码检索结果与编码输入合并。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">简单的方法是FID[<span class="number">66</span>]，首先将检索结果们编码到稀疏/稠密空间，然后将编码检索结果和编码输入concat，作为输入给生成器。FID在sota最先进性能表现证明了feature concatenation的有效性。</span><br><span class="line">后续工作[<span class="number">25</span>,<span class="number">48</span>,<span class="number">67</span>,<span class="number">97</span>,<span class="number">127</span>]通过联合调整检索器和编码器进一步改进了FID，这可以增强检索到的知识的表示。</span><br><span class="line">此外，[<span class="number">14</span>]将相关知识的表示连接起来作为prompt learning的演示，从而产生更好的泛化能力。</span><br></pre></td></tr></table></figure></p>
<p>2.如算法4.1所示，query-based fusions的伪代码：<br />
<img src="/images/RAG/6.query_base_fusions.png" width="55%"><br />
（1）对于使用text
concatenation的[49,122]：首先将检索结果和输入concat起来（第2行），然后将concat结果输入到生成器（第3行）。注意，目前LLMs对输入长度有限制，太多的检索结果concat后会导致输入过长而被LLMs截断。因此，<strong>设计prompt
template是text concatenation一个关键步骤</strong>。<br />
（2）对于使用feature
concatenation的[48,66]：首先将检索结果和输入进行编码得到特征（第5行），然后将检索结果和输入特征concat（第6行），作为输入给生成器（第7行）。由于序列长度过长，导致产生较高的内存成本。</p>
<p>1.<strong>Logits-based
Fusion</strong>：指的是将检索到的知识整合到输出层，基本上，检索到的知识被输入到同一模型中以获得用于增强或校准的logits。因此，logits的融合可以分为两个分支，即<strong>ensemble-based
fusion</strong>（基于集成的融合）和<strong>calibration-based
fusion</strong>（基于校准的融合）。<br />
（1）<strong>ensemble-based
fusion</strong>：将检索到的知识中的逻辑视为预测集成的一部分。这种基于集成的融合可以显着提高模型的泛化性和鲁棒性[80,81,158]。基于集成的融合的一项值得注意的工作是
kNN-LM [81]，它聚合了最邻近目标的 logits，然后对最终预测进行插值。与
kNN-LM 类似[80]提出 kNN-MT 使用检索的 logits
来增强机器翻译，这也是后续工作的一个分支 [64,172]。<br />
（2）<strong>calibration-based
fusion</strong>：使用检索到的知识中的逻辑作为模型预测的校准形式。[72]提出了一种置信度增强的kNN-MT，它利用神经机器翻译置信度来细化kNN分布和插值权重。[89]建议利用源上下文来校准检索增强神经机器翻译。<br />
2.如算法4.2所示，logits-based fusions的伪代码：<br />
<img src="/images/RAG/7.logits_base_funsions.png" width="55%"><br />
（1）先将检索到的相似结果、query输入到生成器中，得到临时生成结果（2-4行）。对于ensemble融合，利用超参数
<span class="math inline">\(\lambda\)</span> 融合检索logits和query
logits（第6行）。<br />
（2）对于calibration融合，动态调整超参数 <span
class="math inline">\(\lambda\)</span> 来融合检索logits和query
logits（第7行）。</p>
<p>1.<strong>Latent
Funsion</strong>：将检索到的知识合并到生成器的隐状态中，以获得更好的生成。根据引入方法，可以分为两类：<strong>attention-based</strong>（基于注意力）
和 <strong>weighted-addition</strong>（基于权重）。<br />
（1）<strong>attention-based</strong>：基于注意力的融合方式，一个重要成果是增强型变压器（RETRO）。RETRO
引入了新的交叉注意力模块，将检索到的知识直接集成到模型的隐状态中。这项研究的一个重要发现是展示了检索数据库的缩放规律，其中
RETRO 拥有2万亿个token数据库，其中性能和GPT-3相当。在 RETRO 中自定义
Transformer 模型凸显了预训练、检索增强架构在提高 LLM
效率和可扩展性方面的潜力。除了 RETRO 之外，其他研究
[12、26、93、151、154]
通过利用新的注意力模块引入外部知识。[93]通过将上下文编码与模型推理解耦来扩展
RETRO
模型。[154,147]将隐注意力keys和values存储到外部存储器中，并使用注意机制从存储器中检索知识。<br />
（2）<strong>weighted-addition</strong>：由于注意力机制的高度复杂性，另一个工作分支采用轻量级（加权）添加来引入检索到的知识。
[38]提出了 EAE
模型，该模型从可学习的外部存储器中检索top-k最相关的实体的embedding，并将实体的embedding加入到模型的隐状态中。[153]提出了ReFusion，它探索了各种可学习的重新排序方案，首先对检索到的知识的embedding进行重新加权，然后使用加权加法将它们合并到模型的隐状态中。<br />
2.如算法4.3所示，latent fusions的伪代码：<br />
<img src="/images/RAG/8.latent_funsions.png" width="55%"><br />
（1）首先使用上一个模块FFN module的输出输入到当前attention
module，计算得到attention隐状态（第4行），然后使用encoder对attention隐状态+检索到的embedding进行编码（第5行），之后使用cross-attention
module将编码后的检索embedding+attention隐状态进行融合（第6行），最后将融合后的结果输入到FFN
module（第7行）。<br />
（2）基于加权方式，是先对检索到的embedding进行编码（第11行）好处是可以离线完成并存储下来，再使用上一个模块FFN
module的输出输入到当前attention
module，计算得到attention隐状态（第14行），然后使用一组权重，将编码后的检索embedding+attention隐状态进行融合（第15行），最后将融合后的结果输入到FFN
module（第16行）。</p>
<h2 id="生成器第5节">生成器（第5节）</h2>
<h1
id="retrieval-augmented-generation-for-ai-generated-content-a-survey">Retrieval-Augmented
Generation for AI-Generated Content: A Survey</h1>
<h2 id="摘要-1">摘要</h2>
<h1 id="参考文献">参考文献</h1>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzI0MDcuMTMxOTM=">Retrieval-Augmented
Generation for Natural Language Processing: A Survey<i class="fa fa-external-link-alt"></i></span><br />
<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzI0MDIuMTk0NzM=">Retrieval-Augmented
Generation for AI-Generated Content: A Survey<i class="fa fa-external-link-alt"></i></span><br />
<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2h5bWllMTIyL1JBRy1TdXJ2ZXk=">Retrieval-Augmented
Generation for AI-Generated Content: A Survey参考文献整理<i class="fa fa-external-link-alt"></i></span></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>SoundMemories
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/" title="Retrieval-Augmented Generation Survey">https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented Generation Survey/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Paper/" rel="tag"><i class="fa fa-tag"></i> Paper</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/04/05/Web/04.Vue/" rel="prev" title="Vue">
                  <i class="fa fa-chevron-left"></i> Vue
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/10/09/Python/23.FastAPI/" rel="next" title="FastAPI">
                  FastAPI <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">SoundMemories</span>
  </div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"neutral"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js","integrity":"sha256-JFptYy4KzJ5OQP+Q9fubNf3cxpPPmZKqUOovyEONKrQ="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
