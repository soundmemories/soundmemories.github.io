<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.17.1","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Retrieval-Augmented Generation for Natural Language Processing: A Survey 摘要 1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识。 2.检索增强生成（RAG，Retrieval-Augment">
<meta property="og:type" content="article">
<meta property="og:title" content="Retrieval-Augmented Generation Survey">
<meta property="og:url" content="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="Retrieval-Augmented Generation for Natural Language Processing: A Survey 摘要 1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识。 2.检索增强生成（RAG，Retrieval-Augment">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/1.RAG%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0%E5%9B%BE.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/2.%E6%A3%80%E7%B4%A2%E5%99%A8%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/3.%E5%88%9B%E5%BB%BA%E6%A3%80%E7%B4%A2%E5%99%A8%E4%BC%AA%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/4.%E6%9F%A5%E8%AF%A2%E6%A3%80%E7%B4%A2%E5%99%A8%E4%BC%AA%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/5.%E6%A3%80%E7%B4%A2%E8%9E%8D%E5%90%88%E5%88%86%E7%B1%BB.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/6.query_base_fusions.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/7.logits_base_funsions.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/8.latent_funsions.png">
<meta property="og:image" content="https://soundmemories.github.io/images/RAG/9.RAG%E8%AE%AD%E7%BB%83.png">
<meta property="article:published_time" content="2024-07-17T16:00:00.000Z">
<meta property="article:modified_time" content="2024-12-26T08:06:02.619Z">
<meta property="article:author" content="SoundMemories">
<meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soundmemories.github.io/images/RAG/1.RAG%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0%E5%9B%BE.png">


<link rel="canonical" href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":"","permalink":"https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/","path":"2024/07/18/Paper/04.Retrieval-Augmented Generation Survey/","title":"Retrieval-Augmented Generation Survey"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Retrieval-Augmented Generation Survey | SoundMemories</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SoundMemories</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">10</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">10</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">129</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#retrieval-augmented-generation-for-natural-language-processing-a-survey"><span class="nav-number">1.</span> <span class="nav-text">Retrieval-Augmented
Generation for Natural Language Processing: A Survey</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0-%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E7%AC%AC2%E8%8A%82"><span class="nav-number">1.3.</span> <span class="nav-text">概述-检索,增强,生成（第2节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="nav-number">1.3.1.</span> <span class="nav-text">检索器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E8%9E%8D%E5%90%88"><span class="nav-number">1.3.2.</span> <span class="nav-text">检索融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%99%A8"><span class="nav-number">1.3.3.</span> <span class="nav-text">生成器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E5%99%A8%E7%AC%AC3%E8%8A%82"><span class="nav-number">1.4.</span> <span class="nav-text">检索器（第3节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="nav-number">1.4.1.</span> <span class="nav-text">构建检索器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="nav-number">1.4.2.</span> <span class="nav-text">查询检索器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E8%9E%8D%E5%90%88%E7%AC%AC4%E8%8A%82"><span class="nav-number">1.5.</span> <span class="nav-text">检索融合（第4节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%9F%A5%E8%AF%A2%E7%9A%84%E8%9E%8D%E5%90%88"><span class="nav-number">1.5.1.</span> <span class="nav-text">基于查询的融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%95%B0%E7%9A%84%E8%9E%8D%E5%90%88"><span class="nav-number">1.5.2.</span> <span class="nav-text">基于对数的融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BD%9C%E5%9C%A8%E8%9E%8D%E5%90%88"><span class="nav-number">1.5.3.</span> <span class="nav-text">潜在融合</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%99%A8%E7%AC%AC5%E8%8A%82"><span class="nav-number">1.6.</span> <span class="nav-text">生成器（第5节）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rag%E8%AE%AD%E7%BB%83%E7%AC%AC6%E8%8A%82"><span class="nav-number">1.7.</span> <span class="nav-text">RAG训练（第6节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9B%B4%E6%96%B0%E7%9A%84rag"><span class="nav-number">1.7.1.</span> <span class="nav-text">无数据存储更新的RAG</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%89%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9B%B4%E6%96%B0%E7%9A%84rag"><span class="nav-number">1.7.2.</span> <span class="nav-text">有数据存储更新的RAG</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rag%E7%BB%8F%E5%85%B8%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%BD%B1%E5%93%8D%E7%AC%AC7%E8%8A%82"><span class="nav-number">1.8.</span> <span class="nav-text">RAG经典任务的影响（第7节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.8.1.</span> <span class="nav-text">语言模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="nav-number">1.8.2.</span> <span class="nav-text">机器翻译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81"><span class="nav-number">1.8.3.</span> <span class="nav-text">文本摘要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.8.4.</span> <span class="nav-text">问答系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96"><span class="nav-number">1.8.5.</span> <span class="nav-text">信息提取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="nav-number">1.8.6.</span> <span class="nav-text">文本分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.8.7.</span> <span class="nav-text">对话系统</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E7%AC%AC8%E8%8A%82"><span class="nav-number">1.9.</span> <span class="nav-text">实际应用（第8节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Ellm%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93"><span class="nav-number">1.9.1.</span> <span class="nav-text">基于LLM的智能体</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A1%86%E6%9E%B6"><span class="nav-number">1.9.2.</span> <span class="nav-text">框架</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A8%E8%AE%BA%E5%92%8C%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91%E7%AC%AC9%E8%8A%82"><span class="nav-number">1.10.</span> <span class="nav-text">讨论和未来方向（第9节）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E8%B4%A8%E9%87%8F"><span class="nav-number">1.10.1.</span> <span class="nav-text">检索质量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rag%E6%95%88%E7%8E%87"><span class="nav-number">1.10.2.</span> <span class="nav-text">RAG效率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%9E%8D%E5%90%88%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-number">1.10.3.</span> <span class="nav-text">融合的选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rag%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="nav-number">1.10.4.</span> <span class="nav-text">RAG的训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%A8%E6%A8%A1%E6%80%81%E6%A3%80%E7%B4%A2"><span class="nav-number">1.10.5.</span> <span class="nav-text">跨模态检索</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA"><span class="nav-number">1.11.</span> <span class="nav-text">结论</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#retrieval-augmented-generation-for-ai-generated-content-a-survey"><span class="nav-number">2.</span> <span class="nav-text">Retrieval-Augmented
Generation for AI-Generated Content: A Survey</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81-1"><span class="nav-number">2.1.</span> <span class="nav-text">摘要</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">3.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="/images/avstar.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">129</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avstar.png">
      <meta itemprop="name" content="SoundMemories">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Retrieval-Augmented Generation Survey | SoundMemories">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Retrieval-Augmented Generation Survey
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2024-07-18T00:00:00+08:00">2024-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>51 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1
id="retrieval-augmented-generation-for-natural-language-processing-a-survey">Retrieval-Augmented
Generation for Natural Language Processing: A Survey</h1>
<h2 id="摘要">摘要</h2>
<p>1.大语言模型（LLMs）的成功，得益于存储知识的巨大参数量，然而LLMs仍然面临几个关键问题，比如<strong>幻觉问题（hallucination）、知识更新问题、缺乏特定领域的专业知识</strong>。<br />
2.检索增强生成（RAG，Retrieval-Augmented
Generation）<strong>利用外部知识数据库来增强LLMs</strong>，弥补了LLMs的这些缺点。<br />
3.本文回顾了RAG的所有<strong>重要技术</strong>，特别时在<strong>检索器（retriever）</strong>、<strong>检索融合（retrieval
fusions）</strong>方面。<br />
4.此外，还<strong>提供</strong>了实现<strong>RAG中代表性技术</strong>的教程<strong>代码</strong>。<br />
5.进一步讨论了RAG训练，包括在<strong>有无数据仓库更新</strong>的情况下RAG的效果。<br />
6.介绍了RAG在<strong>代表性NLP任务</strong>、<strong>工业场景</strong>中的应用。<br />
7.讨论了RAG的<strong>未来方向和挑战</strong>，以促进其发展。</p>
<h2 id="介绍">介绍</h2>
<p>1.大语言模型（LLMs）通常是在<strong>大量的自然语言语料库上进行预训练</strong>的，然后<strong>在特定的下游任务的数据集上进行微调</strong>。LLMs的成功可以解释为语言模型作为知识库，在<strong>参数中隐含地存储了从训练数据集中学到的知识</strong>，作为内部记忆，并通过从记忆中检索答案来生成响应。<br />
2.目前为了存储更多的知识以获得更好的生成性能，现有的方法<strong>通常通过增加参数的体积来扩大存储容量</strong>，从而记忆更多的知识。</p>
<p>1.尽管LLMs已经展示出巨大能力，但仍有几个问题阻碍了LLMs的发展：<br />
（1）最突出的问题是<strong>幻觉问题</strong>，它指定是<strong>LLMs倾向于生成连贯、流畅但事实错误的响应</strong>。<br />
（2）另一个巨大挑战是<strong>知识更新问题</strong>，它指定是<strong>LLMs内部知识的更新，那么这就需要重新/微调LLMs，这就需要花费大量money</strong>。<br />
（3）另一个挑战是<strong>LLMs缺乏特定领域的专业知识</strong>，如果训练一个特定领域的LLMs，这就<strong>需要耗费大量人力来收集这些特定领域的数据</strong>。</p>
<p>1.为了<strong>应对这些问题和挑战</strong>，最近的研究<strong>建议利用外部知识数据库来增强LLMs，这就是RAG</strong>。<br />
（1）RAG通过<strong>从外部数据库检索的相关事实信息</strong>，可以在<strong>一定程度上缓解幻觉问题</strong>。<br />
（2）<strong>知识更新问题</strong>，可以通过<strong>更新外部数据库的知识信息</strong>，从而<strong>增强LLMs的知识实时性</strong>。<br />
（3）RAG通过<strong>构建和利用特定领域知识数据库</strong>，将<strong>通用LLMs扩展到特定领域</strong>，从而<strong>增强LLMs的特定领域专业知识</strong>。</p>
<p>1.本文回顾了涉及RAG涉及的所有技术，尽管已经由很多篇调查论文，但本文仍然提供了一些关键见解：<br />
（1）本文<strong>系统介绍了RAG的各个组成部分</strong>，包括<strong>检索器从构建到查询的细节</strong>，以及<strong>检索融合的指导性代码</strong>。<br />
（2）本文<strong>展示了不同的RAG训练策略</strong>，包括<strong>有/没有数据存储更新</strong>的RAG。<br />
（3）本文进一步讨论了<strong>RAG在下游NLP任务</strong>和<strong>实际NLP场景</strong>中的应用。<br />
（4）本文最终确定了<strong>未来有希望的探索方向</strong>和<strong>需要解决的主要挑战</strong>。</p>
<p>1.文章结构：<br />
（1）第二节给出了<strong>RAG概述</strong>。<br />
（2）第三、四节介绍了<strong>检索器</strong>和<strong>检索融合</strong>中使用的所有技术细节。<br />
（3）第五节介绍了<strong>生成器</strong>。<br />
（4）第六节介绍了<strong>如何训练有/没有数据存储更新的RAG</strong>。<br />
（7）第七节介绍了<strong>代表性的NLP任务中使用的技术</strong>。<br />
（8）第八节展示了<strong>RAG在实际NLP场景中的应用</strong>。<br />
（9）第九节讨论<strong>RAG的未来方向</strong>。<br />
（10）第十节对本文做出了<strong>最终结论</strong>。</p>
<h2 id="概述-检索增强生成第2节">概述-检索,增强,生成（第2节）</h2>
<p>RAG技术应用在NLP任务处理概述：<br />
<img src="/images/RAG/1.RAG处理流程概述图.png" width="75%"></p>
<p>如图1所示，RAG主要包含三个模块：<strong>检索器（Retriever）、检索融合（Retrieval
Fusions）、生成器（Generator）</strong>。</p>
<h3 id="检索器">检索器</h3>
<p>1.<strong>检索器（Retriever）</strong>：主要包含三个部分：<br />
（1）<strong>编码器（encoder）</strong>：encoder将inputs编码为embeddings。<br />
（2）<strong>索引（index）</strong>：用来支持近似最近邻高效搜索的索引。<br />
（3）<strong>数据存储（datastore）</strong>：kv对形式存储外部知识的数据库。<br />
2.检索器主要挑战在于<strong>检索效率和检索质量之间，找到最佳的权衡</strong>。<br />
3.<strong>检索效率</strong>：指获取相关信息的速度有多快，这涉及到<strong>加速编码、高效索引、在数据库中批量查询等</strong>。<br />
4.<strong>检索质量</strong>：指的是信息的关联性如何，这涉及到<strong>块表示学习、高级近似近邻搜索算法等</strong>。</p>
<h3 id="检索融合">检索融合</h3>
<p>1.<strong>检索融合（Retrieval
Fusions）</strong>：利用检索信息来增强生成。<br />
2.<strong>融合技术</strong>，主要包含三种：<br />
（1）<strong>基于查询的融合（Query-based
Fusion）</strong>：在将检索信息输入生成器之前增强输入。<br />
（2）<strong>基于逻辑的融合（Logits-based
Fusion）</strong>：侧重于生成器的输出逻辑，并融合检索的逻辑以获得更稳健的逻辑输出。<br />
（3）<strong>潜在融合（Latent
Fusion）</strong>：将检索表示引入生成器的潜在表示中，从而隐式地提高模型的性能。</p>
<h3 id="生成器">生成器</h3>
<p>1.<strong>生成器（Generator）</strong>：生成器模块可以分为两个分支:<br />
（1）<strong>默认生成器</strong>：预训练/微调的LLMs，如GPT系列、Gemini系列。<br />
（2）<strong>检索增强(RA)生成器</strong>：预训练/微调生成器，融合了检索模块，比如RETRO、ENCDEC。潜在融合使用的时RA生成器。<br />
2.<strong>RAG的工作流程</strong>包括三个步骤：<br />
（1）根据给定的输入从外部数据库检索相关信息。<br />
（2）根据融合技术将检索到的信息与输入或中间状态融合。<br />
（3）根据输入和相应的检索结果由生成器进行预测。</p>
<h2 id="检索器第3节">检索器（第3节）</h2>
<p><img src="/images/RAG/2.检索器处理流程.png" width="85%"></p>
<p>如图2展示了检索器的两个步骤：1.<strong>构建检索器</strong>。2.<strong>查询检索器</strong>。</p>
<h3 id="构建检索器">构建检索器</h3>
<p>1.<strong>构建检索器</strong>：涉及三个步骤（图2,a）：<br />
（1）<strong>语料分块</strong>：将输入的大文件，分块成小的文本块。<br />
（2）<strong>块编码</strong>：将文本块数字化为向量表示（embedding）。<br />
（3）<strong>向量数据库构建</strong>：包括<strong>ANN索引构建</strong>、<strong>kv对形式的数据存储</strong>。</p>
<p>1.<strong>语料分块</strong>：<br />
（1）<strong>用于索引的文本或embedding应该在语义上是独立的</strong>。注意，短文本易产生歧义，比如"苹果"可以指水果或公司。<br />
（2）编码整个文档（长文本）导致资源开销大。<strong>而处理短文本，可以加速编码过程、节省内存开销</strong>。<br />
（3）分块主要挑战在于，<strong>找到最佳的分块大小，在文本语义和编码效率之间做出权衡</strong>。<br />
2.<strong>决定分块大小时</strong>，主要考虑三个要点：<br />
（1）<strong>任务属性</strong>：<strong>不同的检索快有益于不同任务</strong>，比如问答任务更喜欢简短的短语，摘要任务可能喜欢长文档。<br />
（2）<strong>编码属性</strong>：<strong>不同的编码器对不同长度的文本效果有很大区别</strong>。例如，sentence-transformer
[125]中的模型在单个句子上表现更好，而 text-embedding-ada-002
[113]则擅长较长的文本。<br />
（3）<strong>查询属性</strong>：<strong>用户查询的长度应与分块大小保持一致</strong>。这隐式地将块中的上下文信息量与查询中的上下文信息量对齐，从而提高查询和检索之间的相关性。例如，基于短语构建的检索数据库对于长文档的查询可能毫无用处。<br />
3.<strong>基础的分块技术</strong>，主要有三种：<br />
（1）<strong>固定长度分块</strong>：使用长度超参数按顺序分割文档的最简单方法。<br />
（2）<strong>基于语义分块</strong>：根据语义来切割文档，例如代表句子结尾的字符或换行符。NLTK[112]和spaCy[33]提供了方便的句子切割方法。<br />
（3）<strong>基于内容的分块</strong>：根据独特的结构特征对文档进行分块。例如，电子病历可以轻松地根据小节进行分块，编程代码可以根据功能块进行分块。</p>
<p>1.<strong>块编码</strong>：指的是将文本块编码为向量表示（embedding）。这些embedding通常能捕获块的语义，使<strong>检索器</strong>能够<strong>基于内容相关性</strong>而<strong>不是仅是关键字匹配</strong>来执行相似性搜索。<br />
2.<strong>根据embedding的稀疏性，有两种编码方法</strong>：<br />
（1）<strong>稀疏编码（sparse
encoding）</strong>：稀疏编码创建的向量，大多数元素为零。此种编码<strong>无法捕捉更深层的语义含义</strong>。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">one-hot[<span class="number">50</span>]：向量维度为词表大小，句子中出现的单词，其对应的向量位，置<span class="number">1</span>。</span><br><span class="line">Bag of Words (BoW)[<span class="number">51</span>]：改进one-hot编码，使用词频代替零，但仍忽略了文档中语法和词序信息，专注统计信息，只能表达有限的语义。</span><br><span class="line">TF-IDF[<span class="number">120</span>]：除了计算词频，还根据单词在所有文档中的常见程度（逆文档频率）来调整结果，更倾向于强调描述文档内容的单词。</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>稠密编码（dense
encoding）</strong>：稠密编码创建的向量，每个维度都可以捕获一系列语义特征，并且大多数元素是非零浮点数。通常由DNN模型产生的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BERT及其变体：Bert[<span class="number">29</span>]是一种来自Transformers的双向编码器，典型的预训练模型，可以捕捉上下问信息，使用稠密向量表示语义信息。其他变体RoBERTa[<span class="number">99</span>]、DistilBERT[<span class="number">128</span>]、ELECTRA[<span class="number">19</span>]进一步改进了语义表示。</span><br><span class="line">孪生编码器（siamese encoder）：这是一种旨在学习输入之间相似性的神经网络，通常通过对比学习进行训练。</span><br><span class="line">    现有最先进的孪生编码器是DPR[<span class="number">79</span>]、SimCSE[<span class="number">40</span>]。</span><br><span class="line">基于LLM的编码器：LLMs在涵盖广泛主题的大数据上进行预训练，具有强大的语义理解能力。</span><br><span class="line">    典型的基于LLMs的编码器是text-embedding-ada-002[<span class="number">113</span>]、bge-embedding[<span class="number">156</span>]、mxbai-embedding[<span class="number">130</span>]。</span><br></pre></td></tr></table></figure></p>
<p>3.与稀疏编码相比，稠密编码利用深层神经网络，尤其是Transformer[140]来捕获更广泛的语言和语义信息。目前，此类编码广泛应用于大多数语义表示场景。</p>
<p>1.<strong>创建索引</strong>：<br />
创建索引的目的：<strong>加速处理query
embedding和表示知识的高维embedding之间的相似性搜索</strong>。<br />
向量数据库中的索引主要侧重于支持高效的近似近邻（ANN）搜索[32,47,77]，而不是插入、删除和更新等事务操作。<br />
索引的难点在于<strong>搜索质量</strong>和<strong>搜索效率</strong>之间取得良好的平衡。<br />
为解决这一难题，在算法和系统两方面都有各种具体的优化方案有待探索，包括相似度指标的选择、embeddings降维（DR）、高级ANN索引、系统级优化、硬件感知优化等。<br />
本文只讲<strong>明显影响</strong>，<strong>搜索质量</strong>和<strong>搜索效率</strong>的优化：<br />
（1）<strong>相似度指标的选择</strong>：相似性度量是检索器中的基本组件，它测量query
embedding和chunk
embedding之间的相关程度。相似性度量会影响搜索质量。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常见的相似度指标</span></span><br><span class="line">cosine similarity</span><br><span class="line">Euclidean similarity</span><br><span class="line">Manhattan distance</span><br><span class="line">Jaccard similarity</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>embeddings降维（DR）</strong>：降低embedding维度可以提高搜索效率，但存在损害语义表示的风险。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主成分分析（PCA，Principal Component Analysis）：它将原始数据转换到新的坐标系，同时保留最重要的特征。</span><br><span class="line">局部敏感哈希（LSH，Locality Sensitive Hashing）：它将数据映射到哈希桶中来降维，保留了和输入数据的相似性。</span><br><span class="line">乘积量化（PQ，Product Quantization）[<span class="number">68</span>]：将高维空间划分为更小的、独立量化的子空间，每个子空间都会创建一个由不同量化整数组成的编码本，以形成具有代表性的紧凑向量。</span><br><span class="line">最新的是一种名为AutoCompressor[<span class="number">17</span>]的新技术：通过将原始上下文压缩为语义上更短的嵌入来减少嵌入的维度。</span><br></pre></td></tr></table></figure></p>
<p>（3）<strong>高级ANN索引</strong>：ANN
索引通常是指用于组织和管理数据的方法或结构，以便优化近似最近邻搜索过程以提高检索质量和检索效率。本文将介绍几种先进的
ANN 索引技术。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The InVerted File system <span class="keyword">with</span> Product Quantization(IVFPQ)：首先对数据进行聚类，进行粗粒度划分；然后对每个聚类内的数据进行压缩，形成子向量，进行细粒度量化。</span><br><span class="line">    粗粒度聚类（IVF 组件）显著减少了搜索空间。</span><br><span class="line">    细粒度量化（PQ 组件）确保了较高的检索性能。</span><br><span class="line">The Hierarchical Navigable Small World (HNSW) ：使用分层图结构在高维空间中高效地执行 ANN 搜索。</span><br><span class="line">    将高向量视为节点，并将它们与其最近的邻居连接起来。</span><br><span class="line">    多层图结构是按概率确定的，以确保较高层的节点较少，从而实现高效搜索。</span><br><span class="line">tree-based Indexing：将高维向量组织成树状结构。例如KD 树 [<span class="number">123</span>]、Ball 树 [<span class="number">62</span>] 和 VP 树 [<span class="number">98</span>]。</span><br><span class="line">    典型的基于树的索引是近似最近邻ANN[<span class="number">135</span>]，它使用基于随机预测建立的树森林，将向量空间分离成多个超平面，以实现高效的ANN搜索。</span><br></pre></td></tr></table></figure></p>
<p>以上三种是<strong>明显影响</strong>，<strong>搜索质量</strong>和<strong>搜索效率</strong>的优化。</p>
<p>1.<strong>创建kv对形式的数据存储</strong>：向量数据使用专用的数据库存储，它将数据作为kv对集合进行存储和管理，其中k是高维embedding唯一标识符，v是特定领域的知识。<br />
2.由于数据存储中存储的数据量可能非常大，因此存储引擎（例如LMDB[100]或RocksDB[35]）应该能够高效检索和数据持久化。<br />
3.存储的关键在于，把什么样的数据作为v进行存储，这有助于后续的生成过程。比如，问答任务中，可以把问题embedding作为k，问题对作为v进行存储。<br />
5.最近的工作提出了各种最先进的向量数据库，包括索引和数据存储，例如Milvus[46,143]、FAISS[32,77]、LlamaIndex[95]等。</p>
<p>1.<strong>创建检索器的伪代码</strong>：<br />
<img src="/images/RAG/3.创建检索器伪代码.png" width="55%"></p>
<p>2.第2~9行展示了将多个文档分块、编码的过程。<br />
3.第6行将当前块和下一个块concatenate在一起作为v值存储，注意，不同任务v值得选择会有所不同。<br />
4.实际任务中，所有kv值的内存消耗可能超过服务器内存容量，因此建议将kv持久化到磁盘上，以减少内存消耗。</p>
<h3 id="查询检索器">查询检索器</h3>
<p>1.<strong>查询检索器</strong>（图2,b）：如何查询预构建的检索器，三个步骤：<br />
（1）<strong>编码查询</strong>：将输入的query编码为向量表示（embedding）。<br />
（2）<strong>ANN搜索</strong>：利用预先构建index，使用近似搜索算法，找到与query相似的key，然后获取对应的value。<br />
（3）<strong>后处理</strong>：对检索到的value重新排序（reorder）。</p>
<p>1.<strong>编码查询</strong>：为了与预先构建index的embedding空间一致，使用相同的编码器对query进行编码。</p>
<p>1.<strong>ANN搜索</strong>：具体指搜索预先构建的index，找到前k个最近邻的key。<br />
2.<strong>最近邻搜索取决于使用的索引算法和结构</strong>：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以IVFPQ为例，搜索过程：</span></span><br><span class="line">首先将query embedding与粗粒度的聚类embedding进行比较，并选择几个候选聚类进行进一步搜索。</span><br><span class="line">然后在每个候选聚类内，对query embedding执行相同的乘积量化，并根据距离找到前 k 个最近邻。</span><br><span class="line">最后合并所有最近邻候选者，并对最终的前 k 个最近邻的所有候选者重新排序。</span><br></pre></td></tr></table></figure></p>
<p>3.<strong>根据找到k个最近邻的key，从向量数据库中取对应的value</strong>。</p>
<p>1.<strong>后处理</strong>：根据特定任务目标细化、增强、调整检索结果。一些经典的后处理技术：<br />
<strong>重排（rerank）</strong>：根据任务特定的目标，对检索到的知识进行重新排序。直观理解是，基于和任务无关的指标，对知识进行排序，比如欧式距离。现有的重新排序方法[18、56、85、141]大多设计不同的架构或策略来对检索到的知识进行重新排序。</p>
<p>1.<strong>查询检索器的伪代码</strong>：<br />
<img src="/images/RAG/4.查询检索器伪代码.png" width="55%"></p>
<p>2.第1行：将query编码为向量表示。<br />
3.第2行：执行最近邻搜索ANN，使用预先构建的index，找到前k个最近邻的key。<br />
4.第3行：根据找到的key，从向量数据库中取对应的value。<br />
5.第4行：对检索到的value进行后处理，比如重排。</p>
<h2 id="检索融合第4节">检索融合（第4节）</h2>
<p>1.<strong>检索融合（Retrieval
Fusions）</strong>：指得是如何有效的利用检索到的知识，以提高生成器（generator）的性能。<br />
2.基本上检索融合分为前面介绍的三类：<strong>query-based fusions,
logits-based fusions, latent fusions</strong>。<br />
<img src="/images/RAG/5.检索融合分类.png" width="75%"></p>
<p>3.图3展示了检索融合的分类和每个类别下的代表性方法。</p>
<h3 id="基于查询的融合">基于查询的融合</h3>
<p>1.<strong>Query-based
fusions（基于查询的融合）</strong>：这是最简单直接的一种融合方式，它将检索到的信息与输入查询信息相集成来生成响应。<br />
根据连接信息的方式，分为两个类别：text concatenation、feature
concatenation。<br />
（1）<strong>text
concatenation（文本连接）</strong>：涉及检索结果与原始文本合并，使其特别适合GPT-4等当代LLM。这些模型充当黑盒系统，交互能力有限，通常只向用户提供API接口。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当前的研究工作[<span class="number">49</span>,<span class="number">87</span>,<span class="number">122</span>]直接将输入与检索最多的句子/文档连接起来以形成生成器的查询语句。</span><br><span class="line">为了更好的利用LLMs上下文学习能力，一些研究工作[<span class="number">34</span>,<span class="number">90</span>,<span class="number">141</span>,<span class="number">145</span>]设计了有效的prompt templates来整合输入和检索的信息。</span><br><span class="line">为了解决拼接检索信息导致输入过长的问题，最近的一些研究[<span class="number">5</span>,<span class="number">96</span>,<span class="number">101</span>,<span class="number">150</span>,<span class="number">159</span>]提出了在检索知识结果的基础上，为每个结果中的元素分配重要性权重，并基于此权重，过滤弱相关的检索结果。</span><br></pre></td></tr></table></figure></p>
<p>（2）<strong>feature
concatenation（特征连接）</strong>：涉及编码检索结果与编码输入合并。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">简单的方法是FID[<span class="number">66</span>]，首先将检索结果们编码到稀疏/稠密空间，然后将编码检索结果和编码输入concat，作为输入给生成器。FID在sota最先进性能表现证明了feature concatenation的有效性。</span><br><span class="line">后续工作[<span class="number">25</span>,<span class="number">48</span>,<span class="number">67</span>,<span class="number">97</span>,<span class="number">127</span>]通过联合调整检索器和编码器进一步改进了FID，这可以增强检索到的知识的表示。</span><br><span class="line">此外，[<span class="number">14</span>]将相关知识的表示连接起来作为prompt learning的演示，从而产生更好的泛化能力。</span><br></pre></td></tr></table></figure></p>
<p>2.如算法4.1所示，query-based fusions的伪代码：<br />
<img src="/images/RAG/6.query_base_fusions.png" width="55%"><br />
（1）对于使用text
concatenation的[49,122]：首先将检索结果和输入concat起来（第2行），然后将concat结果输入到生成器（第3行）。注意，目前LLMs对输入长度有限制，太多的检索结果concat后会导致输入过长而被LLMs截断。因此，<strong>设计prompt
template是text concatenation一个关键步骤</strong>。<br />
（2）对于使用feature
concatenation的[48,66]：首先将检索结果和输入进行编码得到特征（第5行），然后将检索结果和输入特征concat（第6行），作为输入给生成器（第7行）。由于序列长度过长，导致产生较高的内存成本。</p>
<h3 id="基于对数的融合">基于对数的融合</h3>
<p>1.<strong>Logits-based
Fusion（基于对数的融合）</strong>：指的是将检索到的知识整合到输出层，基本上，检索到的知识被输入到同一模型中以获得用于增强或校准的logits。因此，logits的融合可以分为两个分支，即<strong>ensemble-based
fusion</strong>（基于集成的融合）和<strong>calibration-based
fusion</strong>（基于校准的融合）。<br />
（1）<strong>ensemble-based
fusion（集成融合）</strong>：将检索到的知识中的逻辑视为预测集成的一部分。这种基于集成的融合可以显着提高模型的泛化性和鲁棒性[80,81,158]。基于集成的融合的一项值得注意的工作是
kNN-LM [81]，它聚合了最邻近目标的 logits，然后对最终预测进行插值。与
kNN-LM 类似[80]提出 kNN-MT 使用检索的 logits
来增强机器翻译，这也是后续工作的一个分支 [64,172]。<br />
（2）<strong>calibration-based
fusion（校准融合）</strong>：使用检索到的知识中的逻辑作为模型预测的校准形式。[72]提出了一种置信度增强的kNN-MT，它利用神经机器翻译置信度来细化kNN分布和插值权重。[89]建议利用源上下文来校准检索增强神经机器翻译。<br />
2.如算法4.2所示，logits-based fusions的伪代码：<br />
<img src="/images/RAG/7.logits_base_funsions.png" width="55%"><br />
（1）先将检索到的相似结果、query输入到生成器中，得到临时生成结果（2-4行）。对于ensemble融合，利用超参数
<span class="math inline">\(\lambda\)</span> 融合检索logits和query
logits（第6行）。<br />
（2）对于calibration融合，动态调整超参数 <span
class="math inline">\(\lambda\)</span> 来融合检索logits和query
logits（第7行）。</p>
<h3 id="潜在融合">潜在融合</h3>
<p>1.<strong>Latent
Funsion（潜在融合）</strong>：将检索到的知识合并到生成器的隐状态中，以获得更好的生成。根据引入方法，可以分为两类：<strong>attention-based</strong>（基于注意力）
和 <strong>weighted-addition</strong>（基于权重）。<br />
（1）<strong>attention-based（基于注意力的融合）</strong>：基于注意力的融合方式，一个重要成果是RETRO。RETRO
引入了新的交叉注意力模块，将检索到的知识直接集成到模型的隐状态中。这项研究的一个重要发现是展示了检索数据库的缩放规律，其中
RETRO 拥有2万亿个token数据库，其中性能和GPT-3相当。在 RETRO 中自定义
Transformer 模型凸显了预训练、检索增强架构在提高 LLM
效率和可扩展性方面的潜力。除了 RETRO 之外，其他研究
[12、26、93、151、154]
通过利用新的注意力模块引入外部知识。[93]通过将上下文编码与模型推理解耦来扩展
RETRO
模型。[154,147]将隐注意力keys和values存储到外部存储器中，并使用注意机制从存储器中检索知识。<br />
（2）<strong>weighted-addition（加权添加）</strong>：由于注意力机制的高度复杂性，另一个工作分支采用轻量级（加权）添加来引入检索到的知识。
[38]提出了 EAE
模型，该模型从可学习的外部存储器中检索top-k最相关的实体的embedding，并将实体的embedding加入到模型的隐状态中。[153]提出了ReFusion，它探索了各种可学习的重新排序方案，首先对检索到的知识的embedding进行重新加权，然后使用加权加法将它们合并到模型的隐状态中。<br />
2.如算法4.3所示，latent fusions的伪代码：<br />
<img src="/images/RAG/8.latent_funsions.png" width="55%"><br />
（1）首先使用上一个模块FFN module的输出输入到当前attention
module，计算得到attention隐状态（第4行），然后使用encoder对attention隐状态+检索到的embedding进行编码（第5行），之后使用cross-attention
module将编码后的检索embedding+attention隐状态进行融合（第6行），最后将融合后的结果输入到FFN
module（第7行）。<br />
（2）基于加权方式，是先对检索到的embedding进行编码（第11行）好处是可以离线完成并存储下来，再使用上一个模块FFN
module的输出输入到当前attention
module，计算得到attention隐状态（第14行），然后使用一组权重，将编码后的检索embedding+attention隐状态进行融合（第15行），最后将融合后的结果输入到FFN
module（第16行）。</p>
<h2 id="生成器第5节">生成器（第5节）</h2>
<p><strong>默认的生成器</strong>普遍基于Transformers结构，例如，Llama系列模型[138,139]，GPT系列模型[11,114,118,119]和Gemini系列模型[4,108,124]删除所有编码器模块，仅保留解码器模块，其中包括注意模块和前馈网络模块。其他先进技术，如均方根层归一化[165]、旋转位置嵌入[136]和组查询注意机制[2]，已被纳入现有大型语言模型的设计中，以增强其性能。</p>
<p><strong>检索增强（RAG）生成器</strong>通常将新模块合并到现有大型语言模型的架构中，他们还接收了大型数据集和大量语料库构建的外部知识数据库的预训练，这种生成器主要利用latent
fusions方式将知识合并到大型语言模型的隐藏状态中[10,93,154]。</p>
<h2 id="rag训练第6节">RAG训练（第6节）</h2>
<p>讨论RAG的训练，主要分为两类：<strong>无数据存储更新的RAG</strong>、<strong>有数据存储更新的RAG</strong>。<br />
<img src="/images/RAG/9.RAG训练.png" width="90%"></p>
<h3 id="无数据存储更新的rag">无数据存储更新的RAG</h3>
<p><strong>1.无数据存储更新的RAG</strong>：<strong>只更新RAG中每个模块的可训练参数，数据存储中的知识保持不变</strong>。如图4(a)-(c)所示，共有三种训练情况：训练检索器、训练生成器以及联合训练检索器和生成器。<br />
（a）<strong>检索器训练（Training
Retriever）</strong>：因为没有数据更新，所以只有训练检索器编码器、重建索引，编码器训练仅适用于密集编码（带参数那种）方法，因为稀疏编码例如one-hot不依赖参数而不用训练。-&gt;不同的训练方法有不同的目标：<strong>通过用更强大/更小的编码器</strong>替换原始编码器能<strong>改进语义表示、加速编码过程</strong>，例如DistilBERT[128]或TinyBERT[75]；<strong>通过对比学习</strong>在特定领域语料上训练原始编码器来<strong>改善在特定领域的信息表示</strong>。-&gt;<strong>训练检索器编码器后，向量数据库中用作键的嵌入也会发生变化</strong>。因此，<strong>所有索引都应该使用新的嵌入来重建</strong>。此外，如果编码器保持不变，可以使用新的
ANN 搜索算法或重新调整超参数来更新索引。检索器训练完成后，可以直接合并到
RAG 中，无需更新生成器。<br />
（b）<strong>生成器训练（Training
Generator）</strong>：<strong>更新生成器的参数</strong>或<strong>检索融合模块中的参数</strong>。生成器一般是LLM，更新它的参数，需要训练，它要大量的资源和时间，现在一些微调技术例如<strong>LoRA[57]</strong>，被提出来解决这种问题。检索融合模块的参数比生成器的参数少，但仅对这些参数微调也会遇到一些训练问题，比如慢速收敛、过拟合等。如果有足够的资源和时间，联合调整生成器和检索融合模块中的参数是训练生成器和检索融合模块的更好方法。<br />
（c）<strong>联合训练检索器和生成器（Jointly Training Retriever and
Generator）</strong>：<strong>同时训练检索器和生成器以提高下游任务的性能</strong>。此方法需要足够的资源和时间，效果也是最好的。<strong>训练的关键在于保证前向过程中从输入到输出的可微性</strong>，通常，复杂的索引，例如
FAISS
[32]，在微调阶段并不是合适的选择。现有的工作通常利用复杂的索引来预先选择最近邻居的一小部分作为候选者，然后通过执行矩阵乘法运算来选择最终的最邻近邻居。联合训练是一种端到端的优化，可以使检索器和生成器之间更好地协调，并提高生成器的上下文理解。</p>
<h3 id="有数据存储更新的rag">有数据存储更新的RAG</h3>
<p><strong>1.有数据存储更新的RAG</strong>：<strong>先更新数据存储中的知识，然后更新RAG中每个模块的参数</strong>。如图4（d）所示，该场景涉及两个阶段：<strong>更新知识数据库</strong>，然后<strong>训练检索器和生成器</strong>。<br />
（1）<strong>更新知识数据库</strong>：分为三种情况，即<strong>使用可训练嵌入更新</strong>、<strong>使用新值（新答案）更新</strong>以及<strong>使用新语料库更新</strong>。在第一种情况下，值通常是可训练的嵌入，并与
RAG
中的参数同时/异步更新[14]。最后两种情况通常是指用最新信息更新知识数据库。以问答语料库为例，更新新值是指更新现有问题的答案，而更新新语料库是指添加新的问答对。要更新现有键的值，需要首先查询现有的键值对，然后执行就地更新。对于新的语料库，数据存储首先需要执行插入操作，然后重建或更新新键的索引。<br />
（2）更新数据存储后，训练检索器和生成器与不更新数据存储的 RAG
类似。然而，这一训练步骤并不总是必要的，只是更有利于LLM的情境学习能力。</p>
<h2 id="rag经典任务的影响第7节">RAG经典任务的影响（第7节）</h2>
<p>本节列出了 NLP 领域的几个经典任务，介绍了用于解决这些任务的高级 RAG
技术。</p>
<h3 id="语言模型">语言模型</h3>
<p>语言建模是需要在给定单词或字符序列的情况下预测下一个单词或字符的概率分布的任务，也称为下一个标记预测任务。语言建模已成为预训练大型语言模型的基本任务。最近的工作主要是进一步利用
RAG 来提高预训练阶段的语言建模能力。<br />
1.分支[10,93,147,154]通过<strong>在每个transformer块中添加新的交叉注意模块</strong>来引入检索知识来修改生成器的架构。<br />
2.Zhong et al.
[173]提出使用<strong>三种类型的检索存储器/数据库</strong>（local memory,
long-term memory, external memory）来增强语言模型。<br />
3.分支[49、64、81、122、160]侧重于<strong>通过检索来增强生成器的输入或输出</strong>。
[49]和[122]将检索到的知识与输入连接起来，并将检索增强的输入输入到生成器中。[64,81,160]融合了输入的逻辑以及最终输出层的检索，并根据插值结果生成最终的概率分布。</p>
<h3 id="机器翻译">机器翻译</h3>
<p>机器翻译（MT）利用计算语言学算法自动将文本或语音从一种语言翻译成另一种语言。机器翻译的目标是产生准确、流畅的翻译，保留原文的含义，同时遵守目标语言的语法和风格规范。机器翻译系统已经从基于规则的机器翻译
(RBMT) 发展到统计机器翻译 (SMT)，最近又发展到神经机器翻译
(NMT)。特别是，NMT
方法通过利用深度学习技术显着提高了翻译质量，因此这将是本节的重点。</p>
<p>RAG
技术可以<strong>通过将外部知识纳入翻译过程</strong>来进一步增强机器翻译。最简单的方法是<strong>将相似的翻译示例连接到输入中或在输出层融合相似翻译示例的逻辑</strong>。<br />
1.[16、145]根据<strong>源文本检索相似的翻译</strong>，并<strong>将相应的目标文本或源文本和目标文本对作为示例连接到输入中</strong>。<br />
2.[56,80,172]将检索到的<strong>源文本输入模型并获取下一个目标标记的logits，然后聚合所有logits以生成最终预测</strong>。此外，[72]和[89]使用检索到的示例的
logits 来校准聚合的 logits，提高生成的稳健性。<br />
3.[173,174]在<strong>训练阶段将外部知识注入到目标函数中</strong>，用类似的翻译来细化表示空间。<br />
4.[12]<strong>对相似的翻译进行编码并将其存储为翻译记忆库，然后使用交叉注意模块引入记忆中的知识</strong>。<br />
5.另外的分支不是提高性能，而是专注于加速 MT
任务的生成效率，例如从预构建的子集[27,107]或动态数据存储[22]中搜索，按块搜索[104]。</p>
<h3 id="文本摘要">文本摘要</h3>
<p>文本摘要是将较大文本文档压缩为较短版本、保留关键信息和整体消息的过程。目标是生成一个连贯且流畅的摘要，其中包含源材料中最关键的信息。这项任务大致可以分为两种类型：<strong>提取摘要</strong>，涉及选择和编译部分原始文本；<strong>抽象摘要</strong>，需要以新的、简洁的形式重写文本的本质。</p>
<p>RAG
技术可以通过利用外部知识和类似文档来为摘要过程提供信息，从而显着增强文本摘要任务。<br />
1.[16,36,90,145]<strong>简单地将检索到的相似摘要连接到输入中以生成摘要</strong>。<br />
2.使用非串联文本，<strong>通过交叉注意力[9]在中间层融合特征</strong>，或者<strong>通过logits集成[56]在输出层融合特征</strong>。<br />
3.[74]认为对每一代进行检索可能并不总是最佳选择，并提出在生成过程中自适应地检索外部知识。</p>
<h3 id="问答系统">问答系统</h3>
<p>问答（QA）是 NLP
中的一项基本任务，涉及构建能够用自然语言自动回答人类问题的系统。<br />
QA
系统可以大致分为两类：<strong>开放域</strong>，系统回答几乎所有问题；<strong>封闭域</strong>，系统专注于特定的知识领域。<br />
质量保证的主要挑战是理解问题的意图，并从大量数据中检索准确的相关信息，以提供简洁的答案。由于篇幅限制，本文仅讨论开放域问答系统的工作。</p>
<p>RAG技术将信息检索与基于模型的生成相结合，非常适合QA系统。特别是，开放域问答系统通常首先需要从互联网或大型数据库中搜索知识，然后根据检索到的知识生成相应的答案。<br />
1.<strong>给定类似的问题和相应的答案作为演示连接到输入</strong>[60,90,145]，RAG
中的生成器可以学习问题和答案之间的模式并推断答案应该是什么。<br />
2.对于一些<strong>给出一组参考文档</strong>的特定QA任务，RAG中的检索器<strong>将检索相关文档进行串联</strong>，然后<strong>RAG中的生成器将读取上下文</strong>，然后<strong>通过自注意力机制生成最终答案</strong>[6,49,86,122]，这类似于解决阅读理解问题。<br />
3.[34]专注于<strong>设计有效的模板来重新组织串联的上下文</strong>。<br />
4.[7]利用<strong>知识图来检索输入问题的相关事实，然后将它们的串联和输入一起输入到生成器中</strong>。<br />
5.另一个分支不是直接连接文本，而是<strong>专注于将检索嵌入与编码器-解码器模型的输入嵌入结合起来</strong>[25,66,67,127]。</p>
<p>有些工作是<strong>将外部知识纳入隐藏状态或生成器的最终逻辑中</strong>。对于隐藏状态的融合，关键是应该注入什么样的知识，例如实体[26,38]，块[10,142]，文档[15]。对于逻辑融合，大多数作品通过集成技术将检索和输入的逻辑结合起来[49,87,110,131]。</p>
<p>现有的工作不是为QA系统设计不同的知识融合，而是从其他方面用RAG改进QA系统。<br />
1.一些工作[45、94、116]使用检索到的问答对作为额外的训练数据。<br />
2.一些作品优化了检索器模块：构建检索器数据库[121]提高了key的表示，用预先训练的排名模型替换索引[163]，或者使用两个查询检索短语[109]。<br />
3.其他工作重点是提高RAG的生成效率。[24]提出层稀疏交叉注意力来加速解码。[6,74,149]观察到检索可能并不总是在生成过程中提供有用的信息并<strong>学习确定何时检索</strong>。此外[137]将RAG<strong>与智能体结合</strong>起来迭代推理最终结果。</p>
<h3 id="信息提取">信息提取</h3>
<p>信息提取（IE）是 NLP
中的一项关键任务，用于<strong>从非结构化和半结构化文本源</strong>中<strong>自动提取结构化信息</strong>。<br />
该任务包含多个子任务，包括命名实体识别（NER）、实体链接（EL）、共指解析（CR）、关系提取（RE）等。<br />
目标是，识别和分类文本中的关键元素并理解文本中的关键元素。它们之间的关系，从而将文本数据转换为易于分析和解释的结构化格式。</p>
<p>利用 RAG 技术，解决 IE
任务不仅可以在<strong>性能方面</strong>而且可以在<strong>可解释性方面</strong>得到显着提高。<br />
1.在NER任务中，[148]首先<strong>检索相似的句子</strong>，然后<strong>连接排序的检索</strong>以获得更好的语义表示。<br />
2.[126]表明<strong>朴素的RAG可能无法解决事件参数提取（EAE）任务</strong>。因此，他们采用基于采样的方法来保证检索和输入之间事件标签的相同分布，然后将检索文本连接到输入中，以便在
EAE
任务中获得更好的性能。表扩充也是一项具有挑战性的任务，需要从表中提取信息。<br />
3.[42]建议以检索增强的方式提取信息。</p>
<h3 id="文本分类">文本分类</h3>
<p>文本分类任务在 NLP 应用中很常见。<strong>情感分析</strong>是 NLP
中一项重要的文本分类任务，需要对文本中传达的情绪基调进行识别和分类。例如，给定一个句子“我喜欢看电影”，分析模型应该确定它是否具有积极态度或消极态度。情感分析中的态度可以从积极到消极，也可以是中立的、细致入微的，甚至是混合的。情感分析任务对于了解消费者反馈、监控品牌声誉以及深入了解各种问题的公众舆论至关重要。</p>
<p>RAG技术可以通过<strong>不同的外部知识融合策略显着增强情感分析</strong>。<br />
1.[90]将<strong>检索到的选项</strong>和<strong>相应的基于提示的标签</strong>与<strong>输入选项</strong>连接起来。<br />
2.[14,48]将<strong>检索嵌入</strong>与<strong>输入嵌入</strong>连接起来，然后将其输入解码器。<br />
3.一些工作通过<strong>交叉注意力</strong>[15,147]或<strong>基于排名的加法</strong>[153]<strong>将检索特征融合到生成器的隐藏状态中</strong>。<br />
4.其他工作侧重于<strong>使用集成技术</strong>将检索的Logit与输出Logit融合[161,167]。除了知识融合之外，[109]能够通过两个查询更准确地定位短语中的知识。</p>
<h3 id="对话系统">对话系统</h3>
<p>对话系统，也称为对话代理或聊天机器人，旨在以文本或语音形式模拟与人类用户的对话。<br />
这些系统可以分为两种主要类型：<strong>面向任务的系统</strong>[61]，它帮助用户完成特定的任务，例如订票或订餐；以及<strong>开放域系统</strong>，它的目标是在广泛的范围内进行一般对话[132]。开发有效对话系统的核心挑战在于理解用户意图、维护上下文并生成连贯、相关的响应。</p>
<p>现有的工作主要通过基于串联的方法来改进 RAG 的对话系统。<br />
1.[16,83,92]将<strong>检索到的历史对话</strong>与<strong>当前输入连接</strong>起来。<br />
2.[16、37、97]首先利用<strong>编码器对历史响应进行编码</strong>，然后将<strong>联合的嵌入（历史+当前）输入解码器</strong>以生成新的响应。</p>
<h2 id="实际应用第8节">实际应用（第8节）</h2>
<h3 id="基于llm的智能体">基于LLM的智能体</h3>
<p>基于LLM的智能体是智能软件系统，它利用LLM的力量来执行任务，而不需要持续的人工干预[91,144,155]。这些智能体<strong>使用
LLM 作为大脑</strong>或控制器 [63]，并通过<strong>多模式感知</strong>
[157]、<strong>工具利用</strong> [129] 和<strong>外部记忆</strong> [115]
扩展其能力。特别是，智能体的外部长期记忆充当 RAG
中的知识数据库，它为智能体提供了长期整合外部知识的能力。因此，应用RAG将有利于获取更广泛的信息，提高智能体的决策和解决问题的能力[169]。本节从两个角度探讨基于
LLM 的代理如何利用 RAG。</p>
<p>1.<strong>使用 RAG
从外部存储器检索</strong>：基于LLM的代理可以利用RAG从它们自己的外部存储器中访问和检索信息[52,105,170]。这种外部记忆充当知识库，代理可以利用它来增强其理解和决策。当面临查询或任务时，代理可以使用
RAG 从该内存中检索相关信息，然后将其集成到 LLM
的生成过程中。这使得代理能够根据更广泛的知识产生响应或解决方案，从而产生更准确和与上下文相关的结果。利用大量外部记忆的能力使智能体能够根据新信息不断学习和适应，从而随着时间的推移变得更加有效。</p>
<p>2.<strong>使用工具在 Web 和 RAG
中搜索最新信息</strong>：除了从自己的内存中检索信息之外，基于LLM的代理还可以使用工具在网络上搜索最新信息[129]。此功能对于需要最新知识的任务特别有用，例如新闻摘要、市场分析或响应快速变化的情况。一旦代理从网络检索到最新信息，它就可以使用
RAG
将此数据集成到其生成过程中。通过将LLM的自然语言理解与来自网络的实时数据相结合，代理可以生成不仅与上下文相关而且反映最新发展的响应。这种方法增强了代理获得准确和及时的信息能力，提高其在动态环境中的有效性。</p>
<p>在这两种情况下，RAG 在增强基于 LLM
的代理的能力方面发挥着至关重要的作用，使他们能够访问和利用更广泛的信息，无论是来自他们自己的外部记忆还是来自网络上的实时来源。这有助于做出更明智的决策并提高代理的整体绩效。</p>
<h3 id="框架">框架</h3>
<p>Langchain [84] 和 LLaMAindex [95] 等框架对增强 RAG
的实际实施产生了重大影响。 Langchain 和 LLaMAindex
体现了复杂的检索机制与生成模型的集成，促进外部数据无缝融入语言生成过程。本节将详细介绍这两个具有代表性的RAG框架。</p>
<p>Langchain
是一个框架，旨在通过将语言模型与外部知识源和数据库集成来增强语言模型的功能。它充当中间件，促进语言模型和各种数据检索系统之间的交互，从而能够更明智、更准确地生成响应。
Langchain
的核心功能涉及将外部数据库的信息流编排到语言模型的生成过程中，从而增强其在响应中利用上下文和特定知识的能力。这种集成在使语言模型能够执行需要访问模型初始训练数据中未包含的最新或详细信息的任务方面发挥着至关重要的作用。</p>
<p>LLaMAindex
是一个专门的数据框架，专注于组织和索引大量数据，以提高语言模型的检索能力。该框架支持高效的查询机制，允许语言模型快速访问结构化存储库中的相关信息。
LLaMAindex
的设计具有高度可扩展性，可以处理从文本文档到结构化数据库的多种数据类型。索引数据支持广泛的应用，从简单的事实检索到复杂的分析任务，使其成为增强语言模型中信息检索阶段不可或缺的工具。</p>
<p>Langchain和LLaMAindex都与RAG的概念息息相关。 Langchain
通过为语言模型在生成过程中与外部数据库和知识源交互提供结构化方式来增强
RAG。另一方面，LLaMAindex 通过确保检索过程快速且相关，充当 RAG
系统的强大后端。 Langchain 和 LLaMAindex 共同增强了 RAG
的功能，确保语言模型不仅能够根据其内部知识生成文本，而且能够提取外部数据以提供上下文丰富且信息稳健的响应。</p>
<h2 id="讨论和未来方向第9节">讨论和未来方向（第9节）</h2>
<p>尽管 RAG
在自然语言处理方面取得了成功，但仍有一些挑战值得考虑。本文强调了这些挑战，以激发未来的研究，并为
NLP 的 RAG 提供未来可能的研究方向。</p>
<h3 id="检索质量">检索质量</h3>
<p>检索质量是指提高RAG中检索到的信息的相关性，涉及到以下四个需要设计的关键因素。</p>
<p>1.首先要考虑的是<strong>确定矢量数据库中使用的最佳密钥</strong>。这个过程通常涉及主观决策，并且需要人力来有效设计。天真的想法是为给定的任务选择输入，将每个任务视为
QA 问题。<br />
2.其次是<strong>嵌入模型的选择</strong>。确定密钥后，下一步是利用嵌入模型将文本转换为向量表示。
BERT [29]、RoBERTa [99]
或特定领域嵌入等模型对于确定捕获细微差别和上下文含义的程度至关重要。调整嵌入模型以更好地适应特定类型的数据或查询可以显着提高检索质量。这需要在特定领域的语料库上训练模型，其中包括系统将遇到的查询和文档类型。<br />
3.<strong>设计有效的相似性度量</strong>对于提高检索质量也至关重要。相似性度量的目标是测量查询和检索信息之间的相关性。用于推荐系统中排名的一些经典相似性度量，例如余弦相似性或欧几里德距离，也可以在
RAG
中使用[44]。除了这些指标之外，一些工作还探索了更复杂的相似性指标，例如最佳传输距离[21]，以获得特定于任务的相似性。<br />
4.<strong>近似最近邻（ANN）搜索</strong>也是确定应将哪些知识作为最近邻返回的关键步骤。高级人工神经网络搜索旨在以牺牲检索质量为代价来提高检索效率。选择合适的ANN算法，例如乘积量化[68]或HNSW[102]，需要在检索效率和检索质量之间进行良好的权衡。所有这些因素共同影响检索器的检索质量。</p>
<h3 id="rag效率">RAG效率</h3>
<p>RAG 效率对于下游 NLP
应用程序至关重要，这限制了可检索的数据量。有两种简单的方法可以在不使用新算法的情况下保证
RAG
效率，即<strong>减少数据量</strong>或<strong>添加更强大的计算和内存资源</strong>。然而，前者可能会影响检索质量，而后者则需要更多的资源成本。</p>
<p>1.<strong>RAG效率</strong>包括<strong>检索器的效率</strong>和<strong>检索融合的效率</strong>。<strong>检索器效率</strong>是指检索相关信息的时间成本，可以分为三个部分，即<strong>编码时间</strong>、<strong>ANN搜索时间</strong>和<strong>数据存储的数据获取时间</strong>。没有必要联合优化所有三个组件，因为不同数据库大小的瓶颈会有所不同。对于较小的检索数据库，例如条目数少于
100
万的数据库，编码阶段通常是主要瓶颈，因为矢量数据库可以全部存储在内存中。模型量化[8,82]、蒸馏[30,75]或模型剪枝[39]等多个主题用于加速编码。相反，对于较大的数据库，在索引中搜索和从数据存储中获取数据的时间成本成为主要瓶颈，因为搜索涉及大量数据，并且获取涉及
I/O
开销。除此之外，有效的ANN搜索算法[32,47,77]和系统级优化[73,76]是主要关注点。</p>
<p>2.<strong>检索融合效率</strong>旨在<strong>提高集成检索时的推理效率</strong>，值得优化以提高
RAG
效率。例如，由于序列长度较长，基于查询的融合的计算开销通常是不可忽略的。一些工作，例如
Fid-light [55] 和 ReFusion
[153]，主要目标是在整合检索到的信息的同时减少计算量。</p>
<h3 id="融合的选择">融合的选择</h3>
<p>本文介绍了三种检索融合，每种融合都值得进一步探讨。</p>
<p>1.<strong>基于查询的融合</strong>将检索到的知识的文本或嵌入与输入连接起来。这些方法具有更好的可解释性，即使只提供LLM的API也很容易应用。然而，串联会导致输入序列很长，从而导致输入的注意力和截断产生大量的计算开销。一些工作
[5, 153] 旨在提高集成检索时的效率，而另一些工作 [9, 147]
则侧重于提高模型输入长度时的效率。<br />
2.<strong>基于潜在的融合</strong>在更深、更抽象的层面上合并信息，这可能会捕获检索到的信息和查询之间更微妙的关系。然而，这些融合明显缺乏可解释性，并且通常需要预训练或微调来调整检索嵌入或重新加权检索。因此，增强这种基于潜在的融合的可解释性也值得未来探索。<br />
3.<strong>基于Logits的融合</strong>在决策级别合并信息，从而提供来自各种来源的数据的潜在更灵活和稳健的集成。尽管如此，这些融合可能会过度简化融合过程，通过将检索到的信息减少到对数值来减少检索信息的丰富性。同时，这种融合需要执行所有检索推理，这也是一个耗时的过程。</p>
<p>除了在实际应用中应用一种融合之外，组合不同的融合以获得更好的性能也值得探索。这些融合方法并不相互排斥，因为它们专注于增强生成器的不同阶段，即输入、隐藏状态和输出。此外，在生成过程中，何时融合检索到的知识也是一个值得进一步探索的重要问题[103]。</p>
<h3 id="rag的训练">RAG的训练</h3>
<p>正如第 6 节中所介绍的，RAG
训练包括两个工作分支：<strong>带/不带数据存储更新的
RAG</strong>。对于没有数据存储更新的RAG，主要挑战是如何联合优化RAG中的所有参数。这可能涉及具有多个目标的新损失函数、检索器和生成器中有效调整参数的新优化或其他训练策略。</p>
<p><strong>对于具有数据存储更新的RAG</strong>，一项挑战是<strong>如何将检索表示与生成器表示对齐</strong>。尽管数据存储中更新操作的时间成本不可忽视，但一些工作[14]通过异步更新来降低更新频率，从而实现知识表示和模型表示的对齐。另一个挑战是<strong>添加新语料库时何时重新训练/微调
RAG
中的生成器</strong>。由于现有基于LLM的生成器的上下文学习能力和高训练开销，重新训练/微调生成器或直接推断生成器成为不同场景的具有挑战性的选择。最近，已经提出了一些有效的训练策略[28,57]来加速微调过程，可以考虑。</p>
<h3 id="跨模态检索">跨模态检索</h3>
<p>在 NLP
任务中<strong>检索跨模态信息可以极大地提高表示的质量和丰富性</strong>，从而提高性能。首先，跨模态信息，例如将<strong>文本与图像、视频或音频相结合</strong>，为内容提供了更丰富的上下文[58]。例如，当语言含糊不清时，随附的图像可以澄清仅通过文本难以传达的含义。其次，不同的方式可以提供无法从单一来源获取的各种类型的信息。例如，视觉数据可以提供空间、颜色和动作线索，而文本数据可以提供详细的描述、情感或抽象概念。将这些结合起来可以更全面地理解数据。此外，在多模态数据上训练的模型通常表现出更高的鲁棒性和泛化性[152]。<strong>这些模型擅长将不同输入的信息关联起来，减轻对单一模态特性的过度拟合</strong>。这一属性在
NLP
的现实应用中特别有价值，例如在自动驾驶汽车中，系统必须解释来自标志或对话的文本信息以及来自周围环境的感官数据，以做出明智的决策。此外，多模态数据可以解决单一模态无法解决的歧义。例如，短语“bank”可以指金融机构或河边，视觉上下文可以帮助消除歧义。最后，人类交流本质上是多模式的，融合了手势、面部表情和语气等元素。能够处理多种通信模式的系统可以以更自然和直观的方式与人类交互。总之，在
NLP 任务的 RAG
中集成跨模态信息不仅增强了数据表示的丰富性和质量，而且还显着提高了系统的理解力、交互能力和对不同应用的适应性。</p>
<h2 id="结论">结论</h2>
<p>本次调查中，我们深入研究了 RAG
在自然语言处理领域的发展。首先，本文介绍了RAG的组成部分及其功能。随后，本文详细阐述了检索器涉及的每个步骤，讨论了各种技术。此外，本文对检索融合进行了分类，评估了每种检索融合技术固有的优点和缺点。此外，本文还讨论了
RAG 训练，包括有/没有数据存储更新的 RAG。然后，本文探讨了 RAG
如何适应各种 NLP 任务，并提供了 RAG
在现实场景中的实际应用。最后，本文确定了当前的挑战，并提出了未来研究的方向，以促进这一不断发展的领域的进步。</p>
<h1
id="retrieval-augmented-generation-for-ai-generated-content-a-survey">Retrieval-Augmented
Generation for AI-Generated Content: A Survey</h1>
<h2 id="摘要-1">摘要</h2>
<h1 id="参考文献">参考文献</h1>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzI0MDcuMTMxOTM=">Retrieval-Augmented
Generation for Natural Language Processing: A Survey<i class="fa fa-external-link-alt"></i></span><br />
<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzI0MDIuMTk0NzM=">Retrieval-Augmented
Generation for AI-Generated Content: A Survey<i class="fa fa-external-link-alt"></i></span><br />
<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2h5bWllMTIyL1JBRy1TdXJ2ZXk=">Retrieval-Augmented
Generation for AI-Generated Content: A Survey参考文献整理<i class="fa fa-external-link-alt"></i></span><br />
<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvaE5ScE5LTGhzZUdjRUNFaVN6TzM0UQ==">一篇RAG全栈技术最新综述！<i class="fa fa-external-link-alt"></i></span></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>SoundMemories
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/" title="Retrieval-Augmented Generation Survey">https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented Generation Survey/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Paper/" rel="tag"><i class="fa fa-tag"></i> Paper</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/04/05/Web/04.Vue/" rel="prev" title="Vue">
                  <i class="fa fa-chevron-left"></i> Vue
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/10/09/Python/23.FastAPI/" rel="next" title="FastAPI">
                  FastAPI <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">SoundMemories</span>
  </div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"neutral"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js","integrity":"sha256-JFptYy4KzJ5OQP+Q9fubNf3cxpPPmZKqUOovyEONKrQ="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://soundmemories.github.io/2024/07/18/Paper/04.Retrieval-Augmented%20Generation%20Survey/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
