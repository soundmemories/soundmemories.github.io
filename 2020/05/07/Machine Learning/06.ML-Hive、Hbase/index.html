<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.17.1","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="数据库和数据仓库？ 数据库： （1）传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。 （2）一般只保存数据的最新状态，极个别重要的值会保存历史版本。 数据仓库： （1）主要应用是OLAP（On-Line Analytical Processing），支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 （2）会保存所有历史版本，只记录，很少更新、删">
<meta property="og:type" content="article">
<meta property="og:title" content="ML-Hive、Hbase">
<meta property="og:url" content="https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="数据库和数据仓库？ 数据库： （1）传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。 （2）一般只保存数据的最新状态，极个别重要的值会保存历史版本。 数据仓库： （1）主要应用是OLAP（On-Line Analytical Processing），支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 （2）会保存所有历史版本，只记录，很少更新、删">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/hive2.jpg">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/hive3.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/sqoop.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/error.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/hbase&hive.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/hbase4.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/Consistency.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/cap.jpg">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/structure.jpg">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/2.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/Hbase%E5%91%BD%E4%BB%A4%E8%A1%A8.jpg">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/table1.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/table2.png">
<meta property="og:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/table3.png">
<meta property="article:published_time" content="2020-05-06T16:00:00.000Z">
<meta property="article:modified_time" content="2023-05-24T16:23:07.437Z">
<meta property="article:author" content="SoundMemories">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soundmemories.github.io/images/Hive%E3%80%81Hbase/hive2.jpg">


<link rel="canonical" href="https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":"","permalink":"https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/","path":"2020/05/07/Machine Learning/06.ML-Hive、Hbase/","title":"ML-Hive、Hbase"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ML-Hive、Hbase | SoundMemories</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SoundMemories</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">8</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">122</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93"><span class="nav-number">1.</span> <span class="nav-text">数据库和数据仓库？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive%E6%A6%82%E8%BF%B0"><span class="nav-number">2.</span> <span class="nav-text">Hive概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#hive-%E6%9E%B6%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">Hive 架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.2.</span> <span class="nav-text">Hive数据模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="nav-number">2.3.</span> <span class="nav-text">Hive安装部署</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="nav-number">2.4.</span> <span class="nav-text">Hive基本操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E7%9A%84%E5%86%85%E9%83%A8%E8%A1%A8%E5%92%8C%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="nav-number">2.5.</span> <span class="nav-text">Hive的内部表和外部表</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">2.6.</span> <span class="nav-text">分区表</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E5%87%BD%E6%95%B0"><span class="nav-number">2.7.</span> <span class="nav-text">Hive函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B"><span class="nav-number">2.8.</span> <span class="nav-text">Hive综合案例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sqoop%E6%A6%82%E8%BF%B0"><span class="nav-number">3.</span> <span class="nav-text">Sqoop概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sqoop%E5%AE%89%E8%A3%85"><span class="nav-number">3.1.</span> <span class="nav-text">Sqoop安装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8sqoop%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0hdfs%E4%B8%AD"><span class="nav-number">3.2.</span> <span class="nav-text">使用Sqoop导入数据到hdfs中</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E4%B8%8E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">3.3.</span> <span class="nav-text">HBase与关系型数据库的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.4.</span> <span class="nav-text">HBase的数据模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="nav-number">3.5.</span> <span class="nav-text">HBase基础架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E6%A8%A1%E5%9D%97%E5%8D%8F%E4%BD%9C"><span class="nav-number">3.6.</span> <span class="nav-text">HBase模块协作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E7%9A%84%E5%AE%89%E8%A3%85"><span class="nav-number">3.7.</span> <span class="nav-text">HBase的安装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase-shell"><span class="nav-number">3.8.</span> <span class="nav-text">HBase shell</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#happybase%E6%93%8D%E4%BD%9Chbase"><span class="nav-number">3.9.</span> <span class="nav-text">HappyBase操作Hbase</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E8%A1%A8%E8%AE%BE%E8%AE%A1"><span class="nav-number">3.10.</span> <span class="nav-text">HBase表设计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hbase%E8%A1%A8%E8%AE%BE%E8%AE%A1%E6%A1%88%E4%BE%8B-%E7%A4%BE%E4%BA%A4%E5%BA%94%E7%94%A8%E4%BA%92%E7%B2%89%E4%BF%A1%E6%81%AF%E8%A1%A8"><span class="nav-number">3.11.</span> <span class="nav-text">HBase表设计案例:
社交应用互粉信息表</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="/images/avstar.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">122</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avstar.png">
      <meta itemprop="name" content="SoundMemories">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ML-Hive、Hbase | SoundMemories">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML-Hive、Hbase
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-05-07 00:00:00" itemprop="dateCreated datePublished" datetime="2020-05-07T00:00:00+08:00">2020-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>45 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="数据库和数据仓库">数据库和数据仓库？</h1>
<p>数据库：<br />
（1）传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。<br />
（2）一般只保存数据的最新状态，极个别重要的值会保存历史版本。</p>
<p>数据仓库：<br />
（1）主要应用是OLAP（On-Line Analytical
Processing），支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。<br />
（2）会保存所有历史版本，只记录，很少更新、删除等。</p>
<p>以电商为例：基本每家电商公司都会经历，从只需要业务数据库到要数据仓库的阶段。</p>
<ul>
<li>第一阶段，电商早期启动非常容易，入行门槛低。“一个可下单的网页前端 +
几台服务器 + 一个MySQL”，就能开门迎客了。这好比手工作坊时期。</li>
<li>第二阶段，流量来了，客户和订单都多起来了，普通查询已经有压力了，这个时候就需要升级架构变成多台服务器和多个业务数据库（量大+分库分表），这个阶段的业务数字和指标还可以勉强从业务数据库里查询。初步进入工业化。</li>
<li>第三个阶段，一般需要 3-5
年左右的时间，随着业务指数级的增长，数据量的会陡增，公司角色也开始多了起来，开始有了
CEO、CMO、CIO，大家需要面临的问题越来越复杂，越来越深入。高管们关心的问题，从最初非常粗放的：“昨天的收入是多少”、“上个月的
PV、UV
是多少”，逐渐演化到非常精细化和具体的用户的集群分析，特定用户在某种使用场景中，例如“某年龄段某性别用户群体，在过去五年的第一季度某类商品的购买行为与公司进行的促销活动方案之间的关系”。</li>
</ul>
<p>第三个阶段，这种非常具体，且能够对公司决策起到关键性作用的问题，基本很难从<strong>业务数据库</strong>从调取出来。原因在于：<br />
（1）业务数据库中的数据结构是为了完成交易而设计的，不是为了而查询和分析的便利设计的。<br />
（2）业务数据库大多是读写优化的，即又要读（查看商品信息），也要写（产生订单，完成支付）。因此对于大量数据的读（查询指标，一般是复杂的只读类型查询）是支持不足的。</p>
<p>而怎么解决这个问题，此时我们就需要<strong>建立一个数据仓库</strong>了，公司也算开始进入信息化阶段了。数据仓库的作用在于：<br />
（1）数据结构为了分析和查询的便利；<br />
（2）只读优化的数据库，即不需要它写入速度多么快，只要做大量数据的复杂查询的速度足够快就行了。</p>
<p>那么在这里前一种业务数据库（读写都优化）的是业务性数据库，后一种是分析性数据库，即数据仓库。<br />
数据库：MySQL、Oracle、SqlServer、Hbase等。<br />
数据仓库：Hive、Greenplum等。</p>
<p>ETL（Extract-Transform-Load，抽取-转换-加载）：数据从<strong>业务性的数据库</strong>中提取、加工、导入<strong>分析性的数据库</strong>的工作。<br />
常见的ETL工具：Spark。</p>
<h1 id="hive概述">Hive概述</h1>
<p>（1）Hive 由 Facebook 实现并开源，是基于 Hadoop
的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供
HQL(Hive SQL)查询功能，底层数据是存储在 HDFS 上。<br />
（2）Hive 本质: 将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce
的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，是一款基于 HDFS
的 MapReduce <strong>计算框架</strong>。<br />
（3）主要用途：用来做离线数据分析，比直接用 MapReduce 开发效率更高。</p>
<p><strong>1、为什么使用Hive？</strong><br />
（1）需要保存大量历史数据、支持快速查询、数据分析，传统的数据库很难做到。<br />
（2）直接使用 Hadoop MapReduce
处理数据所面临的问题：人员学习成本太高、MapReduce
实现复杂查询逻辑开发难度太大。<br />
（3）使用 Hive：操作接口采用类 SQL 语法，提供快速开发的能力、避免了去写
MapReduce，减少开发人员的学习成本、功能扩展很方便。</p>
<p><strong>2、Hive 与 Hadoop 的关系？</strong><br />
Hive 利用 HDFS 存储数据，利用 MapReduce 查询分析数据。</p>
<p>Hive 是数据仓库工具，没有集群的概念，如果想提交 Hive 作业只需要在
hadoop 集群 Master 节点上装 Hive 就可以了。</p>
<p><strong>3、 Hive 与传统数据库对比</strong><br />
Hive 用于海量数据的离线数据分析。</p>
<table>
<tr>
<th>
</th>
<th>
Hive
</th>
<th>
关系型数据库
</th>
</tr>
<tr>
<td>
ANSI SQL
</td>
<td>
不完全支持
</td>
<td>
支持
</td>
</tr>
<tr>
<td>
更新
</td>
<td>
INSERT OVERWRITETABLE(默认)
</td>
<td>
UPDATE
</td>
</tr>
<tr>
<td>
事务
</td>
<td>
不支持(默认)
</td>
<td>
支持
</td>
</tr>
<tr>
<td>
模式
</td>
<td>
读模式
</td>
<td>
写模式
</td>
</tr>
<tr>
<td>
查询语言
</td>
<td>
HQL
</td>
<td>
SQL
</td>
</tr>
<tr>
<td>
数据存储
</td>
<td>
HDFS
</td>
<td>
Raw Device or Local FS
</td>
</tr>
<tr>
<td>
执行
</td>
<td>
MapReduce
</td>
<td>
Executor
</td>
</tr>
<tr>
<td>
执行延迟
</td>
<td>
高
</td>
<td>
低
</td>
</tr>
<tr>
<td>
子查询
</td>
<td>
只能用在From子句中
</td>
<td>
完全支持
</td>
</tr>
<tr>
<td>
处理数据规模
</td>
<td>
大
</td>
<td>
小
</td>
</tr>
<tr>
<td>
可扩展性
</td>
<td>
高
</td>
<td>
低
</td>
</tr>
<tr>
<td>
索引
</td>
<td>
0.8版本后加入位图索引
</td>
<td>
有复杂的索引
</td>
</tr>
</table>
<ul>
<li>Hive支持的数据类型
<ul>
<li>原子数据类型：TINYINT SMALLINT INT BIGINT BOOLEAN FLOAT DOUBLE
STRING BINARY TIMESTAMP DECIMAL CHAR VARCHAR DATE<br />
</li>
<li>复杂数据类型：ARRAY MAP STRUCT</li>
</ul></li>
<li>Hive中表的类型
<ul>
<li>托管表 (managed table) (内部表)</li>
<li>外部表</li>
</ul></li>
</ul>
<h2 id="hive-架构">Hive 架构</h2>
<p><img src="/images/Hive、Hbase/hive2.jpg"></p>
<ul>
<li>用户接口：包括 CLI、JDBC/ODBC、WebGUI。
<ul>
<li>CLI（command line interface）是 shell 命令行。</li>
<li>JDBC/ODBC 是 Hive 的 JAVA 实现，与传统数据库 JDBC 类似。</li>
<li>WebGUI 是通过浏览器访问 Hive。</li>
<li>HiveServer2基于Thrift，允许远程客户端使用多种编程语言如Java、Python
向 Hive 提交请求</li>
</ul></li>
<li>元数据存储：通常是存储在关系数据库如 mysql/derby 中。
<ul>
<li>Hive 将元数据存储在数据库中。</li>
<li>Hive 中的元数据包括：
<ul>
<li>表的名字</li>
<li>表的列</li>
<li>分区及其属性</li>
<li>表的属性（是否为外部表等）</li>
<li>表的数据所在目录等。</li>
</ul></li>
</ul></li>
<li>解释器、编译器、优化器、执行器：完成 HQL
查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在
HDFS 中，并在随后由 MapReduce 调用执行。</li>
</ul>
<h2 id="hive数据模型">Hive数据模型</h2>
<ul>
<li>Hive 中所有的数据都存储在 HDFS 中，没有专门的数据存储格式。</li>
<li>在创建表时指定数据中的分隔符，Hive 就可以映射成功，解析数据。</li>
<li>Hive 中包含以下数据模型：
<ul>
<li>db：在 hdfs 中表现为 hive.metastore.warehouse.dir
目录下一个文件夹。</li>
<li>table：在 hdfs 中表现所属 db 目录下一个文件夹。</li>
<li>external table：数据存放位置可以在 hdfs 任意指定路径。</li>
<li>partition：在 hdfs 中表现为 table 目录下的子目录。</li>
<li>bucket：在 hdfs 中表现为同一个表目录下根据 hash
散列之后的多个文件。</li>
</ul></li>
</ul>
<h2 id="hive安装部署">Hive安装部署</h2>
<p>Hive 安装前需要安装好 JDK 和 Hadoop。配置好环境变量。</p>
<p>下载Hive的安装包 http://archive.cloudera.com/cdh5/cdh/5/
并解压：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz  -C ~/app/</span></span><br></pre></td></tr></table></figure><br />
进入到 解压后的hive目录 找到 conf目录, 修改配置文件：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> hive-env.sh.template hive-env.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi hive-env.sh</span></span><br></pre></td></tr></table></figure><br />
在hive-env.sh中指定hadoop的路径：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0</span><br></pre></td></tr></table></figure><br />
配置环境变量：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi ~/.bash_profile</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加环境变量</span></span><br><span class="line">export HIVE_HOME=/home/hadoop/app/hive-1.1.0-cdh5.7.0</span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bash_profile</span></span><br></pre></td></tr></table></figure><br />
根据元数据存储的介质不同，分为下面两个版本，其中 derby
属于内嵌模式。实际生产环境中则使用 mysql 来进行元数据的存储。<br />
（1）内置 derby 版： bin/hive 启动即可使用。缺点：不同路径启动
hive，每一个 hive 拥有一套自己的元数据，无法共享。<br />
（2）mysql
版：上传mysql驱动<code>mysql-connector-java-5.*.jar</code>到hive安装目录的lib目录下。配置
Mysql 元数据库信息<code>vi conf/hive-site.xml</code>：<br />
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> standalone=<span class="string">&quot;no&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 插入以下代码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!-- 指定mysql用户名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!-- 指定mysql密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>mysql</span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://127.0.0.1:3306/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 指定mysql数据库地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!-- 指定mysql驱动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 到此结束代码 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.script.wrapper<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>hive启动
<ul>
<li>启动docker：<code>service docker start</code></li>
<li>通过docker，启动mysql：<code>docker start mysql</code></li>
<li>启动hive的metastore元数据服务：<code>hive --service metastore</code></li>
<li>启动hive：<code>hive</code></li>
</ul></li>
</ul>
<h2 id="hive基本操作">Hive基本操作</h2>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE test;</span><br><span class="line"><span class="comment">-- 显示所有数据库</span></span><br><span class="line"><span class="keyword">SHOW</span> DATABASES;</span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="comment">-- 默认表创建在hadoop的user/hive/warehouse下</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(classNo string, stuNo string, score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><code>row format delimited fields terminated by ','</code>：指定了字段的分隔符为逗号，所以load数据的时候，load的文本也要为逗号，否则加载后为NULL。hive只支持单个字符的分隔符，hive默认的分隔符是\001。</p>
<ul>
<li>将数据load到表中
<ul>
<li>在本地文件系统创建一个如下的文本文件：/home/hadoop/tmp/student.txt<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">C01,N0101,82</span><br><span class="line">C01,N0102,59</span><br><span class="line">C01,N0103,65</span><br><span class="line">C02,N0201,81</span><br><span class="line">C02,N0202,82</span><br><span class="line">C02,N0203,79</span><br><span class="line">C03,N0301,56</span><br><span class="line">C03,N0302,92</span><br><span class="line">C03,N0306,72</span><br></pre></td></tr></table></figure></li>
<li>在hive中执行下面语句导入文件：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/hadoop/tmp/student.txt&#x27;</span>overwrite <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br><span class="line"><span class="comment">-- 等价于 hadoop fs -put /home/hadoop/tmp/student.txt /user/hive/warehouse/student </span></span><br></pre></td></tr></table></figure></li>
<li>这个命令将student.txt文件复制到hive的warehouse目录中，这个目录由hive.metastore.warehouse.dir配置项设置，默认值为/user/hive/warehouse。Overwrite选项将导致Hive事先删除student目录下所有的文件,
并将文件内容映射到表中。<br />
Hive不会对student.txt做任何格式处理，因为Hive本身并不强调数据的存储格式。</li>
</ul></li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询表中的数据，跟SQL类似</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line"><span class="comment">-- 分组查询group by和统计count</span></span><br><span class="line"><span class="keyword">select</span> classNo,<span class="built_in">count</span>(score) <span class="keyword">from</span> student <span class="keyword">where</span> score<span class="operator">&gt;=</span><span class="number">60</span> <span class="keyword">group</span> <span class="keyword">by</span> classNo;</span><br></pre></td></tr></table></figure>
<p>从执行结果可以看出hive把查询的结果变成了MapReduce作业通过hadoop执行。</p>
<h2 id="hive的内部表和外部表">Hive的内部表和外部表</h2>
<table>
<tr>
<th>
</th>
<th>
内部表(managed table)
</th>
<th>
外部表(external table)
</th>
</tr>
<tr>
<td>
概念
</td>
<td>
创建表时无external修饰
</td>
<td>
创建表时被external修饰
</td>
</tr>
<tr>
<td>
数据管理
</td>
<td>
由Hive自身管理
</td>
<td>
由HDFS管理
</td>
</tr>
<tr>
<td>
数据保存位置
</td>
<td>
hive.metastore.warehouse.dir<br>默认位置：/user/hive/warehouse
</td>
<td>
hdfs中任意位置
</td>
</tr>
<tr>
<td>
删除时影响
</td>
<td>
直接删除元数据（metadata）及存储数据
</td>
<td>
仅会删除元数据，HDFS上的文件并不会被删除
</td>
</tr>
<tr>
<td>
表结构修改时影响
</td>
<td>
修改会将修改直接同步给元数据
</td>
<td>
表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）
</td>
</tr>
</table>
<p><strong>案例:</strong><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建一个外部表student2，位置指定为hdfs上的/tmp/student</span></span><br><span class="line"><span class="comment">-- TABLE 表名(字段名 字段类型，...)  </span></span><br><span class="line"><span class="comment">-- location &#x27;数据在hdfs上的路径&#x27;;</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> student2 (classNo string, stuNo string, score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> location <span class="string">&#x27;/tmp/student2&#x27;</span>;</span><br><span class="line"><span class="comment">-- 装载数据</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/hadoop/tmp/student.txt&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> student2;</span><br><span class="line"><span class="comment">-- 显示表信息</span></span><br><span class="line"><span class="keyword">desc</span> formatted table_name;</span><br><span class="line"><span class="comment">-- 删除表查看结果</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2;</span><br><span class="line"><span class="comment">-- 再次创建外部表student2</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> student2 (classNo string, stuNo string, score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> location <span class="string">&#x27;/tmp/student2&#x27;</span>;</span><br><span class="line"><span class="comment">-- 不装载数据直接查询查看结果</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2;</span><br></pre></td></tr></table></figure></p>
<h2 id="分区表">分区表</h2>
<p>什么是分区表？<br />
-
随着表的不断增大，对于新纪录的增加，查找，删除等(DML)的维护也更加困难。对于数据库中的超大型表，可以通过把它的数据分成若干个小表，从而简化数据库的管理活动，对于每一个简化后的小表，我们称为一个单个的分区。<br />
-
hive中分区表实际就是对应hdfs文件系统上独立的文件夹，该文件夹内的文件是该分区所有数据文件。<br />
- 分区可以理解为分类，通过分类把不同类型的数据放到不同的目录下。<br />
- 分类的标准就是分区字段，可以一个，也可以多个。<br />
-
分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</p>
<p>创建一个employee.txt：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tom,4300</span><br><span class="line">jerry,12000</span><br><span class="line">mike,13000</span><br><span class="line">jake,11000</span><br><span class="line">rob,10000</span><br></pre></td></tr></table></figure><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建分区表</span></span><br><span class="line"><span class="comment">-- partitioned by (分区字段名 分区字段类型)</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> employee (name string,salary <span class="type">bigint</span>) partitioned <span class="keyword">by</span> (date1 string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span> stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看表的分区</span></span><br><span class="line"><span class="keyword">show</span> partitions employee;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 添加分区：分区是表文件夹的子文件夹</span></span><br><span class="line"><span class="comment">-- 就是更新hive原数据，使分区生效</span></span><br><span class="line"><span class="comment">-- partition(分区字段名字=&#x27;分区的具体值&#x27;)</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> employee <span class="keyword">add</span> if <span class="keyword">not</span> <span class="keyword">exists</span> <span class="keyword">partition</span>(date1<span class="operator">=</span><span class="string">&#x27;2018-12-01&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 加载数据到分区</span></span><br><span class="line"><span class="comment">-- 如果重复加载同名文件，不会报错，会自动创建一个*_copy_1.txt</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/hadoop/tmp/employee.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> employee <span class="keyword">partition</span>(date1<span class="operator">=</span><span class="string">&#x27;2018-12-01&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看数据</span></span><br><span class="line"><span class="comment">-- 分区字段也会显示出来，也可以作为查询条件，但它不是原数据内容</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> employee;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> employee <span class="keyword">where</span> date1<span class="operator">=</span><span class="string">&#x27;2018-12-01&#x27;</span>;</span><br></pre></td></tr></table></figure><br />
如果是外部分区表即使有分区的目录结构, 也必须要添加分区,
才能看到相应的数据：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">手动创建一个分区，并添加数据</span></span><br><span class="line">hadoop fs -mkdir /user/hive/warehouse/employee/dt=2018-12-04</span><br><span class="line">hadoop fs -copyFromLocal /tmp/employee.txt /user/hive/warehouse/employee/dt=2018-12-04/employee.txt</span><br></pre></td></tr></table></figure><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 此时查看表中数据发现没有新的分区</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> employee;</span><br><span class="line"><span class="comment">-- 需要更新hive原数据，使分区生效</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> employee <span class="keyword">add</span> if <span class="keyword">not</span> <span class="keyword">exists</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2018-12-04&#x27;</span>);</span><br><span class="line"><span class="comment">-- 此时再次查看才能看到新加入的数据</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure><br />
分区表目的：利用分区表方式减少查询时需要扫描的数据量<br />
（1）分区字段不是表中的列，数据文件中没有对应的列<br />
（2）分区仅仅是一个目录名<br />
（3）查看数据时，hive会自动添加分区列<br />
（4）支持多级分区，多级子目录</p>
<p><strong>动态分区：在写入数据时自动创建分区(包括目录结构)</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> employee2 (name string,salary <span class="type">bigint</span>) partitioned <span class="keyword">by</span> (date1 string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span> stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用动态分区需要设置参数</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入数据时指定分区date1</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> employee2 <span class="keyword">partition</span>(date1) <span class="keyword">select</span> name,salary,date1 <span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure>
<h2 id="hive函数">Hive函数</h2>
<p>在 Hive
有四种类型的运算符：关系运算符、算术运算符、逻辑运算符、复杂运算。和SQL中的运算符差异不大，不讲了。</p>
<p><strong>1、内置函数：<span class="exturl" data-url="aHR0cHM6Ly9jd2lraS5hcGFjaGUub3JnL2NvbmZsdWVuY2UvZGlzcGxheS9IaXZlL0xhbmd1YWdlTWFudWFsK1VERg==">参考手册<i class="fa fa-external-link-alt"></i></span></strong><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 显示所有函数</span></span><br><span class="line"><span class="keyword">show</span> functions;</span><br><span class="line"><span class="comment">-- 描述函数用途</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> 函数名;</span><br><span class="line"><span class="comment">-- 详细描述函数用法</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> extended 函数名;</span><br></pre></td></tr></table></figure><br />
- 简单函数：日期函数、字符串函数、类型转换...<br />
- 统计函数：sum、avg、distinct...<br />
- 集合函数<br />
- 分析函数</p>
<p><strong>2、自定义函数和Transform</strong><br />
当 Hive
提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined
function）。</p>
<p><strong>TRANSFORM</strong>、
<strong>UDF</strong>、<strong>UDAF</strong>：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">it is possible to plug in your own custom mappers and reducers</span><br><span class="line"></span><br><span class="line">A UDF is basically only a transformation done by a mapper meaning that each row should be </span><br><span class="line">mapped to exactly one row. A UDAF on the other hand allows us to transform a group of rows </span><br><span class="line">into one or more rows, meaning that we can reduce the number of input rows to </span><br><span class="line">a single output row by some custom aggregation.</span><br></pre></td></tr></table></figure><br />
<strong>UDF</strong>：就是做一个mapper，对每一条输入数据，映射为一条输出数据。</p>
<p><strong>UDAF</strong>：就是一个reducer，把一组输入数据映射为一条(或多条)输出数据。</p>
<p>一个脚本至于是做mapper还是做reducer，又或者是做udf还是做udaf，取决于我们把它放在什么样的hive操作符中。放在select中的基本就是udf，放在distribute
by和cluster by中的就是reducer。<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">We can control if the script is run in a mapper or reducer </span><br><span class="line">step by the way we formulate our HiveQL query.</span><br><span class="line"></span><br><span class="line">The statements DISTRIBUTE BY and CLUSTER BY allow us to </span><br><span class="line">indicate that we want to actually perform an aggregation.</span><br><span class="line"></span><br><span class="line">User-Defined Functions (UDFs) for transformations and </span><br><span class="line">even aggregations which are therefore called User-Defined Aggregation Functions (UDAFs)</span><br></pre></td></tr></table></figure><br />
<strong>UDF示例(运行java已经编写好的UDF)：</strong><br />
jar加载到hive环境中，jar可以在hdfs上，也可以在本地上。<br />
如果想永久使用，创建FUNCTION时指定jar地址。<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hdfs中创建 /user/hive/lib目录</span></span><br><span class="line">hadoop fs -mkdir /user/hive/lib</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把 hive目录下 lib/hive-contrib-hive-contrib-1.1.0-cdh5.7.0.jar 放到hdfs中</span></span><br><span class="line">hadoop fs -put hive-contrib-1.1.0-cdh5.7.0.jar /user/hive/lib/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把集群中jar包的位置添加到hive中</span></span><br><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">add jar hdfs:///user/hive/lib/hive-contrib-1.1.0-cdh5.7.0.jar;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hive中创建**临时**UDF</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CREATE TEMPORARY FUNCTION 自定义函数名字 as 自定义函数在jar包中的包名</span></span><br><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">CREATE TEMPORARY FUNCTION row_sequence as <span class="string">&#x27;org.apache.hadoop.hive.contrib.udf.UDFRowSequence&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在之前的案例中使用**临时**自定义函数(函数功能: 添加自增长的行号)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意，临时的自定义函数，在退出hive后再进入hive就无效了</span></span><br><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">Select row_sequence(),* from employee;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建**永久的**自定义函数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CREATE FUNCTION 自定义函数名字 as <span class="string">&#x27;自定义函数在jar包中的包名&#x27;</span> using jar <span class="string">&#x27;jar位置&#x27;</span>;</span></span><br><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">CREATE FUNCTION row_sequence as <span class="string">&#x27;org.apache.hadoop.hive.contrib.udf.UDFRowSequence&#x27;</span> \</span></span><br><span class="line"><span class="language-bash">using jar <span class="string">&#x27;hdfs:///user/hive/lib/hive-contrib-1.1.0-cdh5.7.0.jar&#x27;</span>;</span></span><br></pre></td></tr></table></figure><br />
<strong>Python写UDF：</strong><br />
准备案例环境：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span> u2(fname STRING,lname STRING);</span><br><span class="line"><span class="comment">-- 向表中插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;washington&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;bush&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;clinton&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> u2 <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;gates&#x27;</span>);</span><br></pre></td></tr></table></figure><br />
编写map风格脚本：<br />
<figure class="highlight python"><figcaption><span>udf.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    line = line.strip()</span><br><span class="line">    fname , lname = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    l_name = lname.upper()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\t&#x27;</span>.join([fname, <span class="built_in">str</span>(l_name)])</span><br></pre></td></tr></table></figure><br />
通过hdfs向hive中ADD file：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第一种方式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载文件到hdfs</span></span><br><span class="line">hadoop fs -put udf.py /user/hive/lib/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hive从hdfs中加载python脚本</span></span><br><span class="line">ADD FILE hdfs:///user/hive/lib/udf.py;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第二种方式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">直接本地加载脚本</span></span><br><span class="line">ADD FILE /root/tmp/udf1.py;</span><br></pre></td></tr></table></figure><br />
Transform使用Python udf脚本：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> TRANSFORM(fname, lname) <span class="keyword">USING</span> <span class="string">&#x27;python udf1.py&#x27;</span> <span class="keyword">AS</span> (fname, l_name) <span class="keyword">FROM</span> u2;</span><br></pre></td></tr></table></figure></p>
<h2 id="hive综合案例">Hive综合案例</h2>
<p>内容推荐数据处理：<br />
<img src="/images/Hive、Hbase/hive3.png"></p>
<p>需求：根据用户行为、文章标签，筛选出用户最感兴趣(阅读最多)的标签</p>
<p>用户行为数据（用户什么时间阅读了哪篇文章）：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">user_id article_id event_time</span><br><span class="line">11,101,2018-12-01 06:01:10</span><br><span class="line">22,102,2018-12-01 07:28:12</span><br><span class="line">33,103,2018-12-01 07:50:14</span><br><span class="line">11,104,2018-12-01 09:08:12</span><br><span class="line">22,103,2018-12-01 13:37:12</span><br><span class="line">33,102,2018-12-02 07:09:12</span><br><span class="line">11,101,2018-12-02 18:42:12</span><br><span class="line">35,105,2018-12-03 09:21:12</span><br><span class="line">22,104,2018-12-03 16:42:12</span><br><span class="line">77,103,2018-12-03 18:31:12</span><br><span class="line">99,102,2018-12-04 00:04:12</span><br><span class="line">33,101,2018-12-04 19:10:12</span><br><span class="line">11,101,2018-12-05 09:07:12</span><br><span class="line">35,102,2018-12-05 11:00:12</span><br><span class="line">22,103,2018-12-05 12:11:12</span><br><span class="line">77,104,2018-12-05 18:02:02</span><br><span class="line">99,105,2018-12-05 20:09:11</span><br></pre></td></tr></table></figure><br />
文章数据：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">artical_id,artical_url,artical_keywords</span><br><span class="line">101,http://www.itcast.cn/1.html,kw8|kw1</span><br><span class="line">102,http://www.itcast.cn/2.html,kw6|kw3</span><br><span class="line">103,http://www.itcast.cn/3.html,kw7</span><br><span class="line">104,http://www.itcast.cn/4.html,kw5|kw1|kw4|kw9</span><br><span class="line">105,http://www.itcast.cn/5.html,</span><br></pre></td></tr></table></figure><br />
数据上传hdfs：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp/demo</span><br><span class="line">hadoop fs -mkdir /tmp/demo/user_action</span><br></pre></td></tr></table></figure><br />
创建外部表：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 用户行为表user_actions</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> user_actions;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> user_actions(</span><br><span class="line">    user_id STRING,</span><br><span class="line">    article_id STRING,</span><br><span class="line">    time_stamp STRING</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">LOCATION <span class="string">&#x27;/tmp/demo/user_action&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 文章表articles</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> articles;</span><br><span class="line">  <span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> articles(</span><br><span class="line">      article_id STRING,</span><br><span class="line">      url STRING,</span><br><span class="line">      key_words <span class="keyword">array</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span></span><br><span class="line">  )</span><br><span class="line">  <span class="type">ROW</span> FORMAT delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">  COLLECTION ITEMS terminated <span class="keyword">BY</span> <span class="string">&#x27;|&#x27;</span> </span><br><span class="line">  LOCATION <span class="string">&#x27;/tmp/demo/article_keywords&#x27;</span>;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  key_words array&lt;STRING&gt;  数组的数据类型</span></span><br><span class="line"><span class="comment">  COLLECTION ITEMS terminated BY &#x27;|&#x27;  数组的元素之间用&#x27;|&#x27;分割</span></span><br><span class="line"><span class="comment">  */</span></span><br></pre></td></tr></table></figure><br />
查看数据：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> user_actions;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> articles;</span><br></pre></td></tr></table></figure><br />
分组查询每个用户的浏览记录：<br />
collect_set/collect_list：将group
by中的某列转为一个数组返回。collect_list<strong>不去重</strong>而collect_set<strong>去重</strong>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- collect_set</span></span><br><span class="line"><span class="keyword">select</span> user_id,collect_set(article_id) </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      [&quot;101&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">22      [&quot;102&quot;,&quot;103&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">33      [&quot;103&quot;,&quot;102&quot;,&quot;101&quot;]</span></span><br><span class="line"><span class="string">35      [&quot;105&quot;,&quot;102&quot;]</span></span><br><span class="line"><span class="string">77      [&quot;103&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">99      [&quot;102&quot;,&quot;105&quot;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- collect_list</span></span><br><span class="line"><span class="keyword">select</span> user_id,collect_list(article_id) </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      [&quot;101&quot;,&quot;104&quot;,&quot;101&quot;,&quot;101&quot;]</span></span><br><span class="line"><span class="string">22      [&quot;102&quot;,&quot;103&quot;,&quot;104&quot;,&quot;103&quot;]</span></span><br><span class="line"><span class="string">33      [&quot;103&quot;,&quot;102&quot;,&quot;101&quot;]</span></span><br><span class="line"><span class="string">35      [&quot;105&quot;,&quot;102&quot;]</span></span><br><span class="line"><span class="string">77      [&quot;103&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">99      [&quot;102&quot;,&quot;105&quot;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>对数组排序：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 对数组排序：sort_array</span></span><br><span class="line"><span class="keyword">select</span> user_id,sort_array(collect_list(article_id)) <span class="keyword">as</span> contents </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">group</span> <span class="keyword">by</span> user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      [&quot;101&quot;,&quot;101&quot;,&quot;101&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">22      [&quot;102&quot;,&quot;103&quot;,&quot;103&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">33      [&quot;101&quot;,&quot;102&quot;,&quot;103&quot;]</span></span><br><span class="line"><span class="string">35      [&quot;102&quot;,&quot;105&quot;]</span></span><br><span class="line"><span class="string">77      [&quot;103&quot;,&quot;104&quot;]</span></span><br><span class="line"><span class="string">99      [&quot;102&quot;,&quot;105&quot;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
查看每一篇文章的关键字，按标签拆分：lateral view explode<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- explode函数 将 array 拆分</span></span><br><span class="line"><span class="keyword">select</span> explode(key_words) <span class="keyword">from</span> articles;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- lateral view 和 explode 配合使用,将一行数据拆分成多行数据,在此基础上可以对拆分的数据进行聚合</span></span><br><span class="line"><span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles <span class="keyword">lateral</span> <span class="keyword">view</span> explode(key_words) t <span class="keyword">as</span> kw;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">101     kw8</span></span><br><span class="line"><span class="string">101     kw1</span></span><br><span class="line"><span class="string">102     kw6</span></span><br><span class="line"><span class="string">102     kw3</span></span><br><span class="line"><span class="string">103     kw7</span></span><br><span class="line"><span class="string">104     kw5</span></span><br><span class="line"><span class="string">104     kw1</span></span><br><span class="line"><span class="string">104     kw4</span></span><br><span class="line"><span class="string">104     kw9</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">-- outer保留空array</span></span><br><span class="line"><span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">101     kw8</span></span><br><span class="line"><span class="string">101     kw1</span></span><br><span class="line"><span class="string">102     kw6</span></span><br><span class="line"><span class="string">102     kw3</span></span><br><span class="line"><span class="string">103     kw7</span></span><br><span class="line"><span class="string">104     kw5</span></span><br><span class="line"><span class="string">104     kw1</span></span><br><span class="line"><span class="string">104     kw4</span></span><br><span class="line"><span class="string">104     kw9</span></span><br><span class="line"><span class="string">105     NULL</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
根据文章id找到用户查看文章的关键字：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">原始数据</span></span><br><span class="line">101     http://www.itcast.cn/1.html     [&quot;kw8&quot;,&quot;kw1&quot;]</span><br><span class="line">102     http://www.itcast.cn/2.html     [&quot;kw6&quot;,&quot;kw3&quot;]</span><br><span class="line">103     http://www.itcast.cn/3.html     [&quot;kw7&quot;]</span><br><span class="line">104     http://www.itcast.cn/4.html     [&quot;kw5&quot;,&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw9&quot;]</span><br><span class="line">105     http://www.itcast.cn/5.html     []</span><br></pre></td></tr></table></figure><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, b.kw <span class="keyword">from</span> user_actions </span><br><span class="line"><span class="keyword">as</span> a <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a.user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      kw1</span></span><br><span class="line"><span class="string">11      kw8</span></span><br><span class="line"><span class="string">11      kw5</span></span><br><span class="line"><span class="string">11      kw1</span></span><br><span class="line"><span class="string">11      kw4</span></span><br><span class="line"><span class="string">11      kw1</span></span><br><span class="line"><span class="string">11      kw9</span></span><br><span class="line"><span class="string">11      kw8</span></span><br><span class="line"><span class="string">11      kw1</span></span><br><span class="line"><span class="string">11      kw8</span></span><br><span class="line"><span class="string">22      kw1</span></span><br><span class="line"><span class="string">22      kw7</span></span><br><span class="line"><span class="string">22      kw9</span></span><br><span class="line"><span class="string">22      kw4</span></span><br><span class="line"><span class="string">22      kw5</span></span><br><span class="line"><span class="string">22      kw7</span></span><br><span class="line"><span class="string">22      kw3</span></span><br><span class="line"><span class="string">22      kw6</span></span><br><span class="line"><span class="string">33      kw8</span></span><br><span class="line"><span class="string">33      kw1</span></span><br><span class="line"><span class="string">33      kw3</span></span><br><span class="line"><span class="string">33      kw6</span></span><br><span class="line"><span class="string">33      kw7</span></span><br><span class="line"><span class="string">35      NULL</span></span><br><span class="line"><span class="string">35      kw6</span></span><br><span class="line"><span class="string">35      kw3</span></span><br><span class="line"><span class="string">77      kw9</span></span><br><span class="line"><span class="string">77      kw1</span></span><br><span class="line"><span class="string">77      kw7</span></span><br><span class="line"><span class="string">77      kw4</span></span><br><span class="line"><span class="string">77      kw5</span></span><br><span class="line"><span class="string">99      kw3</span></span><br><span class="line"><span class="string">99      kw6</span></span><br><span class="line"><span class="string">99      NULL</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
根据文章id找到用户查看文章的关键字并统计频率：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, b.kw,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> weight </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a.user_id,weight <span class="keyword">desc</span>;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      kw1     4</span></span><br><span class="line"><span class="string">11      kw8     3</span></span><br><span class="line"><span class="string">11      kw5     1</span></span><br><span class="line"><span class="string">11      kw9     1</span></span><br><span class="line"><span class="string">11      kw4     1</span></span><br><span class="line"><span class="string">22      kw7     2</span></span><br><span class="line"><span class="string">22      kw9     1</span></span><br><span class="line"><span class="string">22      kw1     1</span></span><br><span class="line"><span class="string">22      kw3     1</span></span><br><span class="line"><span class="string">22      kw4     1</span></span><br><span class="line"><span class="string">22      kw5     1</span></span><br><span class="line"><span class="string">22      kw6     1</span></span><br><span class="line"><span class="string">33      kw3     1</span></span><br><span class="line"><span class="string">33      kw8     1</span></span><br><span class="line"><span class="string">33      kw7     1</span></span><br><span class="line"><span class="string">33      kw6     1</span></span><br><span class="line"><span class="string">33      kw1     1</span></span><br><span class="line"><span class="string">35      NULL    1</span></span><br><span class="line"><span class="string">35      kw3     1</span></span><br><span class="line"><span class="string">35      kw6     1</span></span><br><span class="line"><span class="string">77      kw1     1</span></span><br><span class="line"><span class="string">77      kw4     1</span></span><br><span class="line"><span class="string">77      kw5     1</span></span><br><span class="line"><span class="string">77      kw7     1</span></span><br><span class="line"><span class="string">77      kw9     1</span></span><br><span class="line"><span class="string">99      NULL    1</span></span><br><span class="line"><span class="string">99      kw3     1</span></span><br><span class="line"><span class="string">99      kw6     1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
CONCAT：返回结果为连接参数产生的字符串。如有任何一个参数为NULL
，则返回值为NULL。<br />
CONCAT_WS：CONCAT With
Separator，是CONCAT()的特殊形式。第一个参数是其它参数的分隔符。分隔符的位置放在要连接的两个字符串之间。分隔符可以是一个字符串，也可以是其它参数。如果分隔符为
NULL，则结果为 NULL。<br />
比如，用户id和文章id做成kv对，使用下面任意一种方法都可以：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- CONCAT(str1,str2,…)  </span></span><br><span class="line"><span class="keyword">select</span> concat(user_id,<span class="string">&#x27;:&#x27;</span>,article_id) <span class="keyword">from</span> user_actions;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- CONCAT_WS(separator,str1,str2,…)</span></span><br><span class="line"><span class="keyword">select</span> concat_ws(<span class="string">&#x27;:&#x27;</span>,user_id,article_id) <span class="keyword">from</span> user_actions;</span><br></pre></td></tr></table></figure><br />
现在将用户查看的关键字和频率合并成kv对形式：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      kw1:4</span></span><br><span class="line"><span class="string">11      kw4:1</span></span><br><span class="line"><span class="string">11      kw5:1</span></span><br><span class="line"><span class="string">11      kw8:3</span></span><br><span class="line"><span class="string">11      kw9:1</span></span><br><span class="line"><span class="string">22      kw1:1</span></span><br><span class="line"><span class="string">22      kw3:1</span></span><br><span class="line"><span class="string">22      kw4:1</span></span><br><span class="line"><span class="string">22      kw5:1</span></span><br><span class="line"><span class="string">22      kw6:1</span></span><br><span class="line"><span class="string">22      kw7:2</span></span><br><span class="line"><span class="string">22      kw9:1</span></span><br><span class="line"><span class="string">33      kw1:1</span></span><br><span class="line"><span class="string">33      kw3:1</span></span><br><span class="line"><span class="string">33      kw6:1</span></span><br><span class="line"><span class="string">33      kw7:1</span></span><br><span class="line"><span class="string">33      kw8:1</span></span><br><span class="line"><span class="string">35      1</span></span><br><span class="line"><span class="string">35      kw3:1</span></span><br><span class="line"><span class="string">35      kw6:1</span></span><br><span class="line"><span class="string">77      kw1:1</span></span><br><span class="line"><span class="string">77      kw4:1</span></span><br><span class="line"><span class="string">77      kw5:1</span></span><br><span class="line"><span class="string">77      kw7:1</span></span><br><span class="line"><span class="string">77      kw9:1</span></span><br><span class="line"><span class="string">99      1</span></span><br><span class="line"><span class="string">99      kw3:1</span></span><br><span class="line"><span class="string">99      kw6:1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
将用户查看的关键字和频率合并成kv对形式并按用户id聚合：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cc.user_id,concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b </span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      kw1:4,kw4:1,kw5:1,kw8:3,kw9:1</span></span><br><span class="line"><span class="string">22      kw1:1,kw3:1,kw4:1,kw5:1,kw6:1,kw7:2,kw9:1</span></span><br><span class="line"><span class="string">33      kw1:1,kw3:1,kw6:1,kw7:1,kw8:1</span></span><br><span class="line"><span class="string">35      1,kw3:1,kw6:1</span></span><br><span class="line"><span class="string">77      kw1:1,kw4:1,kw5:1,kw7:1,kw9:1</span></span><br><span class="line"><span class="string">99      1,kw3:1,kw6:1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
将上面聚合结果转换成map：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- str_to_map转换成map</span></span><br><span class="line"><span class="keyword">select</span> cc.user_id,str_to_map(concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))) <span class="keyword">as</span> wm</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      &#123;&quot;kw1&quot;:&quot;4&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw8&quot;:&quot;3&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">22      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw3&quot;:&quot;1&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;2&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">33      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;1&quot;,&quot;kw8&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">35      &#123;&quot;1&quot;:null,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">77      &#123;&quot;kw1&quot;:&quot;1&quot;,&quot;kw4&quot;:&quot;1&quot;,&quot;kw5&quot;:&quot;1&quot;,&quot;kw7&quot;:&quot;1&quot;,&quot;kw9&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">99      &#123;&quot;1&quot;:null,&quot;kw3&quot;:&quot;1&quot;,&quot;kw6&quot;:&quot;1&quot;&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
将用户的阅读偏好结果保存到表中：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> user_kws <span class="keyword">as</span> </span><br><span class="line"><span class="keyword">select</span> cc.user_id,str_to_map(concat_ws(<span class="string">&#x27;,&#x27;</span>,collect_set(cc.kw_w))) <span class="keyword">as</span> wm</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line"><span class="keyword">select</span> a.user_id, concat_ws(<span class="string">&#x27;:&#x27;</span>,b.kw,<span class="built_in">cast</span> (<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> string)) <span class="keyword">as</span> kw_w </span><br><span class="line"><span class="keyword">from</span> user_actions <span class="keyword">as</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">JOIN</span> (<span class="keyword">select</span> article_id,kw <span class="keyword">from</span> articles</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> explode(key_words) t <span class="keyword">as</span> kw) b</span><br><span class="line"><span class="keyword">on</span> (a.article_id <span class="operator">=</span> b.article_id)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.user_id,b.kw</span><br><span class="line">) <span class="keyword">as</span> cc </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cc.user_id;</span><br></pre></td></tr></table></figure><br />
从表中通过key查询map中的值：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id, wm[<span class="string">&#x27;kw1&#x27;</span>] <span class="keyword">from</span> user_kws;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      4</span></span><br><span class="line"><span class="string">22      1</span></span><br><span class="line"><span class="string">33      1</span></span><br><span class="line"><span class="string">35      NULL</span></span><br><span class="line"><span class="string">77      1</span></span><br><span class="line"><span class="string">99      NULL</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
从表中获取map中所有的 key 和 所有的value :<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,map_keys(wm),map_values(wm) <span class="keyword">from</span> user_kws;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      [&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw8&quot;,&quot;kw9&quot;] [&quot;4&quot;,&quot;1&quot;,&quot;1&quot;,&quot;3&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">22      [&quot;kw1&quot;,&quot;kw3&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw6&quot;,&quot;kw7&quot;,&quot;kw9&quot;]     [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;2&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">33      [&quot;kw1&quot;,&quot;kw3&quot;,&quot;kw6&quot;,&quot;kw7&quot;,&quot;kw8&quot;] [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">35      [&quot;1&quot;,&quot;kw3&quot;,&quot;kw6&quot;]       [null,&quot;1&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">77      [&quot;kw1&quot;,&quot;kw4&quot;,&quot;kw5&quot;,&quot;kw7&quot;,&quot;kw9&quot;] [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">99      [&quot;1&quot;,&quot;kw3&quot;,&quot;kw6&quot;]       [null,&quot;1&quot;,&quot;1&quot;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
用lateral view explode把map中的数据转换成多列：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,keyword,weight <span class="keyword">from</span> user_kws <span class="keyword">lateral</span> <span class="keyword">view</span> explode(wm) t <span class="keyword">as</span> keyword,weight;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">11      kw1     4</span></span><br><span class="line"><span class="string">11      kw4     1</span></span><br><span class="line"><span class="string">11      kw5     1</span></span><br><span class="line"><span class="string">11      kw8     3</span></span><br><span class="line"><span class="string">11      kw9     1</span></span><br><span class="line"><span class="string">22      kw1     1</span></span><br><span class="line"><span class="string">22      kw3     1</span></span><br><span class="line"><span class="string">22      kw4     1</span></span><br><span class="line"><span class="string">22      kw5     1</span></span><br><span class="line"><span class="string">22      kw6     1</span></span><br><span class="line"><span class="string">22      kw7     2</span></span><br><span class="line"><span class="string">22      kw9     1</span></span><br><span class="line"><span class="string">33      kw1     1</span></span><br><span class="line"><span class="string">33      kw3     1</span></span><br><span class="line"><span class="string">33      kw6     1</span></span><br><span class="line"><span class="string">33      kw7     1</span></span><br><span class="line"><span class="string">33      kw8     1</span></span><br><span class="line"><span class="string">35      1       NULL</span></span><br><span class="line"><span class="string">35      kw3     1</span></span><br><span class="line"><span class="string">35      kw6     1</span></span><br><span class="line"><span class="string">77      kw1     1</span></span><br><span class="line"><span class="string">77      kw4     1</span></span><br><span class="line"><span class="string">77      kw5     1</span></span><br><span class="line"><span class="string">77      kw7     1</span></span><br><span class="line"><span class="string">77      kw9     1</span></span><br><span class="line"><span class="string">99      1       NULL</span></span><br><span class="line"><span class="string">99      kw3     1</span></span><br><span class="line"><span class="string">99      kw6     1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="sqoop概述">Sqoop概述</h1>
<p>什么是Sqoop？<br />
（1）Sqoop
是一款进行数据传输的工具，可在hadoop的hdfs&lt;==&gt;关系型数据库之间传输数据。<br />
（2）Sqoop把数据从MySQL或Oracle导入到hdfs中，也可以把数据从hdfs导入到MySQL或Oracle中。<br />
（3）Sqoop可自动执行数据传输的大部分过程，它会把sqoop命令翻译成MapReduce来连接各种数据源实现数据的传递，使用MapReduce导入和导出数据，提供并行操作和容错。</p>
<p>为什么要使用sqoop?<br />
（1）快速实现Hadoop(HDFS/hive/hbase)与mysql/Oracle等关系型数据库之间的数据传递。<br />
（2）Sqoop提供多种数据传输方式。</p>
<p>Sqoop原理：<br />
<img src="/images/Hive、Hbase/sqoop.png" width="50%" height="50%"></p>
<h2 id="sqoop安装">Sqoop安装</h2>
<p>下载<span class="exturl" data-url="aHR0cDovL2FyY2hpdmUuY2xvdWRlcmEuY29tL2NkaDUvY2RoLzUvc3Fvb3AtMS40LjYtY2RoNS43LjAudGFyLmd6">安装包<i class="fa fa-external-link-alt"></i></span>
，解压到centos中：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf /home/hadoop/software/sqoop-1.4.6-cdh5.7.0.tar.gz  -C ~/app/</span><br></pre></td></tr></table></figure><br />
配置环境变量：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi ~/.bash_profile</span></span><br><span class="line">export SQOOP_HOME=/home/hadoop/app/sqoop-1.4.6-cdh5.7.0</span><br><span class="line">export PATH=$SQOOP_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><br />
激活环境变量：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><br />
到 <code>$SQOOP_HOME/conf</code>
目录下配置<code>sqoop_env.sh</code>：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> sqoop-env-template.sh sqoop-env.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi sqoop-env.sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在sqoop_env.sh中添加：</span></span><br><span class="line">export HADOOP_COMMON_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/</span><br><span class="line">export HADOOP_MAPRED_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/</span><br><span class="line">export HIVE_HOME=/home/hadoop/app/hive-1.1.0-cdh5.7.0/</span><br></pre></td></tr></table></figure><br />
拷贝mysql驱动到<code>$SQOOP_HOME/lib</code>目录下：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /home/hadoop/app/hive-1.1.0-cdh5.7.0/lib/mysql-connector-java-5.1.47.jar /home/hadoop/app/sqoop-1.4.6-cdh5.7.0/lib/</span></span><br></pre></td></tr></table></figure><br />
测试sqoop环境：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sqoop-version</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">看到如下输出 说明sqoop安装成功</span></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">Sqoop 1.4.6-cdh5.7.0</span><br><span class="line">git commit id</span><br><span class="line">Compiled by jenkins on ******</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure></p>
<h2 id="使用sqoop导入数据到hdfs中">使用Sqoop导入数据到hdfs中</h2>
<p>准备mysql数据:<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 建表u</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span> u3(id <span class="type">int</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,fname <span class="type">varchar</span>(<span class="number">20</span>),lname <span class="type">varchar</span>(<span class="number">20</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">--插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> u3 (fname, lname) <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;washington&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> u3 (fname, lname) <span class="keyword">values</span>(<span class="string">&#x27;George&#x27;</span>,<span class="string">&#x27;bush&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> u3 (fname, lname) <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;clinton&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> u3 (fname, lname) <span class="keyword">values</span>(<span class="string">&#x27;Bill&#x27;</span>,<span class="string">&#x27;gates&#x27;</span>);</span><br></pre></td></tr></table></figure><br />
- Sqoop导入命令<br />
- 命令语法：<code>sqoop import (控制参数) (导入参数)</code><br />
- 命令元素：导入操作, 数据源, 访问方式, 导入控制, 目标地址<br />
- 命令理解：数据从哪里来, 有什么控制, 到哪里去</p>
<p>使用Sqoop命令把表u3导入到hdfs上，默认导入到hdfs的<code>/user/linux用户名</code>文件夹下。<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">jdbc:mysql://mysql数据库地址:3306/数据库名字</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--table 要导出数据的表名</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-m mrjob的数量，文件分成几份存储在hdfs上</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sqoop import --connect jdbc:mysql://127.0.0.1:3306/test --username root --password 123456 --table u3 -m 1</span></span><br></pre></td></tr></table></figure><br />
添加<code>--target-dir</code>指定导出到hdfs上的地址：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">jdbc:mysql://mysql数据库地址:3306/数据库名字</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--table 要导出数据的表名 -m mrjob的数量</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sqoop import --connect jdbc:mysql://127.0.0.1:3306/test --username root --password 123456 --table u3 --target-dir /tmp/u1 -m 1</span></span><br></pre></td></tr></table></figure><br />
导入可能出现的问题：<br />
<img src="/images/Hive、Hbase/error.png"></p>
<p>解决方法1：上传<code>java-json.jar</code>到<code>$SQOOP_HOME/lib</code>目录下。注意,默认数据上传到hdfs的路径是<code>/user/当前linux用户名/mysql表名/</code>。</p>
<p>解决方法2：通过hive建立外表导入数据到hive。<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> u4(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    fname STRING,</span><br><span class="line">    lname STRING</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">LOCATION <span class="string">&#x27;/user/hadoop/u/&#x27;</span>;</span><br></pre></td></tr></table></figure><br />
# HBase概述<br />
<strong>1、什么是HBase？</strong><br />
- HBase是一个<strong>分布式的、面向列</strong>的开源数据库。<br />
- HBase是Google BigTable的开源实现。<br />
- HBase不同于一般的关系数据库, 适合非结构化数据存储。</p>
<p><strong>2、BigTable</strong><br />
-
BigTable是Google设计的分布式数据存储系统，用来处理海量的数据的一种非关系型的数据库。<br />
- 适合大规模海量数据，PB级数据；<br />
- 分布式、并发数据处理，效率极高（可以支撑在线业务）；<br />
- 易于扩展，支持动态伸缩；<br />
- 适用于廉价设备；<br />
- 不适用于传统关系型数据的存储；</p>
<p><strong>3、什么是非结构化数据存储？</strong><br />
- 结构化数据<br />
-
可预定义的数据模型，模型一旦确定不会经常变化（表结构不会频繁调整）<br />
- 适合用二维表来展示的数据<br />
- 非结构化数据<br />
- 没有预定义的数据模型<br />
- 数据结构不规则或不完整的<br />
- 不方便用数据库二维逻辑表来表现<br />
- 办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等</p>
<p><strong>4、HBase在Hadoop生态中的地位</strong><br />
- HBase是Apache基金会顶级项目<br />
- HBase基于HDFS进行数据存储<br />
- HBase可以存储超大数据并适合用来进行大数据的实时查询<br />
<img src="/images/Hive、Hbase/hbase&hive.png" width="50%" height="50%"></p>
<p><strong>5、Hive和Hbase共同点、区别？</strong><br />
- 共同点<br />
- 都可以处理海量数据<br />
- 文件都是保存到hdfs上<br />
- 区别<br />
-
hive通过mapreduce实现数据查询功能。hbase计算不是通过mapreduce实现的，它自己实现的CRUD功能。<br />
- hive只能做离线计算，hbase提供对数据的随机实时读/写访问功能<br />
- hbase可以有集群，集群的管理是通过zookeeper实现<br />
- HBase 对事务的支持 只支持行级别的事务<br />
- CAP定理<br />
- 分区容错性 分布式系统都要有的特性，任何时候都要能提供服务 P保证<br />
- HBase CP系统 强一致性</p>
<p><strong>6、HBase与HDFS</strong><br />
- HBase建立在Hadoop文件系统上, 利用了HDFS的容错能力<br />
- HBase提供对数据的随机实时读/写访问功能<br />
- HBase内部使用哈希表, 并存储索引, 可以快速查找HDFS中数据</p>
<p><strong>7、HBase使用场景</strong><br />
- 瞬间写入量很大<br />
- 大量数据需要长期保存, 且数量会持续增长<br />
- HBase不适合有join, 多级索引, 表关系复杂的数据模型</p>
<h2 id="hbase与关系型数据库的区别">HBase与关系型数据库的区别</h2>
<table>
<tr>
<th>
</th>
<th>
HBase
</th>
<th>
关系型数据库
</th>
</tr>
<tr>
<td>
数据库大小
</td>
<td>
PB级别
</td>
<td>
GB TB
</td>
</tr>
<tr>
<td>
数据类型
</td>
<td>
Bytes
</td>
<td>
丰富的数据类型
</td>
</tr>
<tr>
<td>
事务支持
</td>
<td>
ACID只支持单个Row级别
</td>
<td>
全面的ACID支持, 对Row和表
</td>
</tr>
<tr>
<td>
索引
</td>
<td>
只支持Row-key
</td>
<td>
支持
</td>
</tr>
<tr>
<td>
吞吐量
</td>
<td>
百万写入/秒
</td>
<td>
数千写入/秒
</td>
</tr>
</table>
关系型数据库中：<br />

<table>
<tr>
<th>
ID
</th>
<th>
FILE NAME
</th>
<th>
FILE PATH
</th>
<th>
FILE TYPE
</th>
<th>
FILE SIZE
</th>
<th>
CREATOR
</th>
</tr>
<tr>
<td>
1
</td>
<td>
file1.txt
</td>
<td>
/home
</td>
<td>
txt
</td>
<td>
1024
</td>
<td>
tom
</td>
</tr>
<tr>
<td>
2
</td>
<td>
file2.txt
</td>
<td>
/home/pics
</td>
<td>
jpg
</td>
<td>
5032
</td>
<td>
jerry
</td>
</tr>
</table>
列式数据库中：<br />

<table>
<tr>
<th>
RowKey
</th>
<th>
FILE INFO
</th>
<th>
SAVE INFO
</th>
</tr>
<tr>
<td>
1
</td>
<td>
name:file1.txt<br><br />
type:txt<br><br />
size:1024
</td>
<td>
path:/home/pics<br><br />
creator:Jerry<br>
</td>
</tr>
<tr>
<td>
2
</td>
<td>
name:file2.jpg<br><br />
type:jpg<br><br />
size:5032
</td>
<td>
path:/home<br><br />
creator:Tom
</td>
</tr>
</table>
<p>行数据库、列数据库，存储方式比较：<br />
<img src="/images/Hive、Hbase/hbase4.png" width="60%" height="60%"></p>
<p><strong>1、ACID定义</strong><br />
指数据库事务正确执行的四个基本要素的缩写：<br />
- 原子性 A<br />
-
整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。<br />
- 一致性 C<br />
-
一个事务可以封装状态改变（除非它是一个只读的）。事务必须始终保持系统处于一致的状态，不管在任何给定的时间[<strong>并发</strong>事务有多少。<br />
- 隔离性 I<br />
-
隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。<br />
- 持久性 D<br />
-
在事务完成以后，该事务对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。</p>
<p><strong>HBase 支持特定场景下的 ACID，即对行级别的 操作保证完全的
ACID</strong>。</p>
<p><strong>2、cap定理</strong><br />
分布式系统的最大难点，就是各个节点的状态如何同步。CAP
定理是这方面的基本定理，也是理解分布式系统的起点。</p>
<p><strong>hbase是CAP中的CP系统,即hbase是强一致性的，牺牲了一定可用性（即会有延时）。</strong></p>
<ul>
<li><p><strong>一致性</strong>：所有节点在同一时间具有相同的数据。会牺牲一定可用性，因为需要一定时间同步数据。<br />
<img src="/images/Hive、Hbase/Consistency.png" width="30%" height="30%"></p></li>
<li><p><strong>可用性</strong>：保证每个请求不管成功或失败都有响应,但不保证获取的数据的正确性。如果请求立即响应，会牺牲一定一致性，因为立即响应返回的数据，不一定是同步的数据。</p></li>
<li><p><strong>分区容错性</strong>：系统中任意信息的丢失或失败不会影响系统的运行,系统如果不能在某个时限内达成数据一致性,就必须在上面两个操作之间做出选择。<br />
<img src="/images/Hive、Hbase/cap.jpg" width="30%" height="30%"></p></li>
</ul>
<h2 id="hbase的数据模型">HBase的数据模型</h2>
<ul>
<li><strong>NameSpace</strong>：关系型数据库的"数据库"(database)。</li>
<li><strong>表(table)</strong>：用于存储管理数据，具有稀疏的、面向列的特点。HBase中的每一张表，就是所谓的大表。(Bigtable)，可以有上亿行，上百万列。对于为值为空的列，并不占用存储空间，因此表可以设计的非常稀疏。</li>
<li><strong>行(Row)</strong>：在表里面,每一行代表着一个数据对象,每一行都是以一个行键(Row
Key)来进行唯一标识的, 行键并没有什么特定的数据类型,
以二进制的字节来存储。</li>
<li><strong>列(Column)</strong>：HBase的列由 Column family 和 Column
qualifier 指定, 由冒号:进行行间隔, 格式为 family: qualifier:
value。</li>
<li><strong>行键(RowKey)</strong>：类似于MySQL中的主键，HBase根据行键来快速检索数据，一个行键对应一条记录。与MySQL主键不同的是，HBase的行键是天然固有的，每一行数据都存在行键。</li>
<li><strong>列族(ColumnFamily)</strong>：是列的集合。列族在表定义时需要指定，而列在插入数据时动态指定。列中的数据都是以二进制形式存在，没有数据类型。在物理存储结构上，每个表中的每个列族单独以一个文件存储。一个表可以有多个列簇。</li>
<li><strong>列修饰符(Column
Qualifier)</strong>：列族中的数据通过列标识来进行映射,
可以理解为一个键值对。(key-value), 列修饰符(Column Qualifier) 就是key
对应关系型数据库的列。</li>
<li><strong>时间戳(TimeStamp)</strong>：是列的一个属性，是一个64位整数。由行键和列确定的单元格，可以存储多个数据，每个数据含有时间戳属性，数据具有版本特性。可根据版本(VERSIONS)或时间戳来指定查询历史版本数据，如果都不指定，则默认返回最新版本的数据。</li>
<li><strong>区域(Region)</strong>：HBase自动把表水平划分成的多个区域，划分的区域随着数据的增大而增多。</li>
<li>HBase支持特定场景下的 ACID，即对行级别的 操作保证完全的 ACID。</li>
</ul>
<h2 id="hbase基础架构">HBase基础架构</h2>
<p><img src="/images/Hive、Hbase/structure.jpg" width="90%" height="90%"></p>
<p><strong>Client</strong><br />
（1）与zookeeper通信, 找到数据入口地址<br />
（2）使用HBase RPC机制与HMaster和HRegionServer进行通信；<br />
（3）Client与HMaster进行通信进行管理类操作；<br />
（4）Client与HRegionServer进行数据读写类操作。</p>
<p><strong>Zookeeper</strong><br />
（1）保证任何时候，集群中只有一个running
master，避免单点问题。即保证HMaster有一个活着；<br />
（2）所有HRegionServer、HMaster地址存储；<br />
（3）实时监控Region Server的状态，将Region
server的上线和下线信息，实时通知给Master；<br />
（4）存储Hbase的schema，即元数据存储。包括有哪些table，每个table有哪些column
family。</p>
<p><strong>HMaster</strong><br />
可以启动多个HMaster，通过Zookeeper的Master
Election机制保证总有一个Master运行。</p>
<p>角色功能：<br />
（1）为Region server分配region；<br />
（2）负责region server的负载均衡；<br />
（3）发现失效的region serve并重新分配其上的region；<br />
（4）HDFS上的垃圾文件回收；<br />
（5）处理用户对表的增删改查操作。</p>
<p><strong>HRegionServer</strong><br />
HBase中最核心的模块，主要负责响应用户I/O请求，向HDFS文件系统中读写数据。</p>
<p>作用：<br />
（1）维护Master分配给它的region，处理对这些region的IO请求；<br />
（2）负责切分在运行过程中变得过大的region。<br />
（3）此外，HRegionServer管理一系列HRegion对象，每个HRegion对应Table中一个Region，HRegion由多个HStore组成，每个HStore对应Table中一个Column
Family的存储，Column
Family就是一个集中的存储单元，故将具有相同IO特性的Column放在一个Column
Family会更高效。</p>
<p><strong>HStore</strong><br />
HBase存储的核心，由MemStore和StoreFile组成。每一个column family
对应了一个HStore。<br />
<img src="/images/Hive、Hbase/2.png" width="60%" height="60%"></p>
<p>用户写入数据的流程为：client访问ZK-&gt;ZK返回RegionServer地址-&gt;client访问RegionServer写入数据-&gt;
数据存入MemStore，一直到MemStore满-&gt;Flush成StoreFile。</p>
<p><strong>HRegion</strong><br />
（1）一个表最开始存储的时候，是一个region。<br />
（2）一个Region中会有个多个store，每个store用来存储一个列簇。如果只有一个column
family，就只有一个store。<br />
（3）region会随着插入的数据越来越多，会进行拆分。默认大小是10G一个。</p>
<p><strong>HLog</strong><br />
在分布式系统环境中，无法避免系统出错或者宕机，一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。</p>
<h2 id="hbase模块协作">HBase模块协作</h2>
<ul>
<li>HBase启动
<ul>
<li>HMaster启动, 注册到Zookeeper, 等待RegionServer汇报</li>
<li>RegionServer注册到Zookeeper, 并向HMaster汇报</li>
<li>对各个RegionServer(包括失效的)的数据进行整理,
分配Region和meta信息</li>
</ul></li>
<li>RegionServer失效
<ul>
<li>HMaster将失效RegionServer上的Region分配到其他节点</li>
<li>HMaster更新hbase: meta 表以保证数据正常访问</li>
</ul></li>
<li>HMaster失效
<ul>
<li>处于Backup状态的其他HMaster节点推选出一个转为Active状态</li>
<li>数据能正常读写, 但是不能创建删除表, 也不能更改表结构</li>
</ul></li>
</ul>
<h2 id="hbase的安装">HBase的安装</h2>
<p>下载<span class="exturl" data-url="aHR0cDovL2FyY2hpdmUuY2xvdWRlcmEuY29tL2NkaDUvY2RoLzUvaGJhc2UtMS4yLjAtY2RoNS43LjAudGFyLmd6">安装包<i class="fa fa-external-link-alt"></i></span>，配置伪分布式环境：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">环境变量配置</span></span><br><span class="line">export HBASE_HOME=/usr/local/development/hbase-1.2.4</span><br><span class="line">export PATH=$HBASE_HOME/bin:$PATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置hbase-env.sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HBASE_MANAGES_ZK：如果你是使用hbase自带的zk就是<span class="literal">true</span>，如果使用自己的zk就是<span class="literal">false</span></span></span><br><span class="line">export JAVA_HOME=/usr/local/development/jdk1.7.0_15</span><br><span class="line">export HBASE_MANAGES_ZK=false  </span><br></pre></td></tr></table></figure><br />
配置hbase-site.xml：<br />
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>　　--hbase持久保存的目录</span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop001:8020/opt/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  --是否是分布式</span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>     </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    --指定要连接zk的端口</span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>            </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/hbase/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>          </span><br></pre></td></tr></table></figure><br />
启动hbase（启动的hbase的时候要保证hadoop集群已经启动）：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/hbase/bin/start-hbase.sh</span><br></pre></td></tr></table></figure><br />
输入hbase shell（进入shell命令行）。</p>
<h2 id="hbase-shell">HBase shell</h2>
HBase DDL 和 DML 命令：<br />

<table>
<tr>
<th>
名称
</th>
<th>
命令表达式
</th>
</tr>
<tr>
<td>
创建表
</td>
<td>
create '表名', '列族名1','列族名2','列族名n'
</td>
</tr>
<tr>
<td>
添加记录
</td>
<td>
put '表名','行名','列名:','值
</td>
</tr>
<tr>
<td>
查看记录
</td>
<td>
get '表名','行名'
</td>
</tr>
<tr>
<td>
查看表中的记录总数
</td>
<td>
count '表名'
</td>
</tr>
<tr>
<td>
删除记录
</td>
<td>
delete '表名', '行名','列名'
</td>
</tr>
<tr>
<td>
删除一张表
</td>
<td>
第一步 disable '表名' 第二步 drop '表名'
</td>
</tr>
<tr>
<td>
查看所有记录
</td>
<td>
scan "表名称"
</td>
</tr>
<tr>
<td>
查看指定表指定列所有数据
</td>
<td>
scan '表名' ,{COLUMNS=&gt;'列族名:列名'}
</td>
</tr>
<tr>
<td>
更新记录
</td>
<td>
重写覆盖
</td>
</tr>
</table>
<p>连接集群：<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure><br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="comment">-- create 表名 列族</span></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;base_info&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除表</span></span><br><span class="line">disable <span class="string">&#x27;user&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;user&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建名称空间</span></span><br><span class="line">create_namespace <span class="string">&#x27;test&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 展示现有名称空间</span></span><br><span class="line">list_namespace</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建表的时候添加namespace</span></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test:user&#x27;</span>,<span class="string">&#x27;base_info&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 显示某个名称空间下有哪些表</span></span><br><span class="line">list_namespace_tables <span class="string">&#x27;test&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入数据：put &#x27;表名&#x27;,&#x27;rowkey的值&#x27;,&#x27;列族:列标识符&#x27;,&#x27;值&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Tom&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:birthday&#x27;</span>,<span class="string">&#x27;2014-07-10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>,<span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:address&#x27;</span>,<span class="string">&#x27;Tokyo&#x27;</span></span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Mike&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info:birthday&#x27;</span>,<span class="string">&#x27;2014-07-10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>,<span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info:address&#x27;</span>,<span class="string">&#x27;beijing&#x27;</span></span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_22&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Jerry&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_22&#x27;</span>,<span class="string">&#x27;base_info:birthday&#x27;</span>,<span class="string">&#x27;2014-07-10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_22&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>,<span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_22&#x27;</span>,<span class="string">&#x27;base_info:address&#x27;</span>,<span class="string">&#x27;Newyork&#x27;</span></span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_24&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Nico&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_24&#x27;</span>,<span class="string">&#x27;base_info:birthday&#x27;</span>,<span class="string">&#x27;2014-07-10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_24&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>,<span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_24&#x27;</span>,<span class="string">&#x27;base_info:address&#x27;</span>,<span class="string">&#x27;shanghai&#x27;</span></span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_25&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Rose&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_25&#x27;</span>,<span class="string">&#x27;base_info:birthday&#x27;</span>,<span class="string">&#x27;2014-07-10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_25&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>,<span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_25&#x27;</span>,<span class="string">&#x27;base_info:address&#x27;</span>,<span class="string">&#x27;Soul&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询表中的所有数据</span></span><br><span class="line">scan <span class="string">&#x27;user&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询某个rowkey的数据</span></span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询某个列簇的数据</span></span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info&#x27;</span></span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_16&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span></span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;rowkey_16&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> [<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;base_info:sex&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除表中的数据</span></span><br><span class="line"><span class="keyword">delete</span> <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;rowkey_16&#x27;</span>, <span class="string">&#x27;base_info:username&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 清空数据</span></span><br><span class="line"><span class="keyword">truncate</span> <span class="string">&#x27;user&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 操作列簇</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;user&#x27;</span>, NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f2&#x27;</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;delete&#x27;</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 修改数据</span></span><br><span class="line">put <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,<span class="string">&#x27;base_info:username&#x27;</span>,<span class="string">&#x27;Tom&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 指定显示多个版本</span></span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;rowkey_10&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;base_info:username&#x27;</span>,VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 修改可以显示的版本数量</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;user&#x27;</span>,NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;base_info&#x27;</span>,VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">10</span></span><br></pre></td></tr></table></figure><br />
HBase追加型数据库，会保留多个版本数据：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- VERSIONS=&gt;&#x27;1&#x27;  &#x27;1&#x27;说明最多可以显示一个版本</span></span><br><span class="line"><span class="keyword">desc</span> <span class="string">&#x27;user&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Table user is ENABLED</span></span><br><span class="line"><span class="string">user</span></span><br><span class="line"><span class="string">COLUMN FAMILIES DESCRIPTION</span></span><br><span class="line"><span class="string">&#123;NAME =&gt; &#x27;</span>base_info<span class="string">&#x27;, VERSIONS =&gt; &#x27;</span><span class="number">1</span><span class="string">&#x27;, EVICT_BLOCKS_ON_CLOSE =&gt; &#x27;</span><span class="literal">false</span><span class="string">&#x27;, NEW_VERSION_B</span></span><br><span class="line"><span class="string">HE_DATA_ON_WRITE =&gt; &#x27;</span><span class="literal">false</span><span class="string">&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;</span><span class="keyword">NONE</span><span class="string">&#x27;, TTL =&gt; &#x27;</span>FOREVER<span class="string">&#x27;, MI</span></span><br><span class="line"><span class="string">ER =&gt; &#x27;</span><span class="keyword">NONE</span><span class="string">&#x27;, CACHE_INDEX_ON_WRITE =&gt; &#x27;</span><span class="literal">false</span><span class="string">&#x27;, IN_MEMORY =&gt; &#x27;</span><span class="literal">false</span><span class="string">&#x27;, CACHE_BLOOM</span></span><br><span class="line"><span class="string">se&#x27;</span>, COMPRESSION <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;NONE&#x27;</span>, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, BLOCKSIZE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;65536&#x27;</span>&#125;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
命令表：<br />
<img src="/images/Hive、Hbase/Hbase命令表.jpg" width="60%" height="60%"></p>
<p>可以通过HbaseUi界面查看表的信息，端口60010打不开的情况，是因为hbase
1.0 以后的版本，需要自己手动配置，在文件hbase-site中。<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;  </span><br><span class="line">&lt;name&gt;hbase.master.info.port&lt;/name&gt;  </span><br><span class="line">&lt;value&gt;60010&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt; </span><br></pre></td></tr></table></figure><br />
## Hive on HBase<br />
（1）HBase 用于在线业务服务, 不适合做统计分析<br />
（2）Hive 适合数据分析 统计<br />
Hive on
HBase适合数据导入查询，不适合数据分析（涉及到MapReduce速度会慢下来）。</p>
<p>Hive表与HBase表之间需要建立映射关系：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hbase_table_1(key <span class="type">int</span>, <span class="keyword">value</span> string) </span><br><span class="line">STORED <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span> </span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (&quot;hbase.columns.mapping&quot;<span class="operator">=</span>&quot;:key,cf1:val&quot;) </span><br><span class="line">TBLPROPERTIES(&quot;hbase.table.name&quot;<span class="operator">=</span>&quot;xyz&quot;);</span><br></pre></td></tr></table></figure><br />
不支持load data导入数据, 要用insert 方式创建新表加载数据<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/1.txt&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> a;</span><br><span class="line"><span class="keyword">insert</span> overwrite tabale hbase_a <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a;</span><br></pre></td></tr></table></figure></p>
<p><strong>Hive on HBase示例</strong><br />
创建student1表，通过hive中创建在hbase中也会同时创建：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student1</span><br><span class="line">(<span class="keyword">no</span> string,</span><br><span class="line">classno string,</span><br><span class="line">stuno string,</span><br><span class="line">score <span class="type">int</span></span><br><span class="line">)</span><br><span class="line">STORED <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span> </span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES </span><br><span class="line">(&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;:key,stuinfo:classno,stuinfo:stuno,stuinfo:score&quot;)</span><br><span class="line">TBLPROPERTIES (&quot;hbase.table.name&quot;<span class="operator">=</span>&quot;student&quot;);</span><br><span class="line"><span class="comment">-- Hbase中创建的表，表名为student</span></span><br></pre></td></tr></table></figure><br />
将查询的数据insert到student1表中：<br />
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student1</span><br><span class="line"><span class="keyword">select</span> reverse(classno) <span class="keyword">as</span> key,classno,stuno,score <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure></p>
<h2 id="happybase操作hbase">HappyBase操作Hbase</h2>
<p>什么是HappyBase？<br />
HappyBase是FaceBook员工开发的操作HBase的Python库, 其基于Python Thrift,
但使用方式比Thrift简单。官网介绍为：</p>
<p><strong>HappyBase</strong> is a developer-friendly <span class="exturl" data-url="aHR0cDovL3B5dGhvbi5vcmcv">Python<i class="fa fa-external-link-alt"></i></span> library to interact with <span class="exturl" data-url="aHR0cDovL2hiYXNlLmFwYWNoZS5vcmcv">Apache HBase<i class="fa fa-external-link-alt"></i></span>. HappyBase is designed
for use in standard HBase setups, and offers application developers a
Pythonic API to interact with HBase. Below the surface, HappyBase uses
the <span class="exturl" data-url="aHR0cDovL3B5cGkucHl0aG9uLm9yZy9weXBpL3RocmlmdA==">Python Thrift
library<i class="fa fa-external-link-alt"></i></span> to connect to HBase using its <span class="exturl" data-url="aHR0cDovL3RocmlmdC5hcGFjaGUub3JnLw==">Thrift<i class="fa fa-external-link-alt"></i></span> gateway, which is included
in the standard HBase 0.9x releases.</p>
<p>使用前，先pip安装下<code>pip install happybase</code>。然后就可以启动第三方服务使用了：<br />
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hbase thrift server</span></span><br><span class="line">hbase-daemon.sh start thrift</span><br></pre></td></tr></table></figure><br />
windows系统问题：happybase1.0在win下不支持绝对路径。<br />
解决办法：将出问题的文件488行的url_scheme == ”改为url_scheme in
(‘代码盘符’, ”)</p>
<p><strong>如何使用HappyBase？</strong><br />
<strong>建立连接：</strong><br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line">connection = happybase.Connection(<span class="string">&#x27;somehost&#x27;</span>)</span><br></pre></td></tr></table></figure><br />
当连接建立时，会自动创建一个与 HBase Thrift server的socket链接。<br />
可以通过参数禁止自动链接，然后再需要连接是调用 <a
target="_blank" rel="noopener" href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection.open"><code>Connection.open()</code></a>:<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">connection = happybase.Connection(<span class="string">&#x27;somehost&#x27;</span>, autoconnect=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># before first use:</span></span><br><span class="line">connection.<span class="built_in">open</span>()</span><br></pre></td></tr></table></figure><br />
<a
target="_blank" rel="noopener" href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection"><code>Connection</code></a>
这个类提供了一个与HBase交互的入口， 比如获取HBase中所有的表：<a
target="_blank" rel="noopener" href="https://happybase.readthedocs.io/en/latest/api.html#happybase.Connection.tables"><code>Connection.tables()</code></a>:<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(connection.tables())</span><br></pre></td></tr></table></figure><br />
<strong>操作表：</strong><br />
Table类提供了大量API, 这些API用于检索和操作HBase中的数据。<br />
在上面的示例中，已经使用<code>Connection.tables()</code>方法查询HBase中的表。
如果还没有任何表，可使用<code>Connection.create_table()</code>创建一个新表：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.create_table(<span class="string">&#x27;users&#x27;</span>,&#123;<span class="string">&#x27;cf1&#x27;</span>: <span class="built_in">dict</span>()&#125;)</span><br></pre></td></tr></table></figure><br />
创建表之后可以传入表名获取到Table类的实例:<br />
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table = connection.table(&#x27;mytable&#x27;)</span><br></pre></td></tr></table></figure><br />
查询操作：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># api</span></span><br><span class="line">table.scan() <span class="comment">#全表查询</span></span><br><span class="line">table.row(row_keys[<span class="number">0</span>]) <span class="comment"># 查询一行</span></span><br><span class="line">table.rows(row_keys) <span class="comment"># 查询多行</span></span><br><span class="line"><span class="comment">#封装函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_rows</span>(<span class="params">table, row_keys=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> row_keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show value of row named %s&#x27;</span> % row_keys)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(row_keys) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(table.row(row_keys[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(table.rows(row_keys))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show all row values of table named %s&#x27;</span> % table.name)</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> table.scan():</span><br><span class="line">            <span class="built_in">print</span>(key, value)</span><br></pre></td></tr></table></figure><br />
插入数据：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">table.put(row_key, &#123;cf:cq:value&#125;)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put_row</span>(<span class="params">table, column_family, row_key, value</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert one row to hbase&#x27;</span>)</span><br><span class="line">    <span class="comment">#put &#x27;user&#x27;,&#x27;rowkey_10&#x27;,&#x27;base_info:username&#x27;,&#x27;Tom&#x27;</span></span><br><span class="line">    <span class="comment">#&#123;&#x27;cf:cq&#x27;:’数据‘&#125;</span></span><br><span class="line">    table.put(row_key, &#123;<span class="string">&#x27;%s:name&#x27;</span> % column_family:<span class="string">&#x27;name_%s&#x27;</span> % value&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put_rows</span>(<span class="params">table, column_family, row_lines=<span class="number">30</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert rows to hbase now&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row_lines):</span><br><span class="line">        put_row(table, column_family, <span class="string">&#x27;row_%s&#x27;</span> % i, i)</span><br></pre></td></tr></table></figure><br />
删除数据：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">table.delete(row_key, cf_list)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#函数封装    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_row</span>(<span class="params">table, row_key, column_family=<span class="literal">None</span>, keys=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete keys:%s from row_key:%s&#x27;</span> % (keys, row_key))</span><br><span class="line">        key_list = [<span class="string">&#x27;%s:%s&#x27;</span> % (column_family, key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">        table.delete(row_key, key_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete row(column_family:) from hbase&#x27;</span>)</span><br><span class="line">        table.delete(row_key)</span><br></pre></td></tr></table></figure><br />
删除表：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#api</span></span><br><span class="line">conn.delete_table(table_name, <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#函数封装</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_table</span>(<span class="params">table_name</span>):</span><br><span class="line">    pretty_print(<span class="string">&#x27;delete table %s now.&#x27;</span> % table_name)</span><br><span class="line">    conn.delete_table(table_name, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br />
完整代码：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line"></span><br><span class="line">hostname = <span class="string">&#x27;192.168.199.188&#x27;</span></span><br><span class="line">table_name = <span class="string">&#x27;users&#x27;</span></span><br><span class="line">column_family = <span class="string">&#x27;cf&#x27;</span></span><br><span class="line">row_key = <span class="string">&#x27;row_1&#x27;</span></span><br><span class="line"></span><br><span class="line">conn = happybase.Connection(hostname)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_tables</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;show all tables now&#x27;</span>)</span><br><span class="line">    tables =  conn.tables()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> tables:</span><br><span class="line">        <span class="built_in">print</span> t</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_table</span>(<span class="params">table_name, column_family</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;create table %s&#x27;</span> % table_name)</span><br><span class="line">    conn.create_table(table_name, &#123;column_family:<span class="built_in">dict</span>()&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_rows</span>(<span class="params">table, row_keys=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> row_keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show value of row named %s&#x27;</span> % row_keys)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(row_keys) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span> table.row(row_keys[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span> table.rows(row_keys)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;show all row values of table named %s&#x27;</span> % table.name)</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> table.scan():</span><br><span class="line">            <span class="built_in">print</span> key, value</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put_row</span>(<span class="params">table, column_family, row_key, value</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert one row to hbase&#x27;</span>)</span><br><span class="line">    table.put(row_key, &#123;<span class="string">&#x27;%s:name&#x27;</span> % column_family:<span class="string">&#x27;name_%s&#x27;</span> % value&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put_rows</span>(<span class="params">table, column_family, row_lines=<span class="number">30</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;insert rows to hbase now&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row_lines):</span><br><span class="line">        put_row(table, column_family, <span class="string">&#x27;row_%s&#x27;</span> % i, i)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_row</span>(<span class="params">table, row_key, column_family=<span class="literal">None</span>, keys=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete keys:%s from row_key:%s&#x27;</span> % (keys, row_key))</span><br><span class="line">        key_list = [<span class="string">&#x27;%s:%s&#x27;</span> % (column_family, key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">        table.delete(row_key, key_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;delete row(column_family:) from hbase&#x27;</span>)</span><br><span class="line">        table.delete(row_key)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_table</span>(<span class="params">table_name</span>):</span><br><span class="line">    pretty_print(<span class="string">&#x27;delete table %s now.&#x27;</span> % table_name)</span><br><span class="line">    conn.delete_table(table_name, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pool</span>():</span><br><span class="line">    pretty_print(<span class="string">&#x27;test pool connection now.&#x27;</span>)</span><br><span class="line">    pool = happybase.ConnectionPool(size=<span class="number">3</span>, host=hostname)</span><br><span class="line">    <span class="keyword">with</span> pool.connection() <span class="keyword">as</span> connection:</span><br><span class="line">        <span class="built_in">print</span> connection.tables()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># show_tables()</span></span><br><span class="line">    <span class="comment"># create_table(table_name, column_family)</span></span><br><span class="line">    <span class="comment"># show_tables()</span></span><br><span class="line"></span><br><span class="line">    table = conn.table(table_name)</span><br><span class="line">    show_rows(table)</span><br><span class="line">    put_rows(table, column_family)</span><br><span class="line">    show_rows(table)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 更新操作</span></span><br><span class="line">    <span class="comment"># put_row(table, column_family, row_key, &#x27;xiaoh.me&#x27;)</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 删除数据</span></span><br><span class="line">    <span class="comment"># delete_row(table, row_key)</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># delete_row(table, row_key, column_family, [&#x27;name&#x27;])</span></span><br><span class="line">    <span class="comment"># show_rows(table, [row_key])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># counter(table, row_key, column_family)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># delete_table(table_name)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h2 id="hbase表设计">HBase表设计</h2>
<ul>
<li>设计HBase表时需要注意的特点
<ul>
<li>HBase中表的索引是通过rowkey实现的</li>
<li>在表中是通过Row key的字典顺序来对数据进行排序的,
表中Region的划分通过起始Rowkey和结束Rowkey来决定的</li>
<li>所有存储在HBase中的数据都是二进制字节, 没有数据类型</li>
<li>原子性只在行内保证, HBase表中没有多行事务</li>
<li>列族(Column Family)在表创建之前就要定义好</li>
<li>列族中的列标识(Column
Qualifier)可以在表创建后动态插入数据的时候添加</li>
<li>不同的column family保存在不同的文件中。</li>
</ul></li>
<li>如何设计HBase表
<ul>
<li>Row key的结构该如何设置, Row key中又该包含什么样的信息</li>
<li>表中应该有多少的列族</li>
<li>列族中应该存储什么样的数据</li>
<li>每个列族中存储多少列数据</li>
<li>列的名字分别是什么</li>
<li>cell中应该存储什么样的信息</li>
<li>每个cell中存储多少个版本信息</li>
</ul></li>
<li>DDI 目的是为了克服HBase架构上的缺陷(join繁琐 只有row key索引等)
<ul>
<li>Denormalization (反规范化, 解决join麻烦的问题)</li>
<li>Duplication (数据冗余)</li>
<li>Intelligent keys(通过row key设计实现 索引 排序对读写优化)</li>
</ul></li>
</ul>
<h2 id="hbase表设计案例-社交应用互粉信息表">HBase表设计案例:
社交应用互粉信息表</h2>
<p>设计表保存应用中用户互粉的信息：<br />
（1）读场景：某用户都关注了哪些用户、用户A有没有关注用户B、谁关注了用户A<br />
（2）写场景：用户关注了某个用户、用户取消关注了某个用户</p>
<p>某用户都关注了哪些用户：<br />
<img src="/images/Hive、Hbase/table1.png" width="60%" height="60%"></p>
<p><img src="/images/Hive、Hbase/table2.png" width="80%" height="80%"></p>
<p>解决 用户A有没有关注用户B 问题，防止像上面那样全表扫描：<br />
<img src="/images/Hive、Hbase/table3.png" width="80%" height="80%"></p>
<p>解决谁关注了用户A问题：<br />
（1）设计一张新表, 里面保存某个用户和他的粉丝。涉及到跨表事务。<br />
（2）在同一张表中同时记录粉丝列表的和用户关注的列表,
并通过Rowkey来区分（01_userid: 用户关注列表、02_userid:
粉丝列表）。涉及到跨行事务。<br />
（3）上两种设计方案的问题(事务)，可能不同步。</p>
<p>案例总结：<br />
（1）Rowkey是HBase表结构设计中很重要的环节,
直接影响到HBase的效率和性能。<br />
（2）HBase的表结构比传统关系型数据库更灵活,
能存储任何二进制数据,无需考虑数据类型。<br />
（3）利用列标识(Column Qualifier)来存储数据。<br />
（4）衡量设计好坏的简单标准 是否会全表查询。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>SoundMemories
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/" title="ML-Hive、Hbase">https://soundmemories.github.io/2020/05/07/Machine Learning/06.ML-Hive、Hbase/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/05/02/Machine%20Learning/05.ML-Hadoop/" rel="prev" title="ML-Hadoop">
                  <i class="fa fa-chevron-left"></i> ML-Hadoop
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/05/10/Machine%20Learning/07.ML-Spark/" rel="next" title="ML-Spark">
                  ML-Spark <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">SoundMemories</span>
  </div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"neutral"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js","integrity":"sha256-JFptYy4KzJ5OQP+Q9fubNf3cxpPPmZKqUOovyEONKrQ="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://soundmemories.github.io/2020/05/07/Machine%20Learning/06.ML-Hive%E3%80%81Hbase/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
