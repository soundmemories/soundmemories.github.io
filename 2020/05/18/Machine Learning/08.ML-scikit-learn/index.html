<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.17.1","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="scikit-learn简介 目前， Python 有不少可以实现各种机器学习算法的程序库。 Scikit-Learn（http:&#x2F;&#x2F;scikit-learn.org）是最流行的程序包之一，它为各种常用机器学习算法提供了高效版本。 Scikit-Learn不仅因其干净、统一、管道命令式的 API 而独具特色，而且它的在线文档又实用、又完整。这种统一性的好处是，只要你掌握了 Scikit-">
<meta property="og:type" content="article">
<meta property="og:title" content="ML-scikit-learn">
<meta property="og:url" content="https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="scikit-learn简介 目前， Python 有不少可以实现各种机器学习算法的程序库。 Scikit-Learn（http:&#x2F;&#x2F;scikit-learn.org）是最流行的程序包之一，它为各种常用机器学习算法提供了高效版本。 Scikit-Learn不仅因其干净、统一、管道命令式的 API 而独具特色，而且它的在线文档又实用、又完整。这种统一性的好处是，只要你掌握了 Scikit-">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-05-17T16:00:00.000Z">
<meta property="article:modified_time" content="2023-05-25T15:00:36.169Z">
<meta property="article:author" content="SoundMemories">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":"","permalink":"https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/","path":"2020/05/18/Machine Learning/08.ML-scikit-learn/","title":"ML-scikit-learn"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ML-scikit-learn | SoundMemories</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SoundMemories</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">8</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">122</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#scikit-learn%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">scikit-learn简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86"><span class="nav-number">2.1.</span> <span class="nav-text">特征处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-number">2.2.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96"><span class="nav-number">2.3.</span> <span class="nav-text">特征抽取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pipeline"><span class="nav-number">2.4.</span> <span class="nav-text">PipeLine</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%8D%E7%BB%B4"><span class="nav-number">3.</span> <span class="nav-text">降维</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pca"><span class="nav-number">3.1.</span> <span class="nav-text">PCA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mds"><span class="nav-number">3.2.</span> <span class="nav-text">MDS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#isomap"><span class="nav-number">3.3.</span> <span class="nav-text">Isomap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#locallylinearembedding"><span class="nav-number">3.4.</span> <span class="nav-text">LocallyLinearEmbedding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fa"><span class="nav-number">3.5.</span> <span class="nav-text">FA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fastica"><span class="nav-number">3.6.</span> <span class="nav-text">FastICA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#t-sne"><span class="nav-number">3.7.</span> <span class="nav-text">t-SNE</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.</span> <span class="nav-text">线性模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">4.2.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.3.</span> <span class="nav-text">贝叶斯模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#knn"><span class="nav-number">4.4.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">4.5.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95"><span class="nav-number">4.6.</span> <span class="nav-text">集成方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.</span> <span class="nav-text">聚类模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.</span> <span class="nav-text">半监督学习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="nav-number">7.</span> <span class="nav-text">模型评估</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%87%E5%88%86"><span class="nav-number">7.1.</span> <span class="nav-text">数据切分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="nav-number">7.2.</span> <span class="nav-text">性能度量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="nav-number">7.3.</span> <span class="nav-text">验证&#x2F;学习曲线</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96"><span class="nav-number">7.4.</span> <span class="nav-text">超参数优化</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="/images/avstar.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">122</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avstar.png">
      <meta itemprop="name" content="SoundMemories">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ML-scikit-learn | SoundMemories">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML-scikit-learn
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-05-18 00:00:00" itemprop="dateCreated datePublished" datetime="2020-05-18T00:00:00+08:00">2020-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>32k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:55</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="scikit-learn简介">scikit-learn简介</h1>
<p>目前， Python 有不少可以实现各种机器学习算法的程序库。
Scikit-Learn（http://scikit-learn.org）是最流行的程序包之一，它为各种常用机器学习算法提供了高效版本。
Scikit-Learn不仅因其干净、统一、管道命令式的 API
而独具特色，而且它的在线文档又实用、又完整。这种统一性的好处是，只要你掌握了
Scikit-Learn
一种模型的基本用法和语法，就可以非常平滑地过渡到新的模型或算法上。<br />
<span id="more"></span></p>
<h1 id="预处理">预处理</h1>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL3ByZXByb2Nlc3NpbmcuaHRtbCNwcmVwcm9jZXNzaW5n">Preprocessing<i class="fa fa-external-link-alt"></i></span>。<br />
通用的方法和参数：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">get_params([deep])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的参数。</span></span><br><span class="line"><span class="string">deep：如果为True，则可以返回模型参数的子对象。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">set_params(**params)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">设置模型的参数。</span></span><br><span class="line"><span class="string">params：待设置的关键字参数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练，获取预处理需要的参数（如：特征的最大值、最小值等），不同的预处理方法需要的参数不同。</span></span><br><span class="line"><span class="string">X：训练集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：训练样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X[, copy])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行预处理，返回处理后的样本集。</span></span><br><span class="line"><span class="string">X：训练集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">copy：一个布尔值，指定是否拷贝数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">获取预处理需要的参数并执行预处理，返回处理后的样本集。</span></span><br><span class="line"><span class="string">X：训练集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：训练样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">通用参数：</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">copy：一个布尔值，指定是否拷贝数据。如果为False则执行原地修改。此时节省空间，但修改了原始数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="特征处理">特征处理</h2>
<p>二元化：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.Binarizer(threshold=<span class="number">0.0</span>, copy=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">threshold：一个浮点数，它指定了转换阈值：低于此阈值的值转换为0，高于此阈值的值转换为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Binarizer的方法：</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">不作任何事情，主要用于为流水线Pipeline 提供接口。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X[, copy])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将每个样本的特征二元化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将每个样本的特征二元化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
独热编码One-Hot：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.OneHotEncoder(*, categories=<span class="string">&#x27;auto&#x27;</span>, drop=<span class="literal">None</span>, sparse=<span class="literal">True</span>,  </span><br><span class="line">                                     dtype=&lt;<span class="keyword">class</span> <span class="string">&#x27;numpy.float64&#x27;</span>&gt;, handle_unknown=<span class="string">&#x27;error&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">categories：&#x27;auto&#x27;/一个整数/一个整数的数组（它指定了样本每个特征取值的上界，特征的取值为从0开始的整数），</span></span><br><span class="line"><span class="string">            categories参数在0.22之前为n_values。</span></span><br><span class="line"><span class="string">            &#x27;auto&#x27;：默认值，自动从训练数据中推断特征值取值的上界。</span></span><br><span class="line"><span class="string">             一个整数：指定了所有特征取值的上界。</span></span><br><span class="line"><span class="string">             一个整数的数组：每个元素依次指定了每个特征取值的上界。</span></span><br><span class="line"><span class="string">drop：&#x27;first&#x27;/&#x27;if_binary&#x27;/一个shape为(n_features,)的array-like，默认值为None。</span></span><br><span class="line"><span class="string">       None : 保留所有特征（默认）。</span></span><br><span class="line"><span class="string">      &#x27;first&#x27;：编码后删除每个特征编码中的第一列。</span></span><br><span class="line"><span class="string">      &#x27;if_binary&#x27;：编码后删除第一个特征的第一列，其他特征保留。</span></span><br><span class="line"><span class="string">      array-like：删除所有特征的第i列。</span></span><br><span class="line"><span class="string">dtype：一个类型，指定了独热码编码的数值类型，默认为np.float。</span></span><br><span class="line"><span class="string">sparse：一个布尔值，指定编码结果是否作为稀疏矩阵。</span></span><br><span class="line"><span class="string">handle_unknown：一个字符串，指定转换过程中遇到了未知特征时的异常处理策略。</span></span><br><span class="line"><span class="string">                &#x27;error&#x27;：抛出异常。</span></span><br><span class="line"><span class="string">                &#x27;ignore&#x27;：忽略。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性：</span></span><br><span class="line">categories_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分类值，编码的取值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">drop_idx_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">删除的列。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法：</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练编码器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行独热码编码。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练编码器，然后执行独热码编码。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">get_feature_names([input_features])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回输出特征的特征名称。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将数据转换回原始表示。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
标准化：MinMaxScaler、MaxAbsScaler、StandardScaler：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>), copy=<span class="literal">True</span>, clip=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现了 min-max 标准化。</span></span><br><span class="line"><span class="string">feature_range：一个元组(min,max)，指定了执行变换之后特征的取值范围。</span></span><br><span class="line"><span class="string">clip：设置为True，修剪训练数据的特征数量到提供的特征范围。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">min_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的原始最小值的调整值。</span></span><br><span class="line"><span class="string">设特征 j 的原始最小值为 j_min，原始最大值为 j_max，则特征 j 的原始最小值的调整值为j_min/(j_max-j_min)。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">scale_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的缩放倍数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">data_min_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的原始最小值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">data_max_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的原始最大值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">data_range_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的原始的范围（最大值减最小值）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_samples_seen_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了当前已经处理的样本的数量（用于分批训练）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算每个特征的最小值和最大值，从而为后续的转换做准备。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行特征的标准化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算每个特征的最大小值和最大值，然后执行特征的标准化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">逆标准化，还原成原始数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">partial_fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">学习部分数据，计算每个特征的最小值和最大值，从而为后续的转换做准备。</span></span><br><span class="line"><span class="string">它支持批量学习，这样对于内存更友好。即训练数据并不是一次性学习，而是分批学习。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.preprocessing.MaxAbsScaler(copy=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现了 max-abs 标准化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">scale_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的缩放倍数的倒数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">max_abs_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的绝对值的最大值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_samples_seen_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了当前已经处理的样本的数量（用于分批训练）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同MinMaxScaler</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考MinMaxScaler的方法</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.preprocessing.StandardScaler(copy=<span class="literal">True</span>, with_mean=<span class="literal">True</span>, with_std=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现了 z-score 标准化。</span></span><br><span class="line"><span class="string">with_mean：一个布尔值，指定是否中心化。</span></span><br><span class="line"><span class="string">          如果为True，则缩放之前先将每个特征中心化（即特征值减去该特征的均值）。</span></span><br><span class="line"><span class="string">          如果元素数据是稀疏矩阵的形式，则不能指定with_mean=True。</span></span><br><span class="line"><span class="string">with_std：一个布尔值，指定是否方差归一化。如果为True，则缩放每个特征到单位方差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">scale_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了每个特征的缩放倍数的倒数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">mean_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了原始数据每个特征的均值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">var_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了原始数据每个特征的方差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_samples_seen_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了当前已经处理的样本的数量（用于分批训练）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同MinMaxScaler</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考MinMaxScaler的方法</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
正则化：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.Normalizer(norm=<span class="string">&#x27;l2&#x27;</span>, copy=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">norm：一个字符串，指定正则化方法。可以为：</span></span><br><span class="line"><span class="string">&#x27;l1&#x27;：采用 L1 范数正则化。</span></span><br><span class="line"><span class="string">&#x27;l2&#x27;：采用 L2 范数正则化。</span></span><br><span class="line"><span class="string">&#x27;max&#x27;：采用 L无穷 范数正则化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">不作任何事情，主要用于为流水线Pipeline 提供接口。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X[, y, copy])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将每一个样本正则化为范数等于单位1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将每一个样本正则化为范数等于单位1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="特征选择">特征选择</h2>
<p>过滤式特征选取：VarianceThreshold、SelectKBest、SelectPercentile：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.VarianceThreshold(threshold=<span class="number">0.0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用于剔除方差很小的特征。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">threshold：一个浮点数，指定方差的阈值。低于此阈值的特征将被剔除。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">variances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素分别是各特征的方差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">从样本数据中学习每个特征的方差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行特征选择，即删除低于指定阈值的特征。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">从样本数据中学习每个特征的方差，然后执行特征选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">get_support([indices])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回保留的特征。</span></span><br><span class="line"><span class="string">如果indices=True，则返回被选出的特征的索引。</span></span><br><span class="line"><span class="string">如果indices=False，则返回一个布尔值组成的数组，该数组指示哪些特征被选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">根据被选出来的特征还原原始数据（特征选取的逆操作），但是对于被删除的特征的值全部用 0 代替。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.feature_selection.SelectKBest(score_func=&lt;function f_classif&gt;, k=<span class="number">10</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用于保留统计得分最高的 k 个特征。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">score_func：一个函数，用于给出统计指标。该函数的参数为(X,y) ，返回值为(scores,pvalues)。</span></span><br><span class="line"><span class="string">            X：样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">            y：样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">            scores：样本的得分集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">            pvalues：样本得分的p值。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">k：一个整数/&#x27;all&#x27;，指定要保留几个最佳特征。如果为&#x27;all&#x27;，则保留所有的特征。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sklearn提供的常用的统计指标函数为：</span></span><br><span class="line"><span class="string">sklearn.feature_selection.f_regression：基于线性回归分析来计算统计指标，适用于回归问题。</span></span><br><span class="line"><span class="string">sklearn.feature_selection.chi2：计算卡方统计量，适用于分类问题。</span></span><br><span class="line"><span class="string">sklearn.feature_selection.f_classif：根据方差分析F值。依靠F-分布为机率分布的依据，利用平方和与自由度所计算的组间与组内均方估计出F值。适用于分类问题 。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">scores_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了所有特征的得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">pvalues_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了所有特征得分的p-values。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同VarianceThreshold </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考VarianceThreshold。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.feature_selection.SelectPercentile(score_func=&lt;function f_classif&gt;,</span><br><span class="line">percentile=<span class="number">10</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用于保留统计得分最高的 k% 比例的特征。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">score_func：一个函数，用于给出统计指标。参考SelectKBest  。</span></span><br><span class="line"><span class="string">percentile：一个整数，指定要保留最佳的百分之几的特征，如10表示保留最佳的百分之十的特征。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，同SelectKBest</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考SelectKBest。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同VarianceThreshold</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考VarianceThreshold。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
包裹式特征选取：RFE、RFECV、SelectFromModel：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.RFE(estimator, n_features_to_select=<span class="literal">None</span>,step=<span class="number">1</span>,verbose=<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用于实现包裹式特征选取。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">estimator：一个学习器，它必须提供一个.fit方法和一个.coef_特征。其中.coef_特征中存放的是学习到的各特征的权重系数。通常使用SVM和广义线性模型作为estimator参数。</span></span><br><span class="line"><span class="string">n_features_to_select：一个整数/None，指定要选出几个特征。如果为None，则默认选取一半的特征。</span></span><br><span class="line"><span class="string">step：一个整数或者浮点数，指定每次迭代要剔除权重最小的几个特征。</span></span><br><span class="line"><span class="string">      如果大于等于1，则作为整数，指定每次迭代要剔除特征的数量。</span></span><br><span class="line"><span class="string">      如果在0.0~1.0之间，则指定每次迭代要剔除特征的比例。</span></span><br><span class="line"><span class="string">verbose：一个整数，控制输出日志。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">RFE要求学习器能够学习特征的权重（如线性模型），其原理为：</span></span><br><span class="line"><span class="string">（1）首先学习器在初始的特征集合上训练。</span></span><br><span class="line"><span class="string">（2）然后学习器学得每个特征的权重，剔除当前权重一批特征，构成新的训练集。</span></span><br><span class="line"><span class="string">（3）再将学习器在新的训练集上训练，直到剩下的特征的数量满足条件。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">n_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了被选出的特征的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">support_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了特征是否被选择的mask。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">ranking_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">特征权重排名。原始第 i 个特征的排名为 raning_[i] 。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimator_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">外部提供的学习器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练RFE模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行特征选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">从样本数据中学习RFE模型，然后执行特征选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">get_support([indices])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回保留的特征。</span></span><br><span class="line"><span class="string">如果indices=True，则返回被选出的特征的索引。</span></span><br><span class="line"><span class="string">如果indices=False，则返回一个布尔值组成的数组，该数组指示哪些特征被选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">根据被选出来的特征还原原始数据（特征选取的逆操作），但是对于被删除的特征值全部用 0 代替。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将X进行特征选择之后，在使用内部的estimator来预测。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，输出预测概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，输出预测对数概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X, y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将X进行特征选择之后，训练内部estimator并对内部的estimator进行评分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.feature_selection.RFECV(estimator, step=<span class="number">1</span>, cv=<span class="literal">None</span>, scoring=<span class="literal">None</span>,verbose=<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是RFE的一个变体，它执行一个交叉验证来寻找最优的剩余特征数量，因此不需要指定保留多少个特征。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">cv：一个整数，或者交叉验证生成器或者一个可迭代对象，它决定了交叉验证策略。</span></span><br><span class="line"><span class="string">    如果为None，则使用默认的3折交叉验证。</span></span><br><span class="line"><span class="string">    如果为整数  ，则使用 k 折交叉验证。</span></span><br><span class="line"><span class="string">    如果为交叉验证生成器，则直接使用该对象。</span></span><br><span class="line"><span class="string">    如果为可迭代对象，则使用该可迭代对象迭代生成 训练-测试 集合。</span></span><br><span class="line"><span class="string">其它参数参考RFE。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，其它属性参考RFE</span></span><br><span class="line">grid_scores_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出了交叉验证的预测性能得分。其元素为每个特征子集上执行交叉验证后的预测得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同RFE</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考RFE。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
嵌入式特征选择：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.SelectFromModel(estimator, threshold=<span class="literal">None</span>, </span><br><span class="line">prefit=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">estimator：一个学习器，它可以是未训练的(prefit=False)，或者是已经训练好的(prefit=True)。</span></span><br><span class="line"><span class="string">           estimator必须有coef_或者feature_importances_属性，给出每个特征的重要性。当某个特征的重要性低于某个阈值时，该特征将被移除。</span></span><br><span class="line"><span class="string">threshold：一个字符串或者浮点数或者None，指定特征重要性的一个阈值。低于此阈值的特征将被剔除。</span></span><br><span class="line"><span class="string">          如果为浮点数，则指定阈值的绝对大小。</span></span><br><span class="line"><span class="string">          如果为字符串，可以是：</span></span><br><span class="line"><span class="string">              &#x27;mean&#x27;：阈值为特征重要性的均值。</span></span><br><span class="line"><span class="string">              &#x27;median&#x27;：阈值为特征重要性的中值。</span></span><br><span class="line"><span class="string">              &#x27;1.5*mean&#x27;，则表示阈值为1.5倍的特征重要性的均值。</span></span><br><span class="line"><span class="string">          如果为None：</span></span><br><span class="line"><span class="string">              如果estimator有一个penalty参数，且该参数设置为&#x27;l1&#x27;，则阈值默认为1e-5。</span></span><br><span class="line"><span class="string">              其他情况下，阈值默认为&#x27;mean&#x27;。</span></span><br><span class="line"><span class="string">prefit：一个布尔值，指定estimator是否已经训练好了。如果为False，则estimator是未训练的。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">threshold_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，存储了用于特征选取重要性的阈值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练SelectFromModel模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行特征选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">从样本数据中学习SelectFromModel模型，然后执行特征选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">get_support([indices])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回保留的特征。</span></span><br><span class="line"><span class="string">如果indices=True，则返回被选出的特征的索引。</span></span><br><span class="line"><span class="string">如果indices=False，则返回一个布尔值组成的数组，该数组指示哪些特征被选择。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">根据被选出来的特征还原原始数据（特征选取的逆操作），但是对于被删除的特征值全部用 0 代替。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">partial_fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">通过部分数据来学习SelectFromModel模型。</span></span><br><span class="line"><span class="string">它支持批量学习，这样对于内存更友好。即训练数据并不是一次性学习，而是分批学习。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="特征抽取">特征抽取</h2>
<p>sklearn.feature_extraction：模块处理从原始数据中提取特征。它目前包括从文本和图像中提取特征的方法。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.DictVectorizer(*, dtype=np.float64, separator=<span class="string">&#x27;=&#x27;</span>, sparse=<span class="literal">True</span>, sort=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将特征值映射为向量。</span></span><br><span class="line"><span class="string">dtype：特征值的数值类型。默认np.float64。</span></span><br><span class="line"><span class="string">separator：一个字符串。为one-hot编码构建新特征时使用的分隔符字符串。</span></span><br><span class="line"><span class="string">sparse：一个布尔值。是否对产生的scipy.sparse矩阵进行转换。</span></span><br><span class="line"><span class="string">sort：一个布尔值。训练时，是否对feature_names_和vocabulary_排序。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">vocabulary_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">字典。将特征名称映射到特征索引的字典。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_names_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">列表。长度为n_features，所有特征名称的列表。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line">fit_transform(X[, y])</span><br><span class="line">get_feature_names()</span><br><span class="line">get_params([deep])</span><br><span class="line">inverse_transform(X[, dict_type])</span><br><span class="line">restrict(support[, indices])</span><br><span class="line">set_params(**params)</span><br><span class="line">transform(X)</span><br></pre></td></tr></table></figure><br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.FeatureHasher(n_features=<span class="number">1048576</span>, *, input_type=<span class="string">&#x27;dict&#x27;</span>, dtype=np.float64, alternate_sign=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现特征散列。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
sklearn.feature_extraction.text子模块从文本文档构建特征向量。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.text.CountVectorizer(*, <span class="built_in">input</span>=<span class="string">&#x27;content&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, decode_error=<span class="string">&#x27;strict&#x27;</span>, </span><br><span class="line">strip_accents=<span class="literal">None</span>, lowercase=<span class="literal">True</span>, preprocessor=<span class="literal">None</span>, tokenizer=<span class="literal">None</span>, stop_words=<span class="literal">None</span>, token_pattern=<span class="string">&#x27;(?u)\b\w\w+\b&#x27;</span>, </span><br><span class="line">ngram_range=(<span class="number">1</span>, <span class="number">1</span>), analyzer=<span class="string">&#x27;word&#x27;</span>, max_df=<span class="number">1.0</span>, min_df=<span class="number">1</span>, max_features=<span class="literal">None</span>, vocabulary=<span class="literal">None</span>, </span><br><span class="line">binary=<span class="literal">False</span>, dtype=&lt;<span class="keyword">class</span> <span class="string">&#x27;numpy.int64&#x27;</span>&gt;)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.text.HashingVectorizer(*, <span class="built_in">input</span>=<span class="string">&#x27;content&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, decode_error=<span class="string">&#x27;strict&#x27;</span>, </span><br><span class="line">strip_accents=<span class="literal">None</span>, lowercase=<span class="literal">True</span>, preprocessor=<span class="literal">None</span>, tokenizer=<span class="literal">None</span>, stop_words=<span class="literal">None</span>, token_pattern=<span class="string">&#x27;(?u)\b\w\w+\b&#x27;</span>, </span><br><span class="line">ngram_range=(<span class="number">1</span>, <span class="number">1</span>), analyzer=<span class="string">&#x27;word&#x27;</span>, n_features=<span class="number">1048576</span>, binary=<span class="literal">False</span>, norm=<span class="string">&#x27;l2&#x27;</span>, </span><br><span class="line">alternate_sign=<span class="literal">True</span>, dtype=&lt;<span class="keyword">class</span> <span class="string">&#x27;numpy.float64&#x27;</span>&gt;)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.text.TfidfTransformer(*, norm=<span class="string">&#x27;l2&#x27;</span>, use_idf=<span class="literal">True</span>, smooth_idf=<span class="literal">True</span>, sublinear_tf=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将计数矩阵转换为标准化的 tf 或 tf-idf 表示。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL2ZlYXR1cmVfZXh0cmFjdGlvbi5odG1sI3RleHQtZmVhdHVyZS1leHRyYWN0aW9u">Feature
extraction<i class="fa fa-external-link-alt"></i></span><br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.text.TfidfVectorizer(*, <span class="built_in">input</span>=<span class="string">&#x27;content&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, decode_error=<span class="string">&#x27;strict&#x27;</span>, </span><br><span class="line">strip_accents=<span class="literal">None</span>, lowercase=<span class="literal">True</span>, preprocessor=<span class="literal">None</span>, tokenizer=<span class="literal">None</span>, analyzer=<span class="string">&#x27;word&#x27;</span>, stop_words=<span class="literal">None</span>, </span><br><span class="line">token_pattern=<span class="string">&#x27;(?u)\b\w\w+\b&#x27;</span>, ngram_range=(<span class="number">1</span>, <span class="number">1</span>), max_df=<span class="number">1.0</span>, min_df=<span class="number">1</span>, max_features=<span class="literal">None</span>, vocabulary=<span class="literal">None</span>, </span><br><span class="line">binary=<span class="literal">False</span>, dtype=&lt;<span class="keyword">class</span> <span class="string">&#x27;numpy.float64&#x27;</span>&gt;, norm=<span class="string">&#x27;l2&#x27;</span>, use_idf=<span class="literal">True</span>, smooth_idf=<span class="literal">True</span>, sublinear_tf=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将原始文档集合转换为 TF-IDF 特征矩阵。</span></span><br><span class="line"><span class="string">input：string &#123;&#x27;filename&#x27;，&#x27;file&#x27;，&#x27;content&#x27;&#125;。</span></span><br><span class="line"><span class="string">       如果&#x27;filename&#x27;，作为参数传递的顺序适合，预计将是需要读取以获取原始内容进行分析的文件名列表。</span></span><br><span class="line"><span class="string">       如果&#x27;file&#x27;，序列项必须有一个&#x27;read&#x27;方法（类文件对象），被调用来获取内存中的字节。</span></span><br><span class="line"><span class="string">       否则，输入将被预期是顺序字符串或字节项预期直接分析。</span></span><br><span class="line"><span class="string">encoding：string，&#x27;utf-8&#x27;。如果要分配字节或文件，则使用该编码进行解码。</span></span><br><span class="line"><span class="string">decode_error：&#123;&#x27;strict&#x27;，&#x27;ignore&#x27;，&#x27;replace&#x27;&#125;。如果给出分析字节序列包含不是给定编码的字符，该怎么做。</span></span><br><span class="line"><span class="string">              默认情况下，它是&#x27;strict&#x27;，这意味着将会引发一个UnicodeDecodeError。其他值是“忽略”和“替换”。</span></span><br><span class="line"><span class="string">strip_accents：&#123;&#x27;ascii&#x27;，&#x27;unicode&#x27;，None&#125;。在预处理步骤中删除方言。</span></span><br><span class="line"><span class="string">              &#x27;ascii&#x27;是一种快速的方法，只适用于具有直接ASCII映射的字符。</span></span><br><span class="line"><span class="string">              &#x27;unicode&#x27;是一种稍慢的方法，适用于任何字符。无（默认）不起作用。</span></span><br><span class="line"><span class="string">lowercase：bool。转化前是否把字符转成小写。</span></span><br><span class="line"><span class="string">preprocessor：callable。覆盖预处理（字符串转换）阶段，同时保留tokenizing和n-gram生成步骤。</span></span><br><span class="line"><span class="string">              仅当分析器不可调用时才适用。</span></span><br><span class="line"><span class="string">tokenizer：callable。覆盖字符串tokenization步骤，同时保留预处理和n-gram生成步骤。</span></span><br><span class="line"><span class="string">          仅在analyzer=&#x27;word&#x27;时能使用。</span></span><br><span class="line"><span class="string">analyzer：&#123;‘word’, ‘char’, ‘char_wb’&#125; or callable。该功能是否应由字符或字符n-gram组成。</span></span><br><span class="line"><span class="string">          如果传递了一个可调用函数，它将用于从原始未处理的输入中提取特征序列。</span></span><br><span class="line"><span class="string">stop_words：&#123;‘english’&#125;, list。</span></span><br><span class="line"><span class="string">            如果是字符串，则将其传递给_check_stop_list，并返回相应的停止列表。&#x27;english&#x27;是目前唯一支持的字符串值。</span></span><br><span class="line"><span class="string">            如果一个列表，该列表被假定为包含停止词，所有这些都将从生成的令牌中删除。仅analyzer=&#x27;word&#x27;时适用。</span></span><br><span class="line"><span class="string">            如果没有，将不会使用停止的单词。max_df可以设置为[0.7,1.0]范围内的值，以根据单词的语料库文档频率自动检测和过滤停止词。</span></span><br><span class="line"><span class="string">token_pattern：str。正则表达式表示什么构成了“token”，仅用于analyzer=&#x27;word&#x27;。</span></span><br><span class="line"><span class="string">               默认只匹配长度大于等于2的单词。</span></span><br><span class="line"><span class="string">ngram_range：tuple(min_n, max_n)。不同n值的n值范围的下边界和上边界被提取。</span></span><br><span class="line"><span class="string">             将使用所有n值，使得min_n &lt;= n &lt;= max_n。</span></span><br><span class="line"><span class="string">			 如果觉得单个的词语作为特征还不足够，能够加入一些词组更好，就可以设置这个参数，</span></span><br><span class="line"><span class="string">			 	比如ngram_range=(1,2)，允许词表使用1个词语，或者2个词语的组合。</span></span><br><span class="line"><span class="string">max_df：float or int。当构建词汇时，忽略文档频率严格高于给定阈值的单词。</span></span><br><span class="line"><span class="string">        如果为float，则该参数代表一定比例的文档，整数绝对计数。如果词汇不是无，则忽略此参数。</span></span><br><span class="line"><span class="string">min_df：float or int。当构建词汇时，忽略文档频率严格低于给定阈值的单词。</span></span><br><span class="line"><span class="string">        如果为float，则该参数代表一定比例的文档，整数绝对计数。如果词汇不是无，则忽略此参数。</span></span><br><span class="line"><span class="string">max_features：int。如果不是无，建立一个词汇，只考虑由词汇频率排序的顶级max_feature。</span></span><br><span class="line"><span class="string">如果词汇不是无，则忽略此参数。</span></span><br><span class="line"><span class="string">			  语料库非常大，或者加上了ngram_range，训练时间很长，通过限制最多使用多少个词语，模型会优先选取词频高的词语留下</span></span><br><span class="line"><span class="string">vocabulary：Mapping or iterable。要么是一个映射（例如，字典），其中键是单词 ，值是特征矩阵中的索引，要么是可迭代的单词。</span></span><br><span class="line"><span class="string">           如果未给出，则从输入文档中确定词汇表。</span></span><br><span class="line"><span class="string">binary：bool。如果为True，则所有非零项计数都设置为1。</span></span><br><span class="line"><span class="string">        这并不意味着输出将只有0/1值，只有tf-idf中的tf项是二进制的。将idf归一化为False，得到0/1输出。</span></span><br><span class="line"><span class="string">dtype：default=float64。由fit_transform()或transform()返回的矩阵的类型。</span></span><br><span class="line"><span class="string">norm：&#123;‘l1’, ‘l2’&#125;。规范化。</span></span><br><span class="line"><span class="string">use_idf：bool。启用逆文档频率重新加权。</span></span><br><span class="line"><span class="string">smooth_idf：bool。通过将文档频率添加 1 平滑的idf权重，就好像一个额外的文档被看到包含一个集合中的每个单词一次。防止零分。</span></span><br><span class="line"><span class="string">sublinear_tf：bool。应用子线性tf缩放，即用1 + log（tf）替换tf。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">vocabulary_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">字典。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fixed_vocabulary_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">如果用户提供了单词到索引映射的固定词汇表，则为真</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">stop_words_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">集合。被忽略的是：</span></span><br><span class="line"><span class="string">	发生在太多的文件（max_df）</span></span><br><span class="line"><span class="string">	发生在太少的文件（min_df）</span></span><br><span class="line"><span class="string">	被特征选择（max_features）截断。</span></span><br><span class="line"><span class="string">这仅在没有提供词汇表的情况下可用。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">build_analyzer()<span class="comment"># 返回处理预处理和标记化的可调用</span></span><br><span class="line">build_preprocessor()<span class="comment"># 返回一个函数，以便在标记化之前对文本进行预处理</span></span><br><span class="line">build_tokenizer()<span class="comment"># 返回一个将字符串分成token序列的函数</span></span><br><span class="line">decode(doc)<span class="comment"># 将输入解码为一串Unicode码元</span></span><br><span class="line">fit(raw_documents[, y])<span class="comment"># 从训练集学习词汇和idf。</span></span><br><span class="line">fit_transform(raw_documents[, y])<span class="comment"># 学习词汇和idf，返回单词文档矩阵。</span></span><br><span class="line">get_feature_names()<span class="comment"># 从特征整数索引到特征名称的数组映射</span></span><br><span class="line">get_params([deep])<span class="comment">#	获取此估计器的参数。</span></span><br><span class="line">get_stop_words()<span class="comment"># 构建或获取有效的停止词列表</span></span><br><span class="line">inverse_transform(X)<span class="comment"># 还原。</span></span><br><span class="line">set_params(**params)<span class="comment"># 设置该估计器的参数。</span></span><br><span class="line">transform(raw_documents)<span class="comment"># 将文档转换为文档单词矩阵。</span></span><br></pre></td></tr></table></figure></p>
<h2 id="pipeline">PipeLine</h2>
<p>scikit-learn 中的流水线的流程通常为：<br />
（1）通过一组特征处理estimator来对特征进行处理（如标准化、正则化）。<br />
（2）通过一组特征提取estimator来提取特征。<br />
（3）通过一个模型预测estimator来学习模型，并执行预测。<br />
除了最后一个estimator之外，前面的所有的estimator必须提供transform方法。该方法用于执行数据变换（如归一化、正则化、以及特征提取等）。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sklearn.pipeline.Pipeline(steps)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Pipeline将多个estimator组成流水线。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">steps：一个列表，列表的元素为(name,transform)元组。其中：</span></span><br><span class="line"><span class="string">      name：estimator的名字，用于输出和日志。</span></span><br><span class="line"><span class="string">      transform：estimator。之所以叫transform是因为这个estimator（除了最后一个）必须提供transform方法。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">named_steps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个字典。键就是steps中各元组的name元素，字典的值就是steps中各元组的transform元素。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">启动流水线，依次对各个estimator（除了最后一个）执行.fit方法和.transform方法转换数据；对最后一个estimator执行.fit方法训练学习器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">启动流水线，依次对各个estimator （包括最后一个）执行.fit方法和.transform方法转换数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">启动流水线，依次对各个estimator（除了最后一个）执行.fit方法和.transform方法转换数据；对最后一个estimator执行.fit_transform方法转换数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将转换后的数据逆转换成原始数据。</span></span><br><span class="line"><span class="string">要求每个estimator都实现了.inverse_transform方法。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将X进行数据转换后，用最后一个estimator学习器来预测。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，结果为预测概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，结果为预测对数概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X, y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将X进行数据转换后，训练最后一个estimator，并对最后一个estimator评分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="降维">降维</h1>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL2RlY29tcG9zaXRpb24uaHRtbCNkZWNvbXBvc2l0aW9ucw==">Dimensionality
reduction<i class="fa fa-external-link-alt"></i></span>。<br />
通用方法和参数：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">get_params([deep])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的参数。</span></span><br><span class="line"><span class="string">deep：如果为True，则可以返回模型参数的子对象。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">set_params(**params)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">设置模型的参数。</span></span><br><span class="line"><span class="string">params：待设置的关键字参数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">X：样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">X ：样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">X：样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维的逆运算，返回降维之前的样本集合。</span></span><br><span class="line"><span class="string">X：降维之后的样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 通用参数</span></span><br><span class="line">copy</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个布尔值，指定是否拷贝原始数据。</span></span><br><span class="line"><span class="string">如果为False则执行原地修改。此时节省空间，但修改了原始数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_jobs</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个正数，指定任务并形时指定的CPU数量。</span></span><br><span class="line"><span class="string">如果为 -1 则使用所有可用的CPU。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">random_state</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数/一个RandomState实例/None。</span></span><br><span class="line"><span class="string">如果为整数，则它指定了随机数生成器的种子。</span></span><br><span class="line"><span class="string">如果为RandomState实例，则指定了随机数生成器。</span></span><br><span class="line"><span class="string">如果为None，则使用默认的随机数生成器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_components</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，指定降维后的维数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="pca">PCA</h2>
<p>PCA、IncrementalPCA、KernelPCA：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.PCA(n_components=<span class="literal">None</span>, copy=<span class="literal">True</span>, whiten=<span class="literal">False</span>,</span><br><span class="line">                         svd_solver=<span class="string">&#x27;auto&#x27;</span>, tol=<span class="number">0.0</span>, iterated_power=<span class="string">&#x27;auto&#x27;</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现了PCA降维模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_components：指定降维后的维数。</span></span><br><span class="line"><span class="string">    None：则选择它的值为min(n_samples,n_features) 。</span></span><br><span class="line"><span class="string">    n_components==&#x27;mle&#x27;且svd_solver==&#x27;full&#x27;：则使用Minka&#x27;s MLE算法来猜测降维后的维数。</span></span><br><span class="line"><span class="string">                                            MLE算法根据特征的方差分布情况自己去选择一定数量的主成分特征来降维。</span></span><br><span class="line"><span class="string">    0&lt;n_components&lt;1且svd_solver==&#x27;full&#x27;：则指定的是降维后的维数占原始维数的百分比。</span></span><br><span class="line"><span class="string">copy：一个布尔值，指定是否拷贝原始数据。</span></span><br><span class="line"><span class="string">whiten：一个布尔值，指定是否执行白化操作。所谓白化，就是对降维后的数据的每个特征进行归一化，让方差都为1。</span></span><br><span class="line"><span class="string">        如果为True，则会将特征向量除以n_samples倍的特征值，从而保证非相关的输出的方差为1。</span></span><br><span class="line"><span class="string">        白化操作可能会丢弃部分信息，但是它有时候在接下来的学习器学习阶段能获得更佳的性能。</span></span><br><span class="line"><span class="string">        对于PCA降维本身来说，一般不需要白化。如果你PCA降维后有后续的数据处理动作，可以考虑白化。</span></span><br><span class="line"><span class="string">svd_solver：指定奇异值分解SVD的方法。有4个可以选择的值：&#123;&#x27;auto&#x27;, &#x27;full&#x27;, &#x27;arpack&#x27;, &#x27;randomized&#x27;&#125;。</span></span><br><span class="line"><span class="string">           &#x27;randomized&#x27;：适用于数据量大，数据维度多同时主成分数目比例又较低的PCA降维，它使用了一些加快SVD的随机算法。 </span></span><br><span class="line"><span class="string">           &#x27;full&#x27;：传统意义上的SVD，使用了scipy库对应的实现。</span></span><br><span class="line"><span class="string">           &#x27;arpack&#x27;：和randomized的适用场景类似，区别是randomized使用的是scikit-learn自己的SVD实现，</span></span><br><span class="line"><span class="string">                     而arpack直接使用了scipy库的sparse SVD实现。</span></span><br><span class="line"><span class="string">           &#x27;auto&#x27;：PCA类会自己去上面3种算法里面去权衡，选择一个合适的SVD算法来降维。一般来说，使用默认值就够了。</span></span><br><span class="line"><span class="string">tol：svd_solver==&#x27;arpack&#x27;时，计算的奇异值的公差。</span></span><br><span class="line"><span class="string">iterated_power：int&gt;=0/&#x27;auto&#x27;。svd_solver==&#x27;randomized&#x27;时，计算出的幂方法的迭代次数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">0.18前，decomposition.PCA基于scipy.linalg来实现SVD分解，因此有两个限制：</span></span><br><span class="line"><span class="string">不能应用于稀疏矩阵。</span></span><br><span class="line"><span class="string">无法适用于超大规模数据，因为它要求所有的数据一次加载进内存。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">components_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，给出主成分。按explained_variance_排序。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">explained_variance_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素是降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">explained_variance_ratio_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素是降维后的各主成分的方差值占总方差值的比例。这个比例越大，则越是重要的主成分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">singular_values_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的奇异值，奇异值等于n_components低维空间中变量的2范数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">mean_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素是每个特征的均值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_components_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，指示主成分有多少个元素。即是上面输入的参数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练数据中的特征数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_samples_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练数据中的样本数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">noise_variance_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">等于X协方差矩阵的 min(n_features，n_samples)-n_components 个最小特征值的平均值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型，获取降维需要的参数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维的逆运算，返回降维之前的样本集合。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.decomposition.IncrementalPCA(n_components=<span class="literal">None</span>, whiten=<span class="literal">False</span>, </span><br><span class="line">copy=<span class="literal">True</span>,batch_size=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">它适用于超大规模数据，可以将数据分批加载进内存。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">batch_size：一个整数/None，指定每个批次训练时，使用的样本数量。</span></span><br><span class="line"><span class="string">            只有当调用fit()/partial_fit()方法时，才会用到该参数。</span></span><br><span class="line"><span class="string">            如果为None，则由算法自动推断。</span></span><br><span class="line"><span class="string">其它参数参考decomposition.PCA。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">mean_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素是每个特征的均值。</span></span><br><span class="line"><span class="string">每调用一次partial_fit()方法就会更新一次该属性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">var_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，元素是每个特征的经验方差。</span></span><br><span class="line"><span class="string">每调用一次partial_fit()方法就会更新一次该属性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_samples_seen_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，指示目前已经处理了多少个样本。</span></span><br><span class="line"><span class="string">每调用一次partial_fit()方法就会更新一次该属性。</span></span><br><span class="line"><span class="string">每调用一次fit()方法就会清零该属性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同decomposition.PCA。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考decomposition.PCA。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.decomposition.KernelPCA(n_components=<span class="literal">None</span>, kernel=<span class="string">&#x27;linear&#x27;</span>,</span><br><span class="line">            gamma=<span class="literal">None</span>, degree=<span class="number">3</span>, coef0=<span class="number">1</span>, kernel_params=<span class="literal">None</span>, alpha=<span class="number">1.0</span>, </span><br><span class="line">            fit_inverse_transform=<span class="literal">False</span>,eigen_solver=<span class="string">&#x27;auto&#x27;</span>, tol=<span class="number">0</span>, max_iter=<span class="literal">None</span>,</span><br><span class="line">            remove_zero_eig=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn实现的核化PCA模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_components：一个整数，指定降维后的维数。</span></span><br><span class="line"><span class="string">kernel：一个字符串/可调用对象，指定核函数。</span></span><br><span class="line"><span class="string">        &#x27;linear&#x27;：线性核，K(x,z)=(x,z)</span></span><br><span class="line"><span class="string">        &#x27;poly&#x27;：多项式核，K(x,z)=(g((x,z)+1)+r)^p，p由degree决定，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;rbf&#x27;：默认值，高斯核，K(x,z)=e^(-g||x-z||^2)，g由gamma决定。</span></span><br><span class="line"><span class="string">        &#x27;sigmoid&#x27;：sigmod核函数，K(x,z)=tanh(g(x,z)+r)，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;precomputed&#x27;：表示提供了kernel matrix。</span></span><br><span class="line"><span class="string">        一个可调用对象：该对象用于计算kernel matrix。</span></span><br><span class="line"><span class="string">degree：一个整数，当核函数是多项式核函数时，指定多项式的系数。</span></span><br><span class="line"><span class="string">gamma：一个浮点数，当核函数是&#x27;rbf&#x27;，&#x27;poly&#x27;，&#x27;sigmoid&#x27;时，指定核函数的系数。如果&#x27;auto&#x27;，则表示系数为1/n_features。</span></span><br><span class="line"><span class="string">coef0：浮点数，当核函数是&#x27;poly&#x27;和&#x27;sigmoid&#x27;，用于指定核函数中的自由项。</span></span><br><span class="line"><span class="string">kernel_params：当核函数是一个可调用对象时才使用它，用于为该可调用对象传递参数。</span></span><br><span class="line"><span class="string">alpha：一个整数，岭回归的超参数，用于计算逆转换矩阵（当fit_inverse_transform=True时）。</span></span><br><span class="line"><span class="string">fit_inverse_transform：一个布尔值，指定是否需要计算逆转换矩阵。当为True时，需要计算逆转换矩阵。</span></span><br><span class="line"><span class="string">eigen_solver：一个字符串，指定求解特征值的算法：</span></span><br><span class="line"><span class="string">             &#x27;auto&#x27;：自动选择。</span></span><br><span class="line"><span class="string">             &#x27;dense&#x27;：dense特征值求解器。</span></span><br><span class="line"><span class="string">             &#x27;arpack&#x27;：arpack特征值求解器，用于当特征数量远小于样本数量的情形。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定arpack特征值求解器的收敛阈值（如果为0，则自动选择阈值）。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定arpack特征值求解器的最大迭代次数（如果为None，则自动选择）。</span></span><br><span class="line"><span class="string">remove_zero_eig：一个布尔值。如果为True，则移除所有为零的特征值。如果n_components=None，则也会移除所有为零的特征值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">lambdas_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">核化矩阵的特征值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">alphas_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">核化矩阵的特征向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">dual_coef_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">逆转换矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同decomposition.PCA</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考decomposition.PCA。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="mds">MDS</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">sklearn.manifold.MDS(n_components=<span class="number">2</span>, metric=<span class="literal">True</span>, n_init=<span class="number">4</span>, max_iter=<span class="number">300</span>,</span><br><span class="line">                     verbose=<span class="number">0</span>, eps=<span class="number">0.001</span>, n_jobs=<span class="number">1</span>, random_state=<span class="literal">None</span>, dissimilarity=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn实现的多维缩放模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">metric：一个布尔值，指定度量类型。如果为True则使用距离度量；否则使用非距离度量SMACOF 。</span></span><br><span class="line"><span class="string">n_components：一个整数，指定降维后的维数。</span></span><br><span class="line"><span class="string">n_init：一个整数，指定初始化的次数。</span></span><br><span class="line"><span class="string">       在使用SMACOF算法时，会选择n_init次不同的初始值，然后选择这些结果中最好的那个作为最终结果。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定在使用SMACOF算法时得到一轮结果需要的最大迭代次数。</span></span><br><span class="line"><span class="string">eps：一个浮点数，用于指定收敛阈值。</span></span><br><span class="line"><span class="string">n_jobs：一个整数，指定并行性。</span></span><br><span class="line"><span class="string">random_state：一个整数或者一个RandomState实例，或者None，指定随机数种子。</span></span><br><span class="line"><span class="string">dissimilarity：一个字符串值，用于定义如何计算不相似度。可以为：</span></span><br><span class="line"><span class="string">              &#x27;euclidean&#x27;：使用欧氏距离。</span></span><br><span class="line"><span class="string">              &#x27;precomputed&#x27;：由使用者提供距离矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">embedding_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了原始数据集在低维空间中的嵌入矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">stress_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，给出了不一致的距离的总和。</span></span><br><span class="line"><span class="string">该指标并不能用于判定降维的效果的好坏，它只是一个中性指标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y, init])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y, init])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="isomap">Isomap</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">sklearn.manifold.Isomap(n_neighbors=<span class="number">5</span>, n_components=<span class="number">2</span>, eigen_solver=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">                        tol=<span class="number">0</span>, max_iter=<span class="literal">None</span>, path_method=<span class="string">&#x27;auto&#x27;</span>, neighbors_algorithm=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn提供的Isomap模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_neighbors：一个整数，指定近邻参数。</span></span><br><span class="line"><span class="string">n_components：一个整数，指定降维后的维数。</span></span><br><span class="line"><span class="string">eigen_solver：一个字符串，指定求解特征值的算法，可以为：</span></span><br><span class="line"><span class="string">              &#x27;auto&#x27;：由算法自动选取。</span></span><br><span class="line"><span class="string">              &#x27;arpack&#x27;：使用Arnoldi分解算法。</span></span><br><span class="line"><span class="string">              &#x27;dense&#x27;：使用一个直接求解特征值的算法（如LAPACK）。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定求解特征值算法的收敛阈值（当eigen_solver=&#x27;dense&#x27;时，该参数无用）。</span></span><br><span class="line"><span class="string">max_iter：一个浮点数，指定求解特征值算法的最大迭代次数（当eigen_solver=&#x27;dense&#x27;时，该参数无用）。</span></span><br><span class="line"><span class="string">path_method：一个字符串，指定寻找最短路径算法。可以为：</span></span><br><span class="line"><span class="string">            &#x27;auto&#x27;：由算法自动选取。</span></span><br><span class="line"><span class="string">            &#x27;FW&#x27;：使用Floyd_Warshall算法。</span></span><br><span class="line"><span class="string">            &#x27;D&#x27;：使用Dijkstra算法。</span></span><br><span class="line"><span class="string">neighbors_algorithm：一字符串，指定计算最近邻的算法。可以为：</span></span><br><span class="line"><span class="string">                    &#x27;ball_tree&#x27;：使用 BallTree算法。</span></span><br><span class="line"><span class="string">                    &#x27;kd_tree：使用 KDTree算法。</span></span><br><span class="line"><span class="string">                    &#x27;brute&#x27;：使用暴力搜索法。</span></span><br><span class="line"><span class="string">                    &#x27;auto&#x27;：自动决定最合适的算法。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">embedding_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了原始数据集在低维空间中的嵌入矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">training_data_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">存储了原始训练数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">dist_matrix_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">存储了原始训练数据的距离矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">reconstruction_error()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算重构误差。</span></span><br><span class="line"><span class="string">该指标并不能用于判定降维的效果的好坏，它只是一个中性指标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="locallylinearembedding">LocallyLinearEmbedding</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">sklearn.manifold.LocallyLinearEmbedding(n_neighbors=<span class="number">5</span>, n_components=<span class="number">2</span>, </span><br><span class="line">                                    reg=<span class="number">0.001</span>,eigen_solver=<span class="string">&#x27;auto&#x27;</span>, tol=<span class="number">1e-06</span>, max_iter=<span class="number">100</span>, method=<span class="string">&#x27;standard&#x27;</span>,</span><br><span class="line">                                    hessian_tol=<span class="number">0.0001</span>,modified_tol=<span class="number">1e-12</span>, neighbors_algorithm=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">                                    random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn提供的LLE模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_neighbors：一个整数，指定近邻参数。</span></span><br><span class="line"><span class="string">n_components：一个整数，指定降维后的维数。</span></span><br><span class="line"><span class="string">reg：一个浮点数，指定正则化项的系数。</span></span><br><span class="line"><span class="string">eigen_solver：一个字符串，指定求解特征值的算法，可以为：</span></span><br><span class="line"><span class="string">            &#x27;auto&#x27;：由算法自动选取。</span></span><br><span class="line"><span class="string">            &#x27;arpack&#x27;：使用Arnoldi分解算法。</span></span><br><span class="line"><span class="string">            &#x27;dense&#x27;：使用一个直接求解特征值的算法（如LAPACK）。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定求解特征值算法的收敛阈值（当eigen_solver=&#x27;dense&#x27;时，该参数无用）。</span></span><br><span class="line"><span class="string">max_iter：一个浮点数，指定求解特征值算法的最大迭代次数（当eigen_solver=&#x27;dense&#x27;时，该参数无用）。</span></span><br><span class="line"><span class="string">method：一个字符串，用于指定LLE算法的形式。可以为：</span></span><br><span class="line"><span class="string">        &#x27;standard&#x27;：使用标准的LLE算法。</span></span><br><span class="line"><span class="string">        &#x27;hessian&#x27;：使用Hessian eignmap算法。</span></span><br><span class="line"><span class="string">        &#x27;modified&#x27;：使用modified LLE算法。</span></span><br><span class="line"><span class="string">&#x27;ltsa&#x27;：使用local tangent space alignment算法。</span></span><br><span class="line"><span class="string">hessian_tol：一个浮点数，用于method=&#x27;hessian&#x27;时收敛的阈值。</span></span><br><span class="line"><span class="string">modified_tol：一个浮点数，用于method=&#x27;modified&#x27;时收敛的阈值。</span></span><br><span class="line"><span class="string">neighbors_algorithm：一字符串，指定计算最近邻的算法。可以为：</span></span><br><span class="line"><span class="string">                    &#x27;ball_tree&#x27;：使用 BallTree算法。</span></span><br><span class="line"><span class="string">                    &#x27;kd_tree：使用 KDTree算法。</span></span><br><span class="line"><span class="string">                    &#x27;brute&#x27;：使用暴力搜索法。</span></span><br><span class="line"><span class="string">                    &#x27;auto&#x27;：自动决定最合适的算法。</span></span><br><span class="line"><span class="string">random_state：一个整数/一个RandomState实例/None，指定随机数种子。它用于eigen_solver=&#x27;arpack&#x27; 。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">embedding_vectors_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了原始数据在低维空间的嵌入矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">reconstruction_error_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了重构误差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行降维，返回降维后的样本集。</span></span><br><span class="line"><span class="string">该指标并不能用于判定降维的效果的好坏，它只是一个中性指标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="fa">FA</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.FactorAnalysis(n_components=<span class="literal">None</span>, tol=<span class="number">0.01</span>, copy=<span class="literal">True</span>,</span><br><span class="line">                                max_iter=<span class="number">1000</span>, noise_variance_init=<span class="literal">None</span>, svd_method=’randomized’, iterated_power=<span class="number">3</span>, </span><br><span class="line">                                random_state=<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn提供的FA模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_components：一个整数/None，指定隐空间的维度。如果为None，则隐空间的维度为数据的特征维度。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定EM算法的收敛阈值。</span></span><br><span class="line"><span class="string">copy：一个布尔值，指定是否拷贝原始数据。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定最大的迭代次数。</span></span><br><span class="line"><span class="string">noise_variance_init：一个形状为(n_features,)的数组/None。</span></span><br><span class="line"><span class="string">                    指定噪音的协方差矩阵X（它时一个对角矩阵，该数组指定了对角矩阵的元素）的初始值。</span></span><br><span class="line"><span class="string">                    如果为None，则它等于全 1 的数据。等价于X=单位阵。</span></span><br><span class="line"><span class="string">svd_method：一个字符串，指定求解SVD的算法。对于大多数场景，该算法的精度已经能够满足需求。可以为：</span></span><br><span class="line"><span class="string">          &#x27;lapack&#x27;：使用scipy.linalg的标准SVD求解算法。</span></span><br><span class="line"><span class="string">          &#x27;randomized&#x27;：使用更快的randomized_svd求解算法。</span></span><br><span class="line"><span class="string">iterated_power：一个整数，指定power method的迭代次数。仅仅用于svd_method=&#x27;randomized&#x27;。</span></span><br><span class="line"><span class="string">random_state： 一个整数/一个RandomState实例/None。指定随机数种子。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">componets_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_components, n_features]的数组，给出了矩阵W。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">loglike_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_iterations,]的列表，给出了每次迭代的对数似然函数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">noise_variance_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_features,] 的数组，给出了噪音的协方差矩阵X。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用EM算法训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行因子分析，返回因子分析后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行因子分析，返回因子分析后的样本集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">get_covariance()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在因子分析中，计算p(x)的协方差矩阵，即C。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">算数据集的平均对数似然函数值，返回一个浮点数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score_samples(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算每个样本的对数似然函数值，返回一个长度为N的序列，N为样本的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="fastica">FastICA</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.FastICA(n_components=<span class="literal">None</span>, algorithm=’parallel’, whiten=<span class="literal">True</span>, fun=’logcosh’, </span><br><span class="line">                    fun_args=<span class="literal">None</span>, max_iter=<span class="number">200</span>, tol=<span class="number">0.0001</span>, w_init=<span class="literal">None</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">是scikit-learn提供的FastICA模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_components ：一个整数/None，指定独立成分的数量。如果为None，则独立成分的数量为n（观测样本的特征数）。</span></span><br><span class="line"><span class="string">algorithm：一个字符串，指定求解FastICA的算法。可以为：&#123;&#x27;parallel&#x27;,&#x27;delfation&#x27;&#125;。</span></span><br><span class="line"><span class="string">whiten：一个布尔值，指定是否执行白化预处理。</span></span><br><span class="line"><span class="string">fun：一个字符串/可调用对象，指定非线性函数F，它是G的原函数。可以为:</span></span><br><span class="line"><span class="string">    &#x27;logcosh&#x27;：F(s)=(1/a)*logcosh(as)，因此G(s)=tanh(as)。</span></span><br><span class="line"><span class="string">    &#x27;exp&#x27;：F(s)=-exp^(-(s^2)/2)，因此G(s)=s*exp(-(s^2)/2)。</span></span><br><span class="line"><span class="string">    &#x27;cube&#x27;：F(s)=-(1/4)*s^4，因此G(s)=s^3。</span></span><br><span class="line"><span class="string">    一个可调用对象：参数为s，返回值为元组(函数值，梯度值)。</span></span><br><span class="line"><span class="string">fun_args：一个字典，用于为fun提供关键字参数。如果fun=&#x27;logcosh&#x27;且fun_args为空，则其默认值为&#123;&#x27;alpha&#x27;:1.0&#125;。</span></span><br><span class="line"><span class="string">max_iter： 一个整数，指定最大迭代次数。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定迭代时的收敛阈值。</span></span><br><span class="line"><span class="string">w_init：一个(n_componets,n_componets)形状的数组/None，指定了混合矩阵A的初始化值。</span></span><br><span class="line"><span class="string">random_state： 一个整数/一个RandomState实例/None。指定随机数种子。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">components_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_componets,n_features)的矩阵，给出了分离矩阵W。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">mixing_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_features,n_components)的矩阵，给出了混合矩阵A。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了迭代次数。</span></span><br><span class="line"><span class="string">如果算法是&#x27;deflation&#x27;，则它是每个分量上迭代次数的最大值。</span></span><br><span class="line"><span class="string">否则它是算法收敛时的总迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行独立成分分离，返回独立因子数据集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行独立成分分离，返回独立因子数据集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inverse_transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行独立成分分离的逆运算，返回混合之后的观测数据集。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="t-sne">t-SNE</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">scikit-learn提供的t-SNE模型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n_components：一个整数，指定低维空间的维度。</span></span><br><span class="line"><span class="string">perplexity：一个浮点数，指定了困惑度。该参数影响的是：对每个点，考虑其周围多少个邻居点。</span></span><br><span class="line"><span class="string">            其取值范围通常在[5,50]之间，对于较大的数据集该参数通常较大。</span></span><br><span class="line"><span class="string">            t-SNE对于该参数不是特别敏感，因此该参数不是特别重要。</span></span><br><span class="line"><span class="string">early_exaggeration：一个浮点数，指定了早期对q_(i,j)放大的倍数。</span></span><br><span class="line"><span class="string">            如果该数值较大，则相当于将高维空间中的点执行压缩。</span></span><br><span class="line"><span class="string">            t-SNE对于该参数不是特别敏感，因此该参数不是特别重要。</span></span><br><span class="line"><span class="string">learning_rate ：一个浮点数，指定学习率。通常范围是在[10.0, 1000.0]。</span></span><br><span class="line"><span class="string">            如果学习率过高，则降维之后的数据就像一个球体，每个点与它最近邻点的距离都几乎相等。</span></span><br><span class="line"><span class="string">            如果学习率过低，则降维之后的数据看起来像是一个密集的压缩云，以及云外少量的异常点。</span></span><br><span class="line"><span class="string">            如果代价函数陷入了局部极小值，则增加学习率会有帮助。</span></span><br><span class="line"><span class="string">n_iter：一个整数，指定最大的迭代次数。</span></span><br><span class="line"><span class="string">n_iter_without_progress：一个整数，在结束优化之前的、不在进度之内的最大迭代次数。主要用于初始化时的early_exaggeration。</span></span><br><span class="line"><span class="string">min_grad_norm：一个浮点数，指定梯度的阈值。如果梯度小于该阈值，则优化过程停止。</span></span><br><span class="line"><span class="string">metric：一个字符串/可调用对象，指定距离的度量函数。</span></span><br><span class="line"><span class="string">        如果是字符串，则它必须匹配scipy.spatial.distance.pdist的metric参数。</span></span><br><span class="line"><span class="string">        如果是字符串&#x27;precomputed&#x27;，则 X 必须是一个距离矩阵。</span></span><br><span class="line"><span class="string">        如果是可调用对象，则它传入一对样本点返回一个距离值。</span></span><br><span class="line"><span class="string">init：一个字符串/numpy array，指定初始化策略。</span></span><br><span class="line"><span class="string">    &#x27;random&#x27;：使用随机初始化。</span></span><br><span class="line"><span class="string">    &#x27;pca&#x27;：使用PCA 初始化。它通常会更健壮。</span></span><br><span class="line"><span class="string">    一个形状为(n_samples,n_componets)的array：直接初始化。</span></span><br><span class="line"><span class="string">verbose：一个整数，指定日志输出的级别。</span></span><br><span class="line"><span class="string">random_state ： 一个整数/一个RandomState实例/None。指定随机数种子。</span></span><br><span class="line"><span class="string">method：一个字符串，指定梯度计算策略。</span></span><br><span class="line"><span class="string">       &#x27;barnes_ht&#x27;：使用Barnes-Hut 近似算法，它计算梯度的近似值，计算复杂度为O(NlogN)。</span></span><br><span class="line"><span class="string">       &#x27;exact&#x27;：计算梯度的精确值，计算复杂度为O(N^2)。</span></span><br><span class="line"><span class="string">angle：一个浮点数，用于method=&#x27;barnes_ht&#x27;，用于平衡速度和准确率。</span></span><br><span class="line"><span class="string">       该参数在[0.2, 0.8]之间变化时，t-SNE的结果不会发生太大的变化。</span></span><br><span class="line"><span class="string">       如果该参数小于0.2，则计算时间会迅速增长。</span></span><br><span class="line"><span class="string">       如果该参数大于0.8，则计算误差会迅速增长。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">embedding_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,n_components) 的数组，给出了数据集在低维空间的表示。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">kl_divergence_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，给出了优化后的KL散度。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了执行的迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型，并返回训练数据集在低维空间中的表示。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="监督学习">监督学习</h1>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9zdXBlcnZpc2VkX2xlYXJuaW5nLmh0bWwjc3VwZXJ2aXNlZC1sZWFybmluZw==">Classification、Regression<i class="fa fa-external-link-alt"></i></span>。</p>
<p>模型的通用方法和参数：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">get_params([deep])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的参数。</span></span><br><span class="line"><span class="string">deep：如果为True，则可以返回模型参数的子对象。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">set_params(**params)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">设置模型的参数。</span></span><br><span class="line"><span class="string">params：待设置的关键字参数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">X：训练集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：训练样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">sample_weight：每个样本的权重。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">利用模型执行预测。返回一个预测结果序列。</span></span><br><span class="line"><span class="string">X：测试集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对模型进行评估，返回模型的性能评估结果。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">X：验证集样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：验证集样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">sample_weight：每个样本的权重。它与X的每一行相对应。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">对于分类模型，其评估的是accuracy；对于回归模型，其评估的是R2。</span></span><br><span class="line"><span class="string">如果希望有其它的评估指标，则可以执行predict()方法，然后把预测结果、真实标记作为参数来调用一些打分函数即可。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 通用参数</span></span><br><span class="line">n_jobs</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个正数，指定任务并形时指定的CPU数量。</span></span><br><span class="line"><span class="string">如果为 -1 则使用所有可用的CPU。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">verbose</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个正数。用于开启/关闭迭代中间输出日志功能。</span></span><br><span class="line"><span class="string">数值越大，则日志越详细。</span></span><br><span class="line"><span class="string">数值为0或者None，表示关闭日志输出。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">warm_start</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个布尔值。如果为True，那么使用前一次训练结果继续训练。否则从头开始训练。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">max_iter</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，指定最大迭代次数。</span></span><br><span class="line"><span class="string">如果为None则为默认值（不同solver的默认值不同）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">random_state</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数/一个RandomState实例/None。</span></span><br><span class="line"><span class="string">如果为整数，则它指定了随机数生成器的种子。</span></span><br><span class="line"><span class="string">如果为RandomState实例，则指定了随机数生成器。</span></span><br><span class="line"><span class="string">如果为None，则使用默认的随机数生成器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="线性模型">线性模型</h2>
<p>一些通用参数：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fit_intercept</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个布尔值，指定是否需要计算截距项。如果为False，那么不会计算截距项。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_scaling</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，用于缩放截距项的正则化项的影响。</span></span><br><span class="line"><span class="string">当采用fit_intercept时，相当于人造一个特征出来，该特征恒为 1 ，其权重为 b 。</span></span><br><span class="line"><span class="string">在计算正则化项的时候，该人造特征也被考虑了。为了降低这个人造特征的影响，需要提供intercept_scaling。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">tol</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，指定判断迭代收敛与否的阈值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
线性回归：LinearRegression、Ridge、Lasso、ElasticNet、LogisticRegression、LinearDiscriminantAnalysis：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LinearRegression(fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>,</span><br><span class="line">                                        copy_X=<span class="literal">True</span>, n_jobs=<span class="number">1</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">fit_intercept：一个布尔值，指定是否需要计算截距项。</span></span><br><span class="line"><span class="string">normalize：一个布尔值。如果为True，那么训练样本会在训练之前会被归一化。</span></span><br><span class="line"><span class="string">copy_X：一个布尔值。如果为True，则会拷贝X。</span></span><br><span class="line"><span class="string">n_jobs：一个整数，指定计算并行度。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">coef_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">权重向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">b值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.linear_model.Ridge(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, </span><br><span class="line">                           copy_X=<span class="literal">True</span>, max_iter=<span class="literal">None</span>, tol=<span class="number">0.001</span>, solver=<span class="string">&#x27;auto&#x27;</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">alpha：用于缓解过拟合。</span></span><br><span class="line"><span class="string">max_iter： 指定最大迭代次数。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定判断迭代收敛与否的阈值。</span></span><br><span class="line"><span class="string">solver：一个字符串，指定求解最优化问题的算法。可以为：</span></span><br><span class="line"><span class="string">        &#x27;auto&#x27;：根据数据集自动选择算法。</span></span><br><span class="line"><span class="string">        &#x27;svd&#x27;：使用奇异值分解来计算回归系数。</span></span><br><span class="line"><span class="string">        &#x27;cholesky&#x27;：使用scipy.linalg.solve函数来求解。</span></span><br><span class="line"><span class="string">        &#x27;sparse_cg&#x27;：使用scipy.sparse.linalg.cg函数来求解。</span></span><br><span class="line"><span class="string">        &#x27;lsqr&#x27;：使用scipy.sparse.linalg.lsqr函数求解。它运算速度最快，但是可能老版本的scipy不支持。</span></span><br><span class="line"><span class="string">        &#x27;sag&#x27;：使用Stochastic Average Gradient descent算法求解最优化问题。</span></span><br><span class="line"><span class="string">random_state：用于设定随机数生成器，它在solver=sag时使用。</span></span><br><span class="line"><span class="string">其它参数参考LinearRegression。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当alpha超过 1 之后，随着alpha的增长，预测性能急剧下降。</span></span><br><span class="line"><span class="string">这是因为alpha较大时，正则化项alpha||W||^2影响较大，模型趋向于简单。</span></span><br><span class="line"><span class="string">极端情况下当alpha趋于无穷时，W=0从而使得正则化项alpha||W||^2=0，此时的模型最简单。</span></span><br><span class="line"><span class="string">但是预测预测性能非常差，因为对所有的未知样本，模型都预测为同一个常数b。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">coef_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">权重向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">截距，b值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实际迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同LinearRegression</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考LinearRegression。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.linear_model.Lasso(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>,</span><br><span class="line">                    precompute=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="number">1000</span>, tol=<span class="number">0.0001</span>, warm_start=<span class="literal">False</span>, </span><br><span class="line">                    positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, selection=<span class="string">&#x27;cyclic&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">alpha：用于缓解过拟合。</span></span><br><span class="line"><span class="string">precompute：一个布尔值/一个序列。是否提前计算Gram矩阵来加速计算。</span></span><br><span class="line"><span class="string">warm_start：是否从头开始训练。</span></span><br><span class="line"><span class="string">positive：一个布尔值。如果为True，那么强制要求权重向量的分量都为正数。</span></span><br><span class="line"><span class="string">selection：一个字符串，可以为&#x27;cyclic&#x27;/&#x27;random&#x27;。它指定了当每轮迭代的时候，选择权重向量的哪个分量来更新。</span></span><br><span class="line"><span class="string">          &#x27;random&#x27;：更新的时候，随机选择权重向量的一个分量来更新。</span></span><br><span class="line"><span class="string">          &#x27;cyclic&#x27;：更新的时候，从前向后依次选择权重向量的一个分量来更新。</span></span><br><span class="line"><span class="string">其它参数参考Ridge。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当alpha超过 1 之后，随着alpha的增长，预测性能急剧下降。原因同Ridge的分析一样。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，同Ridge </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考Ridge。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同LinearRegression</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考LinearRegression。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.linear_model.ElasticNet(alpha=<span class="number">1.0</span>, l1_ratio=<span class="number">0.5</span>, fit_intercept=<span class="literal">True</span>,</span><br><span class="line">                normalize=<span class="literal">False</span>, precompute=<span class="literal">False</span>, max_iter=<span class="number">1000</span>, copy_X=<span class="literal">True</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">                warm_start=<span class="literal">False</span>, positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, selection=<span class="string">&#x27;cyclic&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">alpha：alpha。</span></span><br><span class="line"><span class="string">l1_ratio：l1_ratio。</span></span><br><span class="line"><span class="string">其他参数，参考Lasso。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">最小化的目标函数：</span></span><br><span class="line"><span class="string">1 / (2 * n_samples) * ||y - Xw||^2_2</span></span><br><span class="line"><span class="string">+ alpha * l1_ratio * ||w||_1</span></span><br><span class="line"><span class="string">+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">随着alpha增大，预测的性能下降，因为正则化项：</span></span><br><span class="line"><span class="string">+ alpha * l1_ratio * ||w||_1</span></span><br><span class="line"><span class="string">+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">l1_ratio影响的是性能下降的速度，因为这个参数控制着||w||_1与||w||^2_2的比例。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，同Lasso</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考Lasso。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同Lasso</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考Lasso。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.linear_model.LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, dual=<span class="literal">False</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">                                C=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>, </span><br><span class="line">                                random_state=<span class="literal">None</span>, solver=<span class="string">&#x27;lbfgs&#x27;</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">&#x27;saga&#x27;</span>, </span><br><span class="line">                                verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>, n_jobs=<span class="number">1</span>, l1_ratio=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">penalty：一个字符串，指定了正则化策略。</span></span><br><span class="line"><span class="string">         如果为&#x27;l2&#x27;， 则为L2正则化。</span></span><br><span class="line"><span class="string">         如果为&#x27;l1&#x27;，则为L1正则化。</span></span><br><span class="line"><span class="string">dual ：一个布尔值。</span></span><br><span class="line"><span class="string">       如果为True，则求解对偶形式（只在penalty=&#x27;l2&#x27;且solver=&#x27;liblinear&#x27;有对偶形式）。</span></span><br><span class="line"><span class="string">       如果为False，则求解原始形式。</span></span><br><span class="line"><span class="string">C：一个浮点数。它指定了罚项系数的倒数。如果它的值越小，则正则化项越大。</span></span><br><span class="line"><span class="string">class_weight：一个字典/&#x27;balanced&#x27; ，指定每个类别的权重。</span></span><br><span class="line"><span class="string">             字典：则字典给出了每个分类的权重。如&#123;class_label: weight&#125;。</span></span><br><span class="line"><span class="string">             &#x27;balanced&#x27;：则每个分类的权重与该分类在样本集中出现的频率成反比。</span></span><br><span class="line"><span class="string">             如果未指定，则每个分类的权重都为1。</span></span><br><span class="line"><span class="string">solver：一个字符串，指定了求解最优化问题的算法。可以为下列的值：</span></span><br><span class="line"><span class="string">        &#x27;newton-cg&#x27;：牛顿法。</span></span><br><span class="line"><span class="string">        &#x27;lbfgs&#x27;：L-BFGS拟牛顿法。</span></span><br><span class="line"><span class="string">        &#x27;liblinear&#x27;：liblinear。</span></span><br><span class="line"><span class="string">        &#x27;sag&#x27;：Stochastic Average Gradient descent算法。</span></span><br><span class="line"><span class="string">        &#x27;saga&#x27;：sag增加惩罚项。</span></span><br><span class="line"><span class="string">          对于规模小的数据集&#x27;liblinear&#x27;比较适用；对于规模大的数据集&#x27;sag&#x27;比较适用。</span></span><br><span class="line"><span class="string">         &#x27;newton-cg&#x27;、&#x27;lbfgs&#x27;、&#x27;sag&#x27;只处理penalty=&#x27;l2&#x27;的情况。</span></span><br><span class="line"><span class="string">multi_class：一个字符串，指定对于多分类问题的策略。可以为：</span></span><br><span class="line"><span class="string">            &#x27;ovr&#x27;：采用one-vs-rest策略。</span></span><br><span class="line"><span class="string">            &#x27;multinomial&#x27;：直接采用多分类logistic回归策略。</span></span><br><span class="line"><span class="string">            &#x27;auto&#x27;：自动选择。当数据是二分类/solver=&#x27;liblinear&#x27;时选择&#x27;ovr&#x27;，否则选择&#x27;multinomial&#x27;。</span></span><br><span class="line"><span class="string">l1_ratio：一个浮点数，0&lt;=l1_ratio&lt;=1。仅在penalty=&#x27;elasticnet&#x27;时使用。</span></span><br><span class="line"><span class="string">         设置l1_ratio=0等价于使用penalty=&#x27;l2&#x27;，而设置l1_ratio=1等价于使用penalty=&#x27;l1&#x27;。</span></span><br><span class="line"><span class="string">         对于0&lt;l1_ratio&lt;1，惩罚是 L1 和 L2 的组合。</span></span><br><span class="line"><span class="string">其它参数参考ElasticNet。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">C是正则化项系数的倒数，它越小则正则化项的权重越大。</span></span><br><span class="line"><span class="string">随着C的增大（即正则化项的减小），LogisticRegression的预测准确率上升。</span></span><br><span class="line"><span class="string">当C增大到一定程度（即正则化项减小到一定程度），LogisticRegression的预测准确率维持在较高的水准保持不变。</span></span><br><span class="line"><span class="string">但事实上，当C太大时，正则化项接近于0，此时容易发生过拟合，泛化能力下降。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，同ElasticNet</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考ElasticNet。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sklearn.discriminant_analysis.LinearDiscriminantAnalysis(solver=<span class="string">&#x27;svd&#x27;</span>, shrinkage=<span class="literal">None</span>, priors=<span class="literal">None</span>,</span><br><span class="line">                              n_components=<span class="literal">None</span>, store_covariance=<span class="literal">False</span>, tol=<span class="number">0.0001</span>, covariance_estimator=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">solver：一个字符串，指定求解最优化问题的算法。可以为：</span></span><br><span class="line"><span class="string">        &#x27;svd&#x27;：奇异值分解。对于有大规模特征的数据，推荐用这种算法。</span></span><br><span class="line"><span class="string">        &#x27;lsqr&#x27;：最小平方差算法，可以结合shrinkage参数。</span></span><br><span class="line"><span class="string">        &#x27;eigen&#x27;：特征值分解算法，可以结合shrinkage参数。</span></span><br><span class="line"><span class="string">shrinkage：字符串&#x27;auto&#x27;/浮点数/None。该参数只有在solver=&#x27;lsqr&#x27;/&#x27;eigen&#x27;下才有意义。</span></span><br><span class="line"><span class="string">           当矩阵求逆时，它会在对角线上增加一个小的数\lambda，防止矩阵为奇异的。其作用相当于正则化。</span></span><br><span class="line"><span class="string">           &#x27;auto&#x27;：根据Ledoit-Wolf引理来自动决定  的大小。</span></span><br><span class="line"><span class="string">           None：不使用shrinkage参数。</span></span><br><span class="line"><span class="string">           一个[0.0, 1.0]浮点数：指定\lambda的值。</span></span><br><span class="line"><span class="string">priors：一个数组，数组中的元素依次指定了每个类别的先验概率。如果为None则认为每个类的先验概率都是等可能的。</span></span><br><span class="line"><span class="string">n_components：一个整数，指定了数据降维后的维度（该值必须小于 n_classes-1）。</span></span><br><span class="line"><span class="string">store_covariance：一个布尔值。如果为True，则需要额外计算每个类别的协方差矩阵。</span></span><br><span class="line"><span class="string">tol：一个浮点值。它指定了用于SVD算法中评判迭代收敛的阈值。</span></span><br><span class="line"><span class="string">covariance_estimator：协方差估计器。</span></span><br><span class="line"><span class="string">          如果非None，则使用指定的估计器，来估计协方差矩阵，而不是依赖经验协方差估计量（具有潜在收缩）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，其他属性参考Ridge</span></span><br><span class="line">covariance_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，依次给出了每个类别的协方差矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">means_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，依次给出了每个类别的均值向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">xbar_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了整体样本的均值向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，同LogisticRegression</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考LogisticRegression。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="支持向量机">支持向量机</h2>
<p>通用参数：<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">fit_intercept</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个布尔值，指定是否需要计算截距项。如果为False，那么不会计算截距项。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_scaling</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，用于缩放截距项的正则化项的影响。</span></span><br><span class="line"><span class="string">当采用fit_intercept时，相当于人造一个特征出来，该特征恒为 1 ，其权重为 b 。</span></span><br><span class="line"><span class="string">在计算正则化项的时候，该人造特征也被考虑了。为了降低这个人造特征的影响，需要提供intercept_scaling。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">tol</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，指定判断迭代收敛与否的阈值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">class_weight</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个字典/&#x27;balanced&#x27; ，指定每个类别的权重。</span></span><br><span class="line"><span class="string">字典：则字典给出了每个分类的权重。如&#123;class_label: weight&#125;。</span></span><br><span class="line"><span class="string">&#x27;balanced&#x27;：则每个分类的权重与该分类在样本集中出现的频率成反比。</span></span><br><span class="line"><span class="string">如果未指定，则每个分类的权重都为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
LinearSVC是根据liblinear实现的，它可以用于二类分类，也可以用于多类分类问题（此时是根据one-vs-rest原则来分类。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.LinearSVC(penalty=<span class="string">&#x27;l2&#x27;</span>, loss=<span class="string">&#x27;squared_hinge&#x27;</span>, dual=<span class="literal">True</span>, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>,</span><br><span class="line">            multi_class=<span class="string">&#x27;ovr&#x27;</span>, fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>, </span><br><span class="line">            verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">penalty：字符串，指定 &#x27;l1&#x27;/&#x27;l2&#x27;，罚项的范数。默认为&#x27;l2&#x27;（它是标准SVC采用的）。</span></span><br><span class="line"><span class="string">loss：一个字符串，表示损失函数。可以为：</span></span><br><span class="line"><span class="string">     &#x27;hinge&#x27;：此时为合页损失函数（它是标准 SVM 的损失函数）。</span></span><br><span class="line"><span class="string">     &#x27;squared_hinge&#x27;：合页损失函数的平方。</span></span><br><span class="line"><span class="string">dual：一个布尔值。如果为True则解决对偶问题；如果是False则解决原始问题。当n_samples&gt;n_features时，倾向于采用False。</span></span><br><span class="line"><span class="string">tol ：一个浮点数，指定终止迭代的阈值。</span></span><br><span class="line"><span class="string">C：一个浮点数，罚项系数。</span></span><br><span class="line"><span class="string">multi_class ：一个字符串，指定多类分类问题的策略。</span></span><br><span class="line"><span class="string">            &#x27;ovr&#x27;：采用one-vs-rest分类策略。</span></span><br><span class="line"><span class="string">            &#x27;crammer_singer&#x27;：多类联合分类，很少用。因为它计算量大而且精度不会更佳。此时忽略loss,penalty,dual项。</span></span><br><span class="line"><span class="string">fit_intercept ：一个布尔值，指定是否需要计算截距项。</span></span><br><span class="line"><span class="string">intercept_scaling：一个浮点数，用于缩放截距项的正则化项的影响。</span></span><br><span class="line"><span class="string">class_weight： 一个字典/&#x27;balanced&#x27; ，指定每个类别的权重。</span></span><br><span class="line"><span class="string">verbose：一个正数。用于开启/关闭迭代中间输出日志功能。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定最大迭代次数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">C衡量了误分类点的重要性，C越大则误分类点越重要。</span></span><br><span class="line"><span class="string">当C较小时，误分类点重要性较低，此时误分类点较多，分类器性能较差。</span></span><br><span class="line"><span class="string">为了便于观察可视化时可将x轴以对数表示。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">coef_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">权重向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">截距值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
SVC是根据libsvm实现的，其训练的时间复杂度是采样点数量的平方。<br />
它可以用于二类分类，也可以用于多类分类问题（此时默认是根据one-vs-rest原则来分类）。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="literal">True</span>,</span><br><span class="line">            probability=<span class="literal">False</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>, verbose=<span class="literal">False</span>,</span><br><span class="line">            max_iter=-<span class="number">1</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>, break_ties=<span class="literal">False</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">linear&#x27;：线性核，K(x,z)=(x,z)</span></span><br><span class="line"><span class="string">        &#x27;poly&#x27;：多项式核，K(x,z)=(g((x,z)+1)+r)^p，p由degree决定，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;rbf&#x27;：默认值，高斯核，K(x,z)=e^(-g||x-z||^2)，g由gamma决定。</span></span><br><span class="line"><span class="string">        &#x27;sigmoid&#x27;：sigmod核函数，K(x,z)=tanh(g(x,z)+r)，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;precomputed&#x27;：表示提供了kernel matrix。</span></span><br><span class="line"><span class="string">C：一个浮点数，罚项系数。</span></span><br><span class="line"><span class="string">kernel：一个字符串，指定核函数。</span></span><br><span class="line"><span class="string">        &#x27;linear&#x27;：线性核，K(x,z)=(x,z)。</span></span><br><span class="line"><span class="string">        &#x27;poly&#x27;：多项式核，K(x,z)=(g((x,z)+1)+r)^p，p由degree决定，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;rbf&#x27;：默认值，高斯核，K(x,z)=e^(-g||x-z||^2)，g由gamma决定。</span></span><br><span class="line"><span class="string">        &#x27;sigmoid&#x27;：sigmod核函数，K(x,z)=tanh(g(x,z)+r)，g由gamma决定，r由coef0决定。</span></span><br><span class="line"><span class="string">        &#x27;precomputed&#x27;：表示提供了kernel matrix。</span></span><br><span class="line"><span class="string">        一个可调用对象，该对象用于计算kernel matrix。</span></span><br><span class="line"><span class="string">degree：一个整数。指定当核函数是多项式核函数时，多项式的系数。对于其他核函数，该参数无效。</span></span><br><span class="line"><span class="string">gamma：一个浮点数。当核函数是&#x27;rbf&#x27;，&#x27;poly&#x27;，&#x27;sigmoid&#x27;时，核函数的系数。如果&#x27;auto&#x27;，则表示系数为1/n_features 。</span></span><br><span class="line"><span class="string">coef0：浮点数，用于指定核函数中的自由项。只有当核函数是&#x27;poly&#x27;和&#x27;sigmoid&#x27;是有效。</span></span><br><span class="line"><span class="string">probability：布尔值。如果为True则会进行概率估计。它必须在训练之前设置好，且概率估计会拖慢训练速度。</span></span><br><span class="line"><span class="string">shrinking：布尔值。如果为True，则使用启发式(shrinking heuristic) 。</span></span><br><span class="line"><span class="string">tol：浮点数，指定终止迭代的阈值。</span></span><br><span class="line"><span class="string">cache_size：浮点值，指定了kernel cache的大小，单位为MB。</span></span><br><span class="line"><span class="string">class_weight：指定各类别的权重。</span></span><br><span class="line"><span class="string">decision_function_shape：为字符串或者None，指定决策函数的形状。</span></span><br><span class="line"><span class="string">        &#x27;ovr&#x27;：则使用one-vs-rest准则。那么决策函数形状是(n_samples,n_classes)。</span></span><br><span class="line"><span class="string">               此时对每个分类定义了一个二类SVM，一共n_classes个二类SVM 。</span></span><br><span class="line"><span class="string">        &#x27;ovo&#x27;：则使用one-vs-one准测。那么决策函数形状是(n_samples, n_classes*(n_classes-1)/2)。</span></span><br><span class="line"><span class="string">               此时对每一对分类直接定义了一个二类SVM，一共n_classes*(n_classes-1)/2)个二类SVM。</span></span><br><span class="line"><span class="string">        None：默认值。采用该值时，目前会使用&#x27;ovo&#x27;，但是在scikit v0.18之后切换成&#x27;ovr&#x27;。</span></span><br><span class="line"><span class="string">break_ties：一个布尔值，如果为True且decision_function_shape=&#x27;ovr&#x27;且分类数量大于2，</span></span><br><span class="line"><span class="string">           预测将根据decision_function的置信度值打破联系。</span></span><br><span class="line"><span class="string">           否则返回绑定类中的第一个类。请注意，与简单的预测相比，打破关系的计算成本相对较高。</span></span><br><span class="line"><span class="string">其它参数参考LinearSVC 。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">support_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组, 形状为[n_SV]，给出了支持向量的下标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">support_vectors_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组, 形状为[n_SV, n_features]，给出了支持向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_support_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组, 形状为[n_class]，给出了每一个分类的支持向量的个数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">dual_coef_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为[n_class-1, n_SV]。给出了对偶问题中，每个支持向量的系数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">coef_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为[n_class-1, n_features]。给出了原始问题中，每个特征的系数。</span></span><br><span class="line"><span class="string">它只有在linear kernel中有效。</span></span><br><span class="line"><span class="string">它是个只读的属性。它是从dual_coef_ 和support_vectors_计算而来。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">intercept_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为[n_class*(n_class-1)/2]，给出了决策函数中的常数项。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
NuSVC与SVC相似，但是用一个参数来控制了支持向量的个数。它是基于libsvm来实现的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.NuSVC(nu=<span class="number">0.5</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, coef0=<span class="number">0.0</span>,</span><br><span class="line">            shrinking=<span class="literal">True</span>,probability=<span class="literal">False</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>,</span><br><span class="line">            verbose=<span class="literal">False</span>,max_iter=-<span class="number">1</span>, decision_function_shape=<span class="literal">None</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">nu : 一个浮点数，取值范围为(0,1]，默认为0.5。它控制训练误差与支持向量的比值，间接控制了支持向量的个数。</span></span><br><span class="line"><span class="string">其它参数、属性、方法，参考SVC。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
LinearSVR是根据liblinear实现的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.LinearSVR(epsilon=<span class="number">0.0</span>, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>, loss=<span class="string">&#x27;epsilon_insensitive&#x27;</span>,</span><br><span class="line">            fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1.0</span>, dual=<span class="literal">True</span>, verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">            max_iter=<span class="number">1000</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">epsilon：一个浮点数，表示epsilon值。</span></span><br><span class="line"><span class="string">loss：字符串。表示损失函数。可以为：</span></span><br><span class="line"><span class="string">    &#x27;epsilon_insensitive&#x27;：此时损失函数为L_epsilon（标准的SVR）。</span></span><br><span class="line"><span class="string">    &#x27;squared_epsilon_insensitive&#x27;：此时损失函数为(L_epsilon)^2。</span></span><br><span class="line"><span class="string">其它参数、属性、方法，参考LinearSVC。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">epsilon增加，预测准确率下降。</span></span><br><span class="line"><span class="string">C增大，预测准确率增加，说明越看重误分类点，则预测的越准确。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
SVR是根据libsvm实现的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.SVR(kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, coef0=<span class="number">0.0</span>, tol=<span class="number">0.001</span>, C=<span class="number">1.0</span>,</span><br><span class="line">            epsilon=<span class="number">0.1</span>, shrinking=<span class="literal">True</span>, cache_size=<span class="number">200</span>, verbose=<span class="literal">False</span>, max_iter=-<span class="number">1</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参数、属性、方法，参考SVC。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
NuSVR是根据libsvm实现的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.NuSVR(nu=<span class="number">0.5</span>, C=<span class="number">1.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, coef0=<span class="number">0.0</span>,</span><br><span class="line">            shrinking=<span class="literal">True</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, verbose=<span class="literal">False</span>, max_iter=-<span class="number">1</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">C：一个浮点数，罚项系数。</span></span><br><span class="line"><span class="string">参数、属性、方法，参考SVC。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
OneClassSVM是根据libsvm实现的。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.OneClassSVM(kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, coef0=<span class="number">0.0</span>, tol=<span class="number">0.001</span>,</span><br><span class="line">            nu=<span class="number">0.5</span>, shrinking=<span class="literal">True</span>, cache_size=<span class="number">200</span>, verbose=<span class="literal">False</span>, max_iter=-<span class="number">1</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参数、属性、方法，参考NuSVC。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="贝叶斯模型">贝叶斯模型</h2>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL25haXZlX2JheWVzLmh0bWwjZ2F1c3NpYW4tbmFpdmUtYmF5ZXM=">Naive
Bayes<i class="fa fa-external-link-alt"></i></span>。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">sklearn.naive_bayes.GaussianNB(*, priors=<span class="literal">None</span>, var_smoothing=<span class="number">1e-09</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">priors：类的先验概率。如果指定，则不会根据数据调整先验。</span></span><br><span class="line"><span class="string">var_smoothing：为计算稳定性添加到方差中的所有特征中最大方差的部分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">class_prior_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes,)，是每个类别的概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">class_count_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes,)，是每个类别包含的训练样本数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">theta_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes,n_features)，是每个类别上，每个特征的均值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sigma_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes,n_features)，是每个类别上，每个特征的标准差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">partial_fit(X, y[, classes, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分批训练模型。该方法主要用于大规模数据集的训练。</span></span><br><span class="line"><span class="string">此时可以将大数据集划分成若干个小数据集，然后在这些小数据集上连续调用partial_fit方法来训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
MultinomialNB：多项式贝叶斯分类器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">sklearn.naive_bayes.MultinomialNB(alpha=<span class="number">1.0</span>, fit_prior=<span class="literal">True</span>, class_prior=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">alpha：一个浮点数。</span></span><br><span class="line"><span class="string">fit_prior：一个布尔值。</span></span><br><span class="line"><span class="string">          如果为True，则不去学习p(y)，替代以均匀分布。</span></span><br><span class="line"><span class="string">          如果为False，则去学习p(y)。</span></span><br><span class="line"><span class="string">class_prior：一个数组。它指定了每个分类的先验概率p(y)。</span></span><br><span class="line"><span class="string">            如果指定了该参数，则每个分类的先验概率不再从数据集中学得。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">alpha超过100之后，随着alpha的增加，预测准确率在下降。</span></span><br><span class="line"><span class="string">alpha趋于无穷时，公式概率趋于1/n，即对任何类型的特征、该类型特征的任意取值，</span></span><br><span class="line"><span class="string">出现的概率都是1/n。它完全忽略了各个特征之间的差别，也忽略了每个特征内部的分布。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">class_log_prior_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组对象，形状为(n_classes,)。</span></span><br><span class="line"><span class="string">给出了每个类别的调整后的的经验概率分布的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_log_prob_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组对象，形状为(n_classes, n_features)。</span></span><br><span class="line"><span class="string">给出了p(x_i|y)的经验概率分布的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">class_count_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes,)，是每个类别包含的训练样本数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_count_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，形状为(n_classes, n_features)。</span></span><br><span class="line"><span class="string">训练过程中，每个类别每个特征遇到的样本数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考GaussianNB。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
ComplementNB：补充朴素贝叶斯。<br />
是标准多项式朴素贝叶斯(MNB)算法的一种改进，特别适用于不平衡数据集。具体来说，CNB使用来自每个类的补数的统计数据来计算模型的权重。CNB的发明者的经验表明，CNB的参数估计比MNB的参数估计更稳定。此外，CNB在文本分类任务上通常比MNB表现得更好(通常有相当大的优势)。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.naive_bayes.ComplementNB(*, alpha=<span class="number">1.0</span>, fit_prior=<span class="literal">True</span>, class_prior=<span class="literal">None</span>, norm=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">norm：是否执行权重的第二次归一化。</span></span><br><span class="line"><span class="string">其他参数、属性、方法，参考MultinomialNB。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
BernoulliNB：伯努利贝叶斯分类器。<br />
它假设特征的条件概率分布满足二项分布。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sklearn.naive_bayes.BernoulliNB(alpha=<span class="number">1.0</span>, binarize=<span class="number">0.0</span>, fit_prior=<span class="literal">True</span>, class_prior=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">binarize：一个浮点数/None。</span></span><br><span class="line"><span class="string">          如果为None，那么会假定原始数据已经是二元化的。</span></span><br><span class="line"><span class="string">          如果是浮点数，则执行二元化策略：以该数值为界：</span></span><br><span class="line"><span class="string">              特征取值大于它的作为 1 。</span></span><br><span class="line"><span class="string">              特征取值小于它的作为 0 。</span></span><br><span class="line"><span class="string">其他参数、属性、方法，参考MultinomialNB。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="knn">KNN</h2>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL25laWdoYm9ycy5odG1sI25lYXJlc3QtbmVpZ2hib3JzLWNsYXNzaWZpY2F0aW9u">Nearest
Neighbors<i class="fa fa-external-link-alt"></i></span>。</p>
<p>KNeighborsClassifier：knn分类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>, weights=<span class="string">&#x27;uniform&#x27;</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>, </span><br><span class="line">                   leaf_size=<span class="number">30</span>, p=<span class="number">2</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>,metric_params=<span class="literal">None</span>, n_jobs=<span class="number">1</span>, **kwargs)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_neighbors：一个整数，指定k值。</span></span><br><span class="line"><span class="string">weights：指定字符串/可调用对象，指定投票权重策略。</span></span><br><span class="line"><span class="string">        &#x27;uniform&#x27;：本结点的所有邻居结点的投票权重都相等。</span></span><br><span class="line"><span class="string">        &#x27;distance&#x27;：本结点的所有邻居结点的投票权重与距离成反比。即越近的结点，其投票权重越大。</span></span><br><span class="line"><span class="string">        一个可调用对象：它传入距离的数组，返回同样形状的权重数组。</span></span><br><span class="line"><span class="string">algorithm：指定字符串，选择计算最近邻的算法。可以为：</span></span><br><span class="line"><span class="string">          &#x27;ball_tree&#x27;：使用BallTree算法。</span></span><br><span class="line"><span class="string">          &#x27;kd_tree：使用KDTree算法。</span></span><br><span class="line"><span class="string">          &#x27;brute&#x27;：使用暴力搜索法。</span></span><br><span class="line"><span class="string">          &#x27;auto&#x27;：自动决定最合适的算法。</span></span><br><span class="line"><span class="string">leaf_size：一个整数，指定BallTree/KDTree叶结点规模。它影响了树的构建和查询速度。</span></span><br><span class="line"><span class="string">metric：指定字符串，选择距离度量。默认为&#x27;minkowski&#x27;距离。</span></span><br><span class="line"><span class="string">p：一个整数，指定在&#x27;Minkowski&#x27;度量上的指数。如果p=1，对应于曼哈顿距离；p=2对应于欧拉距离。</span></span><br><span class="line"><span class="string">n_jobs：并行度。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">kneighbors([X, n_neighbors, return_distance])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回样本点的k近邻点。如果return_distance=True，同时还返回到这些近邻点的距离。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">kneighbors_graph([X, n_neighbors, mode])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回样本点的k近邻点的连接图。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="决策树">决策树</h2>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL3RyZWUuaHRtbA==">Decision
Trees<i class="fa fa-external-link-alt"></i></span>。<br />
DecisionTreeRegressor：回归决策树。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.DecisionTreeRegressor(criterion=<span class="string">&#x27;mse&#x27;</span>, splitter=<span class="string">&#x27;best&#x27;</span>, </span><br><span class="line">            max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">            min_weight_fraction_leaf=<span class="number">0.0</span>, max_features=<span class="literal">None</span>,random_state=<span class="literal">None</span>, </span><br><span class="line">            max_leaf_nodes=<span class="literal">None</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, ccp_alpha=<span class="number">0.0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">criterion：一个字符串，指定切分质量的评价准则。默认为&#x27;mse&#x27;，且只支持该字符串，表示均方误差。</span></span><br><span class="line"><span class="string">splitter：一个字符串，指定切分原则。可以为：</span></span><br><span class="line"><span class="string">         &#x27;best&#x27;：表示选择最优的切分。</span></span><br><span class="line"><span class="string">         &#x27;random&#x27;：表示随机切分。</span></span><br><span class="line"><span class="string">max_features：整数/浮点/指定字符串/None，指定寻找最优拆分时考虑的特征数量。</span></span><br><span class="line"><span class="string">             整数：则每次切分只考虑max_features个特征。</span></span><br><span class="line"><span class="string">             浮点数：则每次切分只考虑max_features*n_features个特征，max_features指定了百分比。</span></span><br><span class="line"><span class="string">             &#x27;sqrt&#x27;：则max_features等于sqrt(n_features)。</span></span><br><span class="line"><span class="string">             &#x27;log2&#x27;：则max_features等于log2(n_features)。</span></span><br><span class="line"><span class="string">             None/&#x27;auto&#x27;：则max_features等于n_features。</span></span><br><span class="line"><span class="string">             注意：如果已经考虑了max_features个特征，但是还没有找到一个有效的切分，</span></span><br><span class="line"><span class="string">                   那么还会继续寻找下一个特征，直到找到一个有效的切分为止。</span></span><br><span class="line"><span class="string">max_depth：整数/None，指定树的最大深度。如果为None，则表示树的深度不限。</span></span><br><span class="line"><span class="string">           分裂子结点，直到每个叶子结点中所有样本点都属于同一类，或者叶结点中包含小于min_samples_split个样点。</span></span><br><span class="line"><span class="string">           如果max_leaf_nodes参数非None，则忽略此选项。</span></span><br><span class="line"><span class="string">min_samples_split：整数，指定每个内部结点包含的最少的样本数。</span></span><br><span class="line"><span class="string">min_samples_leaf：整数，指定每个叶结点包含的最少的样本数。</span></span><br><span class="line"><span class="string">min_weight_fraction_leaf：浮点数，叶结点中样本的最小权重系数。</span></span><br><span class="line"><span class="string">max_leaf_nodes：整数/None，指定最大的叶结点数量。如果为None，此时叶结点数量不限。如果非None，则max_depth被忽略。</span></span><br><span class="line"><span class="string">class_weight：一个字典/&#x27;balanced&#x27;/None。它指定了分类的权重。</span></span><br><span class="line"><span class="string">             字典：则权重的形式为：&#123;class_label:weight&#125;。</span></span><br><span class="line"><span class="string">            &#x27;balanced&#x27;：表示分类的权重是样本中各分类出现的频率的反比。</span></span><br><span class="line"><span class="string">             None：则每个分类的权重都为1。</span></span><br><span class="line"><span class="string">             注意：如果提供了sample_weight参数（由fit方法提供），则这些权重都会乘以sample_weight。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">min_impurity_decrease：一个浮点数，如果此分裂导致不纯度减少量大于或等于该值，则该节点将被分裂。</span></span><br><span class="line"><span class="string">min_impurity_split：一个浮点数，提前停止树木生长的阈值。如果一个节点的不纯度高于阈值，它就会分裂，否则它是一个叶子。</span></span><br><span class="line"><span class="string">ccp_alpha：结构复杂度限制，选取的子树最大结构复杂度小于ccp_alpha。</span></span><br><span class="line"><span class="string">           计算公式参考https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了特征的重要程度。该值越高，则该特征越重要。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">max_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">max_features的推断值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">当执行fit之后，特征的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_outputs_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">当执行fit之后，输出的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">tree_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个 Tree对象，即底层的决策树。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight, check_input, ...])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X[, check_input])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
DecisionTreeClassifier：分类决策树。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>, splitter=<span class="string">&#x27;best&#x27;</span>, max_depth=<span class="literal">None</span>,</span><br><span class="line">            min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>, </span><br><span class="line">            max_features=<span class="literal">None</span>,random_state=<span class="literal">None</span>, max_leaf_nodes=<span class="literal">None</span>, class_weight=<span class="literal">None</span>,</span><br><span class="line">            min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, ccp_alpha=<span class="number">0.0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">criterion：一个字符串，指定切分质量的评价准则。可以为：</span></span><br><span class="line"><span class="string">          &#x27;gini&#x27;：表示切分时评价准则是Gini系数。</span></span><br><span class="line"><span class="string">          &#x27;entropy&#x27;：表示切分时评价准则是熵。</span></span><br><span class="line"><span class="string">其它参数，参考DecisionTreeRegressor。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性，其它属性参考DecisionTreeRegressor。</span></span><br><span class="line">classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分类的标签值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出了分类的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight, check_input, ...])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X[, check_input])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
决策图，先通过<code>pip install Graphviz</code>，在cmd中输入<code>dot -version</code>检查是否成功，不成功需要把Graphviz的bin目录添加到path中，之后再使用sklean画出决策图。<br />
当训练完毕一棵决策树的时候，可以通过<code>sklearn.tree.export_graphviz(classifier,out_file)</code>来将决策树转化成Graphviz格式的文件。<br />
通过<code>dot -Tpng tree.dot -o tree.png</code>命令可以导出png图片，<code>-T</code>选项指定了输出文件的格式，<code>-o</code>选项指定了输出文件名。</p>
<h2 id="集成方法">集成方法</h2>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL2Vuc2VtYmxlLmh0bWw=">Ensemble
methods<i class="fa fa-external-link-alt"></i></span>。</p>
<p>AdaBoostClassifier：AdaBoost分类器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.AdaBoostClassifier(base_estimator=<span class="literal">None</span>, n_estimators=<span class="number">50</span>,  </span><br><span class="line">                learning_rate=<span class="number">1.0</span>, algorithm=<span class="string">&#x27;SAMME.R&#x27;</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">base_estimator：一个基础分类器对象，该基础分类器必须支持带样本权重的学习。默认为DecisionTreeClassfier。</span></span><br><span class="line"><span class="string">n_estimators：一个整数，指定基础分类器的数量（默认为50）。</span></span><br><span class="line"><span class="string">              如果训练集已经完美的训练好了，可能算法会提前停止，此时基础分类器数量少于该值。</span></span><br><span class="line"><span class="string">learning_rate：一个浮点数，表示学习率，默认为1。它就是下式中的v：H_m(x)=H_(m-1)(x)+v*a_m*h_m(x)。</span></span><br><span class="line"><span class="string">              它用于减少每一步的步长，防止步长太大而跨过了极值点。</span></span><br><span class="line"><span class="string">              通常学习率越小，则需要的基础分类器数量会越多，因此在learning_rate和n_estimators之间会有所折中。</span></span><br><span class="line"><span class="string">algorithm：一个字符串，指定用于多类分类问题的算法，默认为&#x27;SAMME.R&#x27; 。</span></span><br><span class="line"><span class="string">          &#x27;SAMME.R&#x27;：SAMME.R算法。基础分类器对象必须支持计算类别的概率。通常&#x27;SAMME.R&#x27;收敛更快且误差更小、迭代数量更少。</span></span><br><span class="line"><span class="string">          &#x27;SAMME&#x27;：SAMME算法。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础分类器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有的类别标签。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">类别数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimator_weights_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个基础分类器的权重。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimator_errors_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个基础分类器的分类误差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：集成分类器在每一轮迭代结束时的预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个二维数组，数组元素依次是：集成分类器在每一轮迭代结束时，预测X为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：集成分类器在每一轮迭代结束时，该集成分类器的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
AdaBoostRegressor：AdaBoost回归器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.AdaBoostRegressor(base_estimator=<span class="literal">None</span>, n_estimators=<span class="number">50</span>,  </span><br><span class="line">                 learning_rate=<span class="number">1.0</span>, loss=<span class="string">&#x27;linear&#x27;</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">base_estimator：一个基础回归器对象，该基础回归器必须支持带样本权重的学习。默认为DecisionTreeRegressor。</span></span><br><span class="line"><span class="string">loss：一个字符串。指定了损失函数。可以为：</span></span><br><span class="line"><span class="string">     &#x27;linear&#x27;：线性损失函数（默认）。</span></span><br><span class="line"><span class="string">     &#x27;square&#x27;：平方损失函数。</span></span><br><span class="line"><span class="string">     &#x27;exponential&#x27;：指数损失函数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其它参数参考AdaBoostClassifier。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础回归器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimator_weights_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个基础回归器的权重。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimator_errors_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个基础回归器的回归误差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：集成回归器在每一轮迭代结束时的预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：集成回归器在每一轮迭代结束时，该集成回归器的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
GradientBoostingClassifier：梯度提升树（GBDT）分类器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.GradientBoostingClassifier(loss=<span class="string">&#x27;deviance&#x27;</span>, learning_rate=<span class="number">0.1</span>,</span><br><span class="line">                 n_estimators=<span class="number">100</span>, subsample=<span class="number">1.0</span>, criterion=<span class="string">&#x27;friedman_mse&#x27;</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">                 min_weight_fraction_leaf=<span class="number">0.0</span>, max_depth=<span class="number">3</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, init=<span class="literal">None</span>, random_state=<span class="literal">None</span>, </span><br><span class="line">                 max_features=<span class="literal">None</span>, verbose=<span class="number">0</span>, max_leaf_nodes=<span class="literal">None</span>, warm_start=<span class="literal">False</span>, </span><br><span class="line">                 validation_fraction=<span class="number">0.1</span>, n_iter_no_change=<span class="literal">None</span>, tol=<span class="number">0.0001</span>, ccp_alpha=<span class="number">0.0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">loss：一个字符串，指定损失函数。可以为：</span></span><br><span class="line"><span class="string">    &#x27;deviance&#x27;（默认值）：损失函数为对数损失函数：L(y_(预测),y_(实际))=-logp(y_(预测))。</span></span><br><span class="line"><span class="string">    &#x27;exponential&#x27;：使用指数损失函数。</span></span><br><span class="line"><span class="string">learning_rate：一个浮点数，表示学习率，默认为1。它就是下式中的v：H_m(x)=H_(m-1)(x)+v*a_m*h_m(x)。</span></span><br><span class="line"><span class="string">              它用于减少每一步的步长，防止步长太大而跨过了极值点。</span></span><br><span class="line"><span class="string">              通常学习率越小，则需要的基础分类器数量会越多，因此在learning_rate和n_estimators之间会有所折中。</span></span><br><span class="line"><span class="string">n_estimators：一个整数，指定基础决策树的数量（默认为100），值越大越好。</span></span><br><span class="line"><span class="string">subsample：0&lt;一个浮点数&lt;=1.0，指定了提取原始训练集中多大比例的一个子集用于训练基础决策树，随机森林使用的是放回抽样。</span></span><br><span class="line"><span class="string">           如果subsample小于1.0，则梯度提升决策树模型就是随机梯度提升决策树。此时会减少方差但是提高了偏差。</span></span><br><span class="line"><span class="string">           它会影响n_estimators参数。</span></span><br><span class="line"><span class="string">criterion：判别标准（默认&#x27;friedman_mse&#x27;），&#123; &#x27;friedman_mse&#x27;,&#x27;mse&#x27;&#125;。</span></span><br><span class="line"><span class="string">min_samples_split：一个整数，指定了每个基础决策树模型的min_samples_split参数。</span></span><br><span class="line"><span class="string">min_samples_leaf：一个整数，指定了每个基础决策树模型的min_samples_leaf参数。</span></span><br><span class="line"><span class="string">min_weight_fraction_leaf：一个浮点数，指定了每个基础决策树模型的min_weight_fraction_leaf参数。</span></span><br><span class="line"><span class="string">max_depth：一个整数/None，指定了每个基础决策树模型的max_depth参数。</span></span><br><span class="line"><span class="string">          调整该参数可以获得最佳性能，一般不指定太深，太深就和决策树一样了，经验值一般为6。</span></span><br><span class="line"><span class="string">          如果max_leaf_nodes不是None，则忽略本参数。</span></span><br><span class="line"><span class="string">max_features：一个整数/浮点数/字符串/None，指定了每个基础决策树模型的max_features参数。</span></span><br><span class="line"><span class="string">              如果max_features&lt;n_features，则会减少方差但是提高了偏差。</span></span><br><span class="line"><span class="string">max_leaf_nodes：为整数/None，指定了每个基础决策树模型的max_leaf_nodes参数。</span></span><br><span class="line"><span class="string">init：一个基础分类器对象/None，该分类器对象用于执行初始的预测。如果为None，则使用loss.init_estimator。</span></span><br><span class="line"><span class="string">verbose：一个正数。用于开启/关闭迭代中间输出日志功能。</span></span><br><span class="line"><span class="string">warm_start：一个布尔值。用于指定是否继续使用上一次训练的结果。</span></span><br><span class="line"><span class="string">random_state：一个随机数种子。</span></span><br><span class="line"><span class="string">validation_fraction：一个浮点数，留出作为早期停止验证集的训练数据的比例。必须介于0和1之间。仅当n_iter_no_change设置为整数时才使用。</span></span><br><span class="line"><span class="string">n_iter_no_change：一个整数/None，用于决定当验证分数没有提高时是否使用提前停止来终止训练。</span></span><br><span class="line"><span class="string">                 默认情况下，它设置为 None 以禁用提前停止。</span></span><br><span class="line"><span class="string">                 如果设置为一个数字，它将留出训练数据的validation_fraction大小作为验证，</span></span><br><span class="line"><span class="string">                    并在之前的所有n_iter_no_change次迭代中验证分数没有提高时终止训练。</span></span><br><span class="line"><span class="string">min_impurity_decrease：一个浮点数，如果此分裂导致不纯度减少量大于或等于该值，则该节点将被分裂。</span></span><br><span class="line"><span class="string">min_impurity_split：一个浮点数，提前停止树木生长的阈值。如果一个节点的不纯度高于阈值，它就会分裂，否则它是一个叶子。</span></span><br><span class="line"><span class="string">tol：一个浮点数，当n_iter_no_change迭代（如果设置为一个数字）的损失没有至少改善tol时，训练停止。</span></span><br><span class="line"><span class="string">ccp_alpha：结构复杂度限制，选取的子树最大结构复杂度小于ccp_alpha。</span></span><br><span class="line"><span class="string">          计算公式参考https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">oob_improvement_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出训练过程中，每增加一个基础决策树，在测试集上损失函数的改善情况（即：损失函数的减少值）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">train_score_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出训练过程中，每增加一个基础决策树，在训练集上的损失函数的值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">init</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">初始预测使用的分类器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础决策树。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight, monitor])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">其中monitor是一个可调用对象，它在当前迭代过程结束时调用。如果它返回True，则训练过程提前终止。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：GBDT在每一轮迭代结束时的预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个二维数组，数组元素依次是：GBDT在每一轮迭代结束时，预测X为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：GBDT在每一轮迭代结束时，该GBDT的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
GradientBoostingRegressor：梯度提升树（GBDT）回归器。<br />
常见的损失函数<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL21vZGVsX2V2YWx1YXRpb24uaHRtbCNmMjAwMQ==">Metrics
and scoring: quantifying the quality of predictions<i class="fa fa-external-link-alt"></i></span>。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.GradientBoostingRegressor(loss=<span class="string">&#x27;ls&#x27;</span>, learning_rate=<span class="number">0.1</span>,</span><br><span class="line">                n_estimators=<span class="number">100</span>, subsample=<span class="number">1.0</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">                min_weight_fraction_leaf=<span class="number">0.0</span>, max_depth=<span class="number">3</span>, init=<span class="literal">None</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">                max_features=<span class="literal">None</span>, alpha=<span class="number">0.9</span>, verbose=<span class="number">0</span>, max_leaf_nodes=<span class="literal">None</span>, warm_start=<span class="literal">False</span>, </span><br><span class="line">                presort=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">loss：一个字符串，指定损失函数。可以为：</span></span><br><span class="line"><span class="string">     &#x27;ls&#x27;：平方损失函数。</span></span><br><span class="line"><span class="string">     &#x27;lad&#x27;：绝对值损失函数。</span></span><br><span class="line"><span class="string">     &#x27;huber&#x27;：损失函数为上述两者的结合，通过alpha参数指定比例，该损失函数的定义为：</span></span><br><span class="line"><span class="string">            L_Huber=1/2(y-f(x))^2,  if|y-f(x)|&lt;=alpha</span></span><br><span class="line"><span class="string">            L_Huber=alpha*|y-f(x)|-1/2*alpha^2,  else</span></span><br><span class="line"><span class="string">            即误差较小时，采用平方损失；在误差较大时，采用绝对值损失。</span></span><br><span class="line"><span class="string">     &#x27;quantile&#x27;：分位数回归（分位数指的是百分之几），通过alpha参数指定分位数。</span></span><br><span class="line"><span class="string">alpha：一个浮点数，只有当loss=&#x27;huber&#x27;/&#x27;quantile&#x27;时才有效。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其它参数参考GradientBoostingClassifier。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">oob_improvement_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出训练过程中，每增加一个基础决策树，在测试集上损失函数的改善情况（即：损失函数的减少值）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">train_score_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出训练过程中，每增加一个基础决策树，在训练集上的损失函数的值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">init</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">初始预测使用的回归器。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础决策树。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight, monitor])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">monitor是一个可调用对象，它在当前迭代过程结束时调用。如果它返回True，则训练过程提前终止。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：GBRT在每一轮迭代结束时的预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">staged_score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回一个数组，数组元素依次是：GBRT在每一轮迭代结束时，该GBRT的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
Random
Forest（随机森林）：RandomForestClassifier、RandomForestRegressor。</p>
<p>RandomForestClassifier：随机森林分类器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestClassifier(n_estimators=<span class="number">100</span>, criterion=<span class="string">&#x27;gini&#x27;</span>, </span><br><span class="line">                 max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">                 max_features=<span class="string">&#x27;auto&#x27;</span>, max_leaf_nodes=<span class="literal">None</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">                 bootstrap=<span class="literal">True</span>, oob_score=<span class="literal">False</span>, n_jobs=<span class="number">1</span>,random_state=<span class="literal">None</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                 warm_start=<span class="literal">False</span>, class_weight=<span class="literal">None</span>, , ccp_alpha=<span class="number">0.0</span>, max_samples=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_estimators：一个整数，指定了随机森林中决策树的数量。</span></span><br><span class="line"><span class="string">criterion：一个字符串，指定了每个决策树的criterion参数。</span></span><br><span class="line"><span class="string">max_features：一个整数/浮点数/字符串/None，指定了每个决策树的max_features参数。</span></span><br><span class="line"><span class="string">max_depth：一个整数/None，指定了每个决策树的max_depth参数。如果max_leaf_nodes非None，则忽略本参数。</span></span><br><span class="line"><span class="string">min_samples_split：一个整数，指定了每个决策树的min_samples_split参数。</span></span><br><span class="line"><span class="string">min_samples_leaf：一个整数，指定了每个决策树的min_samples_leaf参数。</span></span><br><span class="line"><span class="string">min_weight_fraction_leaf：一个浮点数，指定了每个决策树的min_weight_fraction_leaf参数。</span></span><br><span class="line"><span class="string">max_leaf_nodes：为整数/None，指定了每个基础决策树模型的max_leaf_nodes参数。</span></span><br><span class="line"><span class="string">boostrap：为布尔值。如果为True，则使用采样法bootstrap sampling来产生决策树的训练数据集。</span></span><br><span class="line"><span class="string">oob_score：为布尔值。如果为True，则使用包外样本来计算泛化误差。</span></span><br><span class="line"><span class="string">n_jobs：指定并行性。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">verbose：一个正数。用于开启/关闭迭代中间输出日志功能。</span></span><br><span class="line"><span class="string">warm_start：一个布尔值。用于指定是否继续使用上一次训练的结果。</span></span><br><span class="line"><span class="string">class_weight：一个字典/字典的列表/&#x27;balanced&#x27;/&#x27;balanced_subsample&#x27;/None：</span></span><br><span class="line"><span class="string">             字典：则字典给出了每个分类的权重，如：&#123;class_label: weight&#125;。</span></span><br><span class="line"><span class="string">            &#x27;balanced&#x27;：则每个分类的权重与该分类在样本集中出现的频率成反比。</span></span><br><span class="line"><span class="string">            &#x27;balanced_subsample&#x27;：则样本集为采样法bootstrap sampling产生的决策树的训练数据集，</span></span><br><span class="line"><span class="string">                                  每个分类的权重与该分类在采用生成的样本集中出现的频率成反比。</span></span><br><span class="line"><span class="string">             None：则每个分类的权重都为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础决策树。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有的类别标签。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">类别数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练时使用的特征数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_outputs_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练时输出的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">oob_score_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练数据使用包外估计时的得分。 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，返回一个数组，数组的元素依次是X预测为各个类别的概率值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">同predict，返回一个数组，数组的元素依次是X预测为各个类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
RandomForestRegressor：随机森林回归器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestRegressor(n_estimators=<span class="number">100</span>, criterion=<span class="string">&#x27;mse&#x27;</span>, </span><br><span class="line">                max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">                max_features=<span class="string">&#x27;auto&#x27;</span>, max_leaf_nodes=<span class="literal">None</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, </span><br><span class="line">                bootstrap=<span class="literal">True</span>, oob_score=<span class="literal">False</span>, n_jobs=<span class="number">1</span>,random_state=<span class="literal">None</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                warm_start=<span class="literal">False</span>, ccp_alpha=<span class="number">0.0</span>, max_samples=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参数参考GradientBoostingClassifier。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">estimators_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">所有训练过的基础决策树。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_features_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练时使用的特征数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_outputs_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练时输出的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个特征的重要性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">oob_score_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练数据使用包外估计时的得分。 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">oob_prediction_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练数据使用包外估计时的预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">用模型进行预测，返回预测值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X,y[,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回模型的预测性能得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="聚类模型">聚类模型</h1>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2R1bGVzL2NsdXN0ZXJpbmcuaHRtbCNjbHVzdGVyaW5n">Clustering<i class="fa fa-external-link-alt"></i></span>。</p>
<p>KMeans是scikit-learn提供的k均值算法模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans(n_clusters=<span class="number">8</span>, init=<span class="string">&#x27;k-means++&#x27;</span>, n_init=<span class="number">10</span>,</span><br><span class="line">                max_iter=<span class="number">300</span>,tol=<span class="number">0.0001</span>, precompute_distances=<span class="string">&#x27;deprecated&#x27;</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                random_state=<span class="literal">None</span>, copy_x=<span class="literal">True</span>, n_jobs=<span class="string">&#x27;deprecated&#x27;</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_clusters：一个整数，指定分类簇的数量。</span></span><br><span class="line"><span class="string">init：一个字符串，指定初始均值向量的策略。可以为：</span></span><br><span class="line"><span class="string">     &#x27;k-means++&#x27;：该初始化策略选择的初始均值向量相互之间都距离较远，它的效果较好。</span></span><br><span class="line"><span class="string">     &#x27;random&#x27;：从数据集中随机选择k个样本作为初始均值向量。</span></span><br><span class="line"><span class="string">      或者提供一个数组，数组的形状为(n_clusters,n_features)，该数组作为初始均值向量。</span></span><br><span class="line"><span class="string">n_init：一个整数，指定了k均值算法运行的次数。</span></span><br><span class="line"><span class="string">        每次都会选择一组不同的初始化均值向量，最终算法会选择最佳的分类簇来作为最终的结果。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定了单轮k均值算法中，最大的迭代次数。算法总的最大迭代次数为max_iter*n_init。</span></span><br><span class="line"><span class="string">precompute_distances：布尔值/&#x27;auto&#x27;，指定是否提前计算距离。如果提前计算距离，则需要更多的内存，但是算法会运行的更快。</span></span><br><span class="line"><span class="string">                     &#x27;auto&#x27;：如果 n_samples*n_clusters &gt; 12 million，则不提前计算。</span></span><br><span class="line"><span class="string">                     True：总是提前计算。</span></span><br><span class="line"><span class="string">                     False：总是不提前计算。</span></span><br><span class="line"><span class="string">tol：指定收敛阈值。</span></span><br><span class="line"><span class="string">n_jobs：指定并行度。</span></span><br><span class="line"><span class="string">verbose：指定开启/关闭迭代中间输出日志功能。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">copy_x：布尔值，主要用于precompute_distances=True的情况。</span></span><br><span class="line"><span class="string">        如果为True，则预计算距离的时候，并不修改原始数据。</span></span><br><span class="line"><span class="string">        如果为False，则预计算距离的时候，会修改原始数据用以节省内存；</span></span><br><span class="line"><span class="string">            然后当算法结束的时候，会将原始数据还原。但是可能会因为浮点数的表示，会有一些精度误差。</span></span><br><span class="line"><span class="string">algorithm：一个字符串，指定采用的算法。可以为：</span></span><br><span class="line"><span class="string">         &#x27;full&#x27;：使用经典的EM风格的算法。</span></span><br><span class="line"><span class="string">         &#x27;elkan&#x27;：使用&#x27;elkan&#x27;变种算法。它通过使用三角不等式来优化算法，但是不支持稀疏数据。</span></span><br><span class="line"><span class="string">         &#x27;auto&#x27;：自动选择算法。对于稀疏数据使用&#x27;full&#x27;，对于密集数据使用&#x27;elkan&#x27;。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">K均值算法总能够收敛，但是其收敛情况高度依赖于init初始化的均值。有可能收敛到局部极小值。</span></span><br><span class="line"><span class="string">因此通常都是用多组初始均值向量来计算若干次，选择其中最优的那一次。</span></span><br><span class="line"><span class="string">而k-means++策略选择的初始均值向量可以一定程度上的解决这个问题。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">cluster_centers_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_clusters,n_features]的数组，给出分类簇的均值向量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples,] 的数组，给出了每个样本所属的簇的标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">inertia_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，聚类平方误差。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，指定运行的迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[,y ,sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X, sample_weight)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将数据集X转换到cluster center space。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，将数据集X转换到cluster center space。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X[, y, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，给出了聚类平方误差的相反数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
MiniBatchKMeans是scikit-learn提供的批量k均值算法模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.MiniBatchKMeans(n_clusters=<span class="number">8</span>, init=<span class="string">&#x27;k-means++&#x27;</span>,max_iter=<span class="number">100</span>,</span><br><span class="line">                batch_size=<span class="number">100</span>, verbose=<span class="number">0</span>, compute_labels=<span class="literal">True</span>,random_state=<span class="literal">None</span>,tol=<span class="number">0.0</span>,</span><br><span class="line">                max_no_improvement=<span class="number">10</span>, init_size=<span class="literal">None</span>, n_init=<span class="number">3</span>, reassignment_ratio=<span class="number">0.01</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">batch_size：一个整数，指定batch大小。</span></span><br><span class="line"><span class="string">compute_labels：一个布尔值，指定当算法收敛时，是否对全量数据集重新计算其完整的簇标记。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定收敛阈值。它可以用于早停。</span></span><br><span class="line"><span class="string">     当迭代前后聚类中心的变化小于它时，执行早停。如果为0.0，则不开启这种早停。</span></span><br><span class="line"><span class="string">max_no_improvement：一个整数，用于控制早停的轮数。</span></span><br><span class="line"><span class="string">                   如果优化目标在连续max_no_improvement个batch内没有改善时，执行早停。</span></span><br><span class="line"><span class="string">                   这里的优化目标不是聚类中心的变化，而是平方误差。</span></span><br><span class="line"><span class="string">init_size：一个整数，为加速初始化而随机采样的样本数。通常是3倍的batch_size。它必须大于 n_clusters。</span></span><br><span class="line"><span class="string">n_init：一个整数，指定了初始化的尝试次数。与KMeans不同，MiniBatchKMeans只会运行一轮（而不是多轮）。</span></span><br><span class="line"><span class="string">reassignment_ratio：一个浮点数，控制每次迭代中最多有多少个簇中心被重新赋值。</span></span><br><span class="line"><span class="string">                   如果该值较大，则模型可能收敛可能时间更长，但是聚类效果也会更好。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其他参数参考sklearn.cluster.KMeans。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考sklearn.cluster.KMeans。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法，其它方法参考sklearn.cluster.KMeans。</span></span><br><span class="line">partial_fit(X, y=<span class="literal">None</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练k means 一个批次。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
DBSCAN是scikit-learn提供的一种密度聚类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.DBSCAN(eps=<span class="number">0.5</span>, min_samples=<span class="number">5</span>, metric=<span class="string">&#x27;euclidean&#x27;</span>, </span><br><span class="line">                metric_params=<span class="literal">None</span>, algorithm=<span class="string">&#x27;auto&#x27;</span>, leaf_size=<span class="number">30</span>, p=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">eps：eps参数，用于确定邻域大小。</span></span><br><span class="line"><span class="string">min_samples：minpts参数，用于判断核心对象。</span></span><br><span class="line"><span class="string">metric：一个字符串/可调用对象，用于计算距离。</span></span><br><span class="line"><span class="string">        如果是字符串，则必须是metrics.pairwise.calculate_distance中指定的。</span></span><br><span class="line"><span class="string">metric_params：一个字典，当metric为可调用对象时，为metric提供关键字参数。</span></span><br><span class="line"><span class="string">algorithm：一个字符串，用于计算两点间距离并找出最近邻的点。可以为：</span></span><br><span class="line"><span class="string">          &#x27;auto&#x27;：由算法自动选取合适的算法。</span></span><br><span class="line"><span class="string">          &#x27;ball_tree&#x27;：用ball树来搜索。</span></span><br><span class="line"><span class="string">          &#x27;kd_tree&#x27;：用kd树来搜索。</span></span><br><span class="line"><span class="string">          &#x27;brute&#x27;：暴力搜索。</span></span><br><span class="line"><span class="string">leaf_size：一个整数，用于指定当algorithm=ball_tree或者kd_tree时，树的叶结点大小。</span></span><br><span class="line"><span class="string">           该参数会影响构建树、搜索最近邻的速度，同时影响存储树的内存。</span></span><br><span class="line"><span class="string">p：一个浮点数，指定闵可夫斯基距离的p值。</span></span><br><span class="line"><span class="string">n_jobs：指定并行度。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARI指数随着eps的增长，先上升后保持平稳最后断崖下降。</span></span><br><span class="line"><span class="string">断崖下降是因为产生的训练样本的间距比较小，最远的两个样本点之间的距离不超过30。当eps过大时，所有的点都在一个邻域中。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">核心样本数量随着eps的增长而上升。</span></span><br><span class="line"><span class="string">这是因为随着eps的增长，样本点的邻域在扩展，则样本点邻域内的样本会更多，这就产生了更多满足条件的核心样本点。</span></span><br><span class="line"><span class="string">但是样本集中的样本数量有限，因此核心样本点数量的增长到一定数目后稳定。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARI指数随着min_samples的增长，平稳的下降。</span></span><br><span class="line"><span class="string">核心样本数量随着min_samples的增长基本上线性下降。</span></span><br><span class="line"><span class="string">这是因为随着min_samples的增长，样本点的邻域中必须包含更多的样本才能使它成为一个核心样本点。</span></span><br><span class="line"><span class="string">因此产生的核心样本点越来越少。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">core_sample_indices_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_core_samples,]的数组，给出了核心样本在原始训练集中的位置。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">components_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_core_samples,n_features]的数组，给出了核心样本的一份拷贝。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples,]的数组，给出了每个样本所属的簇标记。对于噪音样本，其簇标记为-1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
MeanShift是scikit-learn提供的一种密度聚类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.MeanShift(bandwidth=<span class="literal">None</span>, seeds=<span class="literal">None</span>, bin_seeding=<span class="literal">False</span>,</span><br><span class="line">                min_bin_freq=<span class="number">1</span>, cluster_all=<span class="literal">True</span>, n_jobs=<span class="literal">None</span>, max_iter=<span class="number">300</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">bandwidth：一个浮点数，指定带宽参数。</span></span><br><span class="line"><span class="string">          如果未指定，则通过sklearn.cluster.estimate_bandwith()函数来自动计算。</span></span><br><span class="line"><span class="string">seeds：一个形状为[n_samples,n_features]的数组，用于初始化核函数。</span></span><br><span class="line"><span class="string">          如果未指定，则通过sklearn.cluster.get_bin_seeds()函数来自动计算。</span></span><br><span class="line"><span class="string">bin_seeding：一个布尔值。</span></span><br><span class="line"><span class="string">            如果为True，则并不会使用所有的点来计算核函数，而是使用网格边界上的点（网格宽度为带宽）来计算。</span></span><br><span class="line"><span class="string">            这会加速算法的执行，因为核函数的初始化需要的点大大降低。</span></span><br><span class="line"><span class="string">            如果为False，则使用所有的点来计算核函数。</span></span><br><span class="line"><span class="string">min_bin_freq：一个整数值，指定有效网格包含的数据点的最少数量。</span></span><br><span class="line"><span class="string">当bin_seeding=True时，仅仅接收那些网格内包含超过min_bin_freq个数据点的网格。</span></span><br><span class="line"><span class="string">cluster_all：一个布尔值，指定是否对所有数据点进行聚类。</span></span><br><span class="line"><span class="string">            如果为False，则对离群点不聚类，将离群点的簇标记设置为-1。</span></span><br><span class="line"><span class="string">            如果为True，则对离群点也聚类，将离群点划分到离它最近的簇中。</span></span><br><span class="line"><span class="string">n_jobs：一个整数，指定并行度。</span></span><br><span class="line"><span class="string">max_iter：如果尚未收敛，则在聚类操作终止之前（对于该种子点）每个种子点的最大迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">claster_centers_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_clusters,n_features]的数组，给出了每个簇中心的坐标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples,]的数组，给出了每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">如果cluster_all=False，则对于离群样本，其簇标记为-1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对每个样本预测其簇标记。</span></span><br><span class="line"><span class="string">每个样本距离最近的簇就是该样本所属的簇。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
AgglomerativeClustering是scikit-learn提供的一种层次聚类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.AgglomerativeClustering(n_clusters=<span class="number">2</span>, affinity=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">                memory=<span class="literal">None</span>, connectivity=<span class="literal">None</span>, compute_full_tree=<span class="string">&#x27;auto&#x27;</span>, </span><br><span class="line">                linkage=<span class="string">&#x27;ward&#x27;</span>,distance_threshold=<span class="literal">None</span>, compute_distances=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_clusters：一个整数，指定簇的数量。</span></span><br><span class="line"><span class="string">connectivity：一个数组/可调用对象/None，用于指定连接矩阵。它给出了每个样本的可连接样本。</span></span><br><span class="line"><span class="string">affinity：一个字符串/可调用对象，用于计算距离。可以为：&#x27;euclidean&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;manhattan&#x27;, &#x27;cosine&#x27;, &#x27;precomputed&#x27;。</span></span><br><span class="line"><span class="string">         如果linkage=&#x27;ward&#x27;，则&#x27;affinity必须是&#x27;euclidean&#x27;。</span></span><br><span class="line"><span class="string">memory：用于缓存输出的结果，默认为不缓存。如果给定一个字符串，则表示缓存目录的路径。</span></span><br><span class="line"><span class="string">compute_full_tree：通常当已经训练了n_clusters之后，训练过程就停止。</span></span><br><span class="line"><span class="string">                   但是如果compute_full_tree=True，则会继续训练从而生成一颗完整的树。</span></span><br><span class="line"><span class="string">linkage：一个字符串，用于指定链接算法。</span></span><br><span class="line"><span class="string">        &#x27;ward&#x27;：采用方差恶化距离variance incress distance。</span></span><br><span class="line"><span class="string">        &#x27;complete&#x27;：全链接complete-linkage算法，采用d_max。</span></span><br><span class="line"><span class="string">        &#x27;average&#x27;：均链接average-linkage算法,采用d_avg。</span></span><br><span class="line"><span class="string">        &#x27;single&#x27;：单链接single-linkage算法，采用d_min。</span></span><br><span class="line"><span class="string">distance_threshold：链接距离阈值，高于该阈值，聚类将不会被合并。</span></span><br><span class="line"><span class="string">                    此值若非None，则n_clusters必须是None并且compute_full_tree必须是True。</span></span><br><span class="line"><span class="string">compute_distances：即使不使用distance_threshold也会计算集群之间的距离。</span></span><br><span class="line"><span class="string">                   这可用于进行树状图可视化，但会引入计算和内存开销。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">n_clusters_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">聚类数。</span></span><br><span class="line"><span class="string">如果distance_threshold=None，它将等于给定的n_clusters。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples,]的数组，给出了每个样本的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_leaves_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出了分层树的叶结点数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">children_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples-1,2]数组，给出了每个非叶结点中的子节点数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
BIRCH是scikit-learn提供的一种层次聚类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.Birch(threshold=<span class="number">0.5</span>, branching_factor=<span class="number">50</span>, n_clusters=<span class="number">3</span>, </span><br><span class="line">                compute_labels=<span class="literal">True</span>, copy=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">threshold：一个浮点数，指定空间阈值\tau。</span></span><br><span class="line"><span class="string">branching_facto：一个整数，指定枝平衡因子\beta。叶平衡因子\lambda也等于该数值。</span></span><br><span class="line"><span class="string">n_clusters：一个整数/None/sklearn.cluster模型，指定最终聚类的数量。</span></span><br><span class="line"><span class="string">            如果为None，则由算法自动给出。</span></span><br><span class="line"><span class="string">            如果为一个整数，则使用AgglomerativeClustering算法来对CF本身执行聚类，并将聚类结果返回。</span></span><br><span class="line"><span class="string">            这使得最终的聚类数量就是n_clusters。</span></span><br><span class="line"><span class="string">            如果为一个sklearn.cluster模型，则该模型对CF本身执行聚类，并将聚类结果返回。</span></span><br><span class="line"><span class="string">compute_labels：一个布尔值，指定是否需要计算簇标记。</span></span><br><span class="line"><span class="string">copy：一个布尔值，指定是否拷贝原始数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">root_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个_CFNode对象，表示CF树的根节点。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">subcluster_centers_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，表示所有子簇的中心点。它直接从所有叶结点中读取。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">subcluster_labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，表示所有子簇的簇标记。</span></span><br><span class="line"><span class="string">可能多个子簇会有同样的簇标记，因为子簇可能会被执行进一步的聚类。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为[n_samples,]的数组，给出了每个样本的簇标记。</span></span><br><span class="line"><span class="string">如果执行分批训练，则它给出的是最近一批样本的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">partial_fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分批训练模型（在线学习）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对每个样本预测其簇标记。</span></span><br><span class="line"><span class="string">根据每个子簇的中心点来预测样本的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将样本转换成子簇中心点的坐标：维度d代表样本距离第d个子簇中心的距离。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_transform(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并将样本转换成子簇中心点的坐标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
GaussianMixture是scikit-learn给出的混合高斯模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">sklearn.mixture.GaussianMixture(n_components=<span class="number">1</span>, covariance_type=<span class="string">&#x27;full&#x27;</span>,</span><br><span class="line">                tol=<span class="number">0.001</span>, reg_covar=<span class="number">1e-06</span>, max_iter=<span class="number">100</span>, n_init=<span class="number">1</span>, init_params=<span class="string">&#x27;kmeans&#x27;</span>,</span><br><span class="line">                weights_init=<span class="literal">None</span>, means_init=<span class="literal">None</span>, precisions_init=<span class="literal">None</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">                warm_start=<span class="literal">False</span>, verbose=<span class="number">0</span>, verbose_interval=<span class="number">10</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_components：一个整数，指定分模型的数量，默认为1。</span></span><br><span class="line"><span class="string">covariance_type：一个字符串，指定协方差的类型。必须为下列值之一：</span></span><br><span class="line"><span class="string">                &#x27;spherical&#x27;：球型，每个分模型的协方差矩阵都是各自的标量值。</span></span><br><span class="line"><span class="string">                &#x27;tied&#x27;：结点型，所有的分模型都共享一个协方差矩阵。</span></span><br><span class="line"><span class="string">                &#x27;diag&#x27;：对角型，每个分模型的协方差矩阵都是各自的对角矩阵</span></span><br><span class="line"><span class="string">                &#x27;full&#x27;：全型，每个分模型都有自己的协方差矩阵。</span></span><br><span class="line"><span class="string">tol：一个浮点数，用于指定收敛的阈值。 EM迭代算法中，当对数似然函数平均增益低于此阈值时，迭代停止。</span></span><br><span class="line"><span class="string">reg_covar：一个浮点数，添加到协方差矩阵对角线上元素，确保所有的协方差都是正数。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定EM算法迭代的次数。</span></span><br><span class="line"><span class="string">n_init：一个整数，用于指定初始化次数。即算法会运行多轮，只有表现最好的哪个结果作为最终的结果。</span></span><br><span class="line"><span class="string">init_params:一个字符串，可以为&#x27;kmeans&#x27;/&#x27;random&#x27;，用于指定初始化权重的策略。</span></span><br><span class="line"><span class="string">            &#x27;kmeans&#x27;：通过 kmeans 算法初始化。</span></span><br><span class="line"><span class="string">            &#x27;random&#x27;：随机初始化。</span></span><br><span class="line"><span class="string">weights-init：一个序列，形状为(n_components,)，指定初始化的权重。</span></span><br><span class="line"><span class="string">             如果提供该参数，则不会使用init_params来初始化权重。</span></span><br><span class="line"><span class="string">means_init：一个数组，形状为(n_components,n_features)，指定了初始化的均值。</span></span><br><span class="line"><span class="string">            如果为None，则使用init_params 来初始化均值。</span></span><br><span class="line"><span class="string">precision_init：用户提供的初始precisions（协方差矩阵的逆矩阵）。如果为None，则使用init_params 来初始化。</span></span><br><span class="line"><span class="string">                根据covariance_type的不同，该参数值的形状为不同。</span></span><br><span class="line"><span class="string">                    &#x27;spherical&#x27;：形状为[n_components,]。</span></span><br><span class="line"><span class="string">                    &#x27;tied&#x27;：形状为[n_features,n_features]。</span></span><br><span class="line"><span class="string">                    &#x27;diag&#x27;：形状为[n_components,n_features]。</span></span><br><span class="line"><span class="string">                    &#x27;full&#x27;：形状为[n_components,n_features,n_featuress]。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">warm_start：一个布尔值。</span></span><br><span class="line"><span class="string">            如果为True，则上一次训练的结果将作为本次训练的开始条件。此时忽略n_init，并且只有一次初始化过程发生。</span></span><br><span class="line"><span class="string">verbose：一个整数，指定日志打印级别。</span></span><br><span class="line"><span class="string">verbose_interval：一个整数，指定输出日志的间隔。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">weights_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_components,)的数组，表示每个分模型的权重。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">means_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_components, n_features)的数组，表示每个分模型的均值\mu_k。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">covariances_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，表示每个分模型的方差。数组的形状根据方差类型有所不同。</span></span><br><span class="line"><span class="string">&#x27;spherical&#x27;：形状为[n_components,]。</span></span><br><span class="line"><span class="string">&#x27;tied&#x27;：形状为[n_features,n_features]。</span></span><br><span class="line"><span class="string">&#x27;diag&#x27;：形状为[n_components,n_features]。</span></span><br><span class="line"><span class="string">&#x27;full&#x27;：形状为[n_components,n_features,n_featuress]。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">precision_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，表示精度矩阵（协方差矩阵的逆矩阵），与covariances_ 形状相同。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">precisions_cholesky_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组，表示精度矩阵的Cholesky分解。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">converged_ </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个布尔值。当训练过程收敛时该值为True；不收敛时为False 。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出EM算法收敛时的迭代步数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">lower_bound_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个浮点数，给出了训练集的对数似然函数的下界。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">预测样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">预测样本所属各个簇的后验概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sample([n_samples])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">根据模型来随机生成一组样本。n_samples指定待生成样本的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算模型在样本总体上的对数似然函数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score_samples(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出每个样本的对数似然函数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">aic(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出样本集的AKaike信息准则。选取AIC最小的模型。</span></span><br><span class="line"><span class="string">AIC和BIC都是用于评估模型好坏的准则，用于衡量模型的复杂度和模型的精度。</span></span><br><span class="line"><span class="string">AIC=2k-2logL，k为模型参数个数，L为模型的似然函数。</span></span><br><span class="line"><span class="string">当模型之间的预测能力存在较大差异时，似然函数占主导地位。</span></span><br><span class="line"><span class="string">当模型之间的预测能力差异不大时，模型复杂度占主导地位。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">bic(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">给出样本集的贝叶斯信息准则。选取BIC最小的模型。</span></span><br><span class="line"><span class="string">AIC和BIC都是用于评估模型好坏的准则，用于衡量模型的复杂度和模型的精度。</span></span><br><span class="line"><span class="string">BIC=klogN-2logL，k为模型参数个数（并不是超参数的数量，而是训练参数的数量），L为模型的似然函数，N为训练样本的数量。</span></span><br><span class="line"><span class="string">BIC认为增加参数的数量也会增加模型复杂度。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
SpectralClustering是scikit-learn给出的谱聚类模型。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.SpectralClustering(n_clusters=<span class="number">8</span>, eigen_solver=<span class="literal">None</span>, n_components=<span class="literal">None</span>,</span><br><span class="line">                random_state=<span class="literal">None</span>, n_init=<span class="number">10</span>, gamma=<span class="number">1.0</span>, affinity=<span class="string">&#x27;rbf&#x27;</span>, n_neighbors=<span class="number">10</span>, </span><br><span class="line">                eigen_tol=<span class="number">0.0</span>, assign_labels=<span class="string">&#x27;kmeans&#x27;</span>, degree=<span class="number">3</span>, coef0=<span class="number">1</span>, kernel_params=<span class="literal">None</span>,</span><br><span class="line">                n_jobs=<span class="literal">None</span>, verbose=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_clusters：一个整数，指定降维的维数，即  。</span></span><br><span class="line"><span class="string">eigen_solver：一个字符串/None，指定求解特征值的求解器。可以为：</span></span><br><span class="line"><span class="string">            &#x27;arpack&#x27;：使用arpack求解器。</span></span><br><span class="line"><span class="string">            &#x27;lobpcg&#x27;：使用lobpcg求解器。</span></span><br><span class="line"><span class="string">&#x27;amg&#x27;：使用amg求解器。它要求安装pyamg。优点是计算速度快，支持大规模、稀疏数据，但是可能导致不稳定。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">n_init：一个整数，指定二次聚类时的k-means算法的n_init参数，</span></span><br><span class="line"><span class="string">        它会重复执行k-means算法n_init轮，选择效果最好的那轮作为最终聚类的输出。</span></span><br><span class="line"><span class="string">affinity：一个字符串/数组/可调用对象，指定相似度矩阵的计算方式。</span></span><br><span class="line"><span class="string">         如果是字符串，则必须是&#x27;nearest_neighbors&#x27;,&#x27;precomputed&#x27;,&#x27;rbf&#x27;或者由sklearn.metrics.pairwise_kernels支持的其它核函数。</span></span><br><span class="line"><span class="string">         如果是一个数组，则直接给出相似度矩阵。</span></span><br><span class="line"><span class="string">         如果是可调用对象，则输入两个样本，输出其相似度。</span></span><br><span class="line"><span class="string">gamma：一个浮点数，它给出了rbf,poly,sigmoid,laplacian,chi2核的系数。</span></span><br><span class="line"><span class="string">       如果affinity=&#x27;nearest_neighbors&#x27;，则忽略该参数。</span></span><br><span class="line"><span class="string">degree：一个整数，当使用多项式核时，指定多项式的度。</span></span><br><span class="line"><span class="string">coef0：一个整数，当使用多项式核和sigmoid核时，指定偏置。</span></span><br><span class="line"><span class="string">kernel_params：一个字典，当affinity是可调用对象时，传给该可调用对象的关键词参数。</span></span><br><span class="line"><span class="string">n_neighbors：一个整数，指定当计算相似度矩阵时，考虑样本周围近邻的多少个样本。</span></span><br><span class="line"><span class="string">             如果affinity=&#x27;rbf&#x27;，则忽略该参数。</span></span><br><span class="line"><span class="string">eigen_tol：一个浮点数，当使用arpack求解器求解特征值时，指定收敛阈值。</span></span><br><span class="line"><span class="string">assign_labels：一个字符串，指定二次聚类的算法。</span></span><br><span class="line"><span class="string">             &#x27;kmeans&#x27;：使用k-means算法执行二次聚类。</span></span><br><span class="line"><span class="string">             &#x27;discretize&#x27;：使用discretize执行二次聚类。</span></span><br><span class="line"><span class="string">n_jobs：指定并行度。</span></span><br><span class="line"><span class="string">verbose：一个整数，指定日志打印级别。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">affinity_matrix</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,n_samples)的数组，给出了相似度矩阵。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labels_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,)的数组，给出了每个样本的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[,y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit_predict(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型并执行聚类，返回每个样本所属的簇标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="半监督学习">半监督学习</h1>
<p>标签传播算法：LabelPropagation、LabelSpreading。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">sklearn.semi_supervised.LabelPropagation(kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">20</span>, </span><br><span class="line">                        n_neighbors=<span class="number">7</span>, max_iter=<span class="number">1000</span>, tol=<span class="number">0.001</span>, n_jobs=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">kernel：一个字符串，指定距离函数（用于计算边的权重）。可以为下列的值：</span></span><br><span class="line"><span class="string">        &#x27;rbf&#x27;：它的计算量较大，且距离矩阵是对称的。</span></span><br><span class="line"><span class="string">        &#x27;knn&#x27;：它的计算量较小，且距离矩阵是稀疏矩阵，且距离矩阵不对称的。</span></span><br><span class="line"><span class="string">gamma: 一个浮点数，指定rbf距离函数的参数。</span></span><br><span class="line"><span class="string">n_neighbors：一个整数，指定knn距离函数的参数。</span></span><br><span class="line"><span class="string">max_iter：一个整数，指定最大的迭代次数。</span></span><br><span class="line"><span class="string">tol：一个浮点数，指定收敛的阈值。</span></span><br><span class="line"><span class="string">n_jobs：指定并行度。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">X_  </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,n_features)的数组，表示输入数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">classes_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_classes,)的数组，表示分类问题中，类别种类数组。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">label_distributions_  </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,n_classes)的数组，给出了每个样本的标记在每个类别上的分布。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transduction_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个形状为(n_samples,)的数组，给出每个样本计算出的标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_iter_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个整数，给出迭代次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X, y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">训练模型。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">预测样本标记。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">预测每个样本在每个类别上的概率分布。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X, y[, sample_weight])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">评估在测试集上的预测准确率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sklearn.semi_supervised.LabelSpreading(kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">20</span>, </span><br><span class="line">                        n_neighbors=<span class="number">7</span>, alpha=<span class="number">0.2</span>, max_iter=<span class="number">30</span>, tol=<span class="number">0.001</span>, n_jobs=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考sklearn.semi_supervised.LabelPropagation。</span></span><br><span class="line"><span class="string">alpha：表示折中因子。</span></span><br><span class="line"><span class="string">       alpha=0：保留所有初始标签信息。</span></span><br><span class="line"><span class="string">       alpha=1：修改所有初始标签信息。 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考sklearn.semi_supervised.LabelPropagation。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参考sklearn.semi_supervised.LabelPropagation。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="模型评估">模型评估</h1>
<p>参考官网<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9tb2RlbF9zZWxlY3Rpb24uaHRtbCNtb2RlbC1zZWxlY3Rpb24=">Model
selection and evaluation<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="数据切分">数据切分</h2>
<p>train_test_split用于将数据集切分成训练集和测试集。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.train_test_split(*arrays, test_size=<span class="literal">None</span>, train_size=<span class="literal">None</span>,  </span><br><span class="line">                        random_state=<span class="literal">None</span>, shuffle=<span class="literal">True</span>, stratify=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：一个列表，依次给出一个/多个数据集的划分的结果。</span></span><br><span class="line"><span class="string">        每个数据集都划分为两部分：训练集、测试集。</span></span><br><span class="line"><span class="string">*arrays：一个/多个数组，代表被拆分的一些数据集。</span></span><br><span class="line"><span class="string">test_size：一个浮点数/整数/None，指定测试集大小。</span></span><br><span class="line"><span class="string">           浮点数：必须是0.0到1.0之间的数，代表测试集占原始数据集的比例。</span></span><br><span class="line"><span class="string">           整数：代表测试集大小。</span></span><br><span class="line"><span class="string">           None：如果训练集大小也指定为None，则test_size设为0.25。</span></span><br><span class="line"><span class="string">train_size：一个浮点数/整数/None，指定训练集大小。</span></span><br><span class="line"><span class="string">            浮点数：必须是0.0到1.0之间的数，代表训练集占原始数据集的比例。</span></span><br><span class="line"><span class="string">            整数：代表训练集大小。</span></span><br><span class="line"><span class="string">            None：如果测试集大小也指定为None，则test_size设为0.75。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">stratify：一个数组对象/None。如果非None，则原始数据会分层采样，采样的标记数组就由该参数指定。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">KFold首先将0~(n-1)之间的整数从前到后均匀划分成n_splits份。</span></span><br><span class="line"><span class="string">每次迭代时依次挑选一份作为测试集样本的下标。</span></span><br><span class="line"><span class="string">    如果shuffle=True，则按顺序划分。</span></span><br><span class="line"><span class="string">    如果shuffle=False，则按随机划分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
KFold类实现了数据集的k折交叉切分。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">False</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">n_splits：一个整数，即k（要求该整数值大于等于2）。</span></span><br><span class="line"><span class="string">shuffle：一个布尔值。如果为True，则在切分数据集之前先混洗数据集。</span></span><br><span class="line"><span class="string">random_state：指定随机数种子。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">get_n_splits([X, y, groups])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回n_splits参数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">split(X[, y, groups])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">切分数据集为训练集和测试集。返回测试集的样本索引、训练集的样本索引。</span></span><br><span class="line"><span class="string">X：训练数据集，形状为(n_samples,n_features)。</span></span><br><span class="line"><span class="string">y：标记信息，形状为(n_samples,)。</span></span><br><span class="line"><span class="string">groups：样本的分组标记，用于拆分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
StratifiedKFold类实现了数据集的分层采样k折交叉切分。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.StratifiedKFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">False</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">参数、方法，参考KFold。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">StratifiedKFold的用法类似于KFold，但是StratifiedKFold执行的是分层采样：</span></span><br><span class="line"><span class="string">    保证训练集、测试集中各类别样本的比例与原始数据集中相同。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
LeaveOneOut类实现了数据集的留一法拆分(简称LOO)，它是个生成器。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">klearn.model_selection.LeaveOneOut()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">LeaveOneOut的用法很简单。它每次迭代时，依次取0,1,...(n-1)作为测试集样本的下标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
便利函数cross_val_score对estimator执行k折交叉验证。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.cross_val_score(estimator, X, y=<span class="literal">None</span>, scoring=<span class="literal">None</span>, cv=<span class="literal">None</span>, groups=<span class="literal">None</span>,</span><br><span class="line">                        n_jobs=<span class="number">1</span>, verbose=<span class="number">0</span>, fit_params=<span class="literal">None</span>, pre_dispatch=<span class="string">&#x27;2*n_jobs&#x27;</span>,</span><br><span class="line">                        error_score=nan)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：返回一个浮点数的数组。每个浮点数都是针对某次k折交叉的数据集上estimator预测性能得分。</span></span><br><span class="line"><span class="string">estimator：指定的学习器，该学习器必须有.fit方法来进行训练。</span></span><br><span class="line"><span class="string">X：样本集合。通常是一个numpy array，每行代表一个样本，每列代表一个特征。</span></span><br><span class="line"><span class="string">y：样本的标签集合。它与X的每一行相对应。</span></span><br><span class="line"><span class="string">groups：样本的分组标记集合。它与X的每一行相对应，用于训练集、测试集的拆分。</span></span><br><span class="line"><span class="string">scoring：一个字符串/可调用对象/None，它指定了评分函数。</span></span><br><span class="line"><span class="string">        可调用对象：参数为estimator, X, y ，返回值为一个浮点数表示预测能力得分。</span></span><br><span class="line"><span class="string">        None：采用estimator学习器的.score方法。</span></span><br><span class="line"><span class="string">        字符串：可以为下列字符串：</span></span><br><span class="line"><span class="string">            &#x27;accuracy&#x27;：采用的是metrics.accuracy_score评分函数。</span></span><br><span class="line"><span class="string">            &#x27;average_precision&#x27;：采用的是metrics.average_precision_score评分函数。</span></span><br><span class="line"><span class="string">            f1系列：采用的是metrics.f1_score评分函数。包括：</span></span><br><span class="line"><span class="string">                    &#x27;f1&#x27;：f1值作为评分。用于二分类问题。</span></span><br><span class="line"><span class="string">                    &#x27;f1_micro&#x27;：微f1值作为评分。用于多分类问题。</span></span><br><span class="line"><span class="string">                    &#x27;f1_macro&#x27;：宏f1值作为评分。用于多分类问题。</span></span><br><span class="line"><span class="string">                    &#x27;f1_weighted&#x27;：加权f1值作为评分。</span></span><br><span class="line"><span class="string">                    &#x27;f1_samples&#x27;：多标签f1值作为评分。</span></span><br><span class="line"><span class="string">                    &#x27;log_loss&#x27;：采用的是metrics.log_loss评分函数。</span></span><br><span class="line"><span class="string">            precision系列：采用的是metrics.precision_score评分函数。具体形式类似f1系列。</span></span><br><span class="line"><span class="string">            recall系列：采用的是metrics.recall_score评分函数。具体形式类似f1系列。</span></span><br><span class="line"><span class="string">            &#x27;roc_auc&#x27;：采用的是metrics.roc_auc_score 评分函数。</span></span><br><span class="line"><span class="string">            &#x27;adjusted_rand_score&#x27;：采用的是metrics.adjusted_rand_score 评分函数。</span></span><br><span class="line"><span class="string">            &#x27;mean_absolute_error&#x27;：采用的是metrics.mean_absolute_error 评分函数。</span></span><br><span class="line"><span class="string">            &#x27;mean_squared_error’&#x27;：采用的是metrics.mean_squared_error 评分函数。</span></span><br><span class="line"><span class="string">            &#x27;median_absolute_error&#x27;：采用的是metrics.median_absolute_error 评分函数。</span></span><br><span class="line"><span class="string">            &#x27;r2&#x27;：采用的是metrics.r2_score 评分函数 。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">cv：一个整数/折交叉生成器/一个迭代器/None，指定k折交叉参数。</span></span><br><span class="line"><span class="string">    如果为None，则使用默认的3折交叉生成器。</span></span><br><span class="line"><span class="string">    如果为整数，则指定了k折交叉生成器的k值。</span></span><br><span class="line"><span class="string">    如果为k折交叉生成器，则直接指定了k折交叉生成器。</span></span><br><span class="line"><span class="string">    如果为迭代器，则迭代器的结果就是数据集划分的结果。</span></span><br><span class="line"><span class="string">fit_params：一个字典，指定了estimator执行.fit方法时的关键字参数。</span></span><br><span class="line"><span class="string">n_jobs：一个整数，指定并行性。</span></span><br><span class="line"><span class="string">verbose：一个整数，用于控制输出日志。</span></span><br><span class="line"><span class="string">pre_dispatch：一个整数/字符串/None，用于控制并行执行时，分发的总的任务数量。</span></span><br><span class="line"><span class="string">            如果为None，则所有的job 立即创建并派生。</span></span><br><span class="line"><span class="string">            如果为整数，则它指定了立即派生的job 的数量。</span></span><br><span class="line"><span class="string">            如果为字符串，则指定了n_jobs的表达式。如&#x27;2*n_jobs&#x27;表示立即派生2倍n_jobs数量的job。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">cross_val_score包含了2个步骤：</span></span><br><span class="line"><span class="string">（1）k折交叉划分数据集，对每次划分结果执行：</span></span><br><span class="line"><span class="string">    在训练集上训练estimator。</span></span><br><span class="line"><span class="string">    用训练好的estimator预测测试集，返回测试性能得分。</span></span><br><span class="line"><span class="string">（2）收集所有的测试性能得分，放入一个数组并返回。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="性能度量">性能度量</h2>
<p>在scikit-learn中有三种方法来评估estimator的预测性能：<br />
（1）estimator的.score()方法。<br />
（2）model_selection中的模型评估工具。如model_selection.cross_val_score等方法。<br />
（2）metrics模块中的函数来评估estimator的预测性能。主要为分类问题、回归问题的评估。</p>
<p>metrics模块的<strong>分类问题</strong>评估函数：</p>
<p>accuracy_score函数用于计算分类结果的准确率。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.accuracy_score(y_true, y_pred, normalize=<span class="literal">True</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：如果normalize为True，则返回准确率；如果normalize为False，则返回正确分类的数量。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">y_pred：预测的标记集合。</span></span><br><span class="line"><span class="string">normalize：一个布尔值，指示是否需要归一化结果。</span></span><br><span class="line"><span class="string">            如果为True，则返回分类正确的比例（准确率）。</span></span><br><span class="line"><span class="string">            如果为False，则返回分类正确的样本数量。</span></span><br><span class="line"><span class="string">            sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
precision_score函数用于计算分类结果的查准率。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.precision_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">查准率 = tp / (tp + fp)</span></span><br><span class="line"><span class="string">返回值：查准率。即预测结果为正类的那些样本中，有多少比例确实是正类。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">y_pred：预测的标记集合。</span></span><br><span class="line"><span class="string">labels：一个列表。当average!=&#x27;binary&#x27;时使用。</span></span><br><span class="line"><span class="string">        对于多分类问题，它表示将计算哪些类别。不在labels中的类别，计算macro precision时其成分为0。</span></span><br><span class="line"><span class="string">        对于多标签问题，它指示待考察的标签的索引。</span></span><br><span class="line"><span class="string">        除了average=None之外，labels的元素的顺序也非常重要。</span></span><br><span class="line"><span class="string">        默认情况下，y_true和y_pred中所有的类别都将被用到。</span></span><br><span class="line"><span class="string">pos_label：一个字符串/整数，指定哪个标记值属于正类。</span></span><br><span class="line"><span class="string">            如果是多分类/多标签问题，则该参数被忽略。</span></span><br><span class="line"><span class="string">            如果设置label=[pos_label]以及average!=&#x27;binary&#x27;则会仅仅计算该类别的precision 。</span></span><br><span class="line"><span class="string">average：一个字符串/None，用于指定二分类或者多类分类的precision如何计算。</span></span><br><span class="line"><span class="string">        &#x27;binary&#x27;：计算二类分类的precision。此时由pos_label指定的类为正类，报告其precision。</span></span><br><span class="line"><span class="string">                  它要求y_true、y_pred的元素都是0,1。</span></span><br><span class="line"><span class="string">        &#x27;micro&#x27;：通过全局的正类和父类，计算precision。</span></span><br><span class="line"><span class="string">        &#x27;macro&#x27;：计算每个类别的precision，然后返回它们的均值。</span></span><br><span class="line"><span class="string">        &#x27;weighted&#x27;：计算每个类别的precision，然后返回其加权均值，权重为每个类别的样本数。</span></span><br><span class="line"><span class="string">        &#x27;samples&#x27;：计算每个样本的precision，然后返回其均值。该方法仅仅对于多标签分类问题有意义。</span></span><br><span class="line"><span class="string">        None：计算每个类别的precision，然后以数组的形式返回每个precision。</span></span><br><span class="line"><span class="string">sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
recall_score函数用于计算分类结果的查全率。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, </span><br><span class="line">                average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>, zero_division=<span class="string">&#x27;warn&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">查全率 = tp / (tp + fn)</span></span><br><span class="line"><span class="string">返回值：查全率。即真实的正类中，有多少比例被预测为正类。</span></span><br><span class="line"><span class="string">zero_division：除零处理，当设置为&#x27;warn&#x27;时，值为0，但会抛出警告。</span></span><br><span class="line"><span class="string">参数，参考参考precision_score。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
f1_score函数用于计算分类结果的F1值。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.f1_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, </span><br><span class="line">                average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>, zero_division=<span class="string">&#x27;warn&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">F1 = 2 * (precision * recall) / (precision + recall)</span></span><br><span class="line"><span class="string">返回值：F1值。即查准率和查全率的调和均值。</span></span><br><span class="line"><span class="string">参数：参考recall_score。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
fbeta_score函数用于计算分类结果的<span
class="math inline">\(F_\beta\)</span>值。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.fbeta_score(y_true, y_pred, beta, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：F_\beta值。</span></span><br><span class="line"><span class="string">beta：\beta值</span></span><br><span class="line"><span class="string">其它参数：参考recall_score。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
classification_report函数以文本方式给出了分类结果的主要预测性能指标。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report(y_true, y_pred, labels=<span class="literal">None</span>, target_names=<span class="literal">None</span>,</span><br><span class="line">                sample_weight=<span class="literal">None</span>, digits=<span class="number">2</span>, output_dict=<span class="literal">False</span>, zero_division=<span class="string">&#x27;warn&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：一个格式化的字符串，给出了分类评估报告。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">y_pred：预测的标记集合。</span></span><br><span class="line"><span class="string">labels：一个列表，指定报告中出现哪些类别。</span></span><br><span class="line"><span class="string">target_names：一个列表，指定报告中类别对应的显示出来的名字。</span></span><br><span class="line"><span class="string">digits：用于格式化报告中的浮点数，保留几位小数。</span></span><br><span class="line"><span class="string">sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">output_dict：如果为True，则将输出作为dict返回。</span></span><br><span class="line"><span class="string">zero_division：除零处理，当设置为&#x27;warn&#x27;时，值为0，但会抛出警告。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分类评估报告的内容如下：</span></span><br><span class="line"><span class="string">precision列：给出了查准率。它依次将：类别0作为正类，类别1作为正类...</span></span><br><span class="line"><span class="string">recall列：给出了查全率。它依次将：类别0作为正类，类别1作为正类...</span></span><br><span class="line"><span class="string">f1-score列：给出了F1值。</span></span><br><span class="line"><span class="string">support列：给出了该类有多少个样本。</span></span><br><span class="line"><span class="string">avg/total行：</span></span><br><span class="line"><span class="string">（1）对于precision,recall,f1-score，给出了该列数据的算术平均。</span></span><br><span class="line"><span class="string">（2）对于support列，给出了该列的算术和（其实就等于样本集总样本数量）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
confusion_matrix函数给出了分类结果的混淆矩阵。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.confusion_matrix(y_true, y_pred, labels=<span class="literal">None</span>, sample_weight=<span class="literal">None</span>, normalize=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：一个格式化的字符串，给出了分类结果的混淆矩阵。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sample_weight：一个shape为(n_samples,)的array-like，每个样本权重，默认为1。</span></span><br><span class="line"><span class="string">normalize：&#123;‘true’, ‘pred’, ‘all’&#125;, 默认None，标准化混淆矩阵。如果None，混淆矩阵将不会被归一化。</span></span><br><span class="line"><span class="string">其他参数：参考classification_report。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">混淆矩阵的内容如下：</span></span><br><span class="line"><span class="string">[[5 0]</span></span><br><span class="line"><span class="string">[3 2]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">C_&#123;i,j&#125;表示真实标记为i但是预测为j的样本的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
precision_recall_curve函数用于计算分类结果的P-R曲线。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.precision_recall_curve(y_true, probas_pred, pos_label=<span class="literal">None</span>,sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：一个元组，元组内的元素分别为：</span></span><br><span class="line"><span class="string">（1）P-R曲线的查准率序列。递增序列，序列第i个元素是当正类概率的判定阈值为thresholds[i]时的查准率。</span></span><br><span class="line"><span class="string">（2）P-R曲线的查全率序列。递减序列，序列第i个元素是当正类概率的判定阈值为thresholds[i]时的查全率。</span></span><br><span class="line"><span class="string">（3）P-R曲线的阈值序列thresholds。递增序列，给出了判定为正例时的正类概率的阈值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">probas_pred：每个样本预测为正类的概率的集合。</span></span><br><span class="line"><span class="string">pos_label：正类的类别标记。</span></span><br><span class="line"><span class="string">sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
roc_curve函数用于计算分类结果的ROC曲线。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.roc_curve(y_true, y_score, pos_label=<span class="literal">None</span>, sample_weight=<span class="literal">None</span>,drop_intermediate=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：一个元组，元组内的元素分别为：</span></span><br><span class="line"><span class="string">（1）ROC曲线的FPR序列。递增序列，序列第i个元素是当正类概率的判定阈值为thresholds[i]时的假正例率。</span></span><br><span class="line"><span class="string">（2）ROC曲线的TPR序列。递增序列，序列第i个元素是当正类概率的判定阈值为thresholds[i]时的真正例率。</span></span><br><span class="line"><span class="string">（3）ROC曲线的阈值序列thresholds。递减序列，给出了判定为正例时的正类概率的阈值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">y_score：每个样本预测为正类的概率的集合。</span></span><br><span class="line"><span class="string">pos_label：正类的类别标记。</span></span><br><span class="line"><span class="string">sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">drop_intermediate：一个布尔值。如果为True，则抛弃某些不可能出现在ROC曲线上的阈值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
roc_auc_score函数用于计算分类结果的ROC曲线的面积AUC。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：AUC值。</span></span><br><span class="line"><span class="string">参数：参考roc_curve。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>metrics模块的<strong>回归问题</strong>评估函数：</p>
<p>mean_absolute_error函数用于计算回归预测误差绝对值的均值（MAE）。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_absolute_error(y_true, y_pred, sample_weight=<span class="literal">None</span>, multioutput=<span class="string">&#x27;uniform_average&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：预测误差绝对值的均值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y_true：真实的标记集合。</span></span><br><span class="line"><span class="string">y_pred：预测的标记集合。</span></span><br><span class="line"><span class="string">multioutput：指定对于多输出变量的回归问题的误差类型。可以为：</span></span><br><span class="line"><span class="string">            &#x27;raw_values&#x27;：对每个输出变量，计算其误差 。</span></span><br><span class="line"><span class="string">            &#x27;uniform_average&#x27;：计算其所有输出变量的误差的平均值。</span></span><br><span class="line"><span class="string">sample_weight：样本权重，默认每个样本的权重为1。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
mean_squared_error函数用于计算回归预测误差平方的均值（MSE）。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=<span class="literal">None</span>, multioutput=<span class="string">&#x27;uniform_average&#x27;</span>, squared=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：预测误差的平方的平均值。</span></span><br><span class="line"><span class="string">squared：如果True返回 MSE值，如果False返回RMSE值。</span></span><br><span class="line"><span class="string">其他参数：参考mean_absolute_error。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="验证学习曲线">验证/学习曲线</h2>
<p>验证曲线给出了estimator因为某个<strong>超参数的不同取值</strong>在同一个测试集上预测性能曲线。它的作用是执行<strong>超参数调优</strong>。</p>
<p>validation_curve用于生成验证曲线。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.validation_curve(estimator, X, y, param_name, param_range, groups=<span class="literal">None</span>,</span><br><span class="line">                        cv=<span class="literal">None</span>, scoring=<span class="literal">None</span>, n_jobs=<span class="number">1</span>, pre_dispatch=<span class="string">&#x27;all&#x27;</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                        error_score=nan, fit_params=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：返回一个元组，其元素依次为：</span></span><br><span class="line"><span class="string">train_scores：学习器在训练集上的预测得分的序列（针对不同的参数值），是个二维数组。</span></span><br><span class="line"><span class="string">test_scores：学习器在测试集上的预测得分的序列（针对不同的参数值），是个二维数组。</span></span><br><span class="line"><span class="string">因为对于每个固定的参数值， k折交叉会产生多个测试集，得到多个测试得分。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">estimator：一个学习器对象。它必须有.fit方法用于学习和.predict方法用于预测。</span></span><br><span class="line"><span class="string">param_name：一个字符串，指定了学习器需要变化的参数。</span></span><br><span class="line"><span class="string">param_range：一个序列，指定了param_name指定的参数的取值范围。</span></span><br><span class="line"><span class="string">groups：一个shape为(n_samples,)的array-like，默认为None。</span></span><br><span class="line"><span class="string">        将数据集拆分为训练/测试集时使用的样本的分组标签。仅与group实例结合使用，比如sklearn.model_selection。GroupKFold。</span></span><br><span class="line"><span class="string">error_score：&#x27;raise&#x27;/数字，默认np.nan。</span></span><br><span class="line"><span class="string">            如果estimator拟合发生错误，则分配给分数的值。</span></span><br><span class="line"><span class="string">            如果设置为&#x27;raise&#x27;则会抛出错误。如果给出了数值，则会抛出FitFailedWarning。</span></span><br><span class="line"><span class="string">fit_params：一个字典，默认为None。传递给估计器的.fit方法的参数。</span></span><br><span class="line"><span class="string">其它参数参考cross_val_score。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
学习曲线给出了estimator因为<strong>数据集大小的不同</strong>而导致的学习器在训练集和测试集上预测性能曲线。<br />
其作用是评估<strong>样本集大小的变化</strong>对学习器的性能的影响。</p>
<p>learning_curve函数用于生成学习曲线。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.learning_curve(estimator, X, y, groups=<span class="literal">None</span>,train_sizes=array([<span class="number">0.1</span>, <span class="number">0.33</span>, <span class="number">0.55</span>, <span class="number">0.78</span>, <span class="number">1.0</span>]), </span><br><span class="line">                        cv=<span class="literal">None</span>, scoring=<span class="literal">None</span>, exploit_incremental_learning=<span class="literal">False</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">                        pre_dispatch=<span class="string">&#x27;all&#x27;</span>, verbose=<span class="number">0</span>, shuffle=<span class="literal">False</span>, random_state=<span class="literal">None</span>, </span><br><span class="line">                        error_score=nan, return_times=<span class="literal">False</span>, fit_params=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">返回值：返回一个元组，其元素依次为：</span></span><br><span class="line"><span class="string">train_sizes_abs：考察数据集大小组成的序列。</span></span><br><span class="line"><span class="string">train_scores：学习器在训练集上的预测得分的序列（针对不同的考察数据集），是个二维数组。</span></span><br><span class="line"><span class="string">test_scores：学习器在测试集上的预测得分的序列（针对不同的考察数据集），是个二维数组。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">train_sizes：一个数组，给出了训练集的大小。</span></span><br><span class="line"><span class="string">            如果元素为整数，则表示每个训练集的绝对大小。</span></span><br><span class="line"><span class="string">            如果元素为浮点数，则表示每个训练集的相对大小。</span></span><br><span class="line"><span class="string">exploit_incremental_learning：一个布尔值。如果estimator支持增量学习，那么设置它为True，</span></span><br><span class="line"><span class="string">                             此时该函数会使用增量学习来加速学习曲线的生成过程。</span></span><br><span class="line"><span class="string">groups：一个shape为(n_samples,)的array-like，默认为None。</span></span><br><span class="line"><span class="string">        将数据集拆分为训练/测试集时使用的样本的分组标签。仅与group实例结合使用，比如sklearn.model_selection。GroupKFold。</span></span><br><span class="line"><span class="string">shuffle：一个布尔值，是否在取前缀前混洗数据，它以train_sizes参数为基础混洗。</span></span><br><span class="line"><span class="string">random_state：一个整数/RandomState实例/None（默认）。</span></span><br><span class="line"><span class="string">             当shuffle为True时使用。为跨多个函数调用的可重现输出传递一个int。</span></span><br><span class="line"><span class="string">error_score：&#x27;raise&#x27;/数字，默认np.nan。</span></span><br><span class="line"><span class="string">            如果estimator拟合发生错误，则分配给分数的值。</span></span><br><span class="line"><span class="string">            如果设置为&#x27;raise&#x27;则会抛出错误。如果给出了数值，则会抛出FitFailedWarning。</span></span><br><span class="line"><span class="string">return_times：一个布尔值，是否返回拟合和得分时间。</span></span><br><span class="line"><span class="string">fit_params：一个字典，默认为None。传递给估计器的.fit方法的参数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其它参数参考validation_curve。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="超参数优化">超参数优化</h2>
<p>GridSearchCV采用的是暴力寻找的方法来寻找最优参数。当待优化的参数是离散的取值的时候，GridSearchCV能够顺利找出最优的参数。但是当待优化的参数是连续值的时候，暴力寻找就有心无力，它的做法是从这些连续值中挑选几个值作为代表，从而在这些代表中挑选出最佳的参数。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">klearn.model_selection.GridSearchCV(estimator, param_grid, scoring=<span class="literal">None</span>,</span><br><span class="line">                        n_jobs=<span class="literal">None</span>, refit=<span class="literal">True</span>, cv=<span class="literal">None</span>, verbose=<span class="number">0</span>,pre_dispatch=<span class="string">&#x27;2*n_jobs&#x27;</span>, </span><br><span class="line">                        error_score=nan, return_train_score=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">estimator：一个学习器对象。它必须有.fit方法用于学习和.predict方法用于预测，还需有.score方法用于性能评分。</span></span><br><span class="line"><span class="string">param_grid：字典/字典的列表。每个字典都给出了学习器的一个超参数，其中：</span></span><br><span class="line"><span class="string">            字典的键就是超参数名。</span></span><br><span class="line"><span class="string">            字典的值是一个列表，指定了超参数对应的候选值序列。</span></span><br><span class="line"><span class="string">refit：一个布尔值。如果为True，则在参数优化之后使用整个数据集来重新训练该最优的estimator。</span></span><br><span class="line"><span class="string">error_score：一个数值/&#x27;raise&#x27;，指定当estimator训练发生异常时，如何处理：</span></span><br><span class="line"><span class="string">            如果为&#x27;raise&#x27;，则抛出异常。</span></span><br><span class="line"><span class="string">            如果为数值，则将该数值作为本轮estimator的预测得分。</span></span><br><span class="line"><span class="string">return_train_score： 一个布尔值，指示是否返回训练集的预测得分。</span></span><br><span class="line"><span class="string">                    如果为False，则cv_results_属性将不包括训练分数。</span></span><br><span class="line"><span class="string">                    计算训练分数用于深入了解不同的参数设置如何影响过度拟合/欠拟合及其权衡。</span></span><br><span class="line"><span class="string">                    在训练集上计算分数可能会在计算上很昂贵，并且并不严格要求选择产生最佳泛化性能的参数。</span></span><br><span class="line"><span class="string">其它参数参考cross_val_score。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">GridSearchCV实现了estimator的.fit和.score方法。这些方法内部会调用estimator的对应的方法。</span></span><br><span class="line"><span class="string">在调用.fit方法时，首先会将训练集进行k折交叉，然后在每次划分的集合上进行多轮的训练和验证（每一轮都采用一种参数组合），</span></span><br><span class="line"><span class="string">然后调用最佳学习器的.fit方法。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 属性</span></span><br><span class="line">cv_results_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个数组的字典。可以直接用于生成pandas DataFrame。其中键为超参数名，值为超参数的数组。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mean_fit_time：训练时间。</span></span><br><span class="line"><span class="string">mean_score_time：评估时间的均值，单位为秒。</span></span><br><span class="line"><span class="string">std_score_time：评估时间的方差，单位为秒。</span></span><br><span class="line"><span class="string">std_fit_time：训练时间，单位为秒。</span></span><br><span class="line"><span class="string">xx_score：给出了各种评估得分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">best_estimator_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">一个学习器对象，代表了根据候选参数组合筛选出来的最佳的学习器。</span></span><br><span class="line"><span class="string">如果refit=False，则该属性不可用。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">best_score_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">最佳学习器的性能评分。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">best_params_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">最佳参数组合。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">best_index_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">cv_results_中，第几组参数对应着最佳参数组合。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">scorer_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">评分函数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">n_splits_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">交叉验证的k值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">fit(X[, y,groups])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">执行参数优化。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用学到的最佳学习器来预测数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用学到的最佳学习器来预测数据为各类别的概率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">predict_log_proba(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用学到的最佳学习器来预测数据为各类别的概率的对数值。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">score(X[, y])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">通过给定的数据集来判断学到的最佳学习器的预测性能。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transform(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对最佳学习器执行逆transform。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">decision_function(X)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">对最佳学习器调用决策函数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br />
RandomizedSearchCV采用随机搜索所有的候选参数对的方法来寻找最优的参数组合。<br />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions,</span><br><span class="line">n_iter=<span class="number">10</span>, scoring=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, refit=<span class="literal">True</span>,</span><br><span class="line">cv=<span class="literal">None</span>, verbose=<span class="number">0</span>, pre_dispatch=<span class="string">&#x27;2*n_jobs&#x27;</span>, random_state=<span class="literal">None</span>, </span><br><span class="line">error_score=nan,return_train_score=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">param_distributions：字典/字典的列表。每个字典都给出了学习器的一个参数，其中：</span></span><br><span class="line"><span class="string">                    字典的键就是参数名。</span></span><br><span class="line"><span class="string">                    字典的值是一个分布类，分布类必须提供.rvs方法。</span></span><br><span class="line"><span class="string">                    可以使用scipy.stats模块中提供的分布类，比如scipy.expon(指数分布)、</span></span><br><span class="line"><span class="string">                        scipy.gamma(gamma分布)、scipy.uniform(均匀分布)、randint等等。</span></span><br><span class="line"><span class="string">                    字典的值也可以是一个数值序列，此时就在该序列中均匀采样。</span></span><br><span class="line"><span class="string">n_iter：一个整数，指定每个参数采样的数量。通常该值越大，参数优化的效果越好。但是参数越大，运行时间也更长。</span></span><br><span class="line"><span class="string">其它参数、属性、方法，参考GridSearchCV。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>SoundMemories
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/" title="ML-scikit-learn">https://soundmemories.github.io/2020/05/18/Machine Learning/08.ML-scikit-learn/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/05/10/Machine%20Learning/07.ML-Spark/" rel="prev" title="ML-Spark">
                  <i class="fa fa-chevron-left"></i> ML-Spark
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/05/28/Machine%20Learning/09.ML-XGBoost/" rel="next" title="ML-XGBoost">
                  ML-XGBoost <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">SoundMemories</span>
  </div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"neutral"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js","integrity":"sha256-JFptYy4KzJ5OQP+Q9fubNf3cxpPPmZKqUOovyEONKrQ="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://soundmemories.github.io/2020/05/18/Machine%20Learning/08.ML-scikit-learn/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
