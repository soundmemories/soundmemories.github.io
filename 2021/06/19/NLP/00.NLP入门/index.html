<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"soundmemories.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.0.2","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="什么是NLP？NLP（Natural Language Processing，自然语言处理），是融合了计算机科学、人工智能、语言学的交叉学科。其主要目的是让计算机学会处理人类的语言，甚至实现终极目标——————理解人类语言。 NLP可以概括为NLP&#x3D;NLU+NLG：NLU（Natural Language Understand，自然语言理解）：语音或文本 ——&gt; 结构化的语义。NLG（Nat">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP入门">
<meta property="og:url" content="https://soundmemories.github.io/2021/06/19/NLP/00.NLP%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="SoundMemories">
<meta property="og:description" content="什么是NLP？NLP（Natural Language Processing，自然语言处理），是融合了计算机科学、人工智能、语言学的交叉学科。其主要目的是让计算机学会处理人类的语言，甚至实现终极目标——————理解人类语言。 NLP可以概括为NLP&#x3D;NLU+NLG：NLU（Natural Language Understand，自然语言理解）：语音或文本 ——&gt; 结构化的语义。NLG（Nat">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soundmemories.github.io/images/NLP入门/NLP基础任务.png">
<meta property="og:image" content="https://soundmemories.github.io/images/NLP入门/字典树.png">
<meta property="article:published_time" content="2021-06-18T16:00:00.000Z">
<meta property="article:modified_time" content="2021-06-22T07:20:11.151Z">
<meta property="article:author" content="SoundMemories">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soundmemories.github.io/images/NLP入门/NLP基础任务.png">


<link rel="canonical" href="https://soundmemories.github.io/2021/06/19/NLP/00.NLP%E5%85%A5%E9%97%A8/">


<script data-pjax class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>NLP入门 | SoundMemories</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SoundMemories</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-归档">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
	   
		  
      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFNLP%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">什么是NLP？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NLP%E9%9D%A2%E4%B8%B4%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">NLP面临的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NLP%E5%9F%BA%E7%A1%80%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.</span> <span class="nav-text">NLP基础任务</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D"><span class="nav-number">4.</span> <span class="nav-text">中文分词</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%88%87%E5%88%86"><span class="nav-number">4.1.</span> <span class="nav-text">完全切分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E9%95%BF%E5%8C%B9%E9%85%8D"><span class="nav-number">4.2.</span> <span class="nav-text">最长匹配</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%97%E5%85%B8%E6%A0%91"><span class="nav-number">4.3.</span> <span class="nav-text">字典树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HanLP%E7%9A%84%E8%AF%8D%E5%85%B8%E5%88%86%E8%AF%8D"><span class="nav-number">4.4.</span> <span class="nav-text">HanLP的词典分词</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8"><span class="nav-number">5.</span> <span class="nav-text">词性标注</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB"><span class="nav-number">6.</span> <span class="nav-text">命名实体识别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="nav-number">7.</span> <span class="nav-text">句法分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90"><span class="nav-number">8.</span> <span class="nav-text">语义分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">9.</span> <span class="nav-text">常见的应用</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SoundMemories"
      src="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
  <p class="site-author-name" itemprop="name">SoundMemories</p>
  <div class="site-description" itemprop="description">今日事，今日毕</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">109</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXM=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;soundmemories"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNvdW5kbWVtb3JpZXNAMTYzLmNvbQ==" title="E-Mail → mailto:soundmemories@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://soundmemories.github.io/2021/06/19/NLP/00.NLP%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2020/11/04/6JhNuwtBe4adylS.png">
      <meta itemprop="name" content="SoundMemories">
      <meta itemprop="description" content="今日事，今日毕">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SoundMemories">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NLP入门
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-19 00:00:00" itemprop="dateCreated datePublished" datetime="2021-06-19T00:00:00+08:00">2021-06-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>10k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="什么是NLP？"><a href="#什么是NLP？" class="headerlink" title="什么是NLP？"></a>什么是NLP？</h1><p><strong>NLP（Natural Language Processing，自然语言处理）</strong>，是融合了计算机科学、人工智能、语言学的交叉学科。其主要目的是让计算机学会处理人类的语言，甚至实现终极目标——————理解人类语言。</p>
<p>NLP可以概括为<strong>NLP=NLU+NLG</strong>：<br><strong>NLU（Natural Language Understand，自然语言理解）</strong>：语音或文本 ——&gt; 结构化的语义。<br><strong>NLG（Natural Language Generation，自然语言生成）</strong>：把结构化的语义 ——&gt; 文本或语音。<br><a id="more"></a></p>
<h1 id="NLP面临的问题"><a href="#NLP面临的问题" class="headerlink" title="NLP面临的问题"></a>NLP面临的问题</h1><ol>
<li><strong>结构化</strong>：自然语言是非结构化的（抽象的），计算机编程语言是结构化的（具体的），那么如何相互转化是一个重要的问题。从非结构化到结构化，这涉及到分词、命名实体识别、关系抽取等自然语言处理任务。</li>
<li><strong>歧义性</strong>：自然语言含有大量歧义词，根据语境不同表达的意思千差万别，需要根据上下文才能确定具体的含义。有时故意利用这种歧义性营造幽默效果。</li>
<li><strong>容错性</strong>：自然语言是由人类活动产生的，所以语句中不可避免会出现错别字、语病、不规范的符号等各种问题，但即使这样人类还是可以猜出语句的意思。但在编程中这种不规范的问题会引发无情的BUG，如何处理不规范的文本也是重要问题。</li>
<li><strong>易变性</strong>：自然语言不是一成不变的，随着人类的发展新词新句会很快出现并赋予意义，这种变化是每时每刻都在进行的，这给自然语言处理带来了更大的挑战。</li>
<li><strong>简略性</strong>：有时句子中会出现“老地方”、“同样时间”等简略性词汇，有时是专业词汇，这些词汇的出现是因为默认了双方都知道这些词指代什么，省略了双方都认为是“常识”的知识，但计算机并不知道这些“常识”，这也给自然语言处理带来了挑战。<!-- more -->
<h1 id="NLP基础任务"><a href="#NLP基础任务" class="headerlink" title="NLP基础任务"></a>NLP基础任务</h1><img src="/images/NLP入门/NLP基础任务.png" width="60%"></li>
</ol>
<p>蓝色划线部分就NLP基础任务，其中中文分词、词性标注、命名实体识别围绕词进行，所以统称词法分析。<br>（1）<strong>中文分词（chinese word segmentation）</strong>：将文本分割为有意义的词语。<br>（2）<strong>词性标注（POS，Part-Of-Speech tagging）</strong>：确定每个词语的<strong>类别</strong>和浅层的歧义消除。<br>（3）<strong>命名实体识别（NER，Named Entity Recognition）</strong>：识别出一些较长的<strong>专有名词</strong>。<br>（4）<strong>句法分析（Syntactic Analysis）</strong>：侧重句子的语法，分析句子的主谓宾关系，从而判断句子的意图。经常用在问答系统或搜索引擎。<br>（5）<strong>语义分析（Semantic Analysis）</strong>：侧重于语义而非语法。它包括<strong>词义消歧</strong>（确定一个词在语境中的含义而不是简单的词性）、<strong>语义角色标注</strong>（标注句子中的谓语与其他成分的关系）、<strong>语义存在分析</strong>（分析句子中词语之间的语义关系）。</p>
<h1 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h1><p>首先需要一个词典，互联网有很多公开词典，比如搜狗实验室发布的<span class="exturl" data-url="aHR0cDovL3d3dy5zb2dvdS5jb20vbGFicy9yZXNvdXJjZS93LnBocA==">互联网词典<i class="fa fa-external-link-alt"></i></span>（SogouW，15万个词条），<span class="exturl" data-url="aHR0cDovL3RodW9jbC50aHVubHAub3JnLw==">清华大学开放中文词库<i class="fa fa-external-link-alt"></i></span>（THUOCL），以及HanLP作者发布的<span class="exturl" data-url="aHR0cHM6Ly93d3cuaGFua2NzLmNvbS9ubHAvY29ycHVzL3RlbnMtb2YtbWlsbGlvbnMtb2YtZ2lhbnQtY2hpbmVzZS13b3JkLWxpYnJhcnktc2hhcmUuaHRtbA==">HanLP词库<i class="fa fa-external-link-alt"></i></span>（千万级）。</p>
<p>分词工具有很多，常见的有：<span class="exturl" data-url="aHR0cDovL2dpdGh1Yi5jb20vZnhzankvamllYmE=">Jieba<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cDovL2dpdGh1Yi5jb20vaXNub3dmeS9zbm93bmxw">SnowNLP<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy5sdHAtY2xvdWQuY29tLw==">LTP<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hhbmtjcy9weWhhbmxw">HanLP<i class="fa fa-external-link-alt"></i></span>。下面内容都是基于HanLP项目例子，使用前请先<code>pip install pyhanlp</code>。</p>
<p>加载字典：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dictionary</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载HanLP中的mini词库</span></span><br><span class="line"><span class="string">    :return: 一个set形式的词库</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># JClass是连接Java和Python的桥梁，根据Java路径名得到一个Python类IOUtil</span></span><br><span class="line">    IOUtil = JClass(<span class="string">&#x27;com.hankcs.hanlp.corpus.io.IOUtil&#x27;</span>)</span><br><span class="line">    <span class="comment"># 获取HanLP的配置项Config中的词典路径CoreDictionaryPath</span></span><br><span class="line">    <span class="comment"># 默认路径的词典太大，演示只需加载mini词典，所以把路径替换成mini词典路径</span></span><br><span class="line">    path = HanLP.Config.CoreDictionaryPath.replace(<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;.mini.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># 调用IOUtil静态方法loadDictionary，它支持多个文件读入同一个词典中，因此需传入一个list</span></span><br><span class="line">    <span class="comment"># 返回一个Java Map对象，因为不关系value，只需取key即可</span></span><br><span class="line">    dic = IOUtil.loadDictionary([path])</span><br><span class="line">    <span class="comment"># 转换成Python的set，去重</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>(dic.keySet())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dic = load_dictionary()</span><br><span class="line">    print(<span class="built_in">len</span>(dic))</span><br><span class="line">    print(<span class="built_in">list</span>(dic)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">85584</span></span><br><span class="line"><span class="string">光照</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>接下来边演示边讲解下常见的分词算法。</p>
<h2 id="完全切分"><a href="#完全切分" class="headerlink" title="完全切分"></a>完全切分</h2><p>指的是找出一段文本中的所有词。有人将这个当成分词，这并不是分词，只是找出文本中连续字符串是否在词典中出现，出现的就是一个词。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fully_segment</span>(<span class="params">text, dic</span>):</span></span><br><span class="line">    word_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(text)):                  <span class="comment"># i 从 0 到text的最后一个字的下标遍历</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(text) + <span class="number">1</span>):   <span class="comment"># j 遍历[i + 1, len(text)]区间</span></span><br><span class="line">            word = text[i:j]                    <span class="comment"># 取出连续区间[i, j]对应的字符串</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> dic:                     <span class="comment"># 如果在词典中，则认为是一个词</span></span><br><span class="line">                word_list.append(word)</span><br><span class="line">    <span class="keyword">return</span> word_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dic = load_dictionary()</span><br><span class="line"></span><br><span class="line">    print(fully_segment(<span class="string">&#x27;就读北京大学&#x27;</span>, dic))</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    [&#x27;就&#x27;, &#x27;就读&#x27;, &#x27;读&#x27;, &#x27;北&#x27;, &#x27;北京&#x27;, &#x27;北京大学&#x27;, &#x27;京&#x27;, &#x27;大&#x27;, &#x27;大学&#x27;, &#x27;学&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>输出了所有可能的单词。由于词库中含有单字，所以结果中也出现了一些单字。</p>
<h2 id="最长匹配"><a href="#最长匹配" class="headerlink" title="最长匹配"></a>最长匹配</h2><p>上面的输出并不是中文分词，我们更需要那种有意义的词语序列，而不是所有出现在词典中的单词所构成的链表。比如，我们希望“北京大学”成为一整个词，而不是“北京 + 大学”之类的碎片。具体来说，就是在以某个下标为起点递增查词的过程中，优先输出更长的单词，这种规则被称为<strong>最长匹配算法</strong>。从前往后匹配则称为<strong>正向最长匹配</strong>，反之则称为<strong>逆向最长匹配</strong>，都使用就是<strong>双向最长匹配</strong>。</p>
<p><strong>正向最长匹配</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_segment</span>(<span class="params">text, dic</span>):</span></span><br><span class="line">    word_list = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(text):</span><br><span class="line">        longest_word = text[i]                      <span class="comment"># 当前扫描位置的单字</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(text) + <span class="number">1</span>):       <span class="comment"># 所有可能的结尾</span></span><br><span class="line">            word = text[i:j]                        <span class="comment"># 从当前位置到结尾的连续字符串</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> dic:                         <span class="comment"># 在词典中</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt; <span class="built_in">len</span>(longest_word):   <span class="comment"># 并且更长</span></span><br><span class="line">                    longest_word = word             <span class="comment"># 则更优先输出</span></span><br><span class="line">        word_list.append(longest_word)              <span class="comment"># 输出最长词</span></span><br><span class="line">        i += <span class="built_in">len</span>(longest_word)                      <span class="comment"># 正向扫描</span></span><br><span class="line">    <span class="keyword">return</span> word_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dic = load_dictionary()</span><br><span class="line"></span><br><span class="line">    print(forward_segment(<span class="string">&#x27;就读北京大学&#x27;</span>, dic))</span><br><span class="line">    print(forward_segment(<span class="string">&#x27;研究生命起源&#x27;</span>, dic))</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    [&#x27;就读&#x27;, &#x27;北京大学&#x27;]</span></span><br><span class="line"><span class="string">    [&#x27;研究生&#x27;, &#x27;命&#x27;, &#x27;起源&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>第二句话就产生误差了，我们是需要把“研究”提取出来，结果按照正向最长匹配算法就提取出了“研究生”，所以人们就想出了逆向最长匹配。</p>
<p><strong>逆向最长匹配</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_segment</span>(<span class="params">text, dic</span>):</span></span><br><span class="line">    word_list = []</span><br><span class="line">    i = <span class="built_in">len</span>(text) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> i &gt;= <span class="number">0</span>:                                   <span class="comment"># 扫描位置作为终点</span></span><br><span class="line">        longest_word = text[i]                      <span class="comment"># 扫描位置的单字</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):                       <span class="comment"># 遍历[0, i]区间作为待查询词语的起点</span></span><br><span class="line">            word = text[j: i + <span class="number">1</span>]                   <span class="comment"># 取出[j, i]区间作为待查询单词</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> dic:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt; <span class="built_in">len</span>(longest_word):   <span class="comment"># 越长优先级越高</span></span><br><span class="line">                    longest_word = word</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        word_list.insert(<span class="number">0</span>, longest_word)           <span class="comment"># 逆向扫描，所以越先查出的单词在位置上越靠后</span></span><br><span class="line">        i -= <span class="built_in">len</span>(longest_word)</span><br><span class="line">    <span class="keyword">return</span> word_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dic = load_dictionary()</span><br><span class="line"></span><br><span class="line">    print(backward_segment(<span class="string">&#x27;研究生命起源&#x27;</span>, dic))</span><br><span class="line">    print(backward_segment(<span class="string">&#x27;项目的研究&#x27;</span>, dic))</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    [&#x27;研究&#x27;, &#x27;生命&#x27;, &#x27;起源&#x27;]</span></span><br><span class="line"><span class="string">    [&#x27;项&#x27;, &#x27;目的&#x27;, &#x27;研究&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>第一句正确了，但下一句又出错了，可谓拆东墙补西墙。另一些人提出综合两种规则，期待它们取长补短，称为双向最长匹配。</p>
<p><strong>双向最长匹配</strong>：<br>这是一种融合两种匹配方法的复杂规则集，流程如下：<br>（1）同时执行正向和逆向最长匹配，若两者的词数不同，则返回词数更少的那一个。<br>（2）否则，返回两者中单字更少的那一个。当单字数也相同时，优先返回逆向最长匹配的结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_single_char</span>(<span class="params">word_list: <span class="built_in">list</span></span>):</span>  <span class="comment"># 统计单字成词的个数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> word <span class="keyword">in</span> word_list <span class="keyword">if</span> <span class="built_in">len</span>(word) == <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bidirectional_segment</span>(<span class="params">text, dic</span>):</span></span><br><span class="line">    f = forward_segment(text, dic)</span><br><span class="line">    b = backward_segment(text, dic)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(f) &lt; <span class="built_in">len</span>(b):                                  <span class="comment"># 词数更少优先级更高</span></span><br><span class="line">        <span class="keyword">return</span> f</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(f) &gt; <span class="built_in">len</span>(b):</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> count_single_char(f) &lt; count_single_char(b):  <span class="comment"># 单字更少优先级更高</span></span><br><span class="line">            <span class="keyword">return</span> f</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> b                                     <span class="comment"># 都相等时逆向匹配优先级更高</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dic = load_dictionary()</span><br><span class="line"></span><br><span class="line">    print(bidirectional_segment(<span class="string">&#x27;研究生命起源&#x27;</span>, dic))</span><br><span class="line">    print(bidirectional_segment(<span class="string">&#x27;项目的研究&#x27;</span>, dic))</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    [&#x27;研究&#x27;, &#x27;生命&#x27;, &#x27;起源&#x27;]</span></span><br><span class="line"><span class="string">    [&#x27;项&#x27;, &#x27;目的&#x27;, &#x27;研究&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>有时候双向最长匹配效果反而不如前向或后向匹配，所以规则系统是比较脆弱的，一般情况是拆东墙补西墙，有时甚至帮倒忙。</p>
<h2 id="字典树"><a href="#字典树" class="headerlink" title="字典树"></a>字典树</h2><p>匹配算法的瓶颈之一在于如何判断集合（词典）中是否含有字符串。如果用有序集合（TreeMap）的话，复杂度是$O(logn)$，n是词典大小。如果用散列表（Java的HashMap，Python的dict）的话，时间复杂度虽然下降了，但内存复杂度却上去了。有没有速度又快、内存又省的数据结构呢？这就是<strong>字典树</strong>。</p>
<p>字符串集合常用宇典树（trie树、前缀树）存储，这是一种字符串上的树形数据结构。字典树中每条边都对应一个字， 从根节点往下的路径构成一个个字符串。字典树并不直接在节点上存储字符串， 而是将词语视作根节点到某节点之间的一条路径，并在终点节点（蓝色）上做个标记“该节点对应词语的结尾”。字符串就是一 条路径，要查询一个单词，只需顺着这条路径从根节点往下走。如果能走到特殊标记的节点，则说明该字符串在集合中，否则说明不存在。一个典型的字典树如下图所示所示：<br><img src="/images/NLP入门/字典树.png" width="60%"></p>
<p>其中，蓝色标记着该节点是一个词的结尾，数字是人为的编号。按照路径我们可以得到如下表所示：<br>   | 词语     | 路径      |<br>   | ———— | ———— |<br>   | 入门     | 0-1-2     |<br>   | 自然     | 0-3-4     |<br>   | 自然人   | 0-3-4-5   |<br>   | 自然语言 | 0-3-4-6-7 |<br>   | 自语     | 0-3-8     |<br>当词典大小为 n 时，虽然最坏情况下字典树的复杂度依然是$O(logn)$（假设子节点用对数复杂度的数据结构存储，所有词语都是单字），但它的实际速度比二分查找快。这是因为随着路径的深入，前缀匹配是递进的过程，算法不必比较字符串的前缀。</p>
<p>字典树的数据结构在以上的切分算法中已经很快了，但厉害的是作者通过自己的努力改进了基于字典树的算法，把分词速度推向了千万字每秒的级别，这里不一一详细介绍，详情见HanLP作者的书，主要按照以下递进关系优化：<br>（1）<strong>首字散列其余二分的字典树</strong><br>（2）<strong>双数组字典树</strong><br>（3）<strong>AC自动机(多模式匹配)</strong><br>（4）<strong>基于双数组字典树的AC自动机</strong></p>
<h2 id="HanLP的词典分词"><a href="#HanLP的词典分词" class="headerlink" title="HanLP的词典分词"></a>HanLP的词典分词</h2><p>HanLP中所有的分词器继承自Segment基类，词典分词家族是其中一个分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">                         Segment</span><br><span class="line">                    DictionaryBasedSegment</span><br><span class="line">DoubleArrayTrieSegment              AhoCorasickDoubleArrayTrieSegment</span><br></pre></td></tr></table></figure><br><strong>DoubleArrayTrieSegment</strong>分词器是对DAT最长匹配的封装，默认加载hanlp.properties中CoreDictionaryPath制定的词典。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyhanlp.static <span class="keyword">import</span> HANLP_DATA_PATH</span><br><span class="line"></span><br><span class="line">HanLP.Config.ShowTermNature = <span class="literal">False</span></span><br><span class="line">dict1 = HANLP_DATA_PATH + <span class="string">&quot;/dictionary/CoreNatureDictionary.mini.txt&quot;</span></span><br><span class="line">dict2 = HANLP_DATA_PATH + <span class="string">&quot;/dictionary/custom/上海地名.txt ns&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不显示词性</span></span><br><span class="line">HanLP.Config.ShowTermNature = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可传入自定义字典 [dir1, dir2]</span></span><br><span class="line">segment = DoubleArrayTrieSegment(dict1)</span><br><span class="line"><span class="comment"># 激活数字和英文识别</span></span><br><span class="line">segment.enablePartOfSpeechTagging(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(segment.seg(<span class="string">&quot;江西鄱阳湖干枯，中国最大淡水湖变成大草原&quot;</span>))</span><br><span class="line">print(segment.seg(<span class="string">&quot;上海市虹口区大连西路550号SISU&quot;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[江西, 鄱阳湖, 干枯, ，, 中国, 最大, 淡水湖, 变成, 大草原]</span></span><br><span class="line"><span class="string">[上海市, 虹口区, 大连, 西路, 550, 号, SISU]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">segment = DoubleArrayTrieSegment([dict1, dict2])</span><br><span class="line">print(segment.seg(<span class="string">&#x27;上海市虹口区大连西路550号SISU&#x27;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[上海市, 虹口区, 大连西路, 5, 5, 0, 号, S, I, S, U]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br><strong>AhoCorasickDoubleArrayTrieSegment</strong>分词器是对基于ACDAT的封装。用户的词语都很长时，此算法效果更好。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">HanLP.Config.ShowTermNature = <span class="literal">False</span></span><br><span class="line">segment = JClass(<span class="string">&#x27;com.hankcs.hanlp.seg.Other.AhoCorasickDoubleArrayTrieSegment&#x27;</span>)(HanLP.Config.CoreDictionaryPath)</span><br><span class="line"></span><br><span class="line">print(segment.seg(<span class="string">&quot;江西鄱阳湖干枯，中国最大淡水湖变成大草原&quot;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[江西, 鄱阳湖, 干枯, ，, 中国, 最大, 淡水湖, 变成, 大草原]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br><strong>去停用词</strong>：</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvdW5kbWVtb3JpZXMvU3R1ZHlOb3Rlcy9ibG9iL21hc3Rlci9EYXRhL3N0b3B3b3Jkcy50eHQ=">停用词词典<i class="fa fa-external-link-alt"></i></span>收录了常见的中英文无意义词汇（不含敏感词），每行一个词。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_from_file</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    从词典文件加载DoubleArrayTrie</span></span><br><span class="line"><span class="string">    :param path: 词典路径</span></span><br><span class="line"><span class="string">    :return: 双数组trie树</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">map</span> = JClass(<span class="string">&#x27;java.util.TreeMap&#x27;</span>)()  <span class="comment"># 创建TreeMap实例</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> src:</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> src:</span><br><span class="line">            word = word.strip()  <span class="comment"># 去掉Python读入的\n</span></span><br><span class="line">            <span class="built_in">map</span>[word] = word</span><br><span class="line">    <span class="keyword">return</span> JClass(<span class="string">&#x27;com.hankcs.hanlp.collection.trie.DoubleArrayTrie&#x27;</span>)(<span class="built_in">map</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_stopwords_termlist</span>(<span class="params">termlist, trie</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [term.word <span class="keyword">for</span> term <span class="keyword">in</span> termlist <span class="keyword">if</span> <span class="keyword">not</span> trie.containsKey(term.word)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HanLP.Config.ShowTermNature = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">trie = load_from_file(HanLP.Config.CoreStopWordDictionaryPath)</span><br><span class="line">segment = DoubleArrayTrieSegment()</span><br><span class="line">termlist = segment.seg(<span class="string">&quot;江西鄱阳湖干枯了，中国最大的淡水湖变成了大草原&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;分词：&#x27;</span>, termlist)</span><br><span class="line">print(<span class="string">&#x27;分词后去除停用词：&#x27;</span>, remove_stopwords_termlist(termlist, trie))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分词： [江西, 鄱阳湖, 干枯, 了, ，, 中国, 最大, 的, 淡水湖, 变成, 了, 大草原]</span></span><br><span class="line"><span class="string">分词后去除停用词： [&#x27;江西&#x27;, &#x27;鄱阳湖&#x27;, &#x27;干枯&#x27;, &#x27;中国&#x27;, &#x27;最大&#x27;, &#x27;淡水湖&#x27;, &#x27;变成&#x27;, &#x27;大草原&#x27;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h1><p><strong>词性</strong>（Par-Of-Speech, Pos）指的是单词的语法分类，也称为词类。句子中的每个单词被分类为一种词性，同一个类别的词语具有相似的语法性质，所有词性的集合称为词性标注集。不同的语料库采用了不同的词性标注集，一般都含有形容词、动词、名词等常见词性。词性标注的过程依赖当前单词以及它的上下文信息，词性标注问题也叫做<strong>序列标注</strong>（sequence labeling）问题。还是以HanLP的例子为例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我&#x2F;r 的&#x2F;u 希望&#x2F;n 是&#x2F;v 希望&#x2F;v 张晚霞&#x2F;nr 的&#x2F;u 背影&#x2F;n 被&#x2F;p 晚霞&#x2F;n 映&#x2F;v 红&#x2F;a</span><br></pre></td></tr></table></figure><br>每个单词的后边跟的就是词性标签：r是代词、u是动词、n是名词、v是动词、nr是人名、p是介词、a是形容词。</p>
<p>词性标注的目的，是提供词语的抽象表示，词的数量是无穷的，但词性的数量是有限的。通过词性标注，可以把所有词语分类为数十种。</p>
<p>词性支撑着许多高级应用，当下游应用遇到<strong>OOV</strong>（Out of Vocabulary）问题时，可以通过OOV的词性猜测用法，比如上面的句子“林晚霞”就识别为人名进行处理，而不会拆开。词性也可以直接用于抽取一些信息，比如抽取所有描述特定商品的形容词等。很多时候，可以作为其他任务的特征。</p>
<p>词性标注的难点：<br>（1）一词具有多个词性，但在具体语境下是为一词性。<br>（2）OOV问题。</p>
<p>词性标注模型：统计方法为这两个难点提供了解决方案，那就是<strong>序列标注模型</strong>。序列模型利用概率来表示序列，考虑单词之间的前后依赖关系，常见的算法有：<strong>隐马尔科夫模型</strong>、<strong>条件随机场</strong>、<strong>RNN/LSTM/BiLSTM</strong>、<strong>Transformer</strong>等。</p>
<p>词性标注既可以看作中文分词的后续任务，也可以与中文分词集成为同一个任务。其中就可以把分词语料库加上词性标签就可以了，这样同时进行多个任务的模型称为<strong>联合模型</strong>。由于综合考虑了多种监督信号，联合模型在几乎所有问题上都要优于独立模型。然而工业界就没有那么理想，同时具有分词和词性标注的语料库非常少，需要大量的人力进行标注。实际工程上通常在大型分词语料库上训练分词器，然后与小型词性标注语料库上的词性标注模型灵活组合成为一个异源的流水线式词法分析器。</p>
<h1 id="命名实体识别"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别</h1><p>文本中有一些描述实体的词汇。比如人名、地名、组织机构名、专业术语等，称为命名实体。这些词语具有以下共性:<br>（1）数量无穷。比如宇宙中的恒星命名、新生儿的命名不断出现新组合。<br>（2）构词灵活。比如中国工商银行，既可以称为工商银行，也可以简称工行。<br>（3）类别模糊。有一些地名本身就是机构名，比如“国家博物馆”</p>
<p>识别出句子中命名实体的<strong>边界</strong>与<strong>类别</strong>的任务称<strong>为命名实体识别</strong>。由于上述难点，命名实体识别也是一个统计为主、规则为辅的任务。<br>对于规则性较强的命名实体，比如网址、E-mail、IBSN、商品编号等，完全可以通过正则表达式处理，未匹配上的片段交给统计模型处理。<br>命名实体识别也可以转化为一个序列标注问题。类似于词性标注，方法论上借鉴词性标注，所以使用的算法：<strong>隐马尔科夫模型</strong>、<strong>条件随机场</strong>等。</p>
<h1 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h1><p><strong>句法分析</strong>（Syntactic Analysis）侧重句子的语法，目标是分析句子的<strong>语法结构</strong>（比如主谓宾）并将其表示为容易理解的结构（通常是树形结构）。简单来讲，就是对一个句子的词语句法做分词。</p>
<p>目前来看显示的去做句法分析，对其他任务并没有太大帮助，可能原因是我们所定义的句法的结构是人为定义出来的，而这样一个结构对其他任务是否有效我们并不知道，所以目前这个领域的研究没有那么火热，但相信句法分析依然有很多的意义，相信未来会有所突破。</p>
<h1 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h1><p><strong>语义分析</strong>（Semantic Analysis）侧重于语义而非语法，对不同层次它的任务是不同的：在词的层次上，基本任务是进行<strong>词义消歧</strong>（确定一个词在语境中的含义而不是简单的词性），在句子的层次上，是<strong>语义角色标注</strong>（标注句子中的谓语与其他成分的关系）和<strong>语义存在分析</strong>（分析句子中词语之间的语义关系）。</p>
<p>主要有两个问题：<br>（1）如何理解一个<strong>单词</strong>的意思？<br>（2）如何理解一个<strong>文本</strong>的意思？</p>
<p>随着机器学习和深度学习的发展，在语义理解方面有了突飞猛进的发展，出现了很多关于词向量的模型，预训练语言模型的技术：SkipGram、CBOW、Glove、ELMo、BERT、ALBERT，XLNet、GPT-2、GPT-3、Tiny-BERT。</p>
<h1 id="常见的应用"><a href="#常见的应用" class="headerlink" title="常见的应用"></a>常见的应用</h1><ol>
<li>写作助手：英文写作中纠正错误的应用，常见的应用有Grammar。</li>
<li>文本分类：根据类别进行文本分类，涉及到技术有<strong>情感分析</strong>（sentiment analysis）、<strong>情绪分析</strong>（emotion analysis）、<strong>主题分类</strong>（topic classification）。</li>
<li>信息检索：输入一句简单的语句，来查找相应的信息。比如常用的百度搜索、Google搜索。</li>
<li>问答系统：与检索系统类似，最大的区别是检索系统返回粗粒度的结果，而问答系统直接返回具体答案。问答系统需要更多语义方面的理解。</li>
<li>自动生成文本摘要：不光需要理解，而且能把理解的含义转化成文本。主要方式为<strong>抽取式方法</strong>（Extractive Method）、<strong>抽象式方法</strong>（Abstractive Method）。抽取式会抽取文本中关键句子拼成摘要；抽象式也叫生成式，会重新写出来一些新句子。</li>
<li>机器翻译：各种语言相互翻译。</li>
<li>信息抽取：从复杂文本抽取信息，组成结构化的输出。是很多下游任务的基石。</li>
</ol>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2021\07\21\NLP\04.信息检索常见指标\" rel="bookmark">信息检索常见指标</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2021\07\16\NLP\03.基于LSTM的机器翻译\" rel="bookmark">基于LSTM的机器翻译</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2021\07\18\Paper\03.Get To The Point. Summarization with Pointer-Generator Networks\" rel="bookmark">Get To The Point. Summarization with Pointer-Generator Networks</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2021\07\15\NLP\02.基于LSTM的情感分类\" rel="bookmark">基于LSTM的情感分类</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2020\06\17\Machine Learning\12.ML-特征工程\" rel="bookmark">ML-特征工程</a></div>
    </li>
  </ul>


    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>SoundMemories
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://soundmemories.github.io/2021/06/19/NLP/00.NLP%E5%85%A5%E9%97%A8/" title="NLP入门">https://soundmemories.github.io/2021/06/19/NLP/00.NLP入门/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/02/12/Graph/03.GraphSAGE/" rel="prev" title="GraphSAGE">
                  <i class="fa fa-chevron-left"></i> GraphSAGE
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/06/19/Paper/00.Paper%E9%98%85%E8%AF%BB%E6%8A%80%E5%B7%A7/" rel="next" title="Paper阅读技巧">
                  Paper阅读技巧 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SoundMemories</span>
</div>
  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '.page-configurations',
    '.main-inner',
    '.post-toc-wrap',
    '.languages',
    '.pjax'
  ],
  analytics: false,
  cacheBust: false,
  scrollRestoration: false,
  scrollTo: !CONFIG.bookmark.enable
});

document.addEventListener('pjax:success', () => {
  pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  const hasTOC = document.querySelector('.post-toc');
  document.querySelector('.sidebar-inner').classList.toggle('sidebar-nav-active', hasTOC);
  document.querySelector(hasTOC ? '.sidebar-nav-toc' : '.sidebar-nav-overview').click();
  NexT.utils.updateSidebarPosition();
});
</script>


  




  <script src="/js/local-search.js"></script>








<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  const url = element.dataset.target;
  const pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  const pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  const fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>


<script data-pjax>
if (document.querySelectorAll('.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8.8.2/dist/mermaid.min.js', () => {
    mermaid.init({
      theme    : 'neutral',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    }, '.mermaid');
  }, window.mermaid);
}
</script>





  








    <div class="pjax">
  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@2.0.0/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink.listen({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://soundmemories.github.io/2021/06/19/NLP/00.NLP%E5%85%A5%E9%97%A8/',]
      });
      });
  </script>

    </div>
</body>
</html>
